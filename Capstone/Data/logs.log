2022-11-07 19:59:00,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-07 19:59:00,144:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-07 19:59:00,144:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-07 19:59:00,144:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-07 19:59:01,423:INFO:Soft dependency imported: prophet: 1.1.1
2022-11-07 19:59:05,150:INFO:PyCaret RegressionExperiment
2022-11-07 19:59:05,150:INFO:Logging name: FullData
2022-11-07 19:59:05,151:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-07 19:59:05,151:INFO:version 3.0.0.rc4
2022-11-07 19:59:05,151:INFO:Initializing setup()
2022-11-07 19:59:05,151:INFO:self.USI: 41f2
2022-11-07 19:59:05,151:INFO:self.variable_keys: {'memory', 'fold_shuffle_param', 'fold_generator', 'y_test', 'target_param', 'html_param', 'X_train', 'logging_param', 'X', 'idx', 'seed', 'gpu_param', 'n_jobs_param', 'X_test', '_all_models', 'transform_target_param', 'data', '_all_models_internal', 'USI', 'variable_keys', 'exp_id', '_gpu_n_jobs_param', 'transform_target_method_param', 'master_model_container', 'exp_name_log', 'display_container', 'y_train', '_all_metrics', '_available_plots', 'y', 'log_plots_param', 'fold_groups_param', '_ml_usecase', 'pipeline'}
2022-11-07 19:59:05,151:INFO:Checking environment
2022-11-07 19:59:05,152:INFO:python_version: 3.7.15
2022-11-07 19:59:05,152:INFO:python_build: ('default', 'Oct 12 2022 19:14:55')
2022-11-07 19:59:05,152:INFO:machine: x86_64
2022-11-07 19:59:05,152:INFO:platform: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-07 19:59:05,153:INFO:Memory: svmem(total=13616361472, available=12527484928, percent=8.0, used=858750976, free=6073757696, active=775798784, inactive=6394281984, buffers=422178816, cached=6261673984, shared=1298432, slab=299778048)
2022-11-07 19:59:05,153:INFO:Physical Core: 1
2022-11-07 19:59:05,153:INFO:Logical Core: 2
2022-11-07 19:59:05,153:INFO:Checking libraries
2022-11-07 19:59:05,154:INFO:System:
2022-11-07 19:59:05,154:INFO:    python: 3.7.15 (default, Oct 12 2022, 19:14:55)  [GCC 7.5.0]
2022-11-07 19:59:05,154:INFO:executable: /usr/bin/python3
2022-11-07 19:59:05,154:INFO:   machine: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-07 19:59:05,154:INFO:PyCaret required dependencies:
2022-11-07 19:59:05,154:INFO:                 pip: 21.1.3
2022-11-07 19:59:05,155:INFO:          setuptools: 57.4.0
2022-11-07 19:59:05,155:INFO:             pycaret: 3.0.0rc4
2022-11-07 19:59:05,155:INFO:             IPython: 7.9.0
2022-11-07 19:59:05,155:INFO:          ipywidgets: 7.7.1
2022-11-07 19:59:05,155:INFO:                tqdm: 4.64.1
2022-11-07 19:59:05,155:INFO:               numpy: 1.21.6
2022-11-07 19:59:05,155:INFO:              pandas: 1.3.5
2022-11-07 19:59:05,156:INFO:              jinja2: 2.11.3
2022-11-07 19:59:05,156:INFO:               scipy: 1.7.3
2022-11-07 19:59:05,156:INFO:              joblib: 1.2.0
2022-11-07 19:59:05,156:INFO:             sklearn: 1.0.2
2022-11-07 19:59:05,156:INFO:                pyod: 1.0.6
2022-11-07 19:59:05,156:INFO:            imblearn: 0.8.1
2022-11-07 19:59:05,156:INFO:   category_encoders: 2.5.1.post0
2022-11-07 19:59:05,157:INFO:            lightgbm: 3.3.3
2022-11-07 19:59:05,158:INFO:               numba: 0.55.2
2022-11-07 19:59:05,158:INFO:            requests: 2.28.1
2022-11-07 19:59:05,158:INFO:          matplotlib: 3.5.3
2022-11-07 19:59:05,158:INFO:          scikitplot: 0.3.7
2022-11-07 19:59:05,158:INFO:         yellowbrick: 1.5
2022-11-07 19:59:05,158:INFO:              plotly: 5.5.0
2022-11-07 19:59:05,159:INFO:             kaleido: 0.2.1
2022-11-07 19:59:05,159:INFO:         statsmodels: 0.12.2
2022-11-07 19:59:05,159:INFO:              sktime: 0.13.4
2022-11-07 19:59:05,159:INFO:               tbats: 1.1.1
2022-11-07 19:59:05,159:INFO:            pmdarima: 1.8.5
2022-11-07 19:59:05,159:INFO:              psutil: 5.9.4
2022-11-07 19:59:05,159:INFO:PyCaret optional dependencies:
2022-11-07 19:59:05,174:INFO:                shap: Not installed
2022-11-07 19:59:05,174:INFO:           interpret: Not installed
2022-11-07 19:59:05,175:INFO:                umap: Not installed
2022-11-07 19:59:05,175:INFO:    pandas_profiling: 1.4.1
2022-11-07 19:59:05,175:INFO:  explainerdashboard: Not installed
2022-11-07 19:59:05,175:INFO:             autoviz: Not installed
2022-11-07 19:59:05,175:INFO:           fairlearn: Not installed
2022-11-07 19:59:05,175:INFO:             xgboost: 0.90
2022-11-07 19:59:05,175:INFO:            catboost: Not installed
2022-11-07 19:59:05,176:INFO:              kmodes: Not installed
2022-11-07 19:59:05,176:INFO:             mlxtend: 0.14.0
2022-11-07 19:59:05,176:INFO:       statsforecast: Not installed
2022-11-07 19:59:05,176:INFO:        tune_sklearn: Not installed
2022-11-07 19:59:05,176:INFO:                 ray: Not installed
2022-11-07 19:59:05,176:INFO:            hyperopt: 0.1.2
2022-11-07 19:59:05,176:INFO:              optuna: Not installed
2022-11-07 19:59:05,177:INFO:               skopt: Not installed
2022-11-07 19:59:05,177:INFO:              mlflow: Not installed
2022-11-07 19:59:05,177:INFO:              gradio: Not installed
2022-11-07 19:59:05,177:INFO:             fastapi: Not installed
2022-11-07 19:59:05,177:INFO:             uvicorn: Not installed
2022-11-07 19:59:05,177:INFO:              m2cgen: Not installed
2022-11-07 19:59:05,177:INFO:           evidently: Not installed
2022-11-07 19:59:05,177:INFO:                nltk: 3.7
2022-11-07 19:59:05,178:INFO:            pyLDAvis: Not installed
2022-11-07 19:59:05,178:INFO:              gensim: 3.6.0
2022-11-07 19:59:05,178:INFO:               spacy: 3.4.2
2022-11-07 19:59:05,178:INFO:           wordcloud: 1.8.2.2
2022-11-07 19:59:05,178:INFO:            textblob: 0.15.3
2022-11-07 19:59:05,178:INFO:               fugue: Not installed
2022-11-07 19:59:05,178:INFO:           streamlit: Not installed
2022-11-07 19:59:05,179:INFO:             prophet: 1.1.1
2022-11-07 19:59:05,179:INFO:None
2022-11-07 19:59:05,179:INFO:Set up data.
2022-11-07 19:59:05,186:INFO:Set up train/test split.
2022-11-07 19:59:05,191:INFO:Set up index.
2022-11-07 19:59:05,192:INFO:Set up folding strategy.
2022-11-07 19:59:05,192:INFO:Assigning column types.
2022-11-07 19:59:05,203:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-07 19:59:05,203:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-07 19:59:05,213:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-07 19:59:05,220:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-07 19:59:05,287:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-07 19:59:05,350:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-07 19:59:05,351:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:05,351:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:05,501:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:05,502:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-07 19:59:05,507:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-07 19:59:05,512:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-07 19:59:05,578:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-07 19:59:05,644:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-07 19:59:05,646:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:05,646:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:05,647:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:05,647:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-07 19:59:05,655:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-07 19:59:05,661:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-07 19:59:05,732:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-07 19:59:05,789:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-07 19:59:05,790:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:05,791:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:05,791:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:05,800:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-07 19:59:05,809:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-07 19:59:05,879:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-07 19:59:05,933:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-07 19:59:05,934:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:05,935:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:05,935:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:05,935:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-07 19:59:05,946:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-07 19:59:06,017:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-07 19:59:06,067:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-07 19:59:06,068:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:06,069:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:06,069:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:06,080:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-07 19:59:06,145:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-07 19:59:06,195:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-07 19:59:06,196:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:06,196:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:06,197:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:06,197:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-07 19:59:06,282:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-07 19:59:06,342:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-07 19:59:06,343:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:06,344:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:06,344:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:06,420:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-07 19:59:06,470:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-07 19:59:06,471:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:06,472:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:06,472:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:06,473:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-07 19:59:06,552:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-07 19:59:06,602:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:06,602:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:06,603:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:06,681:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-07 19:59:06,732:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:06,732:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:06,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:06,733:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-07 19:59:06,873:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:06,873:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:06,874:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:07,003:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:07,004:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:07,004:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:07,005:INFO:Preparing preprocessing pipeline...
2022-11-07 19:59:07,007:INFO:Set up simple imputation.
2022-11-07 19:59:07,007:INFO:Set up variance threshold.
2022-11-07 19:59:07,058:INFO:Finished creating preprocessing pipeline.
2022-11-07 19:59:07,069:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['TeamId', 'GameId', 'PTS_QTR1',
                                             'PTS_QTR2', 'PTS_QTR3', 'PTS_QTR4',
                                             'PTS', 'FG_PCT', 'FT_PCT',
                                             'FG3_PCT', 'AST', 'REB'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-07 19:59:07,069:INFO:Creating final display dataframe.
2022-11-07 19:59:07,280:INFO:Setup display_container:                Description       Value
0               Session id         123
1                   Target         TOV
2              Target type  Regression
3               Data shape  (1388, 13)
4         Train data shape   (971, 13)
5          Test data shape   (417, 13)
6         Numeric features          12
7               Preprocess        True
8          Imputation type      simple
9       Numeric imputation        mean
10  Categorical imputation    constant
11  Low variance threshold           0
12          Fold Generator       KFold
13             Fold Number          10
14                CPU Jobs          -1
15                 Use GPU       False
16          Log Experiment       False
17         Experiment Name    FullData
18                     USI        41f2
2022-11-07 19:59:07,446:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:07,446:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:07,447:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:07,586:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:07,587:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:07,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:07,595:INFO:setup() successfully completed in 2.45s...............
2022-11-07 19:59:39,626:INFO:PyCaret RegressionExperiment
2022-11-07 19:59:39,627:INFO:Logging name: FullData
2022-11-07 19:59:39,627:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-07 19:59:39,628:INFO:version 3.0.0.rc4
2022-11-07 19:59:39,628:INFO:Initializing setup()
2022-11-07 19:59:39,628:INFO:self.USI: 38ef
2022-11-07 19:59:39,628:INFO:self.variable_keys: {'memory', 'fold_shuffle_param', 'fold_generator', 'y_test', 'target_param', 'html_param', 'X_train', 'logging_param', 'X', 'idx', 'seed', 'gpu_param', 'n_jobs_param', 'X_test', '_all_models', 'transform_target_param', 'data', '_all_models_internal', 'USI', 'variable_keys', 'exp_id', '_gpu_n_jobs_param', 'transform_target_method_param', 'master_model_container', 'exp_name_log', 'display_container', 'y_train', '_all_metrics', '_available_plots', 'y', 'log_plots_param', 'fold_groups_param', '_ml_usecase', 'pipeline'}
2022-11-07 19:59:39,628:INFO:Checking environment
2022-11-07 19:59:39,629:INFO:python_version: 3.7.15
2022-11-07 19:59:39,629:INFO:python_build: ('default', 'Oct 12 2022 19:14:55')
2022-11-07 19:59:39,629:INFO:machine: x86_64
2022-11-07 19:59:39,629:INFO:platform: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-07 19:59:39,630:INFO:Memory: svmem(total=13616361472, available=12517105664, percent=8.1, used=870154240, free=6017290240, active=776310784, inactive=6449528832, buffers=422301696, cached=6306615296, shared=1298432, slab=301617152)
2022-11-07 19:59:39,630:INFO:Physical Core: 1
2022-11-07 19:59:39,631:INFO:Logical Core: 2
2022-11-07 19:59:39,631:INFO:Checking libraries
2022-11-07 19:59:39,631:INFO:System:
2022-11-07 19:59:39,632:INFO:    python: 3.7.15 (default, Oct 12 2022, 19:14:55)  [GCC 7.5.0]
2022-11-07 19:59:39,632:INFO:executable: /usr/bin/python3
2022-11-07 19:59:39,632:INFO:   machine: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-07 19:59:39,632:INFO:PyCaret required dependencies:
2022-11-07 19:59:39,632:INFO:                 pip: 21.1.3
2022-11-07 19:59:39,632:INFO:          setuptools: 57.4.0
2022-11-07 19:59:39,632:INFO:             pycaret: 3.0.0rc4
2022-11-07 19:59:39,633:INFO:             IPython: 7.9.0
2022-11-07 19:59:39,633:INFO:          ipywidgets: 7.7.1
2022-11-07 19:59:39,633:INFO:                tqdm: 4.64.1
2022-11-07 19:59:39,633:INFO:               numpy: 1.21.6
2022-11-07 19:59:39,633:INFO:              pandas: 1.3.5
2022-11-07 19:59:39,633:INFO:              jinja2: 2.11.3
2022-11-07 19:59:39,633:INFO:               scipy: 1.7.3
2022-11-07 19:59:39,634:INFO:              joblib: 1.2.0
2022-11-07 19:59:39,634:INFO:             sklearn: 1.0.2
2022-11-07 19:59:39,634:INFO:                pyod: 1.0.6
2022-11-07 19:59:39,634:INFO:            imblearn: 0.8.1
2022-11-07 19:59:39,634:INFO:   category_encoders: 2.5.1.post0
2022-11-07 19:59:39,634:INFO:            lightgbm: 3.3.3
2022-11-07 19:59:39,634:INFO:               numba: 0.55.2
2022-11-07 19:59:39,634:INFO:            requests: 2.28.1
2022-11-07 19:59:39,635:INFO:          matplotlib: 3.5.3
2022-11-07 19:59:39,635:INFO:          scikitplot: 0.3.7
2022-11-07 19:59:39,635:INFO:         yellowbrick: 1.5
2022-11-07 19:59:39,635:INFO:              plotly: 5.5.0
2022-11-07 19:59:39,635:INFO:             kaleido: 0.2.1
2022-11-07 19:59:39,635:INFO:         statsmodels: 0.12.2
2022-11-07 19:59:39,635:INFO:              sktime: 0.13.4
2022-11-07 19:59:39,635:INFO:               tbats: 1.1.1
2022-11-07 19:59:39,636:INFO:            pmdarima: 1.8.5
2022-11-07 19:59:39,636:INFO:              psutil: 5.9.4
2022-11-07 19:59:39,636:INFO:PyCaret optional dependencies:
2022-11-07 19:59:39,636:INFO:                shap: Not installed
2022-11-07 19:59:39,636:INFO:           interpret: Not installed
2022-11-07 19:59:39,636:INFO:                umap: Not installed
2022-11-07 19:59:39,637:INFO:    pandas_profiling: 1.4.1
2022-11-07 19:59:39,637:INFO:  explainerdashboard: Not installed
2022-11-07 19:59:39,637:INFO:             autoviz: Not installed
2022-11-07 19:59:39,637:INFO:           fairlearn: Not installed
2022-11-07 19:59:39,637:INFO:             xgboost: 0.90
2022-11-07 19:59:39,637:INFO:            catboost: Not installed
2022-11-07 19:59:39,637:INFO:              kmodes: Not installed
2022-11-07 19:59:39,638:INFO:             mlxtend: 0.14.0
2022-11-07 19:59:39,638:INFO:       statsforecast: Not installed
2022-11-07 19:59:39,638:INFO:        tune_sklearn: Not installed
2022-11-07 19:59:39,638:INFO:                 ray: Not installed
2022-11-07 19:59:39,638:INFO:            hyperopt: 0.1.2
2022-11-07 19:59:39,638:INFO:              optuna: Not installed
2022-11-07 19:59:39,639:INFO:               skopt: Not installed
2022-11-07 19:59:39,640:INFO:              mlflow: Not installed
2022-11-07 19:59:39,640:INFO:              gradio: Not installed
2022-11-07 19:59:39,640:INFO:             fastapi: Not installed
2022-11-07 19:59:39,640:INFO:             uvicorn: Not installed
2022-11-07 19:59:39,640:INFO:              m2cgen: Not installed
2022-11-07 19:59:39,640:INFO:           evidently: Not installed
2022-11-07 19:59:39,641:INFO:                nltk: 3.7
2022-11-07 19:59:39,641:INFO:            pyLDAvis: Not installed
2022-11-07 19:59:39,641:INFO:              gensim: 3.6.0
2022-11-07 19:59:39,641:INFO:               spacy: 3.4.2
2022-11-07 19:59:39,641:INFO:           wordcloud: 1.8.2.2
2022-11-07 19:59:39,642:INFO:            textblob: 0.15.3
2022-11-07 19:59:39,642:INFO:               fugue: Not installed
2022-11-07 19:59:39,642:INFO:           streamlit: Not installed
2022-11-07 19:59:39,642:INFO:             prophet: 1.1.1
2022-11-07 19:59:39,643:INFO:None
2022-11-07 19:59:39,643:INFO:Set up data.
2022-11-07 19:59:39,650:INFO:Set up train/test split.
2022-11-07 19:59:39,654:INFO:Set up index.
2022-11-07 19:59:39,655:INFO:Set up folding strategy.
2022-11-07 19:59:39,655:INFO:Assigning column types.
2022-11-07 19:59:39,661:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-07 19:59:39,662:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-07 19:59:39,667:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-07 19:59:39,673:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-07 19:59:39,744:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-07 19:59:39,814:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-07 19:59:39,816:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:39,816:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:39,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:39,818:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-07 19:59:39,824:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-07 19:59:39,829:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-07 19:59:39,898:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-07 19:59:39,958:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-07 19:59:39,959:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:39,959:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:39,960:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:39,960:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-07 19:59:39,966:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-07 19:59:39,971:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-07 19:59:40,043:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-07 19:59:40,093:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-07 19:59:40,094:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:40,094:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:40,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:40,100:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-07 19:59:40,106:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-07 19:59:40,170:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-07 19:59:40,220:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-07 19:59:40,221:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:40,221:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:40,222:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:40,222:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-07 19:59:40,233:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-07 19:59:40,302:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-07 19:59:40,357:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-07 19:59:40,358:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:40,360:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:40,361:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:40,377:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-07 19:59:40,442:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-07 19:59:40,495:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-07 19:59:40,496:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:40,496:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:40,496:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:40,497:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-07 19:59:40,579:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-07 19:59:40,632:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-07 19:59:40,633:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:40,633:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:40,634:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:40,711:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-07 19:59:40,761:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-07 19:59:40,762:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:40,762:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:40,763:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:40,763:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-07 19:59:40,851:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-07 19:59:40,912:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:40,913:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:40,913:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:40,991:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-07 19:59:41,042:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:41,043:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:41,044:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:41,044:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-07 19:59:41,182:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:41,183:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:41,183:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:41,320:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:41,321:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:41,321:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:41,323:INFO:Preparing preprocessing pipeline...
2022-11-07 19:59:41,324:INFO:Set up simple imputation.
2022-11-07 19:59:41,325:INFO:Set up variance threshold.
2022-11-07 19:59:41,343:INFO:Finished creating preprocessing pipeline.
2022-11-07 19:59:41,350:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['TeamId', 'GameId', 'PTS_QTR1',
                                             'PTS_QTR2', 'PTS_QTR3', 'PTS_QTR4',
                                             'PTS', 'FG_PCT', 'FT_PCT',
                                             'FG3_PCT', 'AST', 'REB'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-07 19:59:41,350:INFO:Creating final display dataframe.
2022-11-07 19:59:41,450:INFO:Setup display_container:                Description       Value
0               Session id         123
1                   Target         TOV
2              Target type  Regression
3               Data shape  (1388, 13)
4         Train data shape   (971, 13)
5          Test data shape   (417, 13)
6         Numeric features          12
7               Preprocess        True
8          Imputation type      simple
9       Numeric imputation        mean
10  Categorical imputation    constant
11  Low variance threshold           0
12          Fold Generator       KFold
13             Fold Number          10
14                CPU Jobs          -1
15                 Use GPU       False
16          Log Experiment       False
17         Experiment Name    FullData
18                     USI        38ef
2022-11-07 19:59:41,608:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:41,608:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:41,609:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:41,750:INFO:Soft dependency imported: xgboost: 0.90
2022-11-07 19:59:41,751:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-07 19:59:41,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-07 19:59:41,759:INFO:setup() successfully completed in 2.14s...............
2022-11-07 19:59:41,760:INFO:Initializing compare_models()
2022-11-07 19:59:41,760:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1facef39d0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f1facef39d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-07 19:59:41,761:INFO:Checking exceptions
2022-11-07 19:59:41,762:INFO:Preparing display monitor
2022-11-07 19:59:41,893:INFO:Initializing Linear Regression
2022-11-07 19:59:41,894:INFO:Total runtime is 9.47713851928711e-06 minutes
2022-11-07 19:59:41,906:INFO:SubProcess create_model() called ==================================
2022-11-07 19:59:41,907:INFO:Initializing create_model()
2022-11-07 19:59:41,907:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1facef39d0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1fac799250>, model_only=True, return_train_score=False, kwargs={})
2022-11-07 19:59:41,907:INFO:Checking exceptions
2022-11-07 19:59:41,910:INFO:Importing libraries
2022-11-07 19:59:41,910:INFO:Copying training dataset
2022-11-07 19:59:41,915:INFO:Defining folds
2022-11-07 19:59:41,916:INFO:Declaring metric variables
2022-11-07 19:59:41,926:INFO:Importing untrained model
2022-11-07 19:59:41,960:INFO:Linear Regression Imported successfully
2022-11-07 19:59:41,981:INFO:Starting cross validation
2022-11-07 19:59:41,998:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-07 19:59:47,946:INFO:Calculating mean and std
2022-11-07 19:59:47,949:INFO:Creating metrics dataframe
2022-11-07 19:59:47,956:INFO:Uploading results into container
2022-11-07 19:59:47,968:INFO:Uploading model into container now
2022-11-07 19:59:47,973:INFO:master_model_container: 1
2022-11-07 19:59:47,974:INFO:display_container: 2
2022-11-07 19:59:47,975:INFO:LinearRegression(n_jobs=-1)
2022-11-07 19:59:47,975:INFO:create_model() successfully completed......................................
2022-11-07 19:59:48,174:INFO:SubProcess create_model() end ==================================
2022-11-07 19:59:48,174:INFO:Creating metrics dataframe
2022-11-07 19:59:48,196:INFO:Initializing Lasso Regression
2022-11-07 19:59:48,203:INFO:Total runtime is 0.105157736937205 minutes
2022-11-07 19:59:48,222:INFO:SubProcess create_model() called ==================================
2022-11-07 19:59:48,222:INFO:Initializing create_model()
2022-11-07 19:59:48,223:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1facef39d0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1fac799250>, model_only=True, return_train_score=False, kwargs={})
2022-11-07 19:59:48,223:INFO:Checking exceptions
2022-11-07 19:59:48,226:INFO:Importing libraries
2022-11-07 19:59:48,229:INFO:Copying training dataset
2022-11-07 19:59:48,237:INFO:Defining folds
2022-11-07 19:59:48,238:INFO:Declaring metric variables
2022-11-07 19:59:48,251:INFO:Importing untrained model
2022-11-07 19:59:48,264:INFO:Lasso Regression Imported successfully
2022-11-07 19:59:48,287:INFO:Starting cross validation
2022-11-07 19:59:48,290:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-07 19:59:48,676:INFO:Calculating mean and std
2022-11-07 19:59:48,680:INFO:Creating metrics dataframe
2022-11-07 19:59:48,692:INFO:Uploading results into container
2022-11-07 19:59:48,697:INFO:Uploading model into container now
2022-11-07 19:59:48,699:INFO:master_model_container: 2
2022-11-07 19:59:48,700:INFO:display_container: 2
2022-11-07 19:59:48,701:INFO:Lasso(random_state=123)
2022-11-07 19:59:48,701:INFO:create_model() successfully completed......................................
2022-11-07 19:59:48,860:INFO:SubProcess create_model() end ==================================
2022-11-07 19:59:48,861:INFO:Creating metrics dataframe
2022-11-07 19:59:48,881:INFO:Initializing Ridge Regression
2022-11-07 19:59:48,881:INFO:Total runtime is 0.1164690097173055 minutes
2022-11-07 19:59:48,893:INFO:SubProcess create_model() called ==================================
2022-11-07 19:59:48,894:INFO:Initializing create_model()
2022-11-07 19:59:48,894:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1facef39d0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1fac799250>, model_only=True, return_train_score=False, kwargs={})
2022-11-07 19:59:48,895:INFO:Checking exceptions
2022-11-07 19:59:48,897:INFO:Importing libraries
2022-11-07 19:59:48,897:INFO:Copying training dataset
2022-11-07 19:59:48,905:INFO:Defining folds
2022-11-07 19:59:48,910:INFO:Declaring metric variables
2022-11-07 19:59:48,925:INFO:Importing untrained model
2022-11-07 19:59:48,941:INFO:Ridge Regression Imported successfully
2022-11-07 19:59:48,968:INFO:Starting cross validation
2022-11-07 19:59:48,969:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-07 19:59:49,302:INFO:Calculating mean and std
2022-11-07 19:59:49,305:INFO:Creating metrics dataframe
2022-11-07 19:59:49,311:INFO:Uploading results into container
2022-11-07 19:59:49,314:INFO:Uploading model into container now
2022-11-07 19:59:49,319:INFO:master_model_container: 3
2022-11-07 19:59:49,322:INFO:display_container: 2
2022-11-07 19:59:49,322:INFO:Ridge(random_state=123)
2022-11-07 19:59:49,323:INFO:create_model() successfully completed......................................
2022-11-07 19:59:49,474:INFO:SubProcess create_model() end ==================================
2022-11-07 19:59:49,474:INFO:Creating metrics dataframe
2022-11-07 19:59:49,493:INFO:Initializing Elastic Net
2022-11-07 19:59:49,493:INFO:Total runtime is 0.1266626238822937 minutes
2022-11-07 19:59:49,503:INFO:SubProcess create_model() called ==================================
2022-11-07 19:59:49,510:INFO:Initializing create_model()
2022-11-07 19:59:49,510:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1facef39d0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1fac799250>, model_only=True, return_train_score=False, kwargs={})
2022-11-07 19:59:49,511:INFO:Checking exceptions
2022-11-07 19:59:49,513:INFO:Importing libraries
2022-11-07 19:59:49,514:INFO:Copying training dataset
2022-11-07 19:59:49,520:INFO:Defining folds
2022-11-07 19:59:49,520:INFO:Declaring metric variables
2022-11-07 19:59:49,531:INFO:Importing untrained model
2022-11-07 19:59:49,545:INFO:Elastic Net Imported successfully
2022-11-07 19:59:49,572:INFO:Starting cross validation
2022-11-07 19:59:49,574:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-07 19:59:49,928:INFO:Calculating mean and std
2022-11-07 19:59:49,931:INFO:Creating metrics dataframe
2022-11-07 19:59:49,948:INFO:Uploading results into container
2022-11-07 19:59:49,950:INFO:Uploading model into container now
2022-11-07 19:59:49,951:INFO:master_model_container: 4
2022-11-07 19:59:49,951:INFO:display_container: 2
2022-11-07 19:59:49,952:INFO:ElasticNet(random_state=123)
2022-11-07 19:59:49,952:INFO:create_model() successfully completed......................................
2022-11-07 19:59:50,109:INFO:SubProcess create_model() end ==================================
2022-11-07 19:59:50,109:INFO:Creating metrics dataframe
2022-11-07 19:59:50,132:INFO:Initializing Least Angle Regression
2022-11-07 19:59:50,132:INFO:Total runtime is 0.1373182495435079 minutes
2022-11-07 19:59:50,143:INFO:SubProcess create_model() called ==================================
2022-11-07 19:59:50,144:INFO:Initializing create_model()
2022-11-07 19:59:50,144:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1facef39d0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1fac799250>, model_only=True, return_train_score=False, kwargs={})
2022-11-07 19:59:50,145:INFO:Checking exceptions
2022-11-07 19:59:50,148:INFO:Importing libraries
2022-11-07 19:59:50,148:INFO:Copying training dataset
2022-11-07 19:59:50,157:INFO:Defining folds
2022-11-07 19:59:50,158:INFO:Declaring metric variables
2022-11-07 19:59:50,168:INFO:Importing untrained model
2022-11-07 19:59:50,178:INFO:Least Angle Regression Imported successfully
2022-11-07 19:59:50,197:INFO:Starting cross validation
2022-11-07 19:59:50,199:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-07 19:59:50,262:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-07 19:59:50,303:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-07 19:59:50,343:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-07 19:59:50,377:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-07 19:59:50,411:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-07 19:59:50,462:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-07 19:59:50,472:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-07 19:59:50,514:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-07 19:59:50,526:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-07 19:59:50,555:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-07 19:59:50,569:INFO:Calculating mean and std
2022-11-07 19:59:50,572:INFO:Creating metrics dataframe
2022-11-07 19:59:50,595:INFO:Uploading results into container
2022-11-07 19:59:50,597:INFO:Uploading model into container now
2022-11-07 19:59:50,599:INFO:master_model_container: 5
2022-11-07 19:59:50,599:INFO:display_container: 2
2022-11-07 19:59:50,600:INFO:Lars(random_state=123)
2022-11-07 19:59:50,600:INFO:create_model() successfully completed......................................
2022-11-07 19:59:50,753:INFO:SubProcess create_model() end ==================================
2022-11-07 19:59:50,753:INFO:Creating metrics dataframe
2022-11-07 19:59:50,776:INFO:Initializing Lasso Least Angle Regression
2022-11-07 19:59:50,777:INFO:Total runtime is 0.14805944363276166 minutes
2022-11-07 19:59:50,786:INFO:SubProcess create_model() called ==================================
2022-11-07 19:59:50,793:INFO:Initializing create_model()
2022-11-07 19:59:50,795:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1facef39d0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1fac799250>, model_only=True, return_train_score=False, kwargs={})
2022-11-07 19:59:50,796:INFO:Checking exceptions
2022-11-07 19:59:50,798:INFO:Importing libraries
2022-11-07 19:59:50,799:INFO:Copying training dataset
2022-11-07 19:59:50,805:INFO:Defining folds
2022-11-07 19:59:50,805:INFO:Declaring metric variables
2022-11-07 19:59:50,823:INFO:Importing untrained model
2022-11-07 19:59:50,835:INFO:Lasso Least Angle Regression Imported successfully
2022-11-07 19:59:50,855:INFO:Starting cross validation
2022-11-07 19:59:50,857:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-07 19:59:50,922:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-07 19:59:50,949:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-07 19:59:50,985:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-07 19:59:51,012:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-07 19:59:51,049:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-07 19:59:51,087:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-07 19:59:51,101:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-07 19:59:51,159:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-07 19:59:51,179:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-07 19:59:51,202:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-07 19:59:51,215:INFO:Calculating mean and std
2022-11-07 19:59:51,217:INFO:Creating metrics dataframe
2022-11-07 19:59:51,225:INFO:Uploading results into container
2022-11-07 19:59:51,226:INFO:Uploading model into container now
2022-11-07 19:59:51,226:INFO:master_model_container: 6
2022-11-07 19:59:51,227:INFO:display_container: 2
2022-11-07 19:59:51,227:INFO:LassoLars(random_state=123)
2022-11-07 19:59:51,227:INFO:create_model() successfully completed......................................
2022-11-07 19:59:51,378:INFO:SubProcess create_model() end ==================================
2022-11-07 19:59:51,378:INFO:Creating metrics dataframe
2022-11-07 19:59:51,421:INFO:Initializing Orthogonal Matching Pursuit
2022-11-07 19:59:51,421:INFO:Total runtime is 0.15879542827606202 minutes
2022-11-07 19:59:51,431:INFO:SubProcess create_model() called ==================================
2022-11-07 19:59:51,432:INFO:Initializing create_model()
2022-11-07 19:59:51,432:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1facef39d0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1fac799250>, model_only=True, return_train_score=False, kwargs={})
2022-11-07 19:59:51,433:INFO:Checking exceptions
2022-11-07 19:59:51,436:INFO:Importing libraries
2022-11-07 19:59:51,437:INFO:Copying training dataset
2022-11-07 19:59:51,448:INFO:Defining folds
2022-11-07 19:59:51,448:INFO:Declaring metric variables
2022-11-07 19:59:51,459:INFO:Importing untrained model
2022-11-07 19:59:51,471:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-07 19:59:51,494:INFO:Starting cross validation
2022-11-07 19:59:51,496:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-07 19:59:51,552:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-07 19:59:51,580:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-07 19:59:51,624:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-07 19:59:51,659:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-07 19:59:51,690:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-07 19:59:51,730:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-07 19:59:51,737:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-07 19:59:51,780:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-07 19:59:51,796:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-07 19:59:51,830:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-07 19:59:51,845:INFO:Calculating mean and std
2022-11-07 19:59:51,847:INFO:Creating metrics dataframe
2022-11-07 19:59:51,863:INFO:Uploading results into container
2022-11-07 19:59:51,868:INFO:Uploading model into container now
2022-11-07 19:59:51,869:INFO:master_model_container: 7
2022-11-07 19:59:51,869:INFO:display_container: 2
2022-11-07 19:59:51,869:INFO:OrthogonalMatchingPursuit()
2022-11-07 19:59:51,870:INFO:create_model() successfully completed......................................
2022-11-07 19:59:52,025:INFO:SubProcess create_model() end ==================================
2022-11-07 19:59:52,025:INFO:Creating metrics dataframe
2022-11-07 19:59:52,045:INFO:Initializing Bayesian Ridge
2022-11-07 19:59:52,046:INFO:Total runtime is 0.16920872131983442 minutes
2022-11-07 19:59:52,068:INFO:SubProcess create_model() called ==================================
2022-11-07 19:59:52,070:INFO:Initializing create_model()
2022-11-07 19:59:52,071:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1facef39d0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1fac799250>, model_only=True, return_train_score=False, kwargs={})
2022-11-07 19:59:52,071:INFO:Checking exceptions
2022-11-07 19:59:52,073:INFO:Importing libraries
2022-11-07 19:59:52,074:INFO:Copying training dataset
2022-11-07 19:59:52,080:INFO:Defining folds
2022-11-07 19:59:52,080:INFO:Declaring metric variables
2022-11-07 19:59:52,094:INFO:Importing untrained model
2022-11-07 19:59:52,108:INFO:Bayesian Ridge Imported successfully
2022-11-07 19:59:52,129:INFO:Starting cross validation
2022-11-07 19:59:52,132:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-07 19:59:52,512:INFO:Calculating mean and std
2022-11-07 19:59:52,514:INFO:Creating metrics dataframe
2022-11-07 19:59:52,527:INFO:Uploading results into container
2022-11-07 19:59:52,528:INFO:Uploading model into container now
2022-11-07 19:59:52,529:INFO:master_model_container: 8
2022-11-07 19:59:52,530:INFO:display_container: 2
2022-11-07 19:59:52,531:INFO:BayesianRidge()
2022-11-07 19:59:52,531:INFO:create_model() successfully completed......................................
2022-11-07 19:59:52,695:INFO:SubProcess create_model() end ==================================
2022-11-07 19:59:52,695:INFO:Creating metrics dataframe
2022-11-07 19:59:52,718:INFO:Initializing Passive Aggressive Regressor
2022-11-07 19:59:52,721:INFO:Total runtime is 0.18046491543451948 minutes
2022-11-07 19:59:52,734:INFO:SubProcess create_model() called ==================================
2022-11-07 19:59:52,736:INFO:Initializing create_model()
2022-11-07 19:59:52,736:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1facef39d0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1fac799250>, model_only=True, return_train_score=False, kwargs={})
2022-11-07 19:59:52,736:INFO:Checking exceptions
2022-11-07 19:59:52,740:INFO:Importing libraries
2022-11-07 19:59:52,740:INFO:Copying training dataset
2022-11-07 19:59:52,751:INFO:Defining folds
2022-11-07 19:59:52,752:INFO:Declaring metric variables
2022-11-07 19:59:52,761:INFO:Importing untrained model
2022-11-07 19:59:52,771:INFO:Passive Aggressive Regressor Imported successfully
2022-11-07 19:59:52,791:INFO:Starting cross validation
2022-11-07 19:59:52,793:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-07 19:59:53,152:INFO:Calculating mean and std
2022-11-07 19:59:53,154:INFO:Creating metrics dataframe
2022-11-07 19:59:53,183:INFO:Uploading results into container
2022-11-07 19:59:53,184:INFO:Uploading model into container now
2022-11-07 19:59:53,185:INFO:master_model_container: 9
2022-11-07 19:59:53,185:INFO:display_container: 2
2022-11-07 19:59:53,185:INFO:PassiveAggressiveRegressor(random_state=123)
2022-11-07 19:59:53,185:INFO:create_model() successfully completed......................................
2022-11-07 19:59:53,345:INFO:SubProcess create_model() end ==================================
2022-11-07 19:59:53,346:INFO:Creating metrics dataframe
2022-11-07 19:59:53,375:INFO:Initializing Huber Regressor
2022-11-07 19:59:53,380:INFO:Total runtime is 0.19144604206085208 minutes
2022-11-07 19:59:53,392:INFO:SubProcess create_model() called ==================================
2022-11-07 19:59:53,392:INFO:Initializing create_model()
2022-11-07 19:59:53,392:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1facef39d0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1fac799250>, model_only=True, return_train_score=False, kwargs={})
2022-11-07 19:59:53,393:INFO:Checking exceptions
2022-11-07 19:59:53,395:INFO:Importing libraries
2022-11-07 19:59:53,396:INFO:Copying training dataset
2022-11-07 19:59:53,405:INFO:Defining folds
2022-11-07 19:59:53,405:INFO:Declaring metric variables
2022-11-07 19:59:53,421:INFO:Importing untrained model
2022-11-07 19:59:53,431:INFO:Huber Regressor Imported successfully
2022-11-07 19:59:53,448:INFO:Starting cross validation
2022-11-07 19:59:53,450:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-07 19:59:53,850:INFO:Calculating mean and std
2022-11-07 19:59:53,852:INFO:Creating metrics dataframe
2022-11-07 19:59:53,866:INFO:Uploading results into container
2022-11-07 19:59:53,867:INFO:Uploading model into container now
2022-11-07 19:59:53,868:INFO:master_model_container: 10
2022-11-07 19:59:53,868:INFO:display_container: 2
2022-11-07 19:59:53,869:INFO:HuberRegressor()
2022-11-07 19:59:53,869:INFO:create_model() successfully completed......................................
2022-11-07 19:59:54,020:INFO:SubProcess create_model() end ==================================
2022-11-07 19:59:54,021:INFO:Creating metrics dataframe
2022-11-07 19:59:54,041:INFO:Initializing K Neighbors Regressor
2022-11-07 19:59:54,042:INFO:Total runtime is 0.20248300631841026 minutes
2022-11-07 19:59:54,052:INFO:SubProcess create_model() called ==================================
2022-11-07 19:59:54,053:INFO:Initializing create_model()
2022-11-07 19:59:54,053:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1facef39d0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1fac799250>, model_only=True, return_train_score=False, kwargs={})
2022-11-07 19:59:54,054:INFO:Checking exceptions
2022-11-07 19:59:54,058:INFO:Importing libraries
2022-11-07 19:59:54,058:INFO:Copying training dataset
2022-11-07 19:59:54,069:INFO:Defining folds
2022-11-07 19:59:54,069:INFO:Declaring metric variables
2022-11-07 19:59:54,080:INFO:Importing untrained model
2022-11-07 19:59:54,092:INFO:K Neighbors Regressor Imported successfully
2022-11-07 19:59:54,111:INFO:Starting cross validation
2022-11-07 19:59:54,113:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-07 19:59:54,960:INFO:Calculating mean and std
2022-11-07 19:59:54,963:INFO:Creating metrics dataframe
2022-11-07 19:59:54,973:INFO:Uploading results into container
2022-11-07 19:59:54,982:INFO:Uploading model into container now
2022-11-07 19:59:54,985:INFO:master_model_container: 11
2022-11-07 19:59:54,985:INFO:display_container: 2
2022-11-07 19:59:54,986:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-07 19:59:54,986:INFO:create_model() successfully completed......................................
2022-11-07 19:59:55,140:INFO:SubProcess create_model() end ==================================
2022-11-07 19:59:55,140:INFO:Creating metrics dataframe
2022-11-07 19:59:55,166:INFO:Initializing Decision Tree Regressor
2022-11-07 19:59:55,166:INFO:Total runtime is 0.22121888399124148 minutes
2022-11-07 19:59:55,176:INFO:SubProcess create_model() called ==================================
2022-11-07 19:59:55,177:INFO:Initializing create_model()
2022-11-07 19:59:55,177:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1facef39d0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1fac799250>, model_only=True, return_train_score=False, kwargs={})
2022-11-07 19:59:55,177:INFO:Checking exceptions
2022-11-07 19:59:55,181:INFO:Importing libraries
2022-11-07 19:59:55,182:INFO:Copying training dataset
2022-11-07 19:59:55,191:INFO:Defining folds
2022-11-07 19:59:55,192:INFO:Declaring metric variables
2022-11-07 19:59:55,203:INFO:Importing untrained model
2022-11-07 19:59:55,215:INFO:Decision Tree Regressor Imported successfully
2022-11-07 19:59:55,244:INFO:Starting cross validation
2022-11-07 19:59:55,245:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-07 19:59:55,701:INFO:Calculating mean and std
2022-11-07 19:59:55,703:INFO:Creating metrics dataframe
2022-11-07 19:59:55,726:INFO:Uploading results into container
2022-11-07 19:59:55,727:INFO:Uploading model into container now
2022-11-07 19:59:55,728:INFO:master_model_container: 12
2022-11-07 19:59:55,729:INFO:display_container: 2
2022-11-07 19:59:55,729:INFO:DecisionTreeRegressor(random_state=123)
2022-11-07 19:59:55,729:INFO:create_model() successfully completed......................................
2022-11-07 19:59:55,879:INFO:SubProcess create_model() end ==================================
2022-11-07 19:59:55,880:INFO:Creating metrics dataframe
2022-11-07 19:59:55,902:INFO:Initializing Random Forest Regressor
2022-11-07 19:59:55,903:INFO:Total runtime is 0.2334896008173625 minutes
2022-11-07 19:59:55,913:INFO:SubProcess create_model() called ==================================
2022-11-07 19:59:55,913:INFO:Initializing create_model()
2022-11-07 19:59:55,914:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1facef39d0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1fac799250>, model_only=True, return_train_score=False, kwargs={})
2022-11-07 19:59:55,914:INFO:Checking exceptions
2022-11-07 19:59:55,917:INFO:Importing libraries
2022-11-07 19:59:55,917:INFO:Copying training dataset
2022-11-07 19:59:55,927:INFO:Defining folds
2022-11-07 19:59:55,927:INFO:Declaring metric variables
2022-11-07 19:59:55,938:INFO:Importing untrained model
2022-11-07 19:59:55,949:INFO:Random Forest Regressor Imported successfully
2022-11-07 19:59:55,968:INFO:Starting cross validation
2022-11-07 19:59:55,970:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-07 20:00:02,870:INFO:Calculating mean and std
2022-11-07 20:00:02,875:INFO:Creating metrics dataframe
2022-11-07 20:00:02,884:INFO:Uploading results into container
2022-11-07 20:00:02,885:INFO:Uploading model into container now
2022-11-07 20:00:02,886:INFO:master_model_container: 13
2022-11-07 20:00:02,887:INFO:display_container: 2
2022-11-07 20:00:02,887:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-07 20:00:02,887:INFO:create_model() successfully completed......................................
2022-11-07 20:00:03,045:INFO:SubProcess create_model() end ==================================
2022-11-07 20:00:03,045:INFO:Creating metrics dataframe
2022-11-07 20:00:03,068:INFO:Initializing Extra Trees Regressor
2022-11-07 20:00:03,069:INFO:Total runtime is 0.3529195944468181 minutes
2022-11-07 20:00:03,082:INFO:SubProcess create_model() called ==================================
2022-11-07 20:00:03,085:INFO:Initializing create_model()
2022-11-07 20:00:03,085:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1facef39d0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1fac799250>, model_only=True, return_train_score=False, kwargs={})
2022-11-07 20:00:03,085:INFO:Checking exceptions
2022-11-07 20:00:03,088:INFO:Importing libraries
2022-11-07 20:00:03,089:INFO:Copying training dataset
2022-11-07 20:00:03,096:INFO:Defining folds
2022-11-07 20:00:03,097:INFO:Declaring metric variables
2022-11-07 20:00:03,107:INFO:Importing untrained model
2022-11-07 20:00:03,125:INFO:Extra Trees Regressor Imported successfully
2022-11-07 20:00:03,146:INFO:Starting cross validation
2022-11-07 20:00:03,148:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-07 20:00:06,664:INFO:Calculating mean and std
2022-11-07 20:00:06,670:INFO:Creating metrics dataframe
2022-11-07 20:00:06,683:INFO:Uploading results into container
2022-11-07 20:00:06,684:INFO:Uploading model into container now
2022-11-07 20:00:06,686:INFO:master_model_container: 14
2022-11-07 20:00:06,686:INFO:display_container: 2
2022-11-07 20:00:06,688:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-07 20:00:06,689:INFO:create_model() successfully completed......................................
2022-11-07 20:00:06,839:INFO:SubProcess create_model() end ==================================
2022-11-07 20:00:06,840:INFO:Creating metrics dataframe
2022-11-07 20:00:06,863:INFO:Initializing AdaBoost Regressor
2022-11-07 20:00:06,864:INFO:Total runtime is 0.41617738405863447 minutes
2022-11-07 20:00:06,875:INFO:SubProcess create_model() called ==================================
2022-11-07 20:00:06,875:INFO:Initializing create_model()
2022-11-07 20:00:06,876:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1facef39d0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1fac799250>, model_only=True, return_train_score=False, kwargs={})
2022-11-07 20:00:06,876:INFO:Checking exceptions
2022-11-07 20:00:06,879:INFO:Importing libraries
2022-11-07 20:00:06,880:INFO:Copying training dataset
2022-11-07 20:00:06,890:INFO:Defining folds
2022-11-07 20:00:06,890:INFO:Declaring metric variables
2022-11-07 20:00:06,900:INFO:Importing untrained model
2022-11-07 20:00:06,911:INFO:AdaBoost Regressor Imported successfully
2022-11-07 20:00:06,930:INFO:Starting cross validation
2022-11-07 20:00:06,931:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-07 20:00:08,561:INFO:Calculating mean and std
2022-11-07 20:00:08,564:INFO:Creating metrics dataframe
2022-11-07 20:00:08,578:INFO:Uploading results into container
2022-11-07 20:00:08,579:INFO:Uploading model into container now
2022-11-07 20:00:08,580:INFO:master_model_container: 15
2022-11-07 20:00:08,580:INFO:display_container: 2
2022-11-07 20:00:08,581:INFO:AdaBoostRegressor(random_state=123)
2022-11-07 20:00:08,581:INFO:create_model() successfully completed......................................
2022-11-07 20:00:08,746:INFO:SubProcess create_model() end ==================================
2022-11-07 20:00:08,746:INFO:Creating metrics dataframe
2022-11-07 20:00:08,774:INFO:Initializing Gradient Boosting Regressor
2022-11-07 20:00:08,774:INFO:Total runtime is 0.44801037708918257 minutes
2022-11-07 20:00:08,783:INFO:SubProcess create_model() called ==================================
2022-11-07 20:00:08,784:INFO:Initializing create_model()
2022-11-07 20:00:08,784:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1facef39d0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1fac799250>, model_only=True, return_train_score=False, kwargs={})
2022-11-07 20:00:08,784:INFO:Checking exceptions
2022-11-07 20:00:08,788:INFO:Importing libraries
2022-11-07 20:00:08,788:INFO:Copying training dataset
2022-11-07 20:00:08,798:INFO:Defining folds
2022-11-07 20:00:08,798:INFO:Declaring metric variables
2022-11-07 20:00:08,809:INFO:Importing untrained model
2022-11-07 20:00:08,822:INFO:Gradient Boosting Regressor Imported successfully
2022-11-07 20:00:08,845:INFO:Starting cross validation
2022-11-07 20:00:08,846:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-07 20:00:11,614:INFO:Calculating mean and std
2022-11-07 20:00:11,619:INFO:Creating metrics dataframe
2022-11-07 20:00:11,634:INFO:Uploading results into container
2022-11-07 20:00:11,636:INFO:Uploading model into container now
2022-11-07 20:00:11,640:INFO:master_model_container: 16
2022-11-07 20:00:11,640:INFO:display_container: 2
2022-11-07 20:00:11,641:INFO:GradientBoostingRegressor(random_state=123)
2022-11-07 20:00:11,646:INFO:create_model() successfully completed......................................
2022-11-07 20:00:11,800:INFO:SubProcess create_model() end ==================================
2022-11-07 20:00:11,800:INFO:Creating metrics dataframe
2022-11-07 20:00:11,836:INFO:Initializing Light Gradient Boosting Machine
2022-11-07 20:00:11,837:INFO:Total runtime is 0.49906716346740726 minutes
2022-11-07 20:00:11,847:INFO:SubProcess create_model() called ==================================
2022-11-07 20:00:11,848:INFO:Initializing create_model()
2022-11-07 20:00:11,849:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1facef39d0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1fac799250>, model_only=True, return_train_score=False, kwargs={})
2022-11-07 20:00:11,850:INFO:Checking exceptions
2022-11-07 20:00:11,858:INFO:Importing libraries
2022-11-07 20:00:11,858:INFO:Copying training dataset
2022-11-07 20:00:11,875:INFO:Defining folds
2022-11-07 20:00:11,876:INFO:Declaring metric variables
2022-11-07 20:00:11,887:INFO:Importing untrained model
2022-11-07 20:00:11,899:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-07 20:00:11,924:INFO:Starting cross validation
2022-11-07 20:00:11,926:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-07 20:00:14,100:INFO:Calculating mean and std
2022-11-07 20:00:14,110:INFO:Creating metrics dataframe
2022-11-07 20:00:14,127:INFO:Uploading results into container
2022-11-07 20:00:14,128:INFO:Uploading model into container now
2022-11-07 20:00:14,129:INFO:master_model_container: 17
2022-11-07 20:00:14,129:INFO:display_container: 2
2022-11-07 20:00:14,129:INFO:LGBMRegressor(random_state=123)
2022-11-07 20:00:14,130:INFO:create_model() successfully completed......................................
2022-11-07 20:00:14,302:INFO:SubProcess create_model() end ==================================
2022-11-07 20:00:14,302:INFO:Creating metrics dataframe
2022-11-07 20:00:14,348:INFO:Initializing Dummy Regressor
2022-11-07 20:00:14,349:INFO:Total runtime is 0.5409258762995403 minutes
2022-11-07 20:00:14,359:INFO:SubProcess create_model() called ==================================
2022-11-07 20:00:14,361:INFO:Initializing create_model()
2022-11-07 20:00:14,361:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1facef39d0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1fac799250>, model_only=True, return_train_score=False, kwargs={})
2022-11-07 20:00:14,361:INFO:Checking exceptions
2022-11-07 20:00:14,365:INFO:Importing libraries
2022-11-07 20:00:14,369:INFO:Copying training dataset
2022-11-07 20:00:14,384:INFO:Defining folds
2022-11-07 20:00:14,384:INFO:Declaring metric variables
2022-11-07 20:00:14,393:INFO:Importing untrained model
2022-11-07 20:00:14,402:INFO:Dummy Regressor Imported successfully
2022-11-07 20:00:14,420:INFO:Starting cross validation
2022-11-07 20:00:14,422:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-07 20:00:14,780:INFO:Calculating mean and std
2022-11-07 20:00:14,782:INFO:Creating metrics dataframe
2022-11-07 20:00:14,800:INFO:Uploading results into container
2022-11-07 20:00:14,802:INFO:Uploading model into container now
2022-11-07 20:00:14,803:INFO:master_model_container: 18
2022-11-07 20:00:14,803:INFO:display_container: 2
2022-11-07 20:00:14,803:INFO:DummyRegressor()
2022-11-07 20:00:14,804:INFO:create_model() successfully completed......................................
2022-11-07 20:00:14,972:INFO:SubProcess create_model() end ==================================
2022-11-07 20:00:14,973:INFO:Creating metrics dataframe
2022-11-07 20:00:15,028:INFO:Initializing create_model()
2022-11-07 20:00:15,033:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f1facef39d0>, estimator=LGBMRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-07 20:00:15,033:INFO:Checking exceptions
2022-11-07 20:00:15,040:INFO:Importing libraries
2022-11-07 20:00:15,044:INFO:Copying training dataset
2022-11-07 20:00:15,049:INFO:Defining folds
2022-11-07 20:00:15,049:INFO:Declaring metric variables
2022-11-07 20:00:15,050:INFO:Importing untrained model
2022-11-07 20:00:15,050:INFO:Declaring custom model
2022-11-07 20:00:15,056:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-07 20:00:15,058:INFO:Cross validation set to False
2022-11-07 20:00:15,058:INFO:Fitting Model
2022-11-07 20:00:15,239:INFO:LGBMRegressor(random_state=123)
2022-11-07 20:00:15,240:INFO:create_model() successfully completed......................................
2022-11-07 20:00:15,517:INFO:master_model_container: 18
2022-11-07 20:00:15,522:INFO:display_container: 2
2022-11-07 20:00:15,523:INFO:LGBMRegressor(random_state=123)
2022-11-07 20:00:15,523:INFO:compare_models() successfully completed......................................
2022-11-07 20:07:37,062:WARNING:/usr/local/lib/python3.7/dist-packages/google/colab/_shell.py:289: FutureWarning: Index.is_all_dates is deprecated, will be removed in a future version.  check index.inferred_type instead
  return getattr(obj, attrname)

2022-11-09 20:01:47,530:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-09 20:01:47,778:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-09 20:01:47,778:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-09 20:01:47,778:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-09 20:01:49,225:INFO:Soft dependency imported: prophet: 1.1.1
2022-11-09 20:01:49,873:INFO:PyCaret RegressionExperiment
2022-11-09 20:01:49,875:INFO:Logging name: FullData
2022-11-09 20:01:49,875:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-09 20:01:49,875:INFO:version 3.0.0.rc4
2022-11-09 20:01:49,876:INFO:Initializing setup()
2022-11-09 20:01:49,876:INFO:self.USI: 0f2c
2022-11-09 20:01:49,876:INFO:self.variable_keys: {'master_model_container', 'transform_target_param', 'display_container', 'idx', 'logging_param', '_ml_usecase', 'html_param', 'y', 'exp_name_log', 'log_plots_param', 'exp_id', '_all_models_internal', '_all_metrics', 'X', 'fold_generator', 'fold_groups_param', '_available_plots', 'variable_keys', '_all_models', 'pipeline', '_gpu_n_jobs_param', 'X_test', 'n_jobs_param', 'gpu_param', 'USI', 'target_param', 'transform_target_method_param', 'memory', 'seed', 'X_train', 'y_train', 'data', 'fold_shuffle_param', 'y_test'}
2022-11-09 20:01:49,876:INFO:Checking environment
2022-11-09 20:01:49,877:INFO:python_version: 3.7.15
2022-11-09 20:01:49,877:INFO:python_build: ('default', 'Oct 12 2022 19:14:55')
2022-11-09 20:01:49,877:INFO:machine: x86_64
2022-11-09 20:01:49,877:INFO:platform: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-09 20:01:49,877:INFO:Memory: svmem(total=13616361472, available=11953500160, percent=12.2, used=1450868736, free=8093315072, active=1048629248, inactive=4128104448, buffers=166637568, cached=3905540096, shared=1294336, slab=260927488)
2022-11-09 20:01:49,878:INFO:Physical Core: 1
2022-11-09 20:01:49,878:INFO:Logical Core: 2
2022-11-09 20:01:49,878:INFO:Checking libraries
2022-11-09 20:01:49,879:INFO:System:
2022-11-09 20:01:49,879:INFO:    python: 3.7.15 (default, Oct 12 2022, 19:14:55)  [GCC 7.5.0]
2022-11-09 20:01:49,879:INFO:executable: /usr/bin/python3
2022-11-09 20:01:49,879:INFO:   machine: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-09 20:01:49,879:INFO:PyCaret required dependencies:
2022-11-09 20:01:49,879:INFO:                 pip: 21.1.3
2022-11-09 20:01:49,879:INFO:          setuptools: 57.4.0
2022-11-09 20:01:49,880:INFO:             pycaret: 3.0.0rc4
2022-11-09 20:01:49,880:INFO:             IPython: 7.9.0
2022-11-09 20:01:49,880:INFO:          ipywidgets: 7.7.1
2022-11-09 20:01:49,880:INFO:                tqdm: 4.64.1
2022-11-09 20:01:49,880:INFO:               numpy: 1.21.6
2022-11-09 20:01:49,880:INFO:              pandas: 1.3.5
2022-11-09 20:01:49,881:INFO:              jinja2: 3.0.0
2022-11-09 20:01:49,881:INFO:               scipy: 1.7.3
2022-11-09 20:01:49,881:INFO:              joblib: 1.2.0
2022-11-09 20:01:49,881:INFO:             sklearn: 1.0.2
2022-11-09 20:01:49,881:INFO:                pyod: 1.0.6
2022-11-09 20:01:49,881:INFO:            imblearn: 0.8.1
2022-11-09 20:01:49,881:INFO:   category_encoders: 2.5.1.post0
2022-11-09 20:01:49,881:INFO:            lightgbm: 3.3.3
2022-11-09 20:01:49,882:INFO:               numba: 0.55.2
2022-11-09 20:01:49,882:INFO:            requests: 2.28.1
2022-11-09 20:01:49,882:INFO:          matplotlib: 3.5.3
2022-11-09 20:01:49,882:INFO:          scikitplot: 0.3.7
2022-11-09 20:01:49,882:INFO:         yellowbrick: 1.5
2022-11-09 20:01:49,883:INFO:              plotly: 5.5.0
2022-11-09 20:01:49,883:INFO:             kaleido: 0.2.1
2022-11-09 20:01:49,883:INFO:         statsmodels: 0.12.2
2022-11-09 20:01:49,883:INFO:              sktime: 0.13.4
2022-11-09 20:01:49,883:INFO:               tbats: 1.1.1
2022-11-09 20:01:49,883:INFO:            pmdarima: 1.8.5
2022-11-09 20:01:49,884:INFO:              psutil: 5.9.4
2022-11-09 20:01:49,884:INFO:PyCaret optional dependencies:
2022-11-09 20:01:49,897:INFO:                shap: Not installed
2022-11-09 20:01:49,898:INFO:           interpret: Not installed
2022-11-09 20:01:49,898:INFO:                umap: Not installed
2022-11-09 20:01:49,898:INFO:    pandas_profiling: 1.4.1
2022-11-09 20:01:49,898:INFO:  explainerdashboard: Not installed
2022-11-09 20:01:49,898:INFO:             autoviz: Not installed
2022-11-09 20:01:49,898:INFO:           fairlearn: Not installed
2022-11-09 20:01:49,898:INFO:             xgboost: 0.90
2022-11-09 20:01:49,898:INFO:            catboost: Not installed
2022-11-09 20:01:49,898:INFO:              kmodes: Not installed
2022-11-09 20:01:49,899:INFO:             mlxtend: 0.14.0
2022-11-09 20:01:49,899:INFO:       statsforecast: Not installed
2022-11-09 20:01:49,899:INFO:        tune_sklearn: Not installed
2022-11-09 20:01:49,899:INFO:                 ray: Not installed
2022-11-09 20:01:49,899:INFO:            hyperopt: 0.1.2
2022-11-09 20:01:49,899:INFO:              optuna: Not installed
2022-11-09 20:01:49,899:INFO:               skopt: Not installed
2022-11-09 20:01:49,899:INFO:              mlflow: Not installed
2022-11-09 20:01:49,899:INFO:              gradio: Not installed
2022-11-09 20:01:49,899:INFO:             fastapi: Not installed
2022-11-09 20:01:49,899:INFO:             uvicorn: Not installed
2022-11-09 20:01:49,899:INFO:              m2cgen: Not installed
2022-11-09 20:01:49,899:INFO:           evidently: Not installed
2022-11-09 20:01:49,899:INFO:                nltk: 3.7
2022-11-09 20:01:49,900:INFO:            pyLDAvis: Not installed
2022-11-09 20:01:49,900:INFO:              gensim: 3.6.0
2022-11-09 20:01:49,900:INFO:               spacy: 3.4.2
2022-11-09 20:01:49,900:INFO:           wordcloud: 1.8.2.2
2022-11-09 20:01:49,900:INFO:            textblob: 0.15.3
2022-11-09 20:01:49,900:INFO:               fugue: Not installed
2022-11-09 20:01:49,900:INFO:           streamlit: Not installed
2022-11-09 20:01:49,900:INFO:             prophet: 1.1.1
2022-11-09 20:01:49,900:INFO:None
2022-11-09 20:01:49,900:INFO:Set up data.
2022-11-09 20:01:49,914:INFO:Set up train/test split.
2022-11-09 20:01:49,919:INFO:Set up index.
2022-11-09 20:01:49,920:INFO:Set up folding strategy.
2022-11-09 20:01:49,920:INFO:Assigning column types.
2022-11-09 20:01:49,927:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-09 20:01:49,927:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-09 20:01:49,933:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-09 20:01:49,939:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-09 20:01:50,011:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-09 20:01:50,064:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-09 20:01:50,065:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:01:50,065:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:01:50,224:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:01:50,225:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-09 20:01:50,232:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-09 20:01:50,242:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-09 20:01:50,311:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-09 20:01:50,369:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-09 20:01:50,370:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:01:50,370:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:01:50,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:01:50,371:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-09 20:01:50,377:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-09 20:01:50,382:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-09 20:01:50,453:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-09 20:01:50,506:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-09 20:01:50,507:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:01:50,507:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:01:50,507:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:01:50,513:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-09 20:01:50,519:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-09 20:01:50,597:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-09 20:01:50,652:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-09 20:01:50,653:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:01:50,653:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:01:50,653:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:01:50,654:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-09 20:01:50,665:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-09 20:01:50,734:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-09 20:01:50,787:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-09 20:01:50,788:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:01:50,789:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:01:50,789:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:01:50,801:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-09 20:01:50,870:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-09 20:01:50,922:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-09 20:01:50,924:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:01:50,924:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:01:50,925:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:01:50,925:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-09 20:01:51,006:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-09 20:01:51,059:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-09 20:01:51,061:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:01:51,061:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:01:51,062:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:01:51,143:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-09 20:01:51,206:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-09 20:01:51,209:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:01:51,210:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:01:51,211:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:01:51,212:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-09 20:01:51,292:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-09 20:01:51,352:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:01:51,352:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:01:51,353:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:01:51,433:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-09 20:01:51,486:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:01:51,486:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:01:51,487:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:01:51,487:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-09 20:01:51,629:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:01:51,629:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:01:51,630:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:01:51,762:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:01:51,762:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:01:51,763:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:01:51,764:INFO:Preparing preprocessing pipeline...
2022-11-09 20:01:51,765:INFO:Set up simple imputation.
2022-11-09 20:01:51,766:INFO:Set up variance threshold.
2022-11-09 20:01:51,812:INFO:Finished creating preprocessing pipeline.
2022-11-09 20:01:51,819:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-09 20:01:51,819:INFO:Creating final display dataframe.
2022-11-09 20:01:51,991:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 12)
4         Train data shape    (607, 12)
5          Test data shape    (261, 12)
6         Numeric features           11
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         0f2c
2022-11-09 20:01:52,157:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:01:52,158:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:01:52,159:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:01:52,301:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:01:52,302:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:01:52,302:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:01:52,309:INFO:setup() successfully completed in 2.44s...............
2022-11-09 20:01:52,310:INFO:Initializing compare_models()
2022-11-09 20:01:52,310:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc491519850>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fc491519850>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-09 20:01:52,310:INFO:Checking exceptions
2022-11-09 20:01:52,311:INFO:Preparing display monitor
2022-11-09 20:01:52,403:INFO:Initializing Linear Regression
2022-11-09 20:01:52,404:INFO:Total runtime is 1.0307629903157552e-05 minutes
2022-11-09 20:01:52,413:INFO:SubProcess create_model() called ==================================
2022-11-09 20:01:52,414:INFO:Initializing create_model()
2022-11-09 20:01:52,414:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc491519850>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc47b1ff0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:01:52,414:INFO:Checking exceptions
2022-11-09 20:01:52,418:INFO:Importing libraries
2022-11-09 20:01:52,418:INFO:Copying training dataset
2022-11-09 20:01:52,427:INFO:Defining folds
2022-11-09 20:01:52,428:INFO:Declaring metric variables
2022-11-09 20:01:52,436:INFO:Importing untrained model
2022-11-09 20:01:52,445:INFO:Linear Regression Imported successfully
2022-11-09 20:01:52,463:INFO:Starting cross validation
2022-11-09 20:01:52,479:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:01:58,491:INFO:Calculating mean and std
2022-11-09 20:01:58,495:INFO:Creating metrics dataframe
2022-11-09 20:01:58,507:INFO:Uploading results into container
2022-11-09 20:01:58,509:INFO:Uploading model into container now
2022-11-09 20:01:58,510:INFO:master_model_container: 1
2022-11-09 20:01:58,510:INFO:display_container: 2
2022-11-09 20:01:58,511:INFO:LinearRegression(n_jobs=-1)
2022-11-09 20:01:58,511:INFO:create_model() successfully completed......................................
2022-11-09 20:01:58,684:INFO:SubProcess create_model() end ==================================
2022-11-09 20:01:58,684:INFO:Creating metrics dataframe
2022-11-09 20:01:58,702:INFO:Initializing Lasso Regression
2022-11-09 20:01:58,703:INFO:Total runtime is 0.10500085353851318 minutes
2022-11-09 20:01:58,711:INFO:SubProcess create_model() called ==================================
2022-11-09 20:01:58,713:INFO:Initializing create_model()
2022-11-09 20:01:58,713:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc491519850>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc47b1ff0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:01:58,713:INFO:Checking exceptions
2022-11-09 20:01:58,716:INFO:Importing libraries
2022-11-09 20:01:58,717:INFO:Copying training dataset
2022-11-09 20:01:58,725:INFO:Defining folds
2022-11-09 20:01:58,725:INFO:Declaring metric variables
2022-11-09 20:01:58,735:INFO:Importing untrained model
2022-11-09 20:01:58,744:INFO:Lasso Regression Imported successfully
2022-11-09 20:01:58,766:INFO:Starting cross validation
2022-11-09 20:01:58,768:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:01:59,114:INFO:Calculating mean and std
2022-11-09 20:01:59,117:INFO:Creating metrics dataframe
2022-11-09 20:01:59,135:INFO:Uploading results into container
2022-11-09 20:01:59,136:INFO:Uploading model into container now
2022-11-09 20:01:59,137:INFO:master_model_container: 2
2022-11-09 20:01:59,137:INFO:display_container: 2
2022-11-09 20:01:59,137:INFO:Lasso(random_state=123)
2022-11-09 20:01:59,137:INFO:create_model() successfully completed......................................
2022-11-09 20:01:59,282:INFO:SubProcess create_model() end ==================================
2022-11-09 20:01:59,282:INFO:Creating metrics dataframe
2022-11-09 20:01:59,302:INFO:Initializing Ridge Regression
2022-11-09 20:01:59,303:INFO:Total runtime is 0.11499885320663453 minutes
2022-11-09 20:01:59,312:INFO:SubProcess create_model() called ==================================
2022-11-09 20:01:59,313:INFO:Initializing create_model()
2022-11-09 20:01:59,313:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc491519850>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc47b1ff0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:01:59,314:INFO:Checking exceptions
2022-11-09 20:01:59,317:INFO:Importing libraries
2022-11-09 20:01:59,317:INFO:Copying training dataset
2022-11-09 20:01:59,325:INFO:Defining folds
2022-11-09 20:01:59,325:INFO:Declaring metric variables
2022-11-09 20:01:59,342:INFO:Importing untrained model
2022-11-09 20:01:59,353:INFO:Ridge Regression Imported successfully
2022-11-09 20:01:59,371:INFO:Starting cross validation
2022-11-09 20:01:59,372:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:01:59,692:INFO:Calculating mean and std
2022-11-09 20:01:59,695:INFO:Creating metrics dataframe
2022-11-09 20:01:59,712:INFO:Uploading results into container
2022-11-09 20:01:59,713:INFO:Uploading model into container now
2022-11-09 20:01:59,714:INFO:master_model_container: 3
2022-11-09 20:01:59,714:INFO:display_container: 2
2022-11-09 20:01:59,714:INFO:Ridge(random_state=123)
2022-11-09 20:01:59,714:INFO:create_model() successfully completed......................................
2022-11-09 20:01:59,859:INFO:SubProcess create_model() end ==================================
2022-11-09 20:01:59,860:INFO:Creating metrics dataframe
2022-11-09 20:01:59,895:INFO:Initializing Elastic Net
2022-11-09 20:01:59,896:INFO:Total runtime is 0.1248908837636312 minutes
2022-11-09 20:01:59,907:INFO:SubProcess create_model() called ==================================
2022-11-09 20:01:59,908:INFO:Initializing create_model()
2022-11-09 20:01:59,909:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc491519850>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc47b1ff0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:01:59,909:INFO:Checking exceptions
2022-11-09 20:01:59,912:INFO:Importing libraries
2022-11-09 20:01:59,913:INFO:Copying training dataset
2022-11-09 20:01:59,924:INFO:Defining folds
2022-11-09 20:01:59,926:INFO:Declaring metric variables
2022-11-09 20:01:59,938:INFO:Importing untrained model
2022-11-09 20:01:59,949:INFO:Elastic Net Imported successfully
2022-11-09 20:01:59,968:INFO:Starting cross validation
2022-11-09 20:01:59,970:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:02:00,294:INFO:Calculating mean and std
2022-11-09 20:02:00,302:INFO:Creating metrics dataframe
2022-11-09 20:02:00,313:INFO:Uploading results into container
2022-11-09 20:02:00,316:INFO:Uploading model into container now
2022-11-09 20:02:00,317:INFO:master_model_container: 4
2022-11-09 20:02:00,317:INFO:display_container: 2
2022-11-09 20:02:00,318:INFO:ElasticNet(random_state=123)
2022-11-09 20:02:00,318:INFO:create_model() successfully completed......................................
2022-11-09 20:02:00,461:INFO:SubProcess create_model() end ==================================
2022-11-09 20:02:00,461:INFO:Creating metrics dataframe
2022-11-09 20:02:00,482:INFO:Initializing Least Angle Regression
2022-11-09 20:02:00,483:INFO:Total runtime is 0.13466279109319051 minutes
2022-11-09 20:02:00,493:INFO:SubProcess create_model() called ==================================
2022-11-09 20:02:00,494:INFO:Initializing create_model()
2022-11-09 20:02:00,494:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc491519850>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc47b1ff0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:02:00,494:INFO:Checking exceptions
2022-11-09 20:02:00,497:INFO:Importing libraries
2022-11-09 20:02:00,498:INFO:Copying training dataset
2022-11-09 20:02:00,504:INFO:Defining folds
2022-11-09 20:02:00,504:INFO:Declaring metric variables
2022-11-09 20:02:00,520:INFO:Importing untrained model
2022-11-09 20:02:00,530:INFO:Least Angle Regression Imported successfully
2022-11-09 20:02:00,548:INFO:Starting cross validation
2022-11-09 20:02:00,552:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:02:00,601:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:02:00,617:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:02:00,662:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:02:00,695:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:02:00,732:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:02:00,773:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:02:00,794:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:02:00,816:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:02:00,847:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:02:00,860:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:02:00,881:INFO:Calculating mean and std
2022-11-09 20:02:00,884:INFO:Creating metrics dataframe
2022-11-09 20:02:00,892:INFO:Uploading results into container
2022-11-09 20:02:00,893:INFO:Uploading model into container now
2022-11-09 20:02:00,894:INFO:master_model_container: 5
2022-11-09 20:02:00,894:INFO:display_container: 2
2022-11-09 20:02:00,895:INFO:Lars(random_state=123)
2022-11-09 20:02:00,895:INFO:create_model() successfully completed......................................
2022-11-09 20:02:01,047:INFO:SubProcess create_model() end ==================================
2022-11-09 20:02:01,048:INFO:Creating metrics dataframe
2022-11-09 20:02:01,069:INFO:Initializing Lasso Least Angle Regression
2022-11-09 20:02:01,070:INFO:Total runtime is 0.14444199403127034 minutes
2022-11-09 20:02:01,078:INFO:SubProcess create_model() called ==================================
2022-11-09 20:02:01,079:INFO:Initializing create_model()
2022-11-09 20:02:01,080:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc491519850>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc47b1ff0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:02:01,080:INFO:Checking exceptions
2022-11-09 20:02:01,083:INFO:Importing libraries
2022-11-09 20:02:01,083:INFO:Copying training dataset
2022-11-09 20:02:01,092:INFO:Defining folds
2022-11-09 20:02:01,093:INFO:Declaring metric variables
2022-11-09 20:02:01,106:INFO:Importing untrained model
2022-11-09 20:02:01,117:INFO:Lasso Least Angle Regression Imported successfully
2022-11-09 20:02:01,151:INFO:Starting cross validation
2022-11-09 20:02:01,153:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:02:01,203:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-09 20:02:01,232:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-09 20:02:01,266:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-09 20:02:01,294:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-09 20:02:01,331:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-09 20:02:01,370:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-09 20:02:01,377:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-09 20:02:01,411:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-09 20:02:01,437:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-09 20:02:01,461:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-09 20:02:01,474:INFO:Calculating mean and std
2022-11-09 20:02:01,481:INFO:Creating metrics dataframe
2022-11-09 20:02:01,492:INFO:Uploading results into container
2022-11-09 20:02:01,492:INFO:Uploading model into container now
2022-11-09 20:02:01,493:INFO:master_model_container: 6
2022-11-09 20:02:01,493:INFO:display_container: 2
2022-11-09 20:02:01,494:INFO:LassoLars(random_state=123)
2022-11-09 20:02:01,494:INFO:create_model() successfully completed......................................
2022-11-09 20:02:01,637:INFO:SubProcess create_model() end ==================================
2022-11-09 20:02:01,638:INFO:Creating metrics dataframe
2022-11-09 20:02:01,662:INFO:Initializing Orthogonal Matching Pursuit
2022-11-09 20:02:01,664:INFO:Total runtime is 0.1543454051017761 minutes
2022-11-09 20:02:01,672:INFO:SubProcess create_model() called ==================================
2022-11-09 20:02:01,673:INFO:Initializing create_model()
2022-11-09 20:02:01,673:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc491519850>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc47b1ff0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:02:01,673:INFO:Checking exceptions
2022-11-09 20:02:01,676:INFO:Importing libraries
2022-11-09 20:02:01,677:INFO:Copying training dataset
2022-11-09 20:02:01,683:INFO:Defining folds
2022-11-09 20:02:01,684:INFO:Declaring metric variables
2022-11-09 20:02:01,697:INFO:Importing untrained model
2022-11-09 20:02:01,708:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-09 20:02:01,726:INFO:Starting cross validation
2022-11-09 20:02:01,728:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:02:01,774:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:02:01,793:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:02:01,844:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:02:01,862:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:02:01,909:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:02:01,952:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:02:01,972:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:02:02,011:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:02:02,012:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:02:02,047:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:02:02,065:INFO:Calculating mean and std
2022-11-09 20:02:02,072:INFO:Creating metrics dataframe
2022-11-09 20:02:02,085:INFO:Uploading results into container
2022-11-09 20:02:02,086:INFO:Uploading model into container now
2022-11-09 20:02:02,087:INFO:master_model_container: 7
2022-11-09 20:02:02,087:INFO:display_container: 2
2022-11-09 20:02:02,088:INFO:OrthogonalMatchingPursuit()
2022-11-09 20:02:02,088:INFO:create_model() successfully completed......................................
2022-11-09 20:02:02,231:INFO:SubProcess create_model() end ==================================
2022-11-09 20:02:02,231:INFO:Creating metrics dataframe
2022-11-09 20:02:02,251:INFO:Initializing Bayesian Ridge
2022-11-09 20:02:02,252:INFO:Total runtime is 0.16415073076883951 minutes
2022-11-09 20:02:02,262:INFO:SubProcess create_model() called ==================================
2022-11-09 20:02:02,263:INFO:Initializing create_model()
2022-11-09 20:02:02,264:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc491519850>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc47b1ff0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:02:02,264:INFO:Checking exceptions
2022-11-09 20:02:02,267:INFO:Importing libraries
2022-11-09 20:02:02,268:INFO:Copying training dataset
2022-11-09 20:02:02,274:INFO:Defining folds
2022-11-09 20:02:02,275:INFO:Declaring metric variables
2022-11-09 20:02:02,289:INFO:Importing untrained model
2022-11-09 20:02:02,301:INFO:Bayesian Ridge Imported successfully
2022-11-09 20:02:02,318:INFO:Starting cross validation
2022-11-09 20:02:02,322:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:02:02,665:INFO:Calculating mean and std
2022-11-09 20:02:02,668:INFO:Creating metrics dataframe
2022-11-09 20:02:02,683:INFO:Uploading results into container
2022-11-09 20:02:02,684:INFO:Uploading model into container now
2022-11-09 20:02:02,685:INFO:master_model_container: 8
2022-11-09 20:02:02,685:INFO:display_container: 2
2022-11-09 20:02:02,685:INFO:BayesianRidge()
2022-11-09 20:02:02,686:INFO:create_model() successfully completed......................................
2022-11-09 20:02:02,827:INFO:SubProcess create_model() end ==================================
2022-11-09 20:02:02,828:INFO:Creating metrics dataframe
2022-11-09 20:02:02,848:INFO:Initializing Passive Aggressive Regressor
2022-11-09 20:02:02,850:INFO:Total runtime is 0.17412441571553547 minutes
2022-11-09 20:02:02,858:INFO:SubProcess create_model() called ==================================
2022-11-09 20:02:02,860:INFO:Initializing create_model()
2022-11-09 20:02:02,860:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc491519850>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc47b1ff0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:02:02,860:INFO:Checking exceptions
2022-11-09 20:02:02,864:INFO:Importing libraries
2022-11-09 20:02:02,865:INFO:Copying training dataset
2022-11-09 20:02:02,870:INFO:Defining folds
2022-11-09 20:02:02,871:INFO:Declaring metric variables
2022-11-09 20:02:02,889:INFO:Importing untrained model
2022-11-09 20:02:02,902:INFO:Passive Aggressive Regressor Imported successfully
2022-11-09 20:02:02,922:INFO:Starting cross validation
2022-11-09 20:02:02,925:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:02:03,268:INFO:Calculating mean and std
2022-11-09 20:02:03,270:INFO:Creating metrics dataframe
2022-11-09 20:02:03,283:INFO:Uploading results into container
2022-11-09 20:02:03,285:INFO:Uploading model into container now
2022-11-09 20:02:03,287:INFO:master_model_container: 9
2022-11-09 20:02:03,287:INFO:display_container: 2
2022-11-09 20:02:03,288:INFO:PassiveAggressiveRegressor(random_state=123)
2022-11-09 20:02:03,288:INFO:create_model() successfully completed......................................
2022-11-09 20:02:03,431:INFO:SubProcess create_model() end ==================================
2022-11-09 20:02:03,431:INFO:Creating metrics dataframe
2022-11-09 20:02:03,455:INFO:Initializing Huber Regressor
2022-11-09 20:02:03,460:INFO:Total runtime is 0.18429091374079384 minutes
2022-11-09 20:02:03,475:INFO:SubProcess create_model() called ==================================
2022-11-09 20:02:03,476:INFO:Initializing create_model()
2022-11-09 20:02:03,476:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc491519850>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc47b1ff0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:02:03,476:INFO:Checking exceptions
2022-11-09 20:02:03,479:INFO:Importing libraries
2022-11-09 20:02:03,479:INFO:Copying training dataset
2022-11-09 20:02:03,484:INFO:Defining folds
2022-11-09 20:02:03,485:INFO:Declaring metric variables
2022-11-09 20:02:03,498:INFO:Importing untrained model
2022-11-09 20:02:03,514:INFO:Huber Regressor Imported successfully
2022-11-09 20:02:03,540:INFO:Starting cross validation
2022-11-09 20:02:03,546:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:02:03,675:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-09 20:02:03,691:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-09 20:02:03,791:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-09 20:02:03,847:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-09 20:02:03,928:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-09 20:02:03,961:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-09 20:02:04,036:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-09 20:02:04,086:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-09 20:02:04,147:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-09 20:02:04,192:INFO:Calculating mean and std
2022-11-09 20:02:04,195:INFO:Creating metrics dataframe
2022-11-09 20:02:04,212:INFO:Uploading results into container
2022-11-09 20:02:04,215:INFO:Uploading model into container now
2022-11-09 20:02:04,216:INFO:master_model_container: 10
2022-11-09 20:02:04,216:INFO:display_container: 2
2022-11-09 20:02:04,216:INFO:HuberRegressor()
2022-11-09 20:02:04,216:INFO:create_model() successfully completed......................................
2022-11-09 20:02:04,362:INFO:SubProcess create_model() end ==================================
2022-11-09 20:02:04,362:INFO:Creating metrics dataframe
2022-11-09 20:02:04,383:INFO:Initializing K Neighbors Regressor
2022-11-09 20:02:04,384:INFO:Total runtime is 0.19968285560607907 minutes
2022-11-09 20:02:04,394:INFO:SubProcess create_model() called ==================================
2022-11-09 20:02:04,395:INFO:Initializing create_model()
2022-11-09 20:02:04,395:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc491519850>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc47b1ff0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:02:04,396:INFO:Checking exceptions
2022-11-09 20:02:04,399:INFO:Importing libraries
2022-11-09 20:02:04,399:INFO:Copying training dataset
2022-11-09 20:02:04,408:INFO:Defining folds
2022-11-09 20:02:04,408:INFO:Declaring metric variables
2022-11-09 20:02:04,418:INFO:Importing untrained model
2022-11-09 20:02:04,430:INFO:K Neighbors Regressor Imported successfully
2022-11-09 20:02:04,447:INFO:Starting cross validation
2022-11-09 20:02:04,452:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:02:05,311:INFO:Calculating mean and std
2022-11-09 20:02:05,324:INFO:Creating metrics dataframe
2022-11-09 20:02:05,338:INFO:Uploading results into container
2022-11-09 20:02:05,340:INFO:Uploading model into container now
2022-11-09 20:02:05,342:INFO:master_model_container: 11
2022-11-09 20:02:05,343:INFO:display_container: 2
2022-11-09 20:02:05,345:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-09 20:02:05,345:INFO:create_model() successfully completed......................................
2022-11-09 20:02:05,738:INFO:SubProcess create_model() end ==================================
2022-11-09 20:02:05,739:INFO:Creating metrics dataframe
2022-11-09 20:02:05,787:INFO:Initializing Decision Tree Regressor
2022-11-09 20:02:05,788:INFO:Total runtime is 0.2230847398440043 minutes
2022-11-09 20:02:05,810:INFO:SubProcess create_model() called ==================================
2022-11-09 20:02:05,813:INFO:Initializing create_model()
2022-11-09 20:02:05,814:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc491519850>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc47b1ff0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:02:05,815:INFO:Checking exceptions
2022-11-09 20:02:05,821:INFO:Importing libraries
2022-11-09 20:02:05,821:INFO:Copying training dataset
2022-11-09 20:02:05,844:INFO:Defining folds
2022-11-09 20:02:05,845:INFO:Declaring metric variables
2022-11-09 20:02:05,862:INFO:Importing untrained model
2022-11-09 20:02:05,873:INFO:Decision Tree Regressor Imported successfully
2022-11-09 20:02:05,891:INFO:Starting cross validation
2022-11-09 20:02:05,895:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:02:06,278:INFO:Calculating mean and std
2022-11-09 20:02:06,282:INFO:Creating metrics dataframe
2022-11-09 20:02:06,290:INFO:Uploading results into container
2022-11-09 20:02:06,292:INFO:Uploading model into container now
2022-11-09 20:02:06,292:INFO:master_model_container: 12
2022-11-09 20:02:06,293:INFO:display_container: 2
2022-11-09 20:02:06,294:INFO:DecisionTreeRegressor(random_state=123)
2022-11-09 20:02:06,294:INFO:create_model() successfully completed......................................
2022-11-09 20:02:06,467:INFO:SubProcess create_model() end ==================================
2022-11-09 20:02:06,467:INFO:Creating metrics dataframe
2022-11-09 20:02:06,492:INFO:Initializing Random Forest Regressor
2022-11-09 20:02:06,492:INFO:Total runtime is 0.23481508096059162 minutes
2022-11-09 20:02:06,501:INFO:SubProcess create_model() called ==================================
2022-11-09 20:02:06,504:INFO:Initializing create_model()
2022-11-09 20:02:06,505:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc491519850>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc47b1ff0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:02:06,505:INFO:Checking exceptions
2022-11-09 20:02:06,508:INFO:Importing libraries
2022-11-09 20:02:06,508:INFO:Copying training dataset
2022-11-09 20:02:06,520:INFO:Defining folds
2022-11-09 20:02:06,521:INFO:Declaring metric variables
2022-11-09 20:02:06,537:INFO:Importing untrained model
2022-11-09 20:02:06,548:INFO:Random Forest Regressor Imported successfully
2022-11-09 20:02:06,566:INFO:Starting cross validation
2022-11-09 20:02:06,569:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:02:11,165:INFO:Calculating mean and std
2022-11-09 20:02:11,170:INFO:Creating metrics dataframe
2022-11-09 20:02:11,182:INFO:Uploading results into container
2022-11-09 20:02:11,183:INFO:Uploading model into container now
2022-11-09 20:02:11,184:INFO:master_model_container: 13
2022-11-09 20:02:11,184:INFO:display_container: 2
2022-11-09 20:02:11,185:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-09 20:02:11,185:INFO:create_model() successfully completed......................................
2022-11-09 20:02:11,333:INFO:SubProcess create_model() end ==================================
2022-11-09 20:02:11,334:INFO:Creating metrics dataframe
2022-11-09 20:02:11,355:INFO:Initializing Extra Trees Regressor
2022-11-09 20:02:11,356:INFO:Total runtime is 0.3158785303433736 minutes
2022-11-09 20:02:11,367:INFO:SubProcess create_model() called ==================================
2022-11-09 20:02:11,368:INFO:Initializing create_model()
2022-11-09 20:02:11,368:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc491519850>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc47b1ff0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:02:11,369:INFO:Checking exceptions
2022-11-09 20:02:11,372:INFO:Importing libraries
2022-11-09 20:02:11,372:INFO:Copying training dataset
2022-11-09 20:02:11,378:INFO:Defining folds
2022-11-09 20:02:11,379:INFO:Declaring metric variables
2022-11-09 20:02:11,390:INFO:Importing untrained model
2022-11-09 20:02:11,405:INFO:Extra Trees Regressor Imported successfully
2022-11-09 20:02:11,424:INFO:Starting cross validation
2022-11-09 20:02:11,428:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:02:14,164:INFO:Calculating mean and std
2022-11-09 20:02:14,169:INFO:Creating metrics dataframe
2022-11-09 20:02:14,183:INFO:Uploading results into container
2022-11-09 20:02:14,184:INFO:Uploading model into container now
2022-11-09 20:02:14,185:INFO:master_model_container: 14
2022-11-09 20:02:14,185:INFO:display_container: 2
2022-11-09 20:02:14,185:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-09 20:02:14,186:INFO:create_model() successfully completed......................................
2022-11-09 20:02:14,333:INFO:SubProcess create_model() end ==================================
2022-11-09 20:02:14,334:INFO:Creating metrics dataframe
2022-11-09 20:02:14,358:INFO:Initializing AdaBoost Regressor
2022-11-09 20:02:14,359:INFO:Total runtime is 0.36593419710795083 minutes
2022-11-09 20:02:14,370:INFO:SubProcess create_model() called ==================================
2022-11-09 20:02:14,370:INFO:Initializing create_model()
2022-11-09 20:02:14,371:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc491519850>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc47b1ff0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:02:14,371:INFO:Checking exceptions
2022-11-09 20:02:14,374:INFO:Importing libraries
2022-11-09 20:02:14,374:INFO:Copying training dataset
2022-11-09 20:02:14,382:INFO:Defining folds
2022-11-09 20:02:14,382:INFO:Declaring metric variables
2022-11-09 20:02:14,392:INFO:Importing untrained model
2022-11-09 20:02:14,402:INFO:AdaBoost Regressor Imported successfully
2022-11-09 20:02:14,422:INFO:Starting cross validation
2022-11-09 20:02:14,424:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:02:15,700:INFO:Calculating mean and std
2022-11-09 20:02:15,710:INFO:Creating metrics dataframe
2022-11-09 20:02:15,718:INFO:Uploading results into container
2022-11-09 20:02:15,719:INFO:Uploading model into container now
2022-11-09 20:02:15,719:INFO:master_model_container: 15
2022-11-09 20:02:15,720:INFO:display_container: 2
2022-11-09 20:02:15,720:INFO:AdaBoostRegressor(random_state=123)
2022-11-09 20:02:15,720:INFO:create_model() successfully completed......................................
2022-11-09 20:02:15,862:INFO:SubProcess create_model() end ==================================
2022-11-09 20:02:15,863:INFO:Creating metrics dataframe
2022-11-09 20:02:15,885:INFO:Initializing Gradient Boosting Regressor
2022-11-09 20:02:15,886:INFO:Total runtime is 0.39138182799021404 minutes
2022-11-09 20:02:15,896:INFO:SubProcess create_model() called ==================================
2022-11-09 20:02:15,897:INFO:Initializing create_model()
2022-11-09 20:02:15,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc491519850>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc47b1ff0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:02:15,898:INFO:Checking exceptions
2022-11-09 20:02:15,901:INFO:Importing libraries
2022-11-09 20:02:15,901:INFO:Copying training dataset
2022-11-09 20:02:15,910:INFO:Defining folds
2022-11-09 20:02:15,910:INFO:Declaring metric variables
2022-11-09 20:02:15,922:INFO:Importing untrained model
2022-11-09 20:02:15,930:INFO:Gradient Boosting Regressor Imported successfully
2022-11-09 20:02:15,947:INFO:Starting cross validation
2022-11-09 20:02:15,953:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:02:17,803:INFO:Calculating mean and std
2022-11-09 20:02:17,808:INFO:Creating metrics dataframe
2022-11-09 20:02:17,821:INFO:Uploading results into container
2022-11-09 20:02:17,821:INFO:Uploading model into container now
2022-11-09 20:02:17,822:INFO:master_model_container: 16
2022-11-09 20:02:17,822:INFO:display_container: 2
2022-11-09 20:02:17,823:INFO:GradientBoostingRegressor(random_state=123)
2022-11-09 20:02:17,823:INFO:create_model() successfully completed......................................
2022-11-09 20:02:17,965:INFO:SubProcess create_model() end ==================================
2022-11-09 20:02:17,966:INFO:Creating metrics dataframe
2022-11-09 20:02:18,002:INFO:Initializing Light Gradient Boosting Machine
2022-11-09 20:02:18,004:INFO:Total runtime is 0.42667677005132043 minutes
2022-11-09 20:02:18,010:INFO:SubProcess create_model() called ==================================
2022-11-09 20:02:18,012:INFO:Initializing create_model()
2022-11-09 20:02:18,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc491519850>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc47b1ff0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:02:18,015:INFO:Checking exceptions
2022-11-09 20:02:18,018:INFO:Importing libraries
2022-11-09 20:02:18,018:INFO:Copying training dataset
2022-11-09 20:02:18,023:INFO:Defining folds
2022-11-09 20:02:18,023:INFO:Declaring metric variables
2022-11-09 20:02:18,035:INFO:Importing untrained model
2022-11-09 20:02:18,050:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-09 20:02:18,068:INFO:Starting cross validation
2022-11-09 20:02:18,069:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:02:19,689:INFO:Calculating mean and std
2022-11-09 20:02:19,693:INFO:Creating metrics dataframe
2022-11-09 20:02:19,704:INFO:Uploading results into container
2022-11-09 20:02:19,705:INFO:Uploading model into container now
2022-11-09 20:02:19,706:INFO:master_model_container: 17
2022-11-09 20:02:19,706:INFO:display_container: 2
2022-11-09 20:02:19,707:INFO:LGBMRegressor(random_state=123)
2022-11-09 20:02:19,707:INFO:create_model() successfully completed......................................
2022-11-09 20:02:19,851:INFO:SubProcess create_model() end ==================================
2022-11-09 20:02:19,851:INFO:Creating metrics dataframe
2022-11-09 20:02:19,873:INFO:Initializing Dummy Regressor
2022-11-09 20:02:19,874:INFO:Total runtime is 0.4578503648440044 minutes
2022-11-09 20:02:19,884:INFO:SubProcess create_model() called ==================================
2022-11-09 20:02:19,889:INFO:Initializing create_model()
2022-11-09 20:02:19,896:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc491519850>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc47b1ff0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:02:19,897:INFO:Checking exceptions
2022-11-09 20:02:19,899:INFO:Importing libraries
2022-11-09 20:02:19,899:INFO:Copying training dataset
2022-11-09 20:02:19,904:INFO:Defining folds
2022-11-09 20:02:19,905:INFO:Declaring metric variables
2022-11-09 20:02:19,917:INFO:Importing untrained model
2022-11-09 20:02:19,928:INFO:Dummy Regressor Imported successfully
2022-11-09 20:02:19,946:INFO:Starting cross validation
2022-11-09 20:02:19,949:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:02:20,222:INFO:Calculating mean and std
2022-11-09 20:02:20,225:INFO:Creating metrics dataframe
2022-11-09 20:02:20,233:INFO:Uploading results into container
2022-11-09 20:02:20,234:INFO:Uploading model into container now
2022-11-09 20:02:20,235:INFO:master_model_container: 18
2022-11-09 20:02:20,235:INFO:display_container: 2
2022-11-09 20:02:20,236:INFO:DummyRegressor()
2022-11-09 20:02:20,236:INFO:create_model() successfully completed......................................
2022-11-09 20:02:20,384:INFO:SubProcess create_model() end ==================================
2022-11-09 20:02:20,384:INFO:Creating metrics dataframe
2022-11-09 20:02:20,442:INFO:Initializing create_model()
2022-11-09 20:02:20,443:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc491519850>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:02:20,443:INFO:Checking exceptions
2022-11-09 20:02:20,450:INFO:Importing libraries
2022-11-09 20:02:20,452:INFO:Copying training dataset
2022-11-09 20:02:20,456:INFO:Defining folds
2022-11-09 20:02:20,456:INFO:Declaring metric variables
2022-11-09 20:02:20,457:INFO:Importing untrained model
2022-11-09 20:02:20,457:INFO:Declaring custom model
2022-11-09 20:02:20,458:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-09 20:02:20,459:INFO:Cross validation set to False
2022-11-09 20:02:20,459:INFO:Fitting Model
2022-11-09 20:02:20,494:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:02:20,499:INFO:OrthogonalMatchingPursuit()
2022-11-09 20:02:20,500:INFO:create_model() successfully completed......................................
2022-11-09 20:02:20,735:INFO:master_model_container: 18
2022-11-09 20:02:20,736:INFO:display_container: 2
2022-11-09 20:02:20,737:INFO:OrthogonalMatchingPursuit()
2022-11-09 20:02:20,740:INFO:compare_models() successfully completed......................................
2022-11-09 20:10:29,544:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2022-11-09 20:10:31,150:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  ConvergenceWarning,

2022-11-09 20:14:09,774:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2022-11-09 20:15:23,123:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-09 20:15:23,169:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-09 20:15:23,170:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-09 20:15:23,170:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-09 20:15:26,624:INFO:Soft dependency imported: prophet: 1.1.1
2022-11-09 20:15:27,649:INFO:PyCaret RegressionExperiment
2022-11-09 20:15:27,650:INFO:Logging name: FullData
2022-11-09 20:15:27,650:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-09 20:15:27,650:INFO:version 3.0.0.rc4
2022-11-09 20:15:27,651:INFO:Initializing setup()
2022-11-09 20:15:27,651:INFO:self.USI: cb38
2022-11-09 20:15:27,651:INFO:self.variable_keys: {'logging_param', 'memory', '_all_metrics', '_all_models_internal', 'target_param', 'y', 'X_train', 'y_train', 'log_plots_param', 'fold_generator', 'variable_keys', 'data', 'USI', 'exp_id', 'idx', 'X_test', 'exp_name_log', 'pipeline', '_gpu_n_jobs_param', 'html_param', 'transform_target_method_param', 'seed', '_all_models', 'n_jobs_param', 'display_container', 'X', 'master_model_container', 'transform_target_param', 'y_test', 'fold_groups_param', '_available_plots', 'gpu_param', 'fold_shuffle_param', '_ml_usecase'}
2022-11-09 20:15:27,651:INFO:Checking environment
2022-11-09 20:15:27,651:INFO:python_version: 3.7.15
2022-11-09 20:15:27,651:INFO:python_build: ('default', 'Oct 12 2022 19:14:55')
2022-11-09 20:15:27,652:INFO:machine: x86_64
2022-11-09 20:15:27,652:INFO:platform: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-09 20:15:27,652:INFO:Memory: svmem(total=13616361472, available=12461654016, percent=8.5, used=921858048, free=11430993920, active=463998976, inactive=1530355712, buffers=72609792, cached=1190899712, shared=1306624, slab=114466816)
2022-11-09 20:15:27,654:INFO:Physical Core: 1
2022-11-09 20:15:27,654:INFO:Logical Core: 2
2022-11-09 20:15:27,654:INFO:Checking libraries
2022-11-09 20:15:27,654:INFO:System:
2022-11-09 20:15:27,654:INFO:    python: 3.7.15 (default, Oct 12 2022, 19:14:55)  [GCC 7.5.0]
2022-11-09 20:15:27,655:INFO:executable: /usr/bin/python3
2022-11-09 20:15:27,655:INFO:   machine: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-09 20:15:27,655:INFO:PyCaret required dependencies:
2022-11-09 20:15:27,655:INFO:                 pip: 21.1.3
2022-11-09 20:15:27,656:INFO:          setuptools: 57.4.0
2022-11-09 20:15:27,656:INFO:             pycaret: 3.0.0rc4
2022-11-09 20:15:27,656:INFO:             IPython: 7.9.0
2022-11-09 20:15:27,656:INFO:          ipywidgets: 7.7.1
2022-11-09 20:15:27,656:INFO:                tqdm: 4.64.1
2022-11-09 20:15:27,656:INFO:               numpy: 1.21.6
2022-11-09 20:15:27,656:INFO:              pandas: 1.3.5
2022-11-09 20:15:27,657:INFO:              jinja2: 3.0.0
2022-11-09 20:15:27,664:INFO:               scipy: 1.7.3
2022-11-09 20:15:27,664:INFO:              joblib: 1.2.0
2022-11-09 20:15:27,664:INFO:             sklearn: 1.0.2
2022-11-09 20:15:27,664:INFO:                pyod: 1.0.6
2022-11-09 20:15:27,665:INFO:            imblearn: 0.8.1
2022-11-09 20:15:27,665:INFO:   category_encoders: 2.5.1.post0
2022-11-09 20:15:27,665:INFO:            lightgbm: 3.3.3
2022-11-09 20:15:27,665:INFO:               numba: 0.55.2
2022-11-09 20:15:27,665:INFO:            requests: 2.28.1
2022-11-09 20:15:27,665:INFO:          matplotlib: 3.5.3
2022-11-09 20:15:27,666:INFO:          scikitplot: 0.3.7
2022-11-09 20:15:27,666:INFO:         yellowbrick: 1.5
2022-11-09 20:15:27,666:INFO:              plotly: 5.5.0
2022-11-09 20:15:27,666:INFO:             kaleido: 0.2.1
2022-11-09 20:15:27,666:INFO:         statsmodels: 0.12.2
2022-11-09 20:15:27,666:INFO:              sktime: 0.13.4
2022-11-09 20:15:27,667:INFO:               tbats: 1.1.1
2022-11-09 20:15:27,667:INFO:            pmdarima: 1.8.5
2022-11-09 20:15:27,667:INFO:              psutil: 5.9.4
2022-11-09 20:15:27,667:INFO:PyCaret optional dependencies:
2022-11-09 20:15:27,683:INFO:                shap: Not installed
2022-11-09 20:15:27,683:INFO:           interpret: Not installed
2022-11-09 20:15:27,683:INFO:                umap: Not installed
2022-11-09 20:15:27,684:INFO:    pandas_profiling: 1.4.1
2022-11-09 20:15:27,684:INFO:  explainerdashboard: Not installed
2022-11-09 20:15:27,684:INFO:             autoviz: Not installed
2022-11-09 20:15:27,684:INFO:           fairlearn: Not installed
2022-11-09 20:15:27,684:INFO:             xgboost: 0.90
2022-11-09 20:15:27,686:INFO:            catboost: Not installed
2022-11-09 20:15:27,687:INFO:              kmodes: Not installed
2022-11-09 20:15:27,687:INFO:             mlxtend: 0.14.0
2022-11-09 20:15:27,687:INFO:       statsforecast: Not installed
2022-11-09 20:15:27,687:INFO:        tune_sklearn: Not installed
2022-11-09 20:15:27,687:INFO:                 ray: Not installed
2022-11-09 20:15:27,687:INFO:            hyperopt: 0.1.2
2022-11-09 20:15:27,688:INFO:              optuna: Not installed
2022-11-09 20:15:27,688:INFO:               skopt: Not installed
2022-11-09 20:15:27,688:INFO:              mlflow: Not installed
2022-11-09 20:15:27,688:INFO:              gradio: Not installed
2022-11-09 20:15:27,688:INFO:             fastapi: Not installed
2022-11-09 20:15:27,688:INFO:             uvicorn: Not installed
2022-11-09 20:15:27,688:INFO:              m2cgen: Not installed
2022-11-09 20:15:27,689:INFO:           evidently: Not installed
2022-11-09 20:15:27,689:INFO:                nltk: 3.7
2022-11-09 20:15:27,689:INFO:            pyLDAvis: Not installed
2022-11-09 20:15:27,689:INFO:              gensim: 3.6.0
2022-11-09 20:15:27,689:INFO:               spacy: 3.4.2
2022-11-09 20:15:27,689:INFO:           wordcloud: 1.8.2.2
2022-11-09 20:15:27,689:INFO:            textblob: 0.15.3
2022-11-09 20:15:27,689:INFO:               fugue: Not installed
2022-11-09 20:15:27,690:INFO:           streamlit: Not installed
2022-11-09 20:15:27,690:INFO:             prophet: 1.1.1
2022-11-09 20:15:27,690:INFO:None
2022-11-09 20:15:27,690:INFO:Set up data.
2022-11-09 20:15:27,714:INFO:Set up train/test split.
2022-11-09 20:15:27,721:INFO:Set up index.
2022-11-09 20:15:27,722:INFO:Set up folding strategy.
2022-11-09 20:15:27,722:INFO:Assigning column types.
2022-11-09 20:15:27,746:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-09 20:15:27,747:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-09 20:15:27,757:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-09 20:15:27,767:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-09 20:15:27,899:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-09 20:15:27,997:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-09 20:15:28,000:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:15:28,001:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:15:28,322:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:15:28,324:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-09 20:15:28,343:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-09 20:15:28,377:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-09 20:15:28,564:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-09 20:15:28,663:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-09 20:15:28,665:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:15:28,672:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:15:28,673:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:15:28,673:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-09 20:15:28,691:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-09 20:15:28,704:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-09 20:15:28,833:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-09 20:15:29,034:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-09 20:15:29,043:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:15:29,043:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:15:29,044:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:15:29,059:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-09 20:15:29,082:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-09 20:15:29,447:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-09 20:15:29,677:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-09 20:15:29,678:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:15:29,679:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:15:29,680:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:15:29,681:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-09 20:15:29,717:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-09 20:15:29,862:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-09 20:15:29,968:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-09 20:15:29,970:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:15:29,971:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:15:29,972:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:15:29,992:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-09 20:15:30,120:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-09 20:15:30,228:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-09 20:15:30,230:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:15:30,230:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:15:30,231:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:15:30,231:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-09 20:15:30,417:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-09 20:15:30,602:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-09 20:15:30,604:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:15:30,604:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:15:30,605:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:15:30,846:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-09 20:15:30,962:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-09 20:15:30,963:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:15:30,964:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:15:30,964:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:15:30,965:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-09 20:15:31,151:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-09 20:15:31,308:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:15:31,315:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:15:31,316:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:15:31,555:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-09 20:15:31,668:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:15:31,669:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:15:31,669:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:15:31,670:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-09 20:15:32,007:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:15:32,008:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:15:32,008:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:15:32,325:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:15:32,326:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:15:32,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:15:32,331:INFO:Preparing preprocessing pipeline...
2022-11-09 20:15:32,333:INFO:Set up simple imputation.
2022-11-09 20:15:32,333:INFO:Set up variance threshold.
2022-11-09 20:15:32,383:INFO:Finished creating preprocessing pipeline.
2022-11-09 20:15:32,428:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-09 20:15:32,428:INFO:Creating final display dataframe.
2022-11-09 20:15:32,723:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 12)
4         Train data shape    (607, 12)
5          Test data shape    (261, 12)
6         Numeric features           11
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         cb38
2022-11-09 20:15:33,148:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:15:33,149:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:15:33,149:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:15:33,463:INFO:Soft dependency imported: xgboost: 0.90
2022-11-09 20:15:33,464:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-09 20:15:33,465:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-09 20:15:33,476:INFO:setup() successfully completed in 5.84s...............
2022-11-09 20:15:33,476:INFO:Initializing compare_models()
2022-11-09 20:15:33,477:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcc8b2fc410>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fcc8b2fc410>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-09 20:15:33,477:INFO:Checking exceptions
2022-11-09 20:15:33,479:INFO:Preparing display monitor
2022-11-09 20:15:33,616:INFO:Initializing Linear Regression
2022-11-09 20:15:33,616:INFO:Total runtime is 6.977717081705729e-06 minutes
2022-11-09 20:15:33,626:INFO:SubProcess create_model() called ==================================
2022-11-09 20:15:33,627:INFO:Initializing create_model()
2022-11-09 20:15:33,627:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcc8b2fc410>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcc75d1ba90>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:15:33,628:INFO:Checking exceptions
2022-11-09 20:15:33,630:INFO:Importing libraries
2022-11-09 20:15:33,631:INFO:Copying training dataset
2022-11-09 20:15:33,635:INFO:Defining folds
2022-11-09 20:15:33,635:INFO:Declaring metric variables
2022-11-09 20:15:33,645:INFO:Importing untrained model
2022-11-09 20:15:33,667:INFO:Linear Regression Imported successfully
2022-11-09 20:15:33,707:INFO:Starting cross validation
2022-11-09 20:15:33,720:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:15:41,544:INFO:Calculating mean and std
2022-11-09 20:15:41,557:INFO:Creating metrics dataframe
2022-11-09 20:15:41,581:INFO:Uploading results into container
2022-11-09 20:15:41,582:INFO:Uploading model into container now
2022-11-09 20:15:41,583:INFO:master_model_container: 1
2022-11-09 20:15:41,584:INFO:display_container: 2
2022-11-09 20:15:41,584:INFO:LinearRegression(n_jobs=-1)
2022-11-09 20:15:41,584:INFO:create_model() successfully completed......................................
2022-11-09 20:15:41,954:INFO:SubProcess create_model() end ==================================
2022-11-09 20:15:41,957:INFO:Creating metrics dataframe
2022-11-09 20:15:41,991:INFO:Initializing Lasso Regression
2022-11-09 20:15:41,994:INFO:Total runtime is 0.1396398146947225 minutes
2022-11-09 20:15:42,013:INFO:SubProcess create_model() called ==================================
2022-11-09 20:15:42,017:INFO:Initializing create_model()
2022-11-09 20:15:42,017:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcc8b2fc410>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcc75d1ba90>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:15:42,017:INFO:Checking exceptions
2022-11-09 20:15:42,021:INFO:Importing libraries
2022-11-09 20:15:42,021:INFO:Copying training dataset
2022-11-09 20:15:42,047:INFO:Defining folds
2022-11-09 20:15:42,047:INFO:Declaring metric variables
2022-11-09 20:15:42,077:INFO:Importing untrained model
2022-11-09 20:15:42,097:INFO:Lasso Regression Imported successfully
2022-11-09 20:15:42,137:INFO:Starting cross validation
2022-11-09 20:15:42,143:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:15:42,928:INFO:Calculating mean and std
2022-11-09 20:15:42,943:INFO:Creating metrics dataframe
2022-11-09 20:15:42,962:INFO:Uploading results into container
2022-11-09 20:15:42,963:INFO:Uploading model into container now
2022-11-09 20:15:42,964:INFO:master_model_container: 2
2022-11-09 20:15:42,964:INFO:display_container: 2
2022-11-09 20:15:42,965:INFO:Lasso(random_state=123)
2022-11-09 20:15:42,965:INFO:create_model() successfully completed......................................
2022-11-09 20:15:43,417:INFO:SubProcess create_model() end ==================================
2022-11-09 20:15:43,419:INFO:Creating metrics dataframe
2022-11-09 20:15:43,463:INFO:Initializing Ridge Regression
2022-11-09 20:15:43,472:INFO:Total runtime is 0.16427011887232462 minutes
2022-11-09 20:15:43,488:INFO:SubProcess create_model() called ==================================
2022-11-09 20:15:43,498:INFO:Initializing create_model()
2022-11-09 20:15:43,499:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcc8b2fc410>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcc75d1ba90>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:15:43,499:INFO:Checking exceptions
2022-11-09 20:15:43,502:INFO:Importing libraries
2022-11-09 20:15:43,510:INFO:Copying training dataset
2022-11-09 20:15:43,536:INFO:Defining folds
2022-11-09 20:15:43,542:INFO:Declaring metric variables
2022-11-09 20:15:43,563:INFO:Importing untrained model
2022-11-09 20:15:43,576:INFO:Ridge Regression Imported successfully
2022-11-09 20:15:43,612:INFO:Starting cross validation
2022-11-09 20:15:43,617:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:15:44,285:INFO:Calculating mean and std
2022-11-09 20:15:44,292:INFO:Creating metrics dataframe
2022-11-09 20:15:44,322:INFO:Uploading results into container
2022-11-09 20:15:44,323:INFO:Uploading model into container now
2022-11-09 20:15:44,324:INFO:master_model_container: 3
2022-11-09 20:15:44,324:INFO:display_container: 2
2022-11-09 20:15:44,325:INFO:Ridge(random_state=123)
2022-11-09 20:15:44,336:INFO:create_model() successfully completed......................................
2022-11-09 20:15:44,974:INFO:SubProcess create_model() end ==================================
2022-11-09 20:15:44,978:INFO:Creating metrics dataframe
2022-11-09 20:15:45,031:INFO:Initializing Elastic Net
2022-11-09 20:15:45,031:INFO:Total runtime is 0.19025441010793048 minutes
2022-11-09 20:15:45,066:INFO:SubProcess create_model() called ==================================
2022-11-09 20:15:45,067:INFO:Initializing create_model()
2022-11-09 20:15:45,067:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcc8b2fc410>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcc75d1ba90>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:15:45,068:INFO:Checking exceptions
2022-11-09 20:15:45,073:INFO:Importing libraries
2022-11-09 20:15:45,085:INFO:Copying training dataset
2022-11-09 20:15:45,107:INFO:Defining folds
2022-11-09 20:15:45,108:INFO:Declaring metric variables
2022-11-09 20:15:45,152:INFO:Importing untrained model
2022-11-09 20:15:45,190:INFO:Elastic Net Imported successfully
2022-11-09 20:15:45,274:INFO:Starting cross validation
2022-11-09 20:15:45,282:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:15:46,001:INFO:Calculating mean and std
2022-11-09 20:15:46,007:INFO:Creating metrics dataframe
2022-11-09 20:15:46,017:INFO:Uploading results into container
2022-11-09 20:15:46,018:INFO:Uploading model into container now
2022-11-09 20:15:46,019:INFO:master_model_container: 4
2022-11-09 20:15:46,019:INFO:display_container: 2
2022-11-09 20:15:46,020:INFO:ElasticNet(random_state=123)
2022-11-09 20:15:46,020:INFO:create_model() successfully completed......................................
2022-11-09 20:15:46,170:INFO:SubProcess create_model() end ==================================
2022-11-09 20:15:46,170:INFO:Creating metrics dataframe
2022-11-09 20:15:46,192:INFO:Initializing Least Angle Regression
2022-11-09 20:15:46,193:INFO:Total runtime is 0.209618079662323 minutes
2022-11-09 20:15:46,203:INFO:SubProcess create_model() called ==================================
2022-11-09 20:15:46,204:INFO:Initializing create_model()
2022-11-09 20:15:46,204:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcc8b2fc410>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcc75d1ba90>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:15:46,204:INFO:Checking exceptions
2022-11-09 20:15:46,208:INFO:Importing libraries
2022-11-09 20:15:46,208:INFO:Copying training dataset
2022-11-09 20:15:46,214:INFO:Defining folds
2022-11-09 20:15:46,214:INFO:Declaring metric variables
2022-11-09 20:15:46,230:INFO:Importing untrained model
2022-11-09 20:15:46,239:INFO:Least Angle Regression Imported successfully
2022-11-09 20:15:46,260:INFO:Starting cross validation
2022-11-09 20:15:46,262:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:15:46,306:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:15:46,345:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:15:46,369:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:15:46,405:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:15:46,470:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:15:46,512:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:15:46,521:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:15:46,555:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:15:46,578:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:15:46,598:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:15:46,614:INFO:Calculating mean and std
2022-11-09 20:15:46,616:INFO:Creating metrics dataframe
2022-11-09 20:15:46,627:INFO:Uploading results into container
2022-11-09 20:15:46,628:INFO:Uploading model into container now
2022-11-09 20:15:46,629:INFO:master_model_container: 5
2022-11-09 20:15:46,630:INFO:display_container: 2
2022-11-09 20:15:46,630:INFO:Lars(random_state=123)
2022-11-09 20:15:46,631:INFO:create_model() successfully completed......................................
2022-11-09 20:15:46,780:INFO:SubProcess create_model() end ==================================
2022-11-09 20:15:46,781:INFO:Creating metrics dataframe
2022-11-09 20:15:46,809:INFO:Initializing Lasso Least Angle Regression
2022-11-09 20:15:46,812:INFO:Total runtime is 0.21993660926818848 minutes
2022-11-09 20:15:46,822:INFO:SubProcess create_model() called ==================================
2022-11-09 20:15:46,823:INFO:Initializing create_model()
2022-11-09 20:15:46,823:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcc8b2fc410>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcc75d1ba90>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:15:46,823:INFO:Checking exceptions
2022-11-09 20:15:46,826:INFO:Importing libraries
2022-11-09 20:15:46,827:INFO:Copying training dataset
2022-11-09 20:15:46,832:INFO:Defining folds
2022-11-09 20:15:46,833:INFO:Declaring metric variables
2022-11-09 20:15:46,848:INFO:Importing untrained model
2022-11-09 20:15:46,863:INFO:Lasso Least Angle Regression Imported successfully
2022-11-09 20:15:46,883:INFO:Starting cross validation
2022-11-09 20:15:46,885:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:15:46,941:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-09 20:15:46,970:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-09 20:15:47,009:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-09 20:15:47,028:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-09 20:15:47,085:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-09 20:15:47,127:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-09 20:15:47,142:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-09 20:15:47,168:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-09 20:15:47,196:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-09 20:15:47,210:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-09 20:15:47,226:INFO:Calculating mean and std
2022-11-09 20:15:47,230:INFO:Creating metrics dataframe
2022-11-09 20:15:47,238:INFO:Uploading results into container
2022-11-09 20:15:47,241:INFO:Uploading model into container now
2022-11-09 20:15:47,242:INFO:master_model_container: 6
2022-11-09 20:15:47,243:INFO:display_container: 2
2022-11-09 20:15:47,244:INFO:LassoLars(random_state=123)
2022-11-09 20:15:47,244:INFO:create_model() successfully completed......................................
2022-11-09 20:15:47,395:INFO:SubProcess create_model() end ==================================
2022-11-09 20:15:47,396:INFO:Creating metrics dataframe
2022-11-09 20:15:47,416:INFO:Initializing Orthogonal Matching Pursuit
2022-11-09 20:15:47,417:INFO:Total runtime is 0.2300169547398885 minutes
2022-11-09 20:15:47,426:INFO:SubProcess create_model() called ==================================
2022-11-09 20:15:47,427:INFO:Initializing create_model()
2022-11-09 20:15:47,427:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcc8b2fc410>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcc75d1ba90>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:15:47,427:INFO:Checking exceptions
2022-11-09 20:15:47,430:INFO:Importing libraries
2022-11-09 20:15:47,431:INFO:Copying training dataset
2022-11-09 20:15:47,436:INFO:Defining folds
2022-11-09 20:15:47,437:INFO:Declaring metric variables
2022-11-09 20:15:47,450:INFO:Importing untrained model
2022-11-09 20:15:47,460:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-09 20:15:47,479:INFO:Starting cross validation
2022-11-09 20:15:47,481:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:15:47,526:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:15:47,561:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:15:47,598:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:15:47,631:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:15:47,669:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:15:47,710:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:15:47,732:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:15:47,751:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:15:47,790:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:15:47,804:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:15:47,824:INFO:Calculating mean and std
2022-11-09 20:15:47,830:INFO:Creating metrics dataframe
2022-11-09 20:15:47,842:INFO:Uploading results into container
2022-11-09 20:15:47,844:INFO:Uploading model into container now
2022-11-09 20:15:47,844:INFO:master_model_container: 7
2022-11-09 20:15:47,845:INFO:display_container: 2
2022-11-09 20:15:47,845:INFO:OrthogonalMatchingPursuit()
2022-11-09 20:15:47,845:INFO:create_model() successfully completed......................................
2022-11-09 20:15:48,062:INFO:SubProcess create_model() end ==================================
2022-11-09 20:15:48,062:INFO:Creating metrics dataframe
2022-11-09 20:15:48,101:INFO:Initializing Bayesian Ridge
2022-11-09 20:15:48,103:INFO:Total runtime is 0.24144978920618693 minutes
2022-11-09 20:15:48,113:INFO:SubProcess create_model() called ==================================
2022-11-09 20:15:48,116:INFO:Initializing create_model()
2022-11-09 20:15:48,116:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcc8b2fc410>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcc75d1ba90>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:15:48,116:INFO:Checking exceptions
2022-11-09 20:15:48,120:INFO:Importing libraries
2022-11-09 20:15:48,120:INFO:Copying training dataset
2022-11-09 20:15:48,128:INFO:Defining folds
2022-11-09 20:15:48,129:INFO:Declaring metric variables
2022-11-09 20:15:48,141:INFO:Importing untrained model
2022-11-09 20:15:48,151:INFO:Bayesian Ridge Imported successfully
2022-11-09 20:15:48,167:INFO:Starting cross validation
2022-11-09 20:15:48,169:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:15:48,526:INFO:Calculating mean and std
2022-11-09 20:15:48,532:INFO:Creating metrics dataframe
2022-11-09 20:15:48,541:INFO:Uploading results into container
2022-11-09 20:15:48,542:INFO:Uploading model into container now
2022-11-09 20:15:48,543:INFO:master_model_container: 8
2022-11-09 20:15:48,543:INFO:display_container: 2
2022-11-09 20:15:48,544:INFO:BayesianRidge()
2022-11-09 20:15:48,544:INFO:create_model() successfully completed......................................
2022-11-09 20:15:48,767:INFO:SubProcess create_model() end ==================================
2022-11-09 20:15:48,768:INFO:Creating metrics dataframe
2022-11-09 20:15:48,798:INFO:Initializing Passive Aggressive Regressor
2022-11-09 20:15:48,799:INFO:Total runtime is 0.25305333534876506 minutes
2022-11-09 20:15:48,810:INFO:SubProcess create_model() called ==================================
2022-11-09 20:15:48,812:INFO:Initializing create_model()
2022-11-09 20:15:48,812:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcc8b2fc410>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcc75d1ba90>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:15:48,812:INFO:Checking exceptions
2022-11-09 20:15:48,816:INFO:Importing libraries
2022-11-09 20:15:48,816:INFO:Copying training dataset
2022-11-09 20:15:48,827:INFO:Defining folds
2022-11-09 20:15:48,827:INFO:Declaring metric variables
2022-11-09 20:15:48,838:INFO:Importing untrained model
2022-11-09 20:15:48,849:INFO:Passive Aggressive Regressor Imported successfully
2022-11-09 20:15:48,869:INFO:Starting cross validation
2022-11-09 20:15:48,871:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:15:49,254:INFO:Calculating mean and std
2022-11-09 20:15:49,257:INFO:Creating metrics dataframe
2022-11-09 20:15:49,268:INFO:Uploading results into container
2022-11-09 20:15:49,269:INFO:Uploading model into container now
2022-11-09 20:15:49,270:INFO:master_model_container: 9
2022-11-09 20:15:49,271:INFO:display_container: 2
2022-11-09 20:15:49,271:INFO:PassiveAggressiveRegressor(random_state=123)
2022-11-09 20:15:49,272:INFO:create_model() successfully completed......................................
2022-11-09 20:15:49,500:INFO:SubProcess create_model() end ==================================
2022-11-09 20:15:49,500:INFO:Creating metrics dataframe
2022-11-09 20:15:49,522:INFO:Initializing Huber Regressor
2022-11-09 20:15:49,523:INFO:Total runtime is 0.26512339115142824 minutes
2022-11-09 20:15:49,535:INFO:SubProcess create_model() called ==================================
2022-11-09 20:15:49,536:INFO:Initializing create_model()
2022-11-09 20:15:49,537:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcc8b2fc410>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcc75d1ba90>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:15:49,537:INFO:Checking exceptions
2022-11-09 20:15:49,542:INFO:Importing libraries
2022-11-09 20:15:49,542:INFO:Copying training dataset
2022-11-09 20:15:49,547:INFO:Defining folds
2022-11-09 20:15:49,548:INFO:Declaring metric variables
2022-11-09 20:15:49,563:INFO:Importing untrained model
2022-11-09 20:15:49,574:INFO:Huber Regressor Imported successfully
2022-11-09 20:15:49,596:INFO:Starting cross validation
2022-11-09 20:15:49,599:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:15:49,698:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-09 20:15:49,780:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-09 20:15:49,824:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-09 20:15:49,930:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-09 20:15:49,947:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-09 20:15:50,027:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-09 20:15:50,076:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-09 20:15:50,141:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-09 20:15:50,211:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-09 20:15:50,271:INFO:Calculating mean and std
2022-11-09 20:15:50,275:INFO:Creating metrics dataframe
2022-11-09 20:15:50,284:INFO:Uploading results into container
2022-11-09 20:15:50,285:INFO:Uploading model into container now
2022-11-09 20:15:50,287:INFO:master_model_container: 10
2022-11-09 20:15:50,287:INFO:display_container: 2
2022-11-09 20:15:50,288:INFO:HuberRegressor()
2022-11-09 20:15:50,288:INFO:create_model() successfully completed......................................
2022-11-09 20:15:50,515:INFO:SubProcess create_model() end ==================================
2022-11-09 20:15:50,516:INFO:Creating metrics dataframe
2022-11-09 20:15:50,543:INFO:Initializing K Neighbors Regressor
2022-11-09 20:15:50,544:INFO:Total runtime is 0.28213930527369185 minutes
2022-11-09 20:15:50,555:INFO:SubProcess create_model() called ==================================
2022-11-09 20:15:50,556:INFO:Initializing create_model()
2022-11-09 20:15:50,556:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcc8b2fc410>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcc75d1ba90>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:15:50,557:INFO:Checking exceptions
2022-11-09 20:15:50,561:INFO:Importing libraries
2022-11-09 20:15:50,561:INFO:Copying training dataset
2022-11-09 20:15:50,567:INFO:Defining folds
2022-11-09 20:15:50,568:INFO:Declaring metric variables
2022-11-09 20:15:50,582:INFO:Importing untrained model
2022-11-09 20:15:50,592:INFO:K Neighbors Regressor Imported successfully
2022-11-09 20:15:50,614:INFO:Starting cross validation
2022-11-09 20:15:50,617:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:15:51,396:INFO:Calculating mean and std
2022-11-09 20:15:51,398:INFO:Creating metrics dataframe
2022-11-09 20:15:51,404:INFO:Uploading results into container
2022-11-09 20:15:51,405:INFO:Uploading model into container now
2022-11-09 20:15:51,406:INFO:master_model_container: 11
2022-11-09 20:15:51,406:INFO:display_container: 2
2022-11-09 20:15:51,407:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-09 20:15:51,407:INFO:create_model() successfully completed......................................
2022-11-09 20:15:51,586:INFO:SubProcess create_model() end ==================================
2022-11-09 20:15:51,587:INFO:Creating metrics dataframe
2022-11-09 20:15:51,618:INFO:Initializing Decision Tree Regressor
2022-11-09 20:15:51,619:INFO:Total runtime is 0.300048033396403 minutes
2022-11-09 20:15:51,630:INFO:SubProcess create_model() called ==================================
2022-11-09 20:15:51,634:INFO:Initializing create_model()
2022-11-09 20:15:51,634:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcc8b2fc410>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcc75d1ba90>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:15:51,635:INFO:Checking exceptions
2022-11-09 20:15:51,637:INFO:Importing libraries
2022-11-09 20:15:51,637:INFO:Copying training dataset
2022-11-09 20:15:51,645:INFO:Defining folds
2022-11-09 20:15:51,645:INFO:Declaring metric variables
2022-11-09 20:15:51,655:INFO:Importing untrained model
2022-11-09 20:15:51,665:INFO:Decision Tree Regressor Imported successfully
2022-11-09 20:15:51,682:INFO:Starting cross validation
2022-11-09 20:15:51,684:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:15:52,078:INFO:Calculating mean and std
2022-11-09 20:15:52,084:INFO:Creating metrics dataframe
2022-11-09 20:15:52,093:INFO:Uploading results into container
2022-11-09 20:15:52,094:INFO:Uploading model into container now
2022-11-09 20:15:52,095:INFO:master_model_container: 12
2022-11-09 20:15:52,095:INFO:display_container: 2
2022-11-09 20:15:52,096:INFO:DecisionTreeRegressor(random_state=123)
2022-11-09 20:15:52,096:INFO:create_model() successfully completed......................................
2022-11-09 20:15:52,324:INFO:SubProcess create_model() end ==================================
2022-11-09 20:15:52,325:INFO:Creating metrics dataframe
2022-11-09 20:15:52,348:INFO:Initializing Random Forest Regressor
2022-11-09 20:15:52,349:INFO:Total runtime is 0.31222852071126306 minutes
2022-11-09 20:15:52,360:INFO:SubProcess create_model() called ==================================
2022-11-09 20:15:52,360:INFO:Initializing create_model()
2022-11-09 20:15:52,362:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcc8b2fc410>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcc75d1ba90>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:15:52,362:INFO:Checking exceptions
2022-11-09 20:15:52,365:INFO:Importing libraries
2022-11-09 20:15:52,365:INFO:Copying training dataset
2022-11-09 20:15:52,371:INFO:Defining folds
2022-11-09 20:15:52,372:INFO:Declaring metric variables
2022-11-09 20:15:52,388:INFO:Importing untrained model
2022-11-09 20:15:52,400:INFO:Random Forest Regressor Imported successfully
2022-11-09 20:15:52,423:INFO:Starting cross validation
2022-11-09 20:15:52,426:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:15:57,222:INFO:Calculating mean and std
2022-11-09 20:15:57,226:INFO:Creating metrics dataframe
2022-11-09 20:15:57,243:INFO:Uploading results into container
2022-11-09 20:15:57,244:INFO:Uploading model into container now
2022-11-09 20:15:57,244:INFO:master_model_container: 13
2022-11-09 20:15:57,244:INFO:display_container: 2
2022-11-09 20:15:57,245:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-09 20:15:57,245:INFO:create_model() successfully completed......................................
2022-11-09 20:15:57,478:INFO:SubProcess create_model() end ==================================
2022-11-09 20:15:57,478:INFO:Creating metrics dataframe
2022-11-09 20:15:57,502:INFO:Initializing Extra Trees Regressor
2022-11-09 20:15:57,503:INFO:Total runtime is 0.3981183807055156 minutes
2022-11-09 20:15:57,514:INFO:SubProcess create_model() called ==================================
2022-11-09 20:15:57,515:INFO:Initializing create_model()
2022-11-09 20:15:57,515:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcc8b2fc410>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcc75d1ba90>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:15:57,516:INFO:Checking exceptions
2022-11-09 20:15:57,518:INFO:Importing libraries
2022-11-09 20:15:57,518:INFO:Copying training dataset
2022-11-09 20:15:57,529:INFO:Defining folds
2022-11-09 20:15:57,530:INFO:Declaring metric variables
2022-11-09 20:15:57,541:INFO:Importing untrained model
2022-11-09 20:15:57,551:INFO:Extra Trees Regressor Imported successfully
2022-11-09 20:15:57,569:INFO:Starting cross validation
2022-11-09 20:15:57,572:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:16:00,438:INFO:Calculating mean and std
2022-11-09 20:16:00,449:INFO:Creating metrics dataframe
2022-11-09 20:16:00,459:INFO:Uploading results into container
2022-11-09 20:16:00,460:INFO:Uploading model into container now
2022-11-09 20:16:00,461:INFO:master_model_container: 14
2022-11-09 20:16:00,461:INFO:display_container: 2
2022-11-09 20:16:00,462:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-09 20:16:00,462:INFO:create_model() successfully completed......................................
2022-11-09 20:16:00,650:INFO:SubProcess create_model() end ==================================
2022-11-09 20:16:00,651:INFO:Creating metrics dataframe
2022-11-09 20:16:00,677:INFO:Initializing AdaBoost Regressor
2022-11-09 20:16:00,677:INFO:Total runtime is 0.45102681716283166 minutes
2022-11-09 20:16:00,693:INFO:SubProcess create_model() called ==================================
2022-11-09 20:16:00,694:INFO:Initializing create_model()
2022-11-09 20:16:00,699:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcc8b2fc410>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcc75d1ba90>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:16:00,699:INFO:Checking exceptions
2022-11-09 20:16:00,701:INFO:Importing libraries
2022-11-09 20:16:00,702:INFO:Copying training dataset
2022-11-09 20:16:00,707:INFO:Defining folds
2022-11-09 20:16:00,707:INFO:Declaring metric variables
2022-11-09 20:16:00,720:INFO:Importing untrained model
2022-11-09 20:16:00,732:INFO:AdaBoost Regressor Imported successfully
2022-11-09 20:16:00,749:INFO:Starting cross validation
2022-11-09 20:16:00,754:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:16:02,033:INFO:Calculating mean and std
2022-11-09 20:16:02,037:INFO:Creating metrics dataframe
2022-11-09 20:16:02,046:INFO:Uploading results into container
2022-11-09 20:16:02,049:INFO:Uploading model into container now
2022-11-09 20:16:02,050:INFO:master_model_container: 15
2022-11-09 20:16:02,051:INFO:display_container: 2
2022-11-09 20:16:02,051:INFO:AdaBoostRegressor(random_state=123)
2022-11-09 20:16:02,052:INFO:create_model() successfully completed......................................
2022-11-09 20:16:02,273:INFO:SubProcess create_model() end ==================================
2022-11-09 20:16:02,274:INFO:Creating metrics dataframe
2022-11-09 20:16:02,301:INFO:Initializing Gradient Boosting Regressor
2022-11-09 20:16:02,302:INFO:Total runtime is 0.4781044642130534 minutes
2022-11-09 20:16:02,312:INFO:SubProcess create_model() called ==================================
2022-11-09 20:16:02,313:INFO:Initializing create_model()
2022-11-09 20:16:02,314:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcc8b2fc410>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcc75d1ba90>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:16:02,314:INFO:Checking exceptions
2022-11-09 20:16:02,317:INFO:Importing libraries
2022-11-09 20:16:02,318:INFO:Copying training dataset
2022-11-09 20:16:02,327:INFO:Defining folds
2022-11-09 20:16:02,328:INFO:Declaring metric variables
2022-11-09 20:16:02,340:INFO:Importing untrained model
2022-11-09 20:16:02,350:INFO:Gradient Boosting Regressor Imported successfully
2022-11-09 20:16:02,371:INFO:Starting cross validation
2022-11-09 20:16:02,374:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:16:04,245:INFO:Calculating mean and std
2022-11-09 20:16:04,250:INFO:Creating metrics dataframe
2022-11-09 20:16:04,261:INFO:Uploading results into container
2022-11-09 20:16:04,262:INFO:Uploading model into container now
2022-11-09 20:16:04,263:INFO:master_model_container: 16
2022-11-09 20:16:04,263:INFO:display_container: 2
2022-11-09 20:16:04,264:INFO:GradientBoostingRegressor(random_state=123)
2022-11-09 20:16:04,264:INFO:create_model() successfully completed......................................
2022-11-09 20:16:04,489:INFO:SubProcess create_model() end ==================================
2022-11-09 20:16:04,490:INFO:Creating metrics dataframe
2022-11-09 20:16:04,514:INFO:Initializing Light Gradient Boosting Machine
2022-11-09 20:16:04,515:INFO:Total runtime is 0.514986781279246 minutes
2022-11-09 20:16:04,532:INFO:SubProcess create_model() called ==================================
2022-11-09 20:16:04,534:INFO:Initializing create_model()
2022-11-09 20:16:04,535:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcc8b2fc410>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcc75d1ba90>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:16:04,535:INFO:Checking exceptions
2022-11-09 20:16:04,538:INFO:Importing libraries
2022-11-09 20:16:04,539:INFO:Copying training dataset
2022-11-09 20:16:04,545:INFO:Defining folds
2022-11-09 20:16:04,546:INFO:Declaring metric variables
2022-11-09 20:16:04,565:INFO:Importing untrained model
2022-11-09 20:16:04,580:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-09 20:16:04,609:INFO:Starting cross validation
2022-11-09 20:16:04,611:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:16:06,299:INFO:Calculating mean and std
2022-11-09 20:16:06,308:INFO:Creating metrics dataframe
2022-11-09 20:16:06,319:INFO:Uploading results into container
2022-11-09 20:16:06,320:INFO:Uploading model into container now
2022-11-09 20:16:06,321:INFO:master_model_container: 17
2022-11-09 20:16:06,321:INFO:display_container: 2
2022-11-09 20:16:06,321:INFO:LGBMRegressor(random_state=123)
2022-11-09 20:16:06,321:INFO:create_model() successfully completed......................................
2022-11-09 20:16:06,546:INFO:SubProcess create_model() end ==================================
2022-11-09 20:16:06,547:INFO:Creating metrics dataframe
2022-11-09 20:16:06,572:INFO:Initializing Dummy Regressor
2022-11-09 20:16:06,573:INFO:Total runtime is 0.5492820700009664 minutes
2022-11-09 20:16:06,583:INFO:SubProcess create_model() called ==================================
2022-11-09 20:16:06,587:INFO:Initializing create_model()
2022-11-09 20:16:06,589:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcc8b2fc410>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcc75d1ba90>, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:16:06,589:INFO:Checking exceptions
2022-11-09 20:16:06,593:INFO:Importing libraries
2022-11-09 20:16:06,594:INFO:Copying training dataset
2022-11-09 20:16:06,602:INFO:Defining folds
2022-11-09 20:16:06,603:INFO:Declaring metric variables
2022-11-09 20:16:06,615:INFO:Importing untrained model
2022-11-09 20:16:06,625:INFO:Dummy Regressor Imported successfully
2022-11-09 20:16:06,647:INFO:Starting cross validation
2022-11-09 20:16:06,649:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-09 20:16:06,981:INFO:Calculating mean and std
2022-11-09 20:16:06,986:INFO:Creating metrics dataframe
2022-11-09 20:16:07,001:INFO:Uploading results into container
2022-11-09 20:16:07,002:INFO:Uploading model into container now
2022-11-09 20:16:07,003:INFO:master_model_container: 18
2022-11-09 20:16:07,003:INFO:display_container: 2
2022-11-09 20:16:07,004:INFO:DummyRegressor()
2022-11-09 20:16:07,004:INFO:create_model() successfully completed......................................
2022-11-09 20:16:07,226:INFO:SubProcess create_model() end ==================================
2022-11-09 20:16:07,227:INFO:Creating metrics dataframe
2022-11-09 20:16:07,288:INFO:Initializing create_model()
2022-11-09 20:16:07,292:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fcc8b2fc410>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-09 20:16:07,294:INFO:Checking exceptions
2022-11-09 20:16:07,303:INFO:Importing libraries
2022-11-09 20:16:07,304:INFO:Copying training dataset
2022-11-09 20:16:07,307:INFO:Defining folds
2022-11-09 20:16:07,307:INFO:Declaring metric variables
2022-11-09 20:16:07,308:INFO:Importing untrained model
2022-11-09 20:16:07,308:INFO:Declaring custom model
2022-11-09 20:16:07,309:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-09 20:16:07,311:INFO:Cross validation set to False
2022-11-09 20:16:07,311:INFO:Fitting Model
2022-11-09 20:16:07,325:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-09 20:16:07,329:INFO:OrthogonalMatchingPursuit()
2022-11-09 20:16:07,329:INFO:create_model() successfully completed......................................
2022-11-09 20:16:07,652:INFO:master_model_container: 18
2022-11-09 20:16:07,653:INFO:display_container: 2
2022-11-09 20:16:07,653:INFO:OrthogonalMatchingPursuit()
2022-11-09 20:16:07,654:INFO:compare_models() successfully completed......................................
2022-11-09 20:16:07,730:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2022-11-14 20:04:15,959:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-14 20:04:16,180:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-14 20:04:16,180:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-14 20:04:16,180:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-14 20:04:18,300:INFO:Soft dependency imported: prophet: 1.1.1
2022-11-14 20:04:19,258:INFO:PyCaret RegressionExperiment
2022-11-14 20:04:19,259:INFO:Logging name: FullData
2022-11-14 20:04:19,259:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-14 20:04:19,259:INFO:version 3.0.0.rc4
2022-11-14 20:04:19,259:INFO:Initializing setup()
2022-11-14 20:04:19,259:INFO:self.USI: 3f4b
2022-11-14 20:04:19,260:INFO:self.variable_keys: {'fold_generator', 'fold_shuffle_param', '_ml_usecase', 'data', 'X_train', 'y', 'transform_target_method_param', 'idx', 'display_container', 'log_plots_param', 'gpu_param', 'y_train', '_available_plots', 'master_model_container', '_gpu_n_jobs_param', 'y_test', '_all_models_internal', 'X_test', 'transform_target_param', 'X', 'html_param', 'logging_param', '_all_metrics', 'exp_name_log', 'pipeline', 'variable_keys', 'seed', 'target_param', '_all_models', 'USI', 'fold_groups_param', 'exp_id', 'memory', 'n_jobs_param'}
2022-11-14 20:04:19,260:INFO:Checking environment
2022-11-14 20:04:19,260:INFO:python_version: 3.7.15
2022-11-14 20:04:19,260:INFO:python_build: ('default', 'Oct 12 2022 19:14:55')
2022-11-14 20:04:19,260:INFO:machine: x86_64
2022-11-14 20:04:19,260:INFO:platform: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-14 20:04:19,261:INFO:Memory: svmem(total=13616361472, available=12466454528, percent=8.4, used=882176000, free=7261749248, active=801710080, inactive=5183053824, buffers=165240832, cached=5307195392, shared=1290240, slab=285757440)
2022-11-14 20:04:19,261:INFO:Physical Core: 1
2022-11-14 20:04:19,261:INFO:Logical Core: 2
2022-11-14 20:04:19,261:INFO:Checking libraries
2022-11-14 20:04:19,261:INFO:System:
2022-11-14 20:04:19,262:INFO:    python: 3.7.15 (default, Oct 12 2022, 19:14:55)  [GCC 7.5.0]
2022-11-14 20:04:19,262:INFO:executable: /usr/bin/python3
2022-11-14 20:04:19,262:INFO:   machine: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-14 20:04:19,262:INFO:PyCaret required dependencies:
2022-11-14 20:04:19,262:INFO:                 pip: 21.1.3
2022-11-14 20:04:19,262:INFO:          setuptools: 57.4.0
2022-11-14 20:04:19,262:INFO:             pycaret: 3.0.0rc4
2022-11-14 20:04:19,262:INFO:             IPython: 7.9.0
2022-11-14 20:04:19,263:INFO:          ipywidgets: 7.7.1
2022-11-14 20:04:19,263:INFO:                tqdm: 4.64.1
2022-11-14 20:04:19,263:INFO:               numpy: 1.21.6
2022-11-14 20:04:19,263:INFO:              pandas: 1.3.5
2022-11-14 20:04:19,263:INFO:              jinja2: 3.0.0
2022-11-14 20:04:19,263:INFO:               scipy: 1.7.3
2022-11-14 20:04:19,263:INFO:              joblib: 1.2.0
2022-11-14 20:04:19,263:INFO:             sklearn: 1.0.2
2022-11-14 20:04:19,264:INFO:                pyod: 1.0.6
2022-11-14 20:04:19,264:INFO:            imblearn: 0.8.1
2022-11-14 20:04:19,264:INFO:   category_encoders: 2.5.1.post0
2022-11-14 20:04:19,264:INFO:            lightgbm: 3.3.3
2022-11-14 20:04:19,264:INFO:               numba: 0.55.2
2022-11-14 20:04:19,264:INFO:            requests: 2.28.1
2022-11-14 20:04:19,264:INFO:          matplotlib: 3.5.3
2022-11-14 20:04:19,264:INFO:          scikitplot: 0.3.7
2022-11-14 20:04:19,265:INFO:         yellowbrick: 1.5
2022-11-14 20:04:19,265:INFO:              plotly: 5.5.0
2022-11-14 20:04:19,265:INFO:             kaleido: 0.2.1
2022-11-14 20:04:19,265:INFO:         statsmodels: 0.12.2
2022-11-14 20:04:19,265:INFO:              sktime: 0.13.4
2022-11-14 20:04:19,265:INFO:               tbats: 1.1.1
2022-11-14 20:04:19,265:INFO:            pmdarima: 1.8.5
2022-11-14 20:04:19,265:INFO:              psutil: 5.9.4
2022-11-14 20:04:19,265:INFO:PyCaret optional dependencies:
2022-11-14 20:04:19,279:INFO:                shap: Not installed
2022-11-14 20:04:19,279:INFO:           interpret: Not installed
2022-11-14 20:04:19,279:INFO:                umap: Not installed
2022-11-14 20:04:19,279:INFO:    pandas_profiling: 1.4.1
2022-11-14 20:04:19,280:INFO:  explainerdashboard: Not installed
2022-11-14 20:04:19,280:INFO:             autoviz: Not installed
2022-11-14 20:04:19,280:INFO:           fairlearn: Not installed
2022-11-14 20:04:19,280:INFO:             xgboost: 0.90
2022-11-14 20:04:19,280:INFO:            catboost: Not installed
2022-11-14 20:04:19,280:INFO:              kmodes: Not installed
2022-11-14 20:04:19,280:INFO:             mlxtend: 0.14.0
2022-11-14 20:04:19,280:INFO:       statsforecast: Not installed
2022-11-14 20:04:19,280:INFO:        tune_sklearn: Not installed
2022-11-14 20:04:19,281:INFO:                 ray: Not installed
2022-11-14 20:04:19,281:INFO:            hyperopt: 0.1.2
2022-11-14 20:04:19,281:INFO:              optuna: Not installed
2022-11-14 20:04:19,281:INFO:               skopt: Not installed
2022-11-14 20:04:19,281:INFO:              mlflow: Not installed
2022-11-14 20:04:19,281:INFO:              gradio: Not installed
2022-11-14 20:04:19,281:INFO:             fastapi: Not installed
2022-11-14 20:04:19,281:INFO:             uvicorn: Not installed
2022-11-14 20:04:19,281:INFO:              m2cgen: Not installed
2022-11-14 20:04:19,282:INFO:           evidently: Not installed
2022-11-14 20:04:19,282:INFO:                nltk: 3.7
2022-11-14 20:04:19,282:INFO:            pyLDAvis: Not installed
2022-11-14 20:04:19,282:INFO:              gensim: 3.6.0
2022-11-14 20:04:19,282:INFO:               spacy: 3.4.2
2022-11-14 20:04:19,282:INFO:           wordcloud: 1.8.2.2
2022-11-14 20:04:19,282:INFO:            textblob: 0.15.3
2022-11-14 20:04:19,282:INFO:               fugue: Not installed
2022-11-14 20:04:19,283:INFO:           streamlit: Not installed
2022-11-14 20:04:19,283:INFO:             prophet: 1.1.1
2022-11-14 20:04:19,283:INFO:None
2022-11-14 20:04:19,283:INFO:Set up data.
2022-11-14 20:04:19,295:INFO:Set up train/test split.
2022-11-14 20:04:19,301:INFO:Set up index.
2022-11-14 20:04:19,302:INFO:Set up folding strategy.
2022-11-14 20:04:19,302:INFO:Assigning column types.
2022-11-14 20:04:19,312:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-14 20:04:19,312:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-14 20:04:19,322:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-14 20:04:19,341:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:04:19,472:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:04:19,611:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:04:19,623:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:04:19,624:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:04:20,019:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:04:20,030:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-14 20:04:20,050:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-14 20:04:20,079:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:04:20,242:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:04:20,334:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:04:20,335:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:04:20,336:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:04:20,336:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:04:20,337:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-14 20:04:20,347:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-14 20:04:20,357:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:04:20,484:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:04:20,639:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:04:20,640:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:04:20,641:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:04:20,641:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:04:20,651:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-14 20:04:20,661:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:04:20,786:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:04:20,899:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:04:20,900:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:04:20,901:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:04:20,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:04:20,902:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-14 20:04:20,921:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:04:21,037:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:04:21,131:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:04:21,132:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:04:21,132:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:04:21,133:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:04:21,172:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:04:21,409:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:04:21,533:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:04:21,541:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:04:21,541:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:04:21,542:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:04:21,543:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-14 20:04:21,748:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:04:21,911:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:04:21,919:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:04:21,919:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:04:21,920:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:04:22,060:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:04:22,176:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:04:22,186:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:04:22,188:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:04:22,189:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:04:22,191:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-14 20:04:22,407:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:04:22,651:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:04:22,651:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:04:22,652:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:04:22,807:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:04:22,927:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:04:22,935:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:04:22,936:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:04:22,936:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-14 20:04:23,245:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:04:23,250:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:04:23,251:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:04:23,533:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:04:23,545:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:04:23,547:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:04:23,556:INFO:Preparing preprocessing pipeline...
2022-11-14 20:04:23,558:INFO:Set up simple imputation.
2022-11-14 20:04:23,571:INFO:Set up variance threshold.
2022-11-14 20:04:23,669:INFO:Finished creating preprocessing pipeline.
2022-11-14 20:04:23,681:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-14 20:04:23,681:INFO:Creating final display dataframe.
2022-11-14 20:04:24,040:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 12)
4         Train data shape    (607, 12)
5          Test data shape    (261, 12)
6         Numeric features           11
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         3f4b
2022-11-14 20:04:24,454:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:04:24,463:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:04:24,464:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:04:24,875:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:04:24,884:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:04:24,885:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:04:24,897:INFO:setup() successfully completed in 5.65s...............
2022-11-14 20:04:24,898:INFO:Initializing compare_models()
2022-11-14 20:04:24,898:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d3dc00ed0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f3d3dc00ed0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-14 20:04:24,898:INFO:Checking exceptions
2022-11-14 20:04:24,900:INFO:Preparing display monitor
2022-11-14 20:04:25,026:INFO:Initializing Linear Regression
2022-11-14 20:04:25,027:INFO:Total runtime is 6.838639577229818e-06 minutes
2022-11-14 20:04:25,035:INFO:SubProcess create_model() called ==================================
2022-11-14 20:04:25,036:INFO:Initializing create_model()
2022-11-14 20:04:25,036:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d3dc00ed0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27884f10>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:04:25,036:INFO:Checking exceptions
2022-11-14 20:04:25,039:INFO:Importing libraries
2022-11-14 20:04:25,039:INFO:Copying training dataset
2022-11-14 20:04:25,044:INFO:Defining folds
2022-11-14 20:04:25,044:INFO:Declaring metric variables
2022-11-14 20:04:25,059:INFO:Importing untrained model
2022-11-14 20:04:25,079:INFO:Linear Regression Imported successfully
2022-11-14 20:04:25,121:INFO:Starting cross validation
2022-11-14 20:04:25,133:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:04:35,604:INFO:Calculating mean and std
2022-11-14 20:04:35,608:INFO:Creating metrics dataframe
2022-11-14 20:04:35,646:INFO:Uploading results into container
2022-11-14 20:04:35,652:INFO:Uploading model into container now
2022-11-14 20:04:35,654:INFO:master_model_container: 1
2022-11-14 20:04:35,654:INFO:display_container: 2
2022-11-14 20:04:35,654:INFO:LinearRegression(n_jobs=-1)
2022-11-14 20:04:35,655:INFO:create_model() successfully completed......................................
2022-11-14 20:04:35,977:INFO:SubProcess create_model() end ==================================
2022-11-14 20:04:35,987:INFO:Creating metrics dataframe
2022-11-14 20:04:36,018:INFO:Initializing Lasso Regression
2022-11-14 20:04:36,018:INFO:Total runtime is 0.18319354057312012 minutes
2022-11-14 20:04:36,035:INFO:SubProcess create_model() called ==================================
2022-11-14 20:04:36,041:INFO:Initializing create_model()
2022-11-14 20:04:36,042:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d3dc00ed0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27884f10>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:04:36,042:INFO:Checking exceptions
2022-11-14 20:04:36,046:INFO:Importing libraries
2022-11-14 20:04:36,046:INFO:Copying training dataset
2022-11-14 20:04:36,065:INFO:Defining folds
2022-11-14 20:04:36,065:INFO:Declaring metric variables
2022-11-14 20:04:36,079:INFO:Importing untrained model
2022-11-14 20:04:36,095:INFO:Lasso Regression Imported successfully
2022-11-14 20:04:36,126:INFO:Starting cross validation
2022-11-14 20:04:36,133:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:04:36,787:INFO:Calculating mean and std
2022-11-14 20:04:36,802:INFO:Creating metrics dataframe
2022-11-14 20:04:36,813:INFO:Uploading results into container
2022-11-14 20:04:36,814:INFO:Uploading model into container now
2022-11-14 20:04:36,815:INFO:master_model_container: 2
2022-11-14 20:04:36,815:INFO:display_container: 2
2022-11-14 20:04:36,815:INFO:Lasso(random_state=123)
2022-11-14 20:04:36,816:INFO:create_model() successfully completed......................................
2022-11-14 20:04:37,121:INFO:SubProcess create_model() end ==================================
2022-11-14 20:04:37,121:INFO:Creating metrics dataframe
2022-11-14 20:04:37,159:INFO:Initializing Ridge Regression
2022-11-14 20:04:37,160:INFO:Total runtime is 0.20222552617390951 minutes
2022-11-14 20:04:37,183:INFO:SubProcess create_model() called ==================================
2022-11-14 20:04:37,184:INFO:Initializing create_model()
2022-11-14 20:04:37,185:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d3dc00ed0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27884f10>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:04:37,189:INFO:Checking exceptions
2022-11-14 20:04:37,193:INFO:Importing libraries
2022-11-14 20:04:37,193:INFO:Copying training dataset
2022-11-14 20:04:37,210:INFO:Defining folds
2022-11-14 20:04:37,218:INFO:Declaring metric variables
2022-11-14 20:04:37,246:INFO:Importing untrained model
2022-11-14 20:04:37,271:INFO:Ridge Regression Imported successfully
2022-11-14 20:04:37,345:INFO:Starting cross validation
2022-11-14 20:04:37,347:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:04:37,919:INFO:Calculating mean and std
2022-11-14 20:04:37,942:INFO:Creating metrics dataframe
2022-11-14 20:04:37,967:INFO:Uploading results into container
2022-11-14 20:04:37,968:INFO:Uploading model into container now
2022-11-14 20:04:37,969:INFO:master_model_container: 3
2022-11-14 20:04:37,970:INFO:display_container: 2
2022-11-14 20:04:37,970:INFO:Ridge(random_state=123)
2022-11-14 20:04:37,970:INFO:create_model() successfully completed......................................
2022-11-14 20:04:38,211:INFO:SubProcess create_model() end ==================================
2022-11-14 20:04:38,212:INFO:Creating metrics dataframe
2022-11-14 20:04:38,292:INFO:Initializing Elastic Net
2022-11-14 20:04:38,293:INFO:Total runtime is 0.22111025651295982 minutes
2022-11-14 20:04:38,330:INFO:SubProcess create_model() called ==================================
2022-11-14 20:04:38,336:INFO:Initializing create_model()
2022-11-14 20:04:38,336:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d3dc00ed0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27884f10>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:04:38,337:INFO:Checking exceptions
2022-11-14 20:04:38,339:INFO:Importing libraries
2022-11-14 20:04:38,340:INFO:Copying training dataset
2022-11-14 20:04:38,354:INFO:Defining folds
2022-11-14 20:04:38,364:INFO:Declaring metric variables
2022-11-14 20:04:38,384:INFO:Importing untrained model
2022-11-14 20:04:38,407:INFO:Elastic Net Imported successfully
2022-11-14 20:04:38,444:INFO:Starting cross validation
2022-11-14 20:04:38,454:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:04:38,974:INFO:Calculating mean and std
2022-11-14 20:04:38,977:INFO:Creating metrics dataframe
2022-11-14 20:04:38,995:INFO:Uploading results into container
2022-11-14 20:04:38,995:INFO:Uploading model into container now
2022-11-14 20:04:38,996:INFO:master_model_container: 4
2022-11-14 20:04:38,996:INFO:display_container: 2
2022-11-14 20:04:38,997:INFO:ElasticNet(random_state=123)
2022-11-14 20:04:38,997:INFO:create_model() successfully completed......................................
2022-11-14 20:04:39,134:INFO:SubProcess create_model() end ==================================
2022-11-14 20:04:39,134:INFO:Creating metrics dataframe
2022-11-14 20:04:39,153:INFO:Initializing Least Angle Regression
2022-11-14 20:04:39,154:INFO:Total runtime is 0.23546806971232098 minutes
2022-11-14 20:04:39,164:INFO:SubProcess create_model() called ==================================
2022-11-14 20:04:39,167:INFO:Initializing create_model()
2022-11-14 20:04:39,167:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d3dc00ed0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27884f10>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:04:39,167:INFO:Checking exceptions
2022-11-14 20:04:39,170:INFO:Importing libraries
2022-11-14 20:04:39,170:INFO:Copying training dataset
2022-11-14 20:04:39,175:INFO:Defining folds
2022-11-14 20:04:39,175:INFO:Declaring metric variables
2022-11-14 20:04:39,190:INFO:Importing untrained model
2022-11-14 20:04:39,199:INFO:Least Angle Regression Imported successfully
2022-11-14 20:04:39,215:INFO:Starting cross validation
2022-11-14 20:04:39,217:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:04:39,273:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:04:39,292:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:04:39,332:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:04:39,372:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:04:39,381:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:04:39,436:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:04:39,475:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:04:39,494:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:04:39,526:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:04:39,543:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:04:39,559:INFO:Calculating mean and std
2022-11-14 20:04:39,561:INFO:Creating metrics dataframe
2022-11-14 20:04:39,577:INFO:Uploading results into container
2022-11-14 20:04:39,580:INFO:Uploading model into container now
2022-11-14 20:04:39,581:INFO:master_model_container: 5
2022-11-14 20:04:39,581:INFO:display_container: 2
2022-11-14 20:04:39,582:INFO:Lars(random_state=123)
2022-11-14 20:04:39,582:INFO:create_model() successfully completed......................................
2022-11-14 20:04:39,722:INFO:SubProcess create_model() end ==================================
2022-11-14 20:04:39,723:INFO:Creating metrics dataframe
2022-11-14 20:04:39,747:INFO:Initializing Lasso Least Angle Regression
2022-11-14 20:04:39,747:INFO:Total runtime is 0.24534749984741214 minutes
2022-11-14 20:04:39,756:INFO:SubProcess create_model() called ==================================
2022-11-14 20:04:39,757:INFO:Initializing create_model()
2022-11-14 20:04:39,758:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d3dc00ed0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27884f10>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:04:39,758:INFO:Checking exceptions
2022-11-14 20:04:39,761:INFO:Importing libraries
2022-11-14 20:04:39,761:INFO:Copying training dataset
2022-11-14 20:04:39,769:INFO:Defining folds
2022-11-14 20:04:39,770:INFO:Declaring metric variables
2022-11-14 20:04:39,780:INFO:Importing untrained model
2022-11-14 20:04:39,790:INFO:Lasso Least Angle Regression Imported successfully
2022-11-14 20:04:39,806:INFO:Starting cross validation
2022-11-14 20:04:39,810:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:04:39,851:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:04:39,879:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:04:39,914:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:04:39,952:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:04:40,005:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:04:40,005:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:04:40,042:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:04:40,056:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:04:40,082:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:04:40,096:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:04:40,109:INFO:Calculating mean and std
2022-11-14 20:04:40,112:INFO:Creating metrics dataframe
2022-11-14 20:04:40,123:INFO:Uploading results into container
2022-11-14 20:04:40,124:INFO:Uploading model into container now
2022-11-14 20:04:40,125:INFO:master_model_container: 6
2022-11-14 20:04:40,125:INFO:display_container: 2
2022-11-14 20:04:40,126:INFO:LassoLars(random_state=123)
2022-11-14 20:04:40,126:INFO:create_model() successfully completed......................................
2022-11-14 20:04:40,260:INFO:SubProcess create_model() end ==================================
2022-11-14 20:04:40,261:INFO:Creating metrics dataframe
2022-11-14 20:04:40,281:INFO:Initializing Orthogonal Matching Pursuit
2022-11-14 20:04:40,282:INFO:Total runtime is 0.2542596499125163 minutes
2022-11-14 20:04:40,290:INFO:SubProcess create_model() called ==================================
2022-11-14 20:04:40,291:INFO:Initializing create_model()
2022-11-14 20:04:40,294:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d3dc00ed0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27884f10>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:04:40,294:INFO:Checking exceptions
2022-11-14 20:04:40,297:INFO:Importing libraries
2022-11-14 20:04:40,297:INFO:Copying training dataset
2022-11-14 20:04:40,304:INFO:Defining folds
2022-11-14 20:04:40,304:INFO:Declaring metric variables
2022-11-14 20:04:40,314:INFO:Importing untrained model
2022-11-14 20:04:40,322:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-14 20:04:40,337:INFO:Starting cross validation
2022-11-14 20:04:40,339:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:04:40,388:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:04:40,406:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:04:40,453:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:04:40,479:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:04:40,532:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:04:40,573:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:04:40,582:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:04:40,613:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:04:40,645:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:04:40,655:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:04:40,675:INFO:Calculating mean and std
2022-11-14 20:04:40,678:INFO:Creating metrics dataframe
2022-11-14 20:04:40,689:INFO:Uploading results into container
2022-11-14 20:04:40,692:INFO:Uploading model into container now
2022-11-14 20:04:40,692:INFO:master_model_container: 7
2022-11-14 20:04:40,693:INFO:display_container: 2
2022-11-14 20:04:40,693:INFO:OrthogonalMatchingPursuit()
2022-11-14 20:04:40,693:INFO:create_model() successfully completed......................................
2022-11-14 20:04:40,829:INFO:SubProcess create_model() end ==================================
2022-11-14 20:04:40,829:INFO:Creating metrics dataframe
2022-11-14 20:04:40,849:INFO:Initializing Bayesian Ridge
2022-11-14 20:04:40,850:INFO:Total runtime is 0.2637213508288066 minutes
2022-11-14 20:04:40,858:INFO:SubProcess create_model() called ==================================
2022-11-14 20:04:40,859:INFO:Initializing create_model()
2022-11-14 20:04:40,859:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d3dc00ed0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27884f10>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:04:40,860:INFO:Checking exceptions
2022-11-14 20:04:40,862:INFO:Importing libraries
2022-11-14 20:04:40,866:INFO:Copying training dataset
2022-11-14 20:04:40,873:INFO:Defining folds
2022-11-14 20:04:40,874:INFO:Declaring metric variables
2022-11-14 20:04:40,884:INFO:Importing untrained model
2022-11-14 20:04:40,894:INFO:Bayesian Ridge Imported successfully
2022-11-14 20:04:40,911:INFO:Starting cross validation
2022-11-14 20:04:40,913:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:04:41,220:INFO:Calculating mean and std
2022-11-14 20:04:41,222:INFO:Creating metrics dataframe
2022-11-14 20:04:41,233:INFO:Uploading results into container
2022-11-14 20:04:41,238:INFO:Uploading model into container now
2022-11-14 20:04:41,239:INFO:master_model_container: 8
2022-11-14 20:04:41,239:INFO:display_container: 2
2022-11-14 20:04:41,240:INFO:BayesianRidge()
2022-11-14 20:04:41,240:INFO:create_model() successfully completed......................................
2022-11-14 20:04:41,375:INFO:SubProcess create_model() end ==================================
2022-11-14 20:04:41,376:INFO:Creating metrics dataframe
2022-11-14 20:04:41,401:INFO:Initializing Passive Aggressive Regressor
2022-11-14 20:04:41,402:INFO:Total runtime is 0.2729259808858236 minutes
2022-11-14 20:04:41,419:INFO:SubProcess create_model() called ==================================
2022-11-14 20:04:41,419:INFO:Initializing create_model()
2022-11-14 20:04:41,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d3dc00ed0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27884f10>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:04:41,420:INFO:Checking exceptions
2022-11-14 20:04:41,423:INFO:Importing libraries
2022-11-14 20:04:41,423:INFO:Copying training dataset
2022-11-14 20:04:41,436:INFO:Defining folds
2022-11-14 20:04:41,437:INFO:Declaring metric variables
2022-11-14 20:04:41,450:INFO:Importing untrained model
2022-11-14 20:04:41,458:INFO:Passive Aggressive Regressor Imported successfully
2022-11-14 20:04:41,475:INFO:Starting cross validation
2022-11-14 20:04:41,477:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:04:41,813:INFO:Calculating mean and std
2022-11-14 20:04:41,815:INFO:Creating metrics dataframe
2022-11-14 20:04:41,828:INFO:Uploading results into container
2022-11-14 20:04:41,829:INFO:Uploading model into container now
2022-11-14 20:04:41,830:INFO:master_model_container: 9
2022-11-14 20:04:41,830:INFO:display_container: 2
2022-11-14 20:04:41,831:INFO:PassiveAggressiveRegressor(random_state=123)
2022-11-14 20:04:41,831:INFO:create_model() successfully completed......................................
2022-11-14 20:04:41,963:INFO:SubProcess create_model() end ==================================
2022-11-14 20:04:41,964:INFO:Creating metrics dataframe
2022-11-14 20:04:41,984:INFO:Initializing Huber Regressor
2022-11-14 20:04:41,985:INFO:Total runtime is 0.28264565865198776 minutes
2022-11-14 20:04:41,994:INFO:SubProcess create_model() called ==================================
2022-11-14 20:04:41,996:INFO:Initializing create_model()
2022-11-14 20:04:41,999:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d3dc00ed0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27884f10>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:04:41,999:INFO:Checking exceptions
2022-11-14 20:04:42,001:INFO:Importing libraries
2022-11-14 20:04:42,001:INFO:Copying training dataset
2022-11-14 20:04:42,005:INFO:Defining folds
2022-11-14 20:04:42,006:INFO:Declaring metric variables
2022-11-14 20:04:42,020:INFO:Importing untrained model
2022-11-14 20:04:42,030:INFO:Huber Regressor Imported successfully
2022-11-14 20:04:42,045:INFO:Starting cross validation
2022-11-14 20:04:42,048:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:04:42,150:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:04:42,203:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:04:42,293:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:04:42,344:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:04:42,417:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:04:42,470:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:04:42,518:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:04:42,597:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:04:42,633:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:04:42,691:INFO:Calculating mean and std
2022-11-14 20:04:42,694:INFO:Creating metrics dataframe
2022-11-14 20:04:42,708:INFO:Uploading results into container
2022-11-14 20:04:42,709:INFO:Uploading model into container now
2022-11-14 20:04:42,710:INFO:master_model_container: 10
2022-11-14 20:04:42,710:INFO:display_container: 2
2022-11-14 20:04:42,710:INFO:HuberRegressor()
2022-11-14 20:04:42,711:INFO:create_model() successfully completed......................................
2022-11-14 20:04:42,857:INFO:SubProcess create_model() end ==================================
2022-11-14 20:04:42,857:INFO:Creating metrics dataframe
2022-11-14 20:04:42,881:INFO:Initializing K Neighbors Regressor
2022-11-14 20:04:42,881:INFO:Total runtime is 0.29757717450459803 minutes
2022-11-14 20:04:42,890:INFO:SubProcess create_model() called ==================================
2022-11-14 20:04:42,891:INFO:Initializing create_model()
2022-11-14 20:04:42,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d3dc00ed0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27884f10>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:04:42,892:INFO:Checking exceptions
2022-11-14 20:04:42,894:INFO:Importing libraries
2022-11-14 20:04:42,894:INFO:Copying training dataset
2022-11-14 20:04:42,900:INFO:Defining folds
2022-11-14 20:04:42,901:INFO:Declaring metric variables
2022-11-14 20:04:42,914:INFO:Importing untrained model
2022-11-14 20:04:42,924:INFO:K Neighbors Regressor Imported successfully
2022-11-14 20:04:42,943:INFO:Starting cross validation
2022-11-14 20:04:42,944:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:04:43,699:INFO:Calculating mean and std
2022-11-14 20:04:43,706:INFO:Creating metrics dataframe
2022-11-14 20:04:43,724:INFO:Uploading results into container
2022-11-14 20:04:43,728:INFO:Uploading model into container now
2022-11-14 20:04:43,729:INFO:master_model_container: 11
2022-11-14 20:04:43,729:INFO:display_container: 2
2022-11-14 20:04:43,730:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-14 20:04:43,735:INFO:create_model() successfully completed......................................
2022-11-14 20:04:43,916:INFO:SubProcess create_model() end ==================================
2022-11-14 20:04:43,916:INFO:Creating metrics dataframe
2022-11-14 20:04:43,966:INFO:Initializing Decision Tree Regressor
2022-11-14 20:04:43,967:INFO:Total runtime is 0.3156744917233785 minutes
2022-11-14 20:04:43,985:INFO:SubProcess create_model() called ==================================
2022-11-14 20:04:43,992:INFO:Initializing create_model()
2022-11-14 20:04:43,992:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d3dc00ed0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27884f10>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:04:43,993:INFO:Checking exceptions
2022-11-14 20:04:43,998:INFO:Importing libraries
2022-11-14 20:04:43,999:INFO:Copying training dataset
2022-11-14 20:04:44,009:INFO:Defining folds
2022-11-14 20:04:44,010:INFO:Declaring metric variables
2022-11-14 20:04:44,027:INFO:Importing untrained model
2022-11-14 20:04:44,049:INFO:Decision Tree Regressor Imported successfully
2022-11-14 20:04:44,080:INFO:Starting cross validation
2022-11-14 20:04:44,083:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:04:44,662:INFO:Calculating mean and std
2022-11-14 20:04:44,667:INFO:Creating metrics dataframe
2022-11-14 20:04:44,678:INFO:Uploading results into container
2022-11-14 20:04:44,679:INFO:Uploading model into container now
2022-11-14 20:04:44,680:INFO:master_model_container: 12
2022-11-14 20:04:44,680:INFO:display_container: 2
2022-11-14 20:04:44,681:INFO:DecisionTreeRegressor(random_state=123)
2022-11-14 20:04:44,681:INFO:create_model() successfully completed......................................
2022-11-14 20:04:44,951:INFO:SubProcess create_model() end ==================================
2022-11-14 20:04:44,951:INFO:Creating metrics dataframe
2022-11-14 20:04:45,008:INFO:Initializing Random Forest Regressor
2022-11-14 20:04:45,008:INFO:Total runtime is 0.3330275893211365 minutes
2022-11-14 20:04:45,017:INFO:SubProcess create_model() called ==================================
2022-11-14 20:04:45,018:INFO:Initializing create_model()
2022-11-14 20:04:45,018:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d3dc00ed0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27884f10>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:04:45,018:INFO:Checking exceptions
2022-11-14 20:04:45,021:INFO:Importing libraries
2022-11-14 20:04:45,021:INFO:Copying training dataset
2022-11-14 20:04:45,030:INFO:Defining folds
2022-11-14 20:04:45,031:INFO:Declaring metric variables
2022-11-14 20:04:45,040:INFO:Importing untrained model
2022-11-14 20:04:45,093:INFO:Random Forest Regressor Imported successfully
2022-11-14 20:04:45,122:INFO:Starting cross validation
2022-11-14 20:04:45,124:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:04:52,235:INFO:Calculating mean and std
2022-11-14 20:04:52,256:INFO:Creating metrics dataframe
2022-11-14 20:04:52,267:INFO:Uploading results into container
2022-11-14 20:04:52,275:INFO:Uploading model into container now
2022-11-14 20:04:52,276:INFO:master_model_container: 13
2022-11-14 20:04:52,276:INFO:display_container: 2
2022-11-14 20:04:52,277:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-14 20:04:52,277:INFO:create_model() successfully completed......................................
2022-11-14 20:04:52,569:INFO:SubProcess create_model() end ==================================
2022-11-14 20:04:52,573:INFO:Creating metrics dataframe
2022-11-14 20:04:52,617:INFO:Initializing Extra Trees Regressor
2022-11-14 20:04:52,618:INFO:Total runtime is 0.45985864003499355 minutes
2022-11-14 20:04:52,651:INFO:SubProcess create_model() called ==================================
2022-11-14 20:04:52,652:INFO:Initializing create_model()
2022-11-14 20:04:52,652:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d3dc00ed0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27884f10>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:04:52,653:INFO:Checking exceptions
2022-11-14 20:04:52,657:INFO:Importing libraries
2022-11-14 20:04:52,658:INFO:Copying training dataset
2022-11-14 20:04:52,676:INFO:Defining folds
2022-11-14 20:04:52,677:INFO:Declaring metric variables
2022-11-14 20:04:52,698:INFO:Importing untrained model
2022-11-14 20:04:52,716:INFO:Extra Trees Regressor Imported successfully
2022-11-14 20:04:52,755:INFO:Starting cross validation
2022-11-14 20:04:52,762:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:04:56,985:INFO:Calculating mean and std
2022-11-14 20:04:56,994:INFO:Creating metrics dataframe
2022-11-14 20:04:57,011:INFO:Uploading results into container
2022-11-14 20:04:57,024:INFO:Uploading model into container now
2022-11-14 20:04:57,030:INFO:master_model_container: 14
2022-11-14 20:04:57,030:INFO:display_container: 2
2022-11-14 20:04:57,031:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-14 20:04:57,031:INFO:create_model() successfully completed......................................
2022-11-14 20:04:57,411:INFO:SubProcess create_model() end ==================================
2022-11-14 20:04:57,411:INFO:Creating metrics dataframe
2022-11-14 20:04:57,455:INFO:Initializing AdaBoost Regressor
2022-11-14 20:04:57,456:INFO:Total runtime is 0.5404871066411336 minutes
2022-11-14 20:04:57,469:INFO:SubProcess create_model() called ==================================
2022-11-14 20:04:57,470:INFO:Initializing create_model()
2022-11-14 20:04:57,471:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d3dc00ed0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27884f10>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:04:57,471:INFO:Checking exceptions
2022-11-14 20:04:57,477:INFO:Importing libraries
2022-11-14 20:04:57,477:INFO:Copying training dataset
2022-11-14 20:04:57,488:INFO:Defining folds
2022-11-14 20:04:57,489:INFO:Declaring metric variables
2022-11-14 20:04:57,510:INFO:Importing untrained model
2022-11-14 20:04:57,523:INFO:AdaBoost Regressor Imported successfully
2022-11-14 20:04:57,547:INFO:Starting cross validation
2022-11-14 20:04:57,552:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:04:59,956:INFO:Calculating mean and std
2022-11-14 20:04:59,965:INFO:Creating metrics dataframe
2022-11-14 20:04:59,979:INFO:Uploading results into container
2022-11-14 20:04:59,980:INFO:Uploading model into container now
2022-11-14 20:04:59,981:INFO:master_model_container: 15
2022-11-14 20:04:59,981:INFO:display_container: 2
2022-11-14 20:04:59,982:INFO:AdaBoostRegressor(random_state=123)
2022-11-14 20:04:59,982:INFO:create_model() successfully completed......................................
2022-11-14 20:05:00,162:INFO:SubProcess create_model() end ==================================
2022-11-14 20:05:00,163:INFO:Creating metrics dataframe
2022-11-14 20:05:00,190:INFO:Initializing Gradient Boosting Regressor
2022-11-14 20:05:00,191:INFO:Total runtime is 0.5860753655433655 minutes
2022-11-14 20:05:00,203:INFO:SubProcess create_model() called ==================================
2022-11-14 20:05:00,203:INFO:Initializing create_model()
2022-11-14 20:05:00,204:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d3dc00ed0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27884f10>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:05:00,204:INFO:Checking exceptions
2022-11-14 20:05:00,209:INFO:Importing libraries
2022-11-14 20:05:00,209:INFO:Copying training dataset
2022-11-14 20:05:00,215:INFO:Defining folds
2022-11-14 20:05:00,216:INFO:Declaring metric variables
2022-11-14 20:05:00,227:INFO:Importing untrained model
2022-11-14 20:05:00,238:INFO:Gradient Boosting Regressor Imported successfully
2022-11-14 20:05:00,254:INFO:Starting cross validation
2022-11-14 20:05:00,256:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:05:02,105:INFO:Calculating mean and std
2022-11-14 20:05:02,108:INFO:Creating metrics dataframe
2022-11-14 20:05:02,118:INFO:Uploading results into container
2022-11-14 20:05:02,126:INFO:Uploading model into container now
2022-11-14 20:05:02,128:INFO:master_model_container: 16
2022-11-14 20:05:02,129:INFO:display_container: 2
2022-11-14 20:05:02,129:INFO:GradientBoostingRegressor(random_state=123)
2022-11-14 20:05:02,130:INFO:create_model() successfully completed......................................
2022-11-14 20:05:02,305:INFO:SubProcess create_model() end ==================================
2022-11-14 20:05:02,306:INFO:Creating metrics dataframe
2022-11-14 20:05:02,336:INFO:Initializing Light Gradient Boosting Machine
2022-11-14 20:05:02,338:INFO:Total runtime is 0.6218573729197184 minutes
2022-11-14 20:05:02,347:INFO:SubProcess create_model() called ==================================
2022-11-14 20:05:02,348:INFO:Initializing create_model()
2022-11-14 20:05:02,348:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d3dc00ed0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27884f10>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:05:02,349:INFO:Checking exceptions
2022-11-14 20:05:02,352:INFO:Importing libraries
2022-11-14 20:05:02,353:INFO:Copying training dataset
2022-11-14 20:05:02,359:INFO:Defining folds
2022-11-14 20:05:02,359:INFO:Declaring metric variables
2022-11-14 20:05:02,375:INFO:Importing untrained model
2022-11-14 20:05:02,387:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-14 20:05:02,408:INFO:Starting cross validation
2022-11-14 20:05:02,410:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:05:04,023:INFO:Calculating mean and std
2022-11-14 20:05:04,026:INFO:Creating metrics dataframe
2022-11-14 20:05:04,036:INFO:Uploading results into container
2022-11-14 20:05:04,037:INFO:Uploading model into container now
2022-11-14 20:05:04,038:INFO:master_model_container: 17
2022-11-14 20:05:04,039:INFO:display_container: 2
2022-11-14 20:05:04,039:INFO:LGBMRegressor(random_state=123)
2022-11-14 20:05:04,040:INFO:create_model() successfully completed......................................
2022-11-14 20:05:04,198:INFO:SubProcess create_model() end ==================================
2022-11-14 20:05:04,199:INFO:Creating metrics dataframe
2022-11-14 20:05:04,222:INFO:Initializing Dummy Regressor
2022-11-14 20:05:04,222:INFO:Total runtime is 0.6532666881879171 minutes
2022-11-14 20:05:04,236:INFO:SubProcess create_model() called ==================================
2022-11-14 20:05:04,236:INFO:Initializing create_model()
2022-11-14 20:05:04,237:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d3dc00ed0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27884f10>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:05:04,237:INFO:Checking exceptions
2022-11-14 20:05:04,241:INFO:Importing libraries
2022-11-14 20:05:04,242:INFO:Copying training dataset
2022-11-14 20:05:04,246:INFO:Defining folds
2022-11-14 20:05:04,247:INFO:Declaring metric variables
2022-11-14 20:05:04,264:INFO:Importing untrained model
2022-11-14 20:05:04,274:INFO:Dummy Regressor Imported successfully
2022-11-14 20:05:04,295:INFO:Starting cross validation
2022-11-14 20:05:04,297:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:05:04,596:INFO:Calculating mean and std
2022-11-14 20:05:04,599:INFO:Creating metrics dataframe
2022-11-14 20:05:04,610:INFO:Uploading results into container
2022-11-14 20:05:04,612:INFO:Uploading model into container now
2022-11-14 20:05:04,614:INFO:master_model_container: 18
2022-11-14 20:05:04,614:INFO:display_container: 2
2022-11-14 20:05:04,614:INFO:DummyRegressor()
2022-11-14 20:05:04,615:INFO:create_model() successfully completed......................................
2022-11-14 20:05:04,758:INFO:SubProcess create_model() end ==================================
2022-11-14 20:05:04,759:INFO:Creating metrics dataframe
2022-11-14 20:05:04,818:INFO:Initializing create_model()
2022-11-14 20:05:04,819:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d3dc00ed0>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:05:04,820:INFO:Checking exceptions
2022-11-14 20:05:04,826:INFO:Importing libraries
2022-11-14 20:05:04,826:INFO:Copying training dataset
2022-11-14 20:05:04,830:INFO:Defining folds
2022-11-14 20:05:04,830:INFO:Declaring metric variables
2022-11-14 20:05:04,831:INFO:Importing untrained model
2022-11-14 20:05:04,831:INFO:Declaring custom model
2022-11-14 20:05:04,832:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-14 20:05:04,833:INFO:Cross validation set to False
2022-11-14 20:05:04,833:INFO:Fitting Model
2022-11-14 20:05:04,861:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:05:04,865:INFO:OrthogonalMatchingPursuit()
2022-11-14 20:05:04,865:INFO:create_model() successfully completed......................................
2022-11-14 20:05:05,090:INFO:master_model_container: 18
2022-11-14 20:05:05,091:INFO:display_container: 2
2022-11-14 20:05:05,092:INFO:OrthogonalMatchingPursuit()
2022-11-14 20:05:05,092:INFO:compare_models() successfully completed......................................
2022-11-14 20:15:29,605:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  app.launch_new_instance()

2022-11-14 20:15:29,607:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:15:29,608:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:15:29,609:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:15:29,610:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:15:29,611:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:15:29,612:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:15:29,613:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:15:29,614:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:15:29,615:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:15:29,616:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:15:29,622:INFO:PyCaret RegressionExperiment
2022-11-14 20:15:29,623:INFO:Logging name: FullData
2022-11-14 20:15:29,624:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-14 20:15:29,624:INFO:version 3.0.0.rc4
2022-11-14 20:15:29,624:INFO:Initializing setup()
2022-11-14 20:15:29,624:INFO:self.USI: 8094
2022-11-14 20:15:29,624:INFO:self.variable_keys: {'fold_generator', 'fold_shuffle_param', '_ml_usecase', 'data', 'X_train', 'y', 'transform_target_method_param', 'idx', 'display_container', 'log_plots_param', 'gpu_param', 'y_train', '_available_plots', 'master_model_container', '_gpu_n_jobs_param', 'y_test', '_all_models_internal', 'X_test', 'transform_target_param', 'X', 'html_param', 'logging_param', '_all_metrics', 'exp_name_log', 'pipeline', 'variable_keys', 'seed', 'target_param', '_all_models', 'USI', 'fold_groups_param', 'exp_id', 'memory', 'n_jobs_param'}
2022-11-14 20:15:29,625:INFO:Checking environment
2022-11-14 20:15:29,625:INFO:python_version: 3.7.15
2022-11-14 20:15:29,625:INFO:python_build: ('default', 'Oct 12 2022 19:14:55')
2022-11-14 20:15:29,625:INFO:machine: x86_64
2022-11-14 20:15:29,626:INFO:platform: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-14 20:15:29,626:INFO:Memory: svmem(total=13616361472, available=11676372992, percent=14.2, used=1771085824, free=7652188160, active=901672960, inactive=4693192704, buffers=167084032, cached=4026003456, shared=1318912, slab=272846848)
2022-11-14 20:15:29,627:INFO:Physical Core: 1
2022-11-14 20:15:29,627:INFO:Logical Core: 2
2022-11-14 20:15:29,627:INFO:Checking libraries
2022-11-14 20:15:29,627:INFO:System:
2022-11-14 20:15:29,627:INFO:    python: 3.7.15 (default, Oct 12 2022, 19:14:55)  [GCC 7.5.0]
2022-11-14 20:15:29,627:INFO:executable: /usr/bin/python3
2022-11-14 20:15:29,628:INFO:   machine: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-14 20:15:29,628:INFO:PyCaret required dependencies:
2022-11-14 20:15:29,628:INFO:                 pip: 21.1.3
2022-11-14 20:15:29,628:INFO:          setuptools: 57.4.0
2022-11-14 20:15:29,628:INFO:             pycaret: 3.0.0rc4
2022-11-14 20:15:29,629:INFO:             IPython: 7.9.0
2022-11-14 20:15:29,629:INFO:          ipywidgets: 7.7.1
2022-11-14 20:15:29,629:INFO:                tqdm: 4.64.1
2022-11-14 20:15:29,629:INFO:               numpy: 1.21.6
2022-11-14 20:15:29,629:INFO:              pandas: 1.3.5
2022-11-14 20:15:29,629:INFO:              jinja2: 3.0.0
2022-11-14 20:15:29,629:INFO:               scipy: 1.7.3
2022-11-14 20:15:29,630:INFO:              joblib: 1.2.0
2022-11-14 20:15:29,630:INFO:             sklearn: 1.0.2
2022-11-14 20:15:29,630:INFO:                pyod: 1.0.6
2022-11-14 20:15:29,630:INFO:            imblearn: 0.8.1
2022-11-14 20:15:29,630:INFO:   category_encoders: 2.5.1.post0
2022-11-14 20:15:29,630:INFO:            lightgbm: 3.3.3
2022-11-14 20:15:29,630:INFO:               numba: 0.55.2
2022-11-14 20:15:29,631:INFO:            requests: 2.28.1
2022-11-14 20:15:29,631:INFO:          matplotlib: 3.5.3
2022-11-14 20:15:29,631:INFO:          scikitplot: 0.3.7
2022-11-14 20:15:29,631:INFO:         yellowbrick: 1.5
2022-11-14 20:15:29,631:INFO:              plotly: 5.5.0
2022-11-14 20:15:29,631:INFO:             kaleido: 0.2.1
2022-11-14 20:15:29,632:INFO:         statsmodels: 0.12.2
2022-11-14 20:15:29,632:INFO:              sktime: 0.13.4
2022-11-14 20:15:29,632:INFO:               tbats: 1.1.1
2022-11-14 20:15:29,632:INFO:            pmdarima: 1.8.5
2022-11-14 20:15:29,632:INFO:              psutil: 5.9.4
2022-11-14 20:15:29,633:INFO:PyCaret optional dependencies:
2022-11-14 20:15:29,633:INFO:                shap: Not installed
2022-11-14 20:15:29,633:INFO:           interpret: Not installed
2022-11-14 20:15:29,633:INFO:                umap: Not installed
2022-11-14 20:15:29,633:INFO:    pandas_profiling: 1.4.1
2022-11-14 20:15:29,633:INFO:  explainerdashboard: Not installed
2022-11-14 20:15:29,634:INFO:             autoviz: Not installed
2022-11-14 20:15:29,634:INFO:           fairlearn: Not installed
2022-11-14 20:15:29,634:INFO:             xgboost: 0.90
2022-11-14 20:15:29,634:INFO:            catboost: Not installed
2022-11-14 20:15:29,634:INFO:              kmodes: Not installed
2022-11-14 20:15:29,634:INFO:             mlxtend: 0.14.0
2022-11-14 20:15:29,634:INFO:       statsforecast: Not installed
2022-11-14 20:15:29,635:INFO:        tune_sklearn: Not installed
2022-11-14 20:15:29,635:INFO:                 ray: Not installed
2022-11-14 20:15:29,635:INFO:            hyperopt: 0.1.2
2022-11-14 20:15:29,635:INFO:              optuna: Not installed
2022-11-14 20:15:29,635:INFO:               skopt: Not installed
2022-11-14 20:15:29,635:INFO:              mlflow: Not installed
2022-11-14 20:15:29,636:INFO:              gradio: Not installed
2022-11-14 20:15:29,636:INFO:             fastapi: Not installed
2022-11-14 20:15:29,636:INFO:             uvicorn: Not installed
2022-11-14 20:15:29,636:INFO:              m2cgen: Not installed
2022-11-14 20:15:29,636:INFO:           evidently: Not installed
2022-11-14 20:15:29,636:INFO:                nltk: 3.7
2022-11-14 20:15:29,636:INFO:            pyLDAvis: Not installed
2022-11-14 20:15:29,637:INFO:              gensim: 3.6.0
2022-11-14 20:15:29,637:INFO:               spacy: 3.4.2
2022-11-14 20:15:29,637:INFO:           wordcloud: 1.8.2.2
2022-11-14 20:15:29,637:INFO:            textblob: 0.15.3
2022-11-14 20:15:29,637:INFO:               fugue: Not installed
2022-11-14 20:15:29,637:INFO:           streamlit: Not installed
2022-11-14 20:15:29,637:INFO:             prophet: 1.1.1
2022-11-14 20:15:29,638:INFO:None
2022-11-14 20:15:29,638:INFO:Set up data.
2022-11-14 20:15:29,645:INFO:Set up train/test split.
2022-11-14 20:15:29,649:INFO:Set up index.
2022-11-14 20:15:29,650:INFO:Set up folding strategy.
2022-11-14 20:15:29,650:INFO:Assigning column types.
2022-11-14 20:15:29,656:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-14 20:15:29,657:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-14 20:15:29,662:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-14 20:15:29,668:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:15:29,734:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:15:29,788:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:15:29,789:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:15:29,790:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:15:29,790:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:15:29,791:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-14 20:15:29,796:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-14 20:15:29,801:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:15:29,868:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:15:29,919:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:15:29,920:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:15:29,920:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:15:29,921:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:15:29,922:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-14 20:15:29,927:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-14 20:15:29,932:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:15:30,009:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:15:30,060:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:15:30,062:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:15:30,062:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:15:30,063:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:15:30,069:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-14 20:15:30,074:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:15:30,139:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:15:30,190:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:15:30,191:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:15:30,191:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:15:30,191:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:15:30,192:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-14 20:15:30,204:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:15:30,270:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:15:30,320:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:15:30,321:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:15:30,322:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:15:30,322:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:15:30,333:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:15:30,398:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:15:30,448:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:15:30,449:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:15:30,450:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:15:30,450:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:15:30,451:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-14 20:15:30,533:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:15:30,586:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:15:30,587:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:15:30,588:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:15:30,588:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:15:30,664:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:15:30,713:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:15:30,715:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:15:30,716:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:15:30,716:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:15:30,717:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-14 20:15:30,797:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:15:30,850:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:15:30,850:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:15:30,851:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:15:30,927:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:15:30,981:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:15:30,982:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:15:30,982:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:15:30,983:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-14 20:15:31,116:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:15:31,116:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:15:31,117:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:15:31,244:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:15:31,245:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:15:31,245:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:15:31,246:INFO:Preparing preprocessing pipeline...
2022-11-14 20:15:31,248:INFO:Set up simple imputation.
2022-11-14 20:15:31,248:INFO:Set up variance threshold.
2022-11-14 20:15:31,262:INFO:Finished creating preprocessing pipeline.
2022-11-14 20:15:31,269:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-14 20:15:31,269:INFO:Creating final display dataframe.
2022-11-14 20:15:31,353:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 12)
4         Train data shape    (607, 12)
5          Test data shape    (261, 12)
6         Numeric features           11
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         8094
2022-11-14 20:15:31,507:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:15:31,508:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:15:31,510:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:15:31,638:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:15:31,639:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:15:31,640:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:15:31,647:INFO:setup() successfully completed in 2.03s...............
2022-11-14 20:15:31,648:INFO:Initializing compare_models()
2022-11-14 20:15:31,648:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232029d0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f3d232029d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-14 20:15:31,649:INFO:Checking exceptions
2022-11-14 20:15:31,650:INFO:Preparing display monitor
2022-11-14 20:15:31,744:INFO:Initializing Linear Regression
2022-11-14 20:15:31,744:INFO:Total runtime is 7.458527882893881e-06 minutes
2022-11-14 20:15:31,754:INFO:SubProcess create_model() called ==================================
2022-11-14 20:15:31,757:INFO:Initializing create_model()
2022-11-14 20:15:31,757:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232029d0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2e0ac7d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:15:31,758:INFO:Checking exceptions
2022-11-14 20:15:31,760:INFO:Importing libraries
2022-11-14 20:15:31,761:INFO:Copying training dataset
2022-11-14 20:15:31,765:INFO:Defining folds
2022-11-14 20:15:31,767:INFO:Declaring metric variables
2022-11-14 20:15:31,773:INFO:Importing untrained model
2022-11-14 20:15:31,784:INFO:Linear Regression Imported successfully
2022-11-14 20:15:31,801:INFO:Starting cross validation
2022-11-14 20:15:31,806:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:15:35,666:INFO:Calculating mean and std
2022-11-14 20:15:35,670:INFO:Creating metrics dataframe
2022-11-14 20:15:35,680:INFO:Uploading results into container
2022-11-14 20:15:35,682:INFO:Uploading model into container now
2022-11-14 20:15:35,683:INFO:master_model_container: 1
2022-11-14 20:15:35,683:INFO:display_container: 2
2022-11-14 20:15:35,684:INFO:LinearRegression(n_jobs=-1)
2022-11-14 20:15:35,685:INFO:create_model() successfully completed......................................
2022-11-14 20:15:35,954:INFO:SubProcess create_model() end ==================================
2022-11-14 20:15:35,955:INFO:Creating metrics dataframe
2022-11-14 20:15:35,975:INFO:Initializing Lasso Regression
2022-11-14 20:15:35,977:INFO:Total runtime is 0.07055054505666097 minutes
2022-11-14 20:15:35,986:INFO:SubProcess create_model() called ==================================
2022-11-14 20:15:35,987:INFO:Initializing create_model()
2022-11-14 20:15:35,987:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232029d0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2e0ac7d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:15:35,988:INFO:Checking exceptions
2022-11-14 20:15:35,993:INFO:Importing libraries
2022-11-14 20:15:35,994:INFO:Copying training dataset
2022-11-14 20:15:35,998:INFO:Defining folds
2022-11-14 20:15:35,998:INFO:Declaring metric variables
2022-11-14 20:15:36,008:INFO:Importing untrained model
2022-11-14 20:15:36,019:INFO:Lasso Regression Imported successfully
2022-11-14 20:15:36,035:INFO:Starting cross validation
2022-11-14 20:15:36,036:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:15:36,345:INFO:Calculating mean and std
2022-11-14 20:15:36,347:INFO:Creating metrics dataframe
2022-11-14 20:15:36,361:INFO:Uploading results into container
2022-11-14 20:15:36,362:INFO:Uploading model into container now
2022-11-14 20:15:36,362:INFO:master_model_container: 2
2022-11-14 20:15:36,362:INFO:display_container: 2
2022-11-14 20:15:36,363:INFO:Lasso(random_state=123)
2022-11-14 20:15:36,363:INFO:create_model() successfully completed......................................
2022-11-14 20:15:36,512:INFO:SubProcess create_model() end ==================================
2022-11-14 20:15:36,513:INFO:Creating metrics dataframe
2022-11-14 20:15:36,531:INFO:Initializing Ridge Regression
2022-11-14 20:15:36,532:INFO:Total runtime is 0.07980388005574544 minutes
2022-11-14 20:15:36,541:INFO:SubProcess create_model() called ==================================
2022-11-14 20:15:36,542:INFO:Initializing create_model()
2022-11-14 20:15:36,542:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232029d0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2e0ac7d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:15:36,543:INFO:Checking exceptions
2022-11-14 20:15:36,545:INFO:Importing libraries
2022-11-14 20:15:36,546:INFO:Copying training dataset
2022-11-14 20:15:36,555:INFO:Defining folds
2022-11-14 20:15:36,559:INFO:Declaring metric variables
2022-11-14 20:15:36,570:INFO:Importing untrained model
2022-11-14 20:15:36,579:INFO:Ridge Regression Imported successfully
2022-11-14 20:15:36,593:INFO:Starting cross validation
2022-11-14 20:15:36,595:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:15:36,895:INFO:Calculating mean and std
2022-11-14 20:15:36,898:INFO:Creating metrics dataframe
2022-11-14 20:15:36,911:INFO:Uploading results into container
2022-11-14 20:15:36,912:INFO:Uploading model into container now
2022-11-14 20:15:36,913:INFO:master_model_container: 3
2022-11-14 20:15:36,913:INFO:display_container: 2
2022-11-14 20:15:36,914:INFO:Ridge(random_state=123)
2022-11-14 20:15:36,914:INFO:create_model() successfully completed......................................
2022-11-14 20:15:37,070:INFO:SubProcess create_model() end ==================================
2022-11-14 20:15:37,071:INFO:Creating metrics dataframe
2022-11-14 20:15:37,090:INFO:Initializing Elastic Net
2022-11-14 20:15:37,091:INFO:Total runtime is 0.08911445140838622 minutes
2022-11-14 20:15:37,100:INFO:SubProcess create_model() called ==================================
2022-11-14 20:15:37,101:INFO:Initializing create_model()
2022-11-14 20:15:37,101:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232029d0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2e0ac7d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:15:37,101:INFO:Checking exceptions
2022-11-14 20:15:37,104:INFO:Importing libraries
2022-11-14 20:15:37,104:INFO:Copying training dataset
2022-11-14 20:15:37,110:INFO:Defining folds
2022-11-14 20:15:37,111:INFO:Declaring metric variables
2022-11-14 20:15:37,125:INFO:Importing untrained model
2022-11-14 20:15:37,138:INFO:Elastic Net Imported successfully
2022-11-14 20:15:37,154:INFO:Starting cross validation
2022-11-14 20:15:37,157:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:15:37,490:INFO:Calculating mean and std
2022-11-14 20:15:37,493:INFO:Creating metrics dataframe
2022-11-14 20:15:37,504:INFO:Uploading results into container
2022-11-14 20:15:37,507:INFO:Uploading model into container now
2022-11-14 20:15:37,508:INFO:master_model_container: 4
2022-11-14 20:15:37,508:INFO:display_container: 2
2022-11-14 20:15:37,509:INFO:ElasticNet(random_state=123)
2022-11-14 20:15:37,509:INFO:create_model() successfully completed......................................
2022-11-14 20:15:37,668:INFO:SubProcess create_model() end ==================================
2022-11-14 20:15:37,668:INFO:Creating metrics dataframe
2022-11-14 20:15:37,689:INFO:Initializing Least Angle Regression
2022-11-14 20:15:37,689:INFO:Total runtime is 0.0990893284479777 minutes
2022-11-14 20:15:37,700:INFO:SubProcess create_model() called ==================================
2022-11-14 20:15:37,700:INFO:Initializing create_model()
2022-11-14 20:15:37,701:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232029d0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2e0ac7d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:15:37,701:INFO:Checking exceptions
2022-11-14 20:15:37,704:INFO:Importing libraries
2022-11-14 20:15:37,704:INFO:Copying training dataset
2022-11-14 20:15:37,711:INFO:Defining folds
2022-11-14 20:15:37,712:INFO:Declaring metric variables
2022-11-14 20:15:37,721:INFO:Importing untrained model
2022-11-14 20:15:37,730:INFO:Least Angle Regression Imported successfully
2022-11-14 20:15:37,749:INFO:Starting cross validation
2022-11-14 20:15:37,751:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:15:37,795:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:15:37,824:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:15:37,859:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:15:37,889:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:15:37,925:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:15:37,964:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:15:37,966:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:15:38,006:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:15:38,030:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:15:38,051:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:15:38,070:INFO:Calculating mean and std
2022-11-14 20:15:38,078:INFO:Creating metrics dataframe
2022-11-14 20:15:38,090:INFO:Uploading results into container
2022-11-14 20:15:38,091:INFO:Uploading model into container now
2022-11-14 20:15:38,091:INFO:master_model_container: 5
2022-11-14 20:15:38,092:INFO:display_container: 2
2022-11-14 20:15:38,092:INFO:Lars(random_state=123)
2022-11-14 20:15:38,092:INFO:create_model() successfully completed......................................
2022-11-14 20:15:38,255:INFO:SubProcess create_model() end ==================================
2022-11-14 20:15:38,256:INFO:Creating metrics dataframe
2022-11-14 20:15:38,276:INFO:Initializing Lasso Least Angle Regression
2022-11-14 20:15:38,276:INFO:Total runtime is 0.10887018044789631 minutes
2022-11-14 20:15:38,284:INFO:SubProcess create_model() called ==================================
2022-11-14 20:15:38,285:INFO:Initializing create_model()
2022-11-14 20:15:38,286:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232029d0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2e0ac7d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:15:38,286:INFO:Checking exceptions
2022-11-14 20:15:38,289:INFO:Importing libraries
2022-11-14 20:15:38,289:INFO:Copying training dataset
2022-11-14 20:15:38,294:INFO:Defining folds
2022-11-14 20:15:38,295:INFO:Declaring metric variables
2022-11-14 20:15:38,308:INFO:Importing untrained model
2022-11-14 20:15:38,319:INFO:Lasso Least Angle Regression Imported successfully
2022-11-14 20:15:38,336:INFO:Starting cross validation
2022-11-14 20:15:38,338:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:15:38,380:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:15:38,410:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:15:38,445:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:15:38,474:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:15:38,509:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:15:38,547:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:15:38,561:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:15:38,589:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:15:38,619:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:15:38,629:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:15:38,644:INFO:Calculating mean and std
2022-11-14 20:15:38,647:INFO:Creating metrics dataframe
2022-11-14 20:15:38,655:INFO:Uploading results into container
2022-11-14 20:15:38,656:INFO:Uploading model into container now
2022-11-14 20:15:38,657:INFO:master_model_container: 6
2022-11-14 20:15:38,658:INFO:display_container: 2
2022-11-14 20:15:38,658:INFO:LassoLars(random_state=123)
2022-11-14 20:15:38,659:INFO:create_model() successfully completed......................................
2022-11-14 20:15:38,826:INFO:SubProcess create_model() end ==================================
2022-11-14 20:15:38,826:INFO:Creating metrics dataframe
2022-11-14 20:15:38,848:INFO:Initializing Orthogonal Matching Pursuit
2022-11-14 20:15:38,849:INFO:Total runtime is 0.11841445366541543 minutes
2022-11-14 20:15:38,859:INFO:SubProcess create_model() called ==================================
2022-11-14 20:15:38,860:INFO:Initializing create_model()
2022-11-14 20:15:38,863:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232029d0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2e0ac7d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:15:38,865:INFO:Checking exceptions
2022-11-14 20:15:38,867:INFO:Importing libraries
2022-11-14 20:15:38,867:INFO:Copying training dataset
2022-11-14 20:15:38,873:INFO:Defining folds
2022-11-14 20:15:38,873:INFO:Declaring metric variables
2022-11-14 20:15:38,886:INFO:Importing untrained model
2022-11-14 20:15:38,895:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-14 20:15:38,913:INFO:Starting cross validation
2022-11-14 20:15:38,914:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:15:38,955:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:15:38,981:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:15:39,016:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:15:39,044:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:15:39,080:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:15:39,119:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:15:39,124:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:15:39,160:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:15:39,186:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:15:39,200:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:15:39,216:INFO:Calculating mean and std
2022-11-14 20:15:39,220:INFO:Creating metrics dataframe
2022-11-14 20:15:39,232:INFO:Uploading results into container
2022-11-14 20:15:39,233:INFO:Uploading model into container now
2022-11-14 20:15:39,235:INFO:master_model_container: 7
2022-11-14 20:15:39,235:INFO:display_container: 2
2022-11-14 20:15:39,236:INFO:OrthogonalMatchingPursuit()
2022-11-14 20:15:39,236:INFO:create_model() successfully completed......................................
2022-11-14 20:15:39,401:INFO:SubProcess create_model() end ==================================
2022-11-14 20:15:39,402:INFO:Creating metrics dataframe
2022-11-14 20:15:39,421:INFO:Initializing Bayesian Ridge
2022-11-14 20:15:39,422:INFO:Total runtime is 0.127965501944224 minutes
2022-11-14 20:15:39,433:INFO:SubProcess create_model() called ==================================
2022-11-14 20:15:39,435:INFO:Initializing create_model()
2022-11-14 20:15:39,435:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232029d0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2e0ac7d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:15:39,435:INFO:Checking exceptions
2022-11-14 20:15:39,438:INFO:Importing libraries
2022-11-14 20:15:39,438:INFO:Copying training dataset
2022-11-14 20:15:39,444:INFO:Defining folds
2022-11-14 20:15:39,444:INFO:Declaring metric variables
2022-11-14 20:15:39,455:INFO:Importing untrained model
2022-11-14 20:15:39,465:INFO:Bayesian Ridge Imported successfully
2022-11-14 20:15:39,484:INFO:Starting cross validation
2022-11-14 20:15:39,487:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:15:39,805:INFO:Calculating mean and std
2022-11-14 20:15:39,808:INFO:Creating metrics dataframe
2022-11-14 20:15:39,821:INFO:Uploading results into container
2022-11-14 20:15:39,822:INFO:Uploading model into container now
2022-11-14 20:15:39,823:INFO:master_model_container: 8
2022-11-14 20:15:39,823:INFO:display_container: 2
2022-11-14 20:15:39,824:INFO:BayesianRidge()
2022-11-14 20:15:39,824:INFO:create_model() successfully completed......................................
2022-11-14 20:15:39,981:INFO:SubProcess create_model() end ==================================
2022-11-14 20:15:39,981:INFO:Creating metrics dataframe
2022-11-14 20:15:40,001:INFO:Initializing Passive Aggressive Regressor
2022-11-14 20:15:40,002:INFO:Total runtime is 0.1376346667607625 minutes
2022-11-14 20:15:40,011:INFO:SubProcess create_model() called ==================================
2022-11-14 20:15:40,012:INFO:Initializing create_model()
2022-11-14 20:15:40,012:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232029d0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2e0ac7d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:15:40,013:INFO:Checking exceptions
2022-11-14 20:15:40,016:INFO:Importing libraries
2022-11-14 20:15:40,016:INFO:Copying training dataset
2022-11-14 20:15:40,022:INFO:Defining folds
2022-11-14 20:15:40,023:INFO:Declaring metric variables
2022-11-14 20:15:40,034:INFO:Importing untrained model
2022-11-14 20:15:40,047:INFO:Passive Aggressive Regressor Imported successfully
2022-11-14 20:15:40,067:INFO:Starting cross validation
2022-11-14 20:15:40,069:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:15:40,395:INFO:Calculating mean and std
2022-11-14 20:15:40,397:INFO:Creating metrics dataframe
2022-11-14 20:15:40,411:INFO:Uploading results into container
2022-11-14 20:15:40,413:INFO:Uploading model into container now
2022-11-14 20:15:40,414:INFO:master_model_container: 9
2022-11-14 20:15:40,414:INFO:display_container: 2
2022-11-14 20:15:40,414:INFO:PassiveAggressiveRegressor(random_state=123)
2022-11-14 20:15:40,415:INFO:create_model() successfully completed......................................
2022-11-14 20:15:40,573:INFO:SubProcess create_model() end ==================================
2022-11-14 20:15:40,574:INFO:Creating metrics dataframe
2022-11-14 20:15:40,595:INFO:Initializing Huber Regressor
2022-11-14 20:15:40,596:INFO:Total runtime is 0.14753242333730057 minutes
2022-11-14 20:15:40,604:INFO:SubProcess create_model() called ==================================
2022-11-14 20:15:40,605:INFO:Initializing create_model()
2022-11-14 20:15:40,608:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232029d0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2e0ac7d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:15:40,608:INFO:Checking exceptions
2022-11-14 20:15:40,610:INFO:Importing libraries
2022-11-14 20:15:40,611:INFO:Copying training dataset
2022-11-14 20:15:40,615:INFO:Defining folds
2022-11-14 20:15:40,616:INFO:Declaring metric variables
2022-11-14 20:15:40,629:INFO:Importing untrained model
2022-11-14 20:15:40,640:INFO:Huber Regressor Imported successfully
2022-11-14 20:15:40,658:INFO:Starting cross validation
2022-11-14 20:15:40,660:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:15:40,760:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:15:40,863:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:15:40,863:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:15:40,964:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:15:41,008:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:15:41,065:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:15:41,155:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:15:41,196:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:15:41,259:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:15:41,305:INFO:Calculating mean and std
2022-11-14 20:15:41,312:INFO:Creating metrics dataframe
2022-11-14 20:15:41,321:INFO:Uploading results into container
2022-11-14 20:15:41,322:INFO:Uploading model into container now
2022-11-14 20:15:41,323:INFO:master_model_container: 10
2022-11-14 20:15:41,323:INFO:display_container: 2
2022-11-14 20:15:41,324:INFO:HuberRegressor()
2022-11-14 20:15:41,324:INFO:create_model() successfully completed......................................
2022-11-14 20:15:41,492:INFO:SubProcess create_model() end ==================================
2022-11-14 20:15:41,492:INFO:Creating metrics dataframe
2022-11-14 20:15:41,514:INFO:Initializing K Neighbors Regressor
2022-11-14 20:15:41,515:INFO:Total runtime is 0.1628421584765116 minutes
2022-11-14 20:15:41,524:INFO:SubProcess create_model() called ==================================
2022-11-14 20:15:41,525:INFO:Initializing create_model()
2022-11-14 20:15:41,525:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232029d0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2e0ac7d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:15:41,525:INFO:Checking exceptions
2022-11-14 20:15:41,528:INFO:Importing libraries
2022-11-14 20:15:41,528:INFO:Copying training dataset
2022-11-14 20:15:41,533:INFO:Defining folds
2022-11-14 20:15:41,534:INFO:Declaring metric variables
2022-11-14 20:15:41,544:INFO:Importing untrained model
2022-11-14 20:15:41,560:INFO:K Neighbors Regressor Imported successfully
2022-11-14 20:15:41,582:INFO:Starting cross validation
2022-11-14 20:15:41,586:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:15:42,383:INFO:Calculating mean and std
2022-11-14 20:15:42,385:INFO:Creating metrics dataframe
2022-11-14 20:15:42,396:INFO:Uploading results into container
2022-11-14 20:15:42,401:INFO:Uploading model into container now
2022-11-14 20:15:42,402:INFO:master_model_container: 11
2022-11-14 20:15:42,402:INFO:display_container: 2
2022-11-14 20:15:42,403:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-14 20:15:42,403:INFO:create_model() successfully completed......................................
2022-11-14 20:15:42,563:INFO:SubProcess create_model() end ==================================
2022-11-14 20:15:42,563:INFO:Creating metrics dataframe
2022-11-14 20:15:42,589:INFO:Initializing Decision Tree Regressor
2022-11-14 20:15:42,589:INFO:Total runtime is 0.18075230518976843 minutes
2022-11-14 20:15:42,598:INFO:SubProcess create_model() called ==================================
2022-11-14 20:15:42,598:INFO:Initializing create_model()
2022-11-14 20:15:42,599:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232029d0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2e0ac7d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:15:42,599:INFO:Checking exceptions
2022-11-14 20:15:42,602:INFO:Importing libraries
2022-11-14 20:15:42,602:INFO:Copying training dataset
2022-11-14 20:15:42,609:INFO:Defining folds
2022-11-14 20:15:42,610:INFO:Declaring metric variables
2022-11-14 20:15:42,619:INFO:Importing untrained model
2022-11-14 20:15:42,628:INFO:Decision Tree Regressor Imported successfully
2022-11-14 20:15:42,647:INFO:Starting cross validation
2022-11-14 20:15:42,651:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:15:42,991:INFO:Calculating mean and std
2022-11-14 20:15:42,994:INFO:Creating metrics dataframe
2022-11-14 20:15:43,003:INFO:Uploading results into container
2022-11-14 20:15:43,003:INFO:Uploading model into container now
2022-11-14 20:15:43,004:INFO:master_model_container: 12
2022-11-14 20:15:43,005:INFO:display_container: 2
2022-11-14 20:15:43,005:INFO:DecisionTreeRegressor(random_state=123)
2022-11-14 20:15:43,005:INFO:create_model() successfully completed......................................
2022-11-14 20:15:43,166:INFO:SubProcess create_model() end ==================================
2022-11-14 20:15:43,166:INFO:Creating metrics dataframe
2022-11-14 20:15:43,192:INFO:Initializing Random Forest Regressor
2022-11-14 20:15:43,193:INFO:Total runtime is 0.19081816673278804 minutes
2022-11-14 20:15:43,202:INFO:SubProcess create_model() called ==================================
2022-11-14 20:15:43,203:INFO:Initializing create_model()
2022-11-14 20:15:43,204:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232029d0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2e0ac7d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:15:43,204:INFO:Checking exceptions
2022-11-14 20:15:43,207:INFO:Importing libraries
2022-11-14 20:15:43,207:INFO:Copying training dataset
2022-11-14 20:15:43,215:INFO:Defining folds
2022-11-14 20:15:43,216:INFO:Declaring metric variables
2022-11-14 20:15:43,226:INFO:Importing untrained model
2022-11-14 20:15:43,235:INFO:Random Forest Regressor Imported successfully
2022-11-14 20:15:43,252:INFO:Starting cross validation
2022-11-14 20:15:43,257:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:15:48,468:INFO:Calculating mean and std
2022-11-14 20:15:48,471:INFO:Creating metrics dataframe
2022-11-14 20:15:48,481:INFO:Uploading results into container
2022-11-14 20:15:48,482:INFO:Uploading model into container now
2022-11-14 20:15:48,483:INFO:master_model_container: 13
2022-11-14 20:15:48,483:INFO:display_container: 2
2022-11-14 20:15:48,484:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-14 20:15:48,485:INFO:create_model() successfully completed......................................
2022-11-14 20:15:48,654:INFO:SubProcess create_model() end ==================================
2022-11-14 20:15:48,655:INFO:Creating metrics dataframe
2022-11-14 20:15:48,677:INFO:Initializing Extra Trees Regressor
2022-11-14 20:15:48,677:INFO:Total runtime is 0.2822248299916585 minutes
2022-11-14 20:15:48,691:INFO:SubProcess create_model() called ==================================
2022-11-14 20:15:48,692:INFO:Initializing create_model()
2022-11-14 20:15:48,693:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232029d0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2e0ac7d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:15:48,693:INFO:Checking exceptions
2022-11-14 20:15:48,696:INFO:Importing libraries
2022-11-14 20:15:48,696:INFO:Copying training dataset
2022-11-14 20:15:48,703:INFO:Defining folds
2022-11-14 20:15:48,704:INFO:Declaring metric variables
2022-11-14 20:15:48,713:INFO:Importing untrained model
2022-11-14 20:15:48,722:INFO:Extra Trees Regressor Imported successfully
2022-11-14 20:15:48,739:INFO:Starting cross validation
2022-11-14 20:15:48,741:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:15:51,494:INFO:Calculating mean and std
2022-11-14 20:15:51,499:INFO:Creating metrics dataframe
2022-11-14 20:15:51,508:INFO:Uploading results into container
2022-11-14 20:15:51,509:INFO:Uploading model into container now
2022-11-14 20:15:51,510:INFO:master_model_container: 14
2022-11-14 20:15:51,510:INFO:display_container: 2
2022-11-14 20:15:51,510:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-14 20:15:51,511:INFO:create_model() successfully completed......................................
2022-11-14 20:15:51,673:INFO:SubProcess create_model() end ==================================
2022-11-14 20:15:51,673:INFO:Creating metrics dataframe
2022-11-14 20:15:51,695:INFO:Initializing AdaBoost Regressor
2022-11-14 20:15:51,695:INFO:Total runtime is 0.33252364397048945 minutes
2022-11-14 20:15:51,704:INFO:SubProcess create_model() called ==================================
2022-11-14 20:15:51,705:INFO:Initializing create_model()
2022-11-14 20:15:51,705:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232029d0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2e0ac7d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:15:51,705:INFO:Checking exceptions
2022-11-14 20:15:51,708:INFO:Importing libraries
2022-11-14 20:15:51,708:INFO:Copying training dataset
2022-11-14 20:15:51,716:INFO:Defining folds
2022-11-14 20:15:51,716:INFO:Declaring metric variables
2022-11-14 20:15:51,726:INFO:Importing untrained model
2022-11-14 20:15:51,735:INFO:AdaBoost Regressor Imported successfully
2022-11-14 20:15:51,754:INFO:Starting cross validation
2022-11-14 20:15:51,760:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:15:52,949:INFO:Calculating mean and std
2022-11-14 20:15:52,951:INFO:Creating metrics dataframe
2022-11-14 20:15:52,959:INFO:Uploading results into container
2022-11-14 20:15:52,960:INFO:Uploading model into container now
2022-11-14 20:15:52,961:INFO:master_model_container: 15
2022-11-14 20:15:52,961:INFO:display_container: 2
2022-11-14 20:15:52,962:INFO:AdaBoostRegressor(random_state=123)
2022-11-14 20:15:52,962:INFO:create_model() successfully completed......................................
2022-11-14 20:15:53,115:INFO:SubProcess create_model() end ==================================
2022-11-14 20:15:53,116:INFO:Creating metrics dataframe
2022-11-14 20:15:53,145:INFO:Initializing Gradient Boosting Regressor
2022-11-14 20:15:53,146:INFO:Total runtime is 0.3566956520080566 minutes
2022-11-14 20:15:53,154:INFO:SubProcess create_model() called ==================================
2022-11-14 20:15:53,155:INFO:Initializing create_model()
2022-11-14 20:15:53,156:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232029d0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2e0ac7d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:15:53,156:INFO:Checking exceptions
2022-11-14 20:15:53,159:INFO:Importing libraries
2022-11-14 20:15:53,159:INFO:Copying training dataset
2022-11-14 20:15:53,166:INFO:Defining folds
2022-11-14 20:15:53,167:INFO:Declaring metric variables
2022-11-14 20:15:53,181:INFO:Importing untrained model
2022-11-14 20:15:53,191:INFO:Gradient Boosting Regressor Imported successfully
2022-11-14 20:15:53,208:INFO:Starting cross validation
2022-11-14 20:15:53,209:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:15:55,083:INFO:Calculating mean and std
2022-11-14 20:15:55,088:INFO:Creating metrics dataframe
2022-11-14 20:15:55,101:INFO:Uploading results into container
2022-11-14 20:15:55,101:INFO:Uploading model into container now
2022-11-14 20:15:55,102:INFO:master_model_container: 16
2022-11-14 20:15:55,102:INFO:display_container: 2
2022-11-14 20:15:55,103:INFO:GradientBoostingRegressor(random_state=123)
2022-11-14 20:15:55,103:INFO:create_model() successfully completed......................................
2022-11-14 20:15:55,264:INFO:SubProcess create_model() end ==================================
2022-11-14 20:15:55,264:INFO:Creating metrics dataframe
2022-11-14 20:15:55,293:INFO:Initializing Light Gradient Boosting Machine
2022-11-14 20:15:55,293:INFO:Total runtime is 0.39249118963877355 minutes
2022-11-14 20:15:55,305:INFO:SubProcess create_model() called ==================================
2022-11-14 20:15:55,307:INFO:Initializing create_model()
2022-11-14 20:15:55,308:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232029d0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2e0ac7d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:15:55,308:INFO:Checking exceptions
2022-11-14 20:15:55,311:INFO:Importing libraries
2022-11-14 20:15:55,311:INFO:Copying training dataset
2022-11-14 20:15:55,316:INFO:Defining folds
2022-11-14 20:15:55,316:INFO:Declaring metric variables
2022-11-14 20:15:55,330:INFO:Importing untrained model
2022-11-14 20:15:55,343:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-14 20:15:55,361:INFO:Starting cross validation
2022-11-14 20:15:55,369:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:15:56,991:INFO:Calculating mean and std
2022-11-14 20:15:56,997:INFO:Creating metrics dataframe
2022-11-14 20:15:57,006:INFO:Uploading results into container
2022-11-14 20:15:57,010:INFO:Uploading model into container now
2022-11-14 20:15:57,011:INFO:master_model_container: 17
2022-11-14 20:15:57,011:INFO:display_container: 2
2022-11-14 20:15:57,012:INFO:LGBMRegressor(random_state=123)
2022-11-14 20:15:57,012:INFO:create_model() successfully completed......................................
2022-11-14 20:15:57,168:INFO:SubProcess create_model() end ==================================
2022-11-14 20:15:57,169:INFO:Creating metrics dataframe
2022-11-14 20:15:57,192:INFO:Initializing Dummy Regressor
2022-11-14 20:15:57,192:INFO:Total runtime is 0.4241386294364929 minutes
2022-11-14 20:15:57,202:INFO:SubProcess create_model() called ==================================
2022-11-14 20:15:57,203:INFO:Initializing create_model()
2022-11-14 20:15:57,207:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232029d0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2e0ac7d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:15:57,207:INFO:Checking exceptions
2022-11-14 20:15:57,209:INFO:Importing libraries
2022-11-14 20:15:57,209:INFO:Copying training dataset
2022-11-14 20:15:57,216:INFO:Defining folds
2022-11-14 20:15:57,216:INFO:Declaring metric variables
2022-11-14 20:15:57,225:INFO:Importing untrained model
2022-11-14 20:15:57,235:INFO:Dummy Regressor Imported successfully
2022-11-14 20:15:57,251:INFO:Starting cross validation
2022-11-14 20:15:57,253:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:15:57,534:INFO:Calculating mean and std
2022-11-14 20:15:57,536:INFO:Creating metrics dataframe
2022-11-14 20:15:57,546:INFO:Uploading results into container
2022-11-14 20:15:57,547:INFO:Uploading model into container now
2022-11-14 20:15:57,548:INFO:master_model_container: 18
2022-11-14 20:15:57,548:INFO:display_container: 2
2022-11-14 20:15:57,549:INFO:DummyRegressor()
2022-11-14 20:15:57,549:INFO:create_model() successfully completed......................................
2022-11-14 20:15:57,711:INFO:SubProcess create_model() end ==================================
2022-11-14 20:15:57,711:INFO:Creating metrics dataframe
2022-11-14 20:15:57,764:INFO:Initializing create_model()
2022-11-14 20:15:57,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232029d0>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:15:57,764:INFO:Checking exceptions
2022-11-14 20:15:57,771:INFO:Importing libraries
2022-11-14 20:15:57,772:INFO:Copying training dataset
2022-11-14 20:15:57,776:INFO:Defining folds
2022-11-14 20:15:57,776:INFO:Declaring metric variables
2022-11-14 20:15:57,777:INFO:Importing untrained model
2022-11-14 20:15:57,777:INFO:Declaring custom model
2022-11-14 20:15:57,780:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-14 20:15:57,781:INFO:Cross validation set to False
2022-11-14 20:15:57,781:INFO:Fitting Model
2022-11-14 20:15:57,792:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:15:57,795:INFO:OrthogonalMatchingPursuit()
2022-11-14 20:15:57,795:INFO:create_model() successfully completed......................................
2022-11-14 20:15:58,038:INFO:master_model_container: 18
2022-11-14 20:15:58,039:INFO:display_container: 2
2022-11-14 20:15:58,039:INFO:OrthogonalMatchingPursuit()
2022-11-14 20:15:58,039:INFO:compare_models() successfully completed......................................
2022-11-14 20:16:02,676:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  app.launch_new_instance()

2022-11-14 20:16:02,678:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:16:02,679:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:16:02,680:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:16:02,681:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:16:02,682:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:16:02,683:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:16:02,684:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:16:02,685:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:16:02,686:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:16:02,688:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:16:02,692:INFO:PyCaret RegressionExperiment
2022-11-14 20:16:02,692:INFO:Logging name: FullData
2022-11-14 20:16:02,692:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-14 20:16:02,692:INFO:version 3.0.0.rc4
2022-11-14 20:16:02,693:INFO:Initializing setup()
2022-11-14 20:16:02,693:INFO:self.USI: 247d
2022-11-14 20:16:02,693:INFO:self.variable_keys: {'fold_generator', 'fold_shuffle_param', '_ml_usecase', 'data', 'X_train', 'y', 'transform_target_method_param', 'idx', 'display_container', 'log_plots_param', 'gpu_param', 'y_train', '_available_plots', 'master_model_container', '_gpu_n_jobs_param', 'y_test', '_all_models_internal', 'X_test', 'transform_target_param', 'X', 'html_param', 'logging_param', '_all_metrics', 'exp_name_log', 'pipeline', 'variable_keys', 'seed', 'target_param', '_all_models', 'USI', 'fold_groups_param', 'exp_id', 'memory', 'n_jobs_param'}
2022-11-14 20:16:02,693:INFO:Checking environment
2022-11-14 20:16:02,693:INFO:python_version: 3.7.15
2022-11-14 20:16:02,693:INFO:python_build: ('default', 'Oct 12 2022 19:14:55')
2022-11-14 20:16:02,693:INFO:machine: x86_64
2022-11-14 20:16:02,694:INFO:platform: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-14 20:16:02,694:INFO:Memory: svmem(total=13616361472, available=11454976000, percent=15.9, used=2039246848, free=7363842048, active=921145344, inactive=4958416896, buffers=167227392, cached=4046045184, shared=1327104, slab=273551360)
2022-11-14 20:16:02,694:INFO:Physical Core: 1
2022-11-14 20:16:02,695:INFO:Logical Core: 2
2022-11-14 20:16:02,695:INFO:Checking libraries
2022-11-14 20:16:02,695:INFO:System:
2022-11-14 20:16:02,695:INFO:    python: 3.7.15 (default, Oct 12 2022, 19:14:55)  [GCC 7.5.0]
2022-11-14 20:16:02,695:INFO:executable: /usr/bin/python3
2022-11-14 20:16:02,695:INFO:   machine: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-14 20:16:02,695:INFO:PyCaret required dependencies:
2022-11-14 20:16:02,696:INFO:                 pip: 21.1.3
2022-11-14 20:16:02,696:INFO:          setuptools: 57.4.0
2022-11-14 20:16:02,696:INFO:             pycaret: 3.0.0rc4
2022-11-14 20:16:02,696:INFO:             IPython: 7.9.0
2022-11-14 20:16:02,696:INFO:          ipywidgets: 7.7.1
2022-11-14 20:16:02,696:INFO:                tqdm: 4.64.1
2022-11-14 20:16:02,697:INFO:               numpy: 1.21.6
2022-11-14 20:16:02,697:INFO:              pandas: 1.3.5
2022-11-14 20:16:02,697:INFO:              jinja2: 3.0.0
2022-11-14 20:16:02,697:INFO:               scipy: 1.7.3
2022-11-14 20:16:02,697:INFO:              joblib: 1.2.0
2022-11-14 20:16:02,697:INFO:             sklearn: 1.0.2
2022-11-14 20:16:02,697:INFO:                pyod: 1.0.6
2022-11-14 20:16:02,697:INFO:            imblearn: 0.8.1
2022-11-14 20:16:02,698:INFO:   category_encoders: 2.5.1.post0
2022-11-14 20:16:02,698:INFO:            lightgbm: 3.3.3
2022-11-14 20:16:02,698:INFO:               numba: 0.55.2
2022-11-14 20:16:02,698:INFO:            requests: 2.28.1
2022-11-14 20:16:02,698:INFO:          matplotlib: 3.5.3
2022-11-14 20:16:02,698:INFO:          scikitplot: 0.3.7
2022-11-14 20:16:02,698:INFO:         yellowbrick: 1.5
2022-11-14 20:16:02,699:INFO:              plotly: 5.5.0
2022-11-14 20:16:02,699:INFO:             kaleido: 0.2.1
2022-11-14 20:16:02,699:INFO:         statsmodels: 0.12.2
2022-11-14 20:16:02,699:INFO:              sktime: 0.13.4
2022-11-14 20:16:02,699:INFO:               tbats: 1.1.1
2022-11-14 20:16:02,699:INFO:            pmdarima: 1.8.5
2022-11-14 20:16:02,699:INFO:              psutil: 5.9.4
2022-11-14 20:16:02,699:INFO:PyCaret optional dependencies:
2022-11-14 20:16:02,700:INFO:                shap: Not installed
2022-11-14 20:16:02,700:INFO:           interpret: Not installed
2022-11-14 20:16:02,700:INFO:                umap: Not installed
2022-11-14 20:16:02,700:INFO:    pandas_profiling: 1.4.1
2022-11-14 20:16:02,700:INFO:  explainerdashboard: Not installed
2022-11-14 20:16:02,700:INFO:             autoviz: Not installed
2022-11-14 20:16:02,701:INFO:           fairlearn: Not installed
2022-11-14 20:16:02,701:INFO:             xgboost: 0.90
2022-11-14 20:16:02,701:INFO:            catboost: Not installed
2022-11-14 20:16:02,701:INFO:              kmodes: Not installed
2022-11-14 20:16:02,701:INFO:             mlxtend: 0.14.0
2022-11-14 20:16:02,701:INFO:       statsforecast: Not installed
2022-11-14 20:16:02,702:INFO:        tune_sklearn: Not installed
2022-11-14 20:16:02,702:INFO:                 ray: Not installed
2022-11-14 20:16:02,702:INFO:            hyperopt: 0.1.2
2022-11-14 20:16:02,702:INFO:              optuna: Not installed
2022-11-14 20:16:02,702:INFO:               skopt: Not installed
2022-11-14 20:16:02,702:INFO:              mlflow: Not installed
2022-11-14 20:16:02,702:INFO:              gradio: Not installed
2022-11-14 20:16:02,702:INFO:             fastapi: Not installed
2022-11-14 20:16:02,703:INFO:             uvicorn: Not installed
2022-11-14 20:16:02,703:INFO:              m2cgen: Not installed
2022-11-14 20:16:02,703:INFO:           evidently: Not installed
2022-11-14 20:16:02,703:INFO:                nltk: 3.7
2022-11-14 20:16:02,703:INFO:            pyLDAvis: Not installed
2022-11-14 20:16:02,703:INFO:              gensim: 3.6.0
2022-11-14 20:16:02,703:INFO:               spacy: 3.4.2
2022-11-14 20:16:02,704:INFO:           wordcloud: 1.8.2.2
2022-11-14 20:16:02,704:INFO:            textblob: 0.15.3
2022-11-14 20:16:02,704:INFO:               fugue: Not installed
2022-11-14 20:16:02,704:INFO:           streamlit: Not installed
2022-11-14 20:16:02,704:INFO:             prophet: 1.1.1
2022-11-14 20:16:02,705:INFO:None
2022-11-14 20:16:02,705:INFO:Set up data.
2022-11-14 20:16:02,712:INFO:Set up train/test split.
2022-11-14 20:16:02,715:INFO:Set up index.
2022-11-14 20:16:02,715:INFO:Set up folding strategy.
2022-11-14 20:16:02,716:INFO:Assigning column types.
2022-11-14 20:16:02,722:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-14 20:16:02,722:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-14 20:16:02,728:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-14 20:16:02,733:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:16:02,800:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:16:02,852:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:16:02,853:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:02,853:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:02,854:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:02,855:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-14 20:16:02,860:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-14 20:16:02,865:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:16:02,935:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:16:02,992:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:16:02,993:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:02,993:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:02,994:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:02,994:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-14 20:16:03,000:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-14 20:16:03,005:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:16:03,069:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:16:03,120:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:16:03,121:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:03,121:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:03,121:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:03,127:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-14 20:16:03,132:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:16:03,196:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:16:03,246:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:16:03,247:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:03,248:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:03,248:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:03,248:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-14 20:16:03,259:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:16:03,323:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:16:03,375:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:16:03,377:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:03,377:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:03,378:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:03,391:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:16:03,459:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:16:03,517:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:16:03,518:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:03,518:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:03,518:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:03,519:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-14 20:16:03,594:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:16:03,645:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:16:03,650:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:03,650:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:03,651:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:03,726:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:16:03,778:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:16:03,779:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:03,779:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:03,780:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:03,780:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-14 20:16:03,877:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:16:03,927:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:03,928:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:03,928:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:04,014:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:16:04,064:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:04,065:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:04,065:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:04,066:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-14 20:16:04,190:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:04,190:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:04,191:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:04,319:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:04,319:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:04,320:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:04,321:INFO:Preparing preprocessing pipeline...
2022-11-14 20:16:04,323:INFO:Set up simple imputation.
2022-11-14 20:16:04,323:INFO:Set up variance threshold.
2022-11-14 20:16:04,336:INFO:Finished creating preprocessing pipeline.
2022-11-14 20:16:04,342:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-14 20:16:04,342:INFO:Creating final display dataframe.
2022-11-14 20:16:04,420:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 12)
4         Train data shape    (607, 12)
5          Test data shape    (261, 12)
6         Numeric features           11
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         247d
2022-11-14 20:16:04,565:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:04,566:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:04,566:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:04,695:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:04,695:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:04,696:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:04,703:INFO:setup() successfully completed in 2.01s...............
2022-11-14 20:16:04,703:INFO:Initializing compare_models()
2022-11-14 20:16:04,704:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2324ab10>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f3d2324ab10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-14 20:16:04,704:INFO:Checking exceptions
2022-11-14 20:16:04,705:INFO:Preparing display monitor
2022-11-14 20:16:04,788:INFO:Initializing Linear Regression
2022-11-14 20:16:04,789:INFO:Total runtime is 6.687641143798828e-06 minutes
2022-11-14 20:16:04,797:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:04,798:INFO:Initializing create_model()
2022-11-14 20:16:04,798:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2324ab10>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2324a0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:04,798:INFO:Checking exceptions
2022-11-14 20:16:04,801:INFO:Importing libraries
2022-11-14 20:16:04,801:INFO:Copying training dataset
2022-11-14 20:16:04,805:INFO:Defining folds
2022-11-14 20:16:04,806:INFO:Declaring metric variables
2022-11-14 20:16:04,814:INFO:Importing untrained model
2022-11-14 20:16:04,822:INFO:Linear Regression Imported successfully
2022-11-14 20:16:04,843:INFO:Starting cross validation
2022-11-14 20:16:04,848:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:05,166:INFO:Calculating mean and std
2022-11-14 20:16:05,167:INFO:Creating metrics dataframe
2022-11-14 20:16:05,171:INFO:Uploading results into container
2022-11-14 20:16:05,172:INFO:Uploading model into container now
2022-11-14 20:16:05,173:INFO:master_model_container: 1
2022-11-14 20:16:05,173:INFO:display_container: 2
2022-11-14 20:16:05,174:INFO:LinearRegression(n_jobs=-1)
2022-11-14 20:16:05,174:INFO:create_model() successfully completed......................................
2022-11-14 20:16:05,337:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:05,338:INFO:Creating metrics dataframe
2022-11-14 20:16:05,356:INFO:Initializing Lasso Regression
2022-11-14 20:16:05,358:INFO:Total runtime is 0.009493017196655275 minutes
2022-11-14 20:16:05,365:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:05,367:INFO:Initializing create_model()
2022-11-14 20:16:05,367:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2324ab10>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2324a0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:05,367:INFO:Checking exceptions
2022-11-14 20:16:05,375:INFO:Importing libraries
2022-11-14 20:16:05,376:INFO:Copying training dataset
2022-11-14 20:16:05,378:INFO:Defining folds
2022-11-14 20:16:05,379:INFO:Declaring metric variables
2022-11-14 20:16:05,385:INFO:Importing untrained model
2022-11-14 20:16:05,395:INFO:Lasso Regression Imported successfully
2022-11-14 20:16:05,411:INFO:Starting cross validation
2022-11-14 20:16:05,414:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:05,720:INFO:Calculating mean and std
2022-11-14 20:16:05,721:INFO:Creating metrics dataframe
2022-11-14 20:16:05,731:INFO:Uploading results into container
2022-11-14 20:16:05,733:INFO:Uploading model into container now
2022-11-14 20:16:05,734:INFO:master_model_container: 2
2022-11-14 20:16:05,734:INFO:display_container: 2
2022-11-14 20:16:05,735:INFO:Lasso(random_state=123)
2022-11-14 20:16:05,735:INFO:create_model() successfully completed......................................
2022-11-14 20:16:05,907:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:05,908:INFO:Creating metrics dataframe
2022-11-14 20:16:05,926:INFO:Initializing Ridge Regression
2022-11-14 20:16:05,927:INFO:Total runtime is 0.018982450167338055 minutes
2022-11-14 20:16:05,937:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:05,937:INFO:Initializing create_model()
2022-11-14 20:16:05,938:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2324ab10>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2324a0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:05,938:INFO:Checking exceptions
2022-11-14 20:16:05,941:INFO:Importing libraries
2022-11-14 20:16:05,941:INFO:Copying training dataset
2022-11-14 20:16:05,950:INFO:Defining folds
2022-11-14 20:16:05,950:INFO:Declaring metric variables
2022-11-14 20:16:05,960:INFO:Importing untrained model
2022-11-14 20:16:05,971:INFO:Ridge Regression Imported successfully
2022-11-14 20:16:05,987:INFO:Starting cross validation
2022-11-14 20:16:05,989:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:06,295:INFO:Calculating mean and std
2022-11-14 20:16:06,298:INFO:Creating metrics dataframe
2022-11-14 20:16:06,307:INFO:Uploading results into container
2022-11-14 20:16:06,308:INFO:Uploading model into container now
2022-11-14 20:16:06,309:INFO:master_model_container: 3
2022-11-14 20:16:06,309:INFO:display_container: 2
2022-11-14 20:16:06,310:INFO:Ridge(random_state=123)
2022-11-14 20:16:06,310:INFO:create_model() successfully completed......................................
2022-11-14 20:16:06,471:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:06,472:INFO:Creating metrics dataframe
2022-11-14 20:16:06,499:INFO:Initializing Elastic Net
2022-11-14 20:16:06,500:INFO:Total runtime is 0.028530128796895347 minutes
2022-11-14 20:16:06,509:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:06,510:INFO:Initializing create_model()
2022-11-14 20:16:06,512:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2324ab10>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2324a0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:06,512:INFO:Checking exceptions
2022-11-14 20:16:06,514:INFO:Importing libraries
2022-11-14 20:16:06,515:INFO:Copying training dataset
2022-11-14 20:16:06,523:INFO:Defining folds
2022-11-14 20:16:06,523:INFO:Declaring metric variables
2022-11-14 20:16:06,534:INFO:Importing untrained model
2022-11-14 20:16:06,542:INFO:Elastic Net Imported successfully
2022-11-14 20:16:06,566:INFO:Starting cross validation
2022-11-14 20:16:06,568:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:06,859:INFO:Calculating mean and std
2022-11-14 20:16:06,862:INFO:Creating metrics dataframe
2022-11-14 20:16:06,873:INFO:Uploading results into container
2022-11-14 20:16:06,874:INFO:Uploading model into container now
2022-11-14 20:16:06,875:INFO:master_model_container: 4
2022-11-14 20:16:06,875:INFO:display_container: 2
2022-11-14 20:16:06,876:INFO:ElasticNet(random_state=123)
2022-11-14 20:16:06,876:INFO:create_model() successfully completed......................................
2022-11-14 20:16:07,028:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:07,028:INFO:Creating metrics dataframe
2022-11-14 20:16:07,053:INFO:Initializing Least Angle Regression
2022-11-14 20:16:07,053:INFO:Total runtime is 0.03774396181106568 minutes
2022-11-14 20:16:07,061:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:07,061:INFO:Initializing create_model()
2022-11-14 20:16:07,062:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2324ab10>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2324a0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:07,062:INFO:Checking exceptions
2022-11-14 20:16:07,064:INFO:Importing libraries
2022-11-14 20:16:07,065:INFO:Copying training dataset
2022-11-14 20:16:07,072:INFO:Defining folds
2022-11-14 20:16:07,073:INFO:Declaring metric variables
2022-11-14 20:16:07,081:INFO:Importing untrained model
2022-11-14 20:16:07,090:INFO:Least Angle Regression Imported successfully
2022-11-14 20:16:07,105:INFO:Starting cross validation
2022-11-14 20:16:07,107:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:07,156:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:07,181:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:07,221:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:07,250:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:07,287:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:07,329:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:07,335:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:07,372:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:07,394:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:07,416:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:07,433:INFO:Calculating mean and std
2022-11-14 20:16:07,436:INFO:Creating metrics dataframe
2022-11-14 20:16:07,451:INFO:Uploading results into container
2022-11-14 20:16:07,454:INFO:Uploading model into container now
2022-11-14 20:16:07,455:INFO:master_model_container: 5
2022-11-14 20:16:07,456:INFO:display_container: 2
2022-11-14 20:16:07,456:INFO:Lars(random_state=123)
2022-11-14 20:16:07,457:INFO:create_model() successfully completed......................................
2022-11-14 20:16:07,616:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:07,617:INFO:Creating metrics dataframe
2022-11-14 20:16:07,641:INFO:Initializing Lasso Least Angle Regression
2022-11-14 20:16:07,646:INFO:Total runtime is 0.047624540328979496 minutes
2022-11-14 20:16:07,653:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:07,654:INFO:Initializing create_model()
2022-11-14 20:16:07,654:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2324ab10>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2324a0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:07,655:INFO:Checking exceptions
2022-11-14 20:16:07,658:INFO:Importing libraries
2022-11-14 20:16:07,658:INFO:Copying training dataset
2022-11-14 20:16:07,663:INFO:Defining folds
2022-11-14 20:16:07,664:INFO:Declaring metric variables
2022-11-14 20:16:07,681:INFO:Importing untrained model
2022-11-14 20:16:07,695:INFO:Lasso Least Angle Regression Imported successfully
2022-11-14 20:16:07,717:INFO:Starting cross validation
2022-11-14 20:16:07,719:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:07,774:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:16:07,804:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:16:07,844:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:16:07,883:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:16:07,900:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:16:07,952:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:16:07,976:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:16:07,991:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:16:08,019:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:16:08,032:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:16:08,050:INFO:Calculating mean and std
2022-11-14 20:16:08,053:INFO:Creating metrics dataframe
2022-11-14 20:16:08,070:INFO:Uploading results into container
2022-11-14 20:16:08,070:INFO:Uploading model into container now
2022-11-14 20:16:08,071:INFO:master_model_container: 6
2022-11-14 20:16:08,071:INFO:display_container: 2
2022-11-14 20:16:08,072:INFO:LassoLars(random_state=123)
2022-11-14 20:16:08,072:INFO:create_model() successfully completed......................................
2022-11-14 20:16:08,238:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:08,239:INFO:Creating metrics dataframe
2022-11-14 20:16:08,259:INFO:Initializing Orthogonal Matching Pursuit
2022-11-14 20:16:08,259:INFO:Total runtime is 0.05785186290740967 minutes
2022-11-14 20:16:08,268:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:08,269:INFO:Initializing create_model()
2022-11-14 20:16:08,270:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2324ab10>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2324a0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:08,270:INFO:Checking exceptions
2022-11-14 20:16:08,273:INFO:Importing libraries
2022-11-14 20:16:08,274:INFO:Copying training dataset
2022-11-14 20:16:08,279:INFO:Defining folds
2022-11-14 20:16:08,279:INFO:Declaring metric variables
2022-11-14 20:16:08,296:INFO:Importing untrained model
2022-11-14 20:16:08,310:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-14 20:16:08,329:INFO:Starting cross validation
2022-11-14 20:16:08,331:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:08,369:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:08,398:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:08,432:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:08,466:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:08,499:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:08,537:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:08,544:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:08,585:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:08,596:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:08,628:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:08,643:INFO:Calculating mean and std
2022-11-14 20:16:08,646:INFO:Creating metrics dataframe
2022-11-14 20:16:08,660:INFO:Uploading results into container
2022-11-14 20:16:08,661:INFO:Uploading model into container now
2022-11-14 20:16:08,662:INFO:master_model_container: 7
2022-11-14 20:16:08,662:INFO:display_container: 2
2022-11-14 20:16:08,662:INFO:OrthogonalMatchingPursuit()
2022-11-14 20:16:08,663:INFO:create_model() successfully completed......................................
2022-11-14 20:16:08,817:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:08,818:INFO:Creating metrics dataframe
2022-11-14 20:16:08,840:INFO:Initializing Bayesian Ridge
2022-11-14 20:16:08,842:INFO:Total runtime is 0.06755767265955608 minutes
2022-11-14 20:16:08,854:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:08,855:INFO:Initializing create_model()
2022-11-14 20:16:08,856:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2324ab10>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2324a0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:08,856:INFO:Checking exceptions
2022-11-14 20:16:08,859:INFO:Importing libraries
2022-11-14 20:16:08,859:INFO:Copying training dataset
2022-11-14 20:16:08,864:INFO:Defining folds
2022-11-14 20:16:08,865:INFO:Declaring metric variables
2022-11-14 20:16:08,877:INFO:Importing untrained model
2022-11-14 20:16:08,887:INFO:Bayesian Ridge Imported successfully
2022-11-14 20:16:08,906:INFO:Starting cross validation
2022-11-14 20:16:08,907:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:09,232:INFO:Calculating mean and std
2022-11-14 20:16:09,237:INFO:Creating metrics dataframe
2022-11-14 20:16:09,251:INFO:Uploading results into container
2022-11-14 20:16:09,252:INFO:Uploading model into container now
2022-11-14 20:16:09,253:INFO:master_model_container: 8
2022-11-14 20:16:09,253:INFO:display_container: 2
2022-11-14 20:16:09,253:INFO:BayesianRidge()
2022-11-14 20:16:09,254:INFO:create_model() successfully completed......................................
2022-11-14 20:16:09,405:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:09,405:INFO:Creating metrics dataframe
2022-11-14 20:16:09,426:INFO:Initializing Passive Aggressive Regressor
2022-11-14 20:16:09,427:INFO:Total runtime is 0.07730934222539267 minutes
2022-11-14 20:16:09,436:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:09,437:INFO:Initializing create_model()
2022-11-14 20:16:09,438:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2324ab10>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2324a0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:09,439:INFO:Checking exceptions
2022-11-14 20:16:09,442:INFO:Importing libraries
2022-11-14 20:16:09,443:INFO:Copying training dataset
2022-11-14 20:16:09,450:INFO:Defining folds
2022-11-14 20:16:09,450:INFO:Declaring metric variables
2022-11-14 20:16:09,459:INFO:Importing untrained model
2022-11-14 20:16:09,476:INFO:Passive Aggressive Regressor Imported successfully
2022-11-14 20:16:09,493:INFO:Starting cross validation
2022-11-14 20:16:09,499:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:09,806:INFO:Calculating mean and std
2022-11-14 20:16:09,809:INFO:Creating metrics dataframe
2022-11-14 20:16:09,818:INFO:Uploading results into container
2022-11-14 20:16:09,818:INFO:Uploading model into container now
2022-11-14 20:16:09,819:INFO:master_model_container: 9
2022-11-14 20:16:09,820:INFO:display_container: 2
2022-11-14 20:16:09,820:INFO:PassiveAggressiveRegressor(random_state=123)
2022-11-14 20:16:09,821:INFO:create_model() successfully completed......................................
2022-11-14 20:16:09,977:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:09,979:INFO:Creating metrics dataframe
2022-11-14 20:16:10,001:INFO:Initializing Huber Regressor
2022-11-14 20:16:10,002:INFO:Total runtime is 0.08689011732737224 minutes
2022-11-14 20:16:10,011:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:10,012:INFO:Initializing create_model()
2022-11-14 20:16:10,013:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2324ab10>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2324a0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:10,015:INFO:Checking exceptions
2022-11-14 20:16:10,019:INFO:Importing libraries
2022-11-14 20:16:10,019:INFO:Copying training dataset
2022-11-14 20:16:10,024:INFO:Defining folds
2022-11-14 20:16:10,028:INFO:Declaring metric variables
2022-11-14 20:16:10,037:INFO:Importing untrained model
2022-11-14 20:16:10,046:INFO:Huber Regressor Imported successfully
2022-11-14 20:16:10,064:INFO:Starting cross validation
2022-11-14 20:16:10,067:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:10,195:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:16:10,237:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:16:10,311:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:16:10,405:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:16:10,427:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:16:10,522:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:16:10,527:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:16:10,623:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:16:10,625:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:16:10,699:INFO:Calculating mean and std
2022-11-14 20:16:10,711:INFO:Creating metrics dataframe
2022-11-14 20:16:10,718:INFO:Uploading results into container
2022-11-14 20:16:10,719:INFO:Uploading model into container now
2022-11-14 20:16:10,720:INFO:master_model_container: 10
2022-11-14 20:16:10,720:INFO:display_container: 2
2022-11-14 20:16:10,720:INFO:HuberRegressor()
2022-11-14 20:16:10,720:INFO:create_model() successfully completed......................................
2022-11-14 20:16:10,885:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:10,886:INFO:Creating metrics dataframe
2022-11-14 20:16:10,911:INFO:Initializing K Neighbors Regressor
2022-11-14 20:16:10,913:INFO:Total runtime is 0.10207288265228273 minutes
2022-11-14 20:16:10,922:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:10,923:INFO:Initializing create_model()
2022-11-14 20:16:10,923:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2324ab10>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2324a0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:10,923:INFO:Checking exceptions
2022-11-14 20:16:10,926:INFO:Importing libraries
2022-11-14 20:16:10,926:INFO:Copying training dataset
2022-11-14 20:16:10,933:INFO:Defining folds
2022-11-14 20:16:10,934:INFO:Declaring metric variables
2022-11-14 20:16:10,947:INFO:Importing untrained model
2022-11-14 20:16:10,957:INFO:K Neighbors Regressor Imported successfully
2022-11-14 20:16:10,978:INFO:Starting cross validation
2022-11-14 20:16:10,980:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:11,754:INFO:Calculating mean and std
2022-11-14 20:16:11,757:INFO:Creating metrics dataframe
2022-11-14 20:16:11,762:INFO:Uploading results into container
2022-11-14 20:16:11,763:INFO:Uploading model into container now
2022-11-14 20:16:11,765:INFO:master_model_container: 11
2022-11-14 20:16:11,776:INFO:display_container: 2
2022-11-14 20:16:11,777:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-14 20:16:11,777:INFO:create_model() successfully completed......................................
2022-11-14 20:16:11,937:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:11,938:INFO:Creating metrics dataframe
2022-11-14 20:16:11,959:INFO:Initializing Decision Tree Regressor
2022-11-14 20:16:11,960:INFO:Total runtime is 0.11952360073725385 minutes
2022-11-14 20:16:11,970:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:11,971:INFO:Initializing create_model()
2022-11-14 20:16:11,971:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2324ab10>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2324a0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:11,971:INFO:Checking exceptions
2022-11-14 20:16:11,975:INFO:Importing libraries
2022-11-14 20:16:11,975:INFO:Copying training dataset
2022-11-14 20:16:11,980:INFO:Defining folds
2022-11-14 20:16:11,981:INFO:Declaring metric variables
2022-11-14 20:16:11,991:INFO:Importing untrained model
2022-11-14 20:16:12,003:INFO:Decision Tree Regressor Imported successfully
2022-11-14 20:16:12,027:INFO:Starting cross validation
2022-11-14 20:16:12,029:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:12,394:INFO:Calculating mean and std
2022-11-14 20:16:12,397:INFO:Creating metrics dataframe
2022-11-14 20:16:12,413:INFO:Uploading results into container
2022-11-14 20:16:12,415:INFO:Uploading model into container now
2022-11-14 20:16:12,415:INFO:master_model_container: 12
2022-11-14 20:16:12,416:INFO:display_container: 2
2022-11-14 20:16:12,416:INFO:DecisionTreeRegressor(random_state=123)
2022-11-14 20:16:12,416:INFO:create_model() successfully completed......................................
2022-11-14 20:16:12,575:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:12,576:INFO:Creating metrics dataframe
2022-11-14 20:16:12,598:INFO:Initializing Random Forest Regressor
2022-11-14 20:16:12,598:INFO:Total runtime is 0.13016380469004316 minutes
2022-11-14 20:16:12,609:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:12,610:INFO:Initializing create_model()
2022-11-14 20:16:12,614:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2324ab10>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2324a0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:12,615:INFO:Checking exceptions
2022-11-14 20:16:12,617:INFO:Importing libraries
2022-11-14 20:16:12,617:INFO:Copying training dataset
2022-11-14 20:16:12,624:INFO:Defining folds
2022-11-14 20:16:12,628:INFO:Declaring metric variables
2022-11-14 20:16:12,635:INFO:Importing untrained model
2022-11-14 20:16:12,644:INFO:Random Forest Regressor Imported successfully
2022-11-14 20:16:12,663:INFO:Starting cross validation
2022-11-14 20:16:12,665:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:17,281:INFO:Calculating mean and std
2022-11-14 20:16:17,286:INFO:Creating metrics dataframe
2022-11-14 20:16:17,296:INFO:Uploading results into container
2022-11-14 20:16:17,297:INFO:Uploading model into container now
2022-11-14 20:16:17,298:INFO:master_model_container: 13
2022-11-14 20:16:17,299:INFO:display_container: 2
2022-11-14 20:16:17,300:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-14 20:16:17,300:INFO:create_model() successfully completed......................................
2022-11-14 20:16:17,459:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:17,459:INFO:Creating metrics dataframe
2022-11-14 20:16:17,483:INFO:Initializing Extra Trees Regressor
2022-11-14 20:16:17,484:INFO:Total runtime is 0.21159048477808637 minutes
2022-11-14 20:16:17,492:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:17,493:INFO:Initializing create_model()
2022-11-14 20:16:17,493:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2324ab10>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2324a0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:17,494:INFO:Checking exceptions
2022-11-14 20:16:17,496:INFO:Importing libraries
2022-11-14 20:16:17,496:INFO:Copying training dataset
2022-11-14 20:16:17,504:INFO:Defining folds
2022-11-14 20:16:17,504:INFO:Declaring metric variables
2022-11-14 20:16:17,513:INFO:Importing untrained model
2022-11-14 20:16:17,522:INFO:Extra Trees Regressor Imported successfully
2022-11-14 20:16:17,540:INFO:Starting cross validation
2022-11-14 20:16:17,541:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:20,225:INFO:Calculating mean and std
2022-11-14 20:16:20,231:INFO:Creating metrics dataframe
2022-11-14 20:16:20,244:INFO:Uploading results into container
2022-11-14 20:16:20,245:INFO:Uploading model into container now
2022-11-14 20:16:20,245:INFO:master_model_container: 14
2022-11-14 20:16:20,245:INFO:display_container: 2
2022-11-14 20:16:20,246:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-14 20:16:20,246:INFO:create_model() successfully completed......................................
2022-11-14 20:16:20,402:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:20,402:INFO:Creating metrics dataframe
2022-11-14 20:16:20,424:INFO:Initializing AdaBoost Regressor
2022-11-14 20:16:20,425:INFO:Total runtime is 0.26060736974080406 minutes
2022-11-14 20:16:20,435:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:20,436:INFO:Initializing create_model()
2022-11-14 20:16:20,436:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2324ab10>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2324a0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:20,436:INFO:Checking exceptions
2022-11-14 20:16:20,439:INFO:Importing libraries
2022-11-14 20:16:20,443:INFO:Copying training dataset
2022-11-14 20:16:20,449:INFO:Defining folds
2022-11-14 20:16:20,450:INFO:Declaring metric variables
2022-11-14 20:16:20,464:INFO:Importing untrained model
2022-11-14 20:16:20,478:INFO:AdaBoost Regressor Imported successfully
2022-11-14 20:16:20,502:INFO:Starting cross validation
2022-11-14 20:16:20,503:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:21,696:INFO:Calculating mean and std
2022-11-14 20:16:21,702:INFO:Creating metrics dataframe
2022-11-14 20:16:21,711:INFO:Uploading results into container
2022-11-14 20:16:21,711:INFO:Uploading model into container now
2022-11-14 20:16:21,712:INFO:master_model_container: 15
2022-11-14 20:16:21,712:INFO:display_container: 2
2022-11-14 20:16:21,713:INFO:AdaBoostRegressor(random_state=123)
2022-11-14 20:16:21,713:INFO:create_model() successfully completed......................................
2022-11-14 20:16:22,010:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:22,016:INFO:Creating metrics dataframe
2022-11-14 20:16:22,110:INFO:Initializing Gradient Boosting Regressor
2022-11-14 20:16:22,116:INFO:Total runtime is 0.2887901385625204 minutes
2022-11-14 20:16:22,141:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:22,148:INFO:Initializing create_model()
2022-11-14 20:16:22,148:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2324ab10>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2324a0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:22,149:INFO:Checking exceptions
2022-11-14 20:16:22,152:INFO:Importing libraries
2022-11-14 20:16:22,160:INFO:Copying training dataset
2022-11-14 20:16:22,168:INFO:Defining folds
2022-11-14 20:16:22,189:INFO:Declaring metric variables
2022-11-14 20:16:22,207:INFO:Importing untrained model
2022-11-14 20:16:22,227:INFO:Gradient Boosting Regressor Imported successfully
2022-11-14 20:16:22,274:INFO:Starting cross validation
2022-11-14 20:16:22,283:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:24,435:INFO:Calculating mean and std
2022-11-14 20:16:24,447:INFO:Creating metrics dataframe
2022-11-14 20:16:24,456:INFO:Uploading results into container
2022-11-14 20:16:24,457:INFO:Uploading model into container now
2022-11-14 20:16:24,458:INFO:master_model_container: 16
2022-11-14 20:16:24,459:INFO:display_container: 2
2022-11-14 20:16:24,459:INFO:GradientBoostingRegressor(random_state=123)
2022-11-14 20:16:24,460:INFO:create_model() successfully completed......................................
2022-11-14 20:16:24,630:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:24,630:INFO:Creating metrics dataframe
2022-11-14 20:16:24,657:INFO:Initializing Light Gradient Boosting Machine
2022-11-14 20:16:24,658:INFO:Total runtime is 0.33115582068761196 minutes
2022-11-14 20:16:24,668:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:24,672:INFO:Initializing create_model()
2022-11-14 20:16:24,672:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2324ab10>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2324a0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:24,672:INFO:Checking exceptions
2022-11-14 20:16:24,675:INFO:Importing libraries
2022-11-14 20:16:24,676:INFO:Copying training dataset
2022-11-14 20:16:24,680:INFO:Defining folds
2022-11-14 20:16:24,681:INFO:Declaring metric variables
2022-11-14 20:16:24,691:INFO:Importing untrained model
2022-11-14 20:16:24,701:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-14 20:16:24,718:INFO:Starting cross validation
2022-11-14 20:16:24,720:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:25,599:INFO:Calculating mean and std
2022-11-14 20:16:25,610:INFO:Creating metrics dataframe
2022-11-14 20:16:25,617:INFO:Uploading results into container
2022-11-14 20:16:25,618:INFO:Uploading model into container now
2022-11-14 20:16:25,619:INFO:master_model_container: 17
2022-11-14 20:16:25,619:INFO:display_container: 2
2022-11-14 20:16:25,620:INFO:LGBMRegressor(random_state=123)
2022-11-14 20:16:25,620:INFO:create_model() successfully completed......................................
2022-11-14 20:16:25,787:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:25,788:INFO:Creating metrics dataframe
2022-11-14 20:16:25,814:INFO:Initializing Dummy Regressor
2022-11-14 20:16:25,815:INFO:Total runtime is 0.3504390041033428 minutes
2022-11-14 20:16:25,824:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:25,825:INFO:Initializing create_model()
2022-11-14 20:16:25,825:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2324ab10>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2324a0d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:25,825:INFO:Checking exceptions
2022-11-14 20:16:25,829:INFO:Importing libraries
2022-11-14 20:16:25,829:INFO:Copying training dataset
2022-11-14 20:16:25,836:INFO:Defining folds
2022-11-14 20:16:25,838:INFO:Declaring metric variables
2022-11-14 20:16:25,847:INFO:Importing untrained model
2022-11-14 20:16:25,857:INFO:Dummy Regressor Imported successfully
2022-11-14 20:16:25,874:INFO:Starting cross validation
2022-11-14 20:16:25,876:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:26,160:INFO:Calculating mean and std
2022-11-14 20:16:26,163:INFO:Creating metrics dataframe
2022-11-14 20:16:26,179:INFO:Uploading results into container
2022-11-14 20:16:26,181:INFO:Uploading model into container now
2022-11-14 20:16:26,181:INFO:master_model_container: 18
2022-11-14 20:16:26,182:INFO:display_container: 2
2022-11-14 20:16:26,182:INFO:DummyRegressor()
2022-11-14 20:16:26,182:INFO:create_model() successfully completed......................................
2022-11-14 20:16:26,342:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:26,342:INFO:Creating metrics dataframe
2022-11-14 20:16:26,396:INFO:Initializing create_model()
2022-11-14 20:16:26,398:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2324ab10>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:26,398:INFO:Checking exceptions
2022-11-14 20:16:26,411:INFO:Importing libraries
2022-11-14 20:16:26,412:INFO:Copying training dataset
2022-11-14 20:16:26,414:INFO:Defining folds
2022-11-14 20:16:26,415:INFO:Declaring metric variables
2022-11-14 20:16:26,415:INFO:Importing untrained model
2022-11-14 20:16:26,416:INFO:Declaring custom model
2022-11-14 20:16:26,417:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-14 20:16:26,418:INFO:Cross validation set to False
2022-11-14 20:16:26,418:INFO:Fitting Model
2022-11-14 20:16:26,428:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:26,432:INFO:OrthogonalMatchingPursuit()
2022-11-14 20:16:26,432:INFO:create_model() successfully completed......................................
2022-11-14 20:16:26,688:INFO:master_model_container: 18
2022-11-14 20:16:26,689:INFO:display_container: 2
2022-11-14 20:16:26,689:INFO:OrthogonalMatchingPursuit()
2022-11-14 20:16:26,689:INFO:compare_models() successfully completed......................................
2022-11-14 20:16:31,362:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  app.launch_new_instance()

2022-11-14 20:16:31,363:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:16:31,364:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:16:31,365:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:16:31,366:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:16:31,367:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:16:31,368:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:16:31,369:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:16:31,370:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:16:31,371:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:16:31,372:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:16:31,377:INFO:PyCaret RegressionExperiment
2022-11-14 20:16:31,377:INFO:Logging name: FullData
2022-11-14 20:16:31,378:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-14 20:16:31,378:INFO:version 3.0.0.rc4
2022-11-14 20:16:31,378:INFO:Initializing setup()
2022-11-14 20:16:31,378:INFO:self.USI: 8dc6
2022-11-14 20:16:31,378:INFO:self.variable_keys: {'fold_generator', 'fold_shuffle_param', '_ml_usecase', 'data', 'X_train', 'y', 'transform_target_method_param', 'idx', 'display_container', 'log_plots_param', 'gpu_param', 'y_train', '_available_plots', 'master_model_container', '_gpu_n_jobs_param', 'y_test', '_all_models_internal', 'X_test', 'transform_target_param', 'X', 'html_param', 'logging_param', '_all_metrics', 'exp_name_log', 'pipeline', 'variable_keys', 'seed', 'target_param', '_all_models', 'USI', 'fold_groups_param', 'exp_id', 'memory', 'n_jobs_param'}
2022-11-14 20:16:31,378:INFO:Checking environment
2022-11-14 20:16:31,378:INFO:python_version: 3.7.15
2022-11-14 20:16:31,379:INFO:python_build: ('default', 'Oct 12 2022 19:14:55')
2022-11-14 20:16:31,379:INFO:machine: x86_64
2022-11-14 20:16:31,379:INFO:platform: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-14 20:16:31,379:INFO:Memory: svmem(total=13616361472, available=11612409856, percent=14.7, used=1898434560, free=7499735040, active=921583616, inactive=4822892544, buffers=167362560, cached=4050829312, shared=1327104, slab=273494016)
2022-11-14 20:16:31,380:INFO:Physical Core: 1
2022-11-14 20:16:31,380:INFO:Logical Core: 2
2022-11-14 20:16:31,380:INFO:Checking libraries
2022-11-14 20:16:31,380:INFO:System:
2022-11-14 20:16:31,380:INFO:    python: 3.7.15 (default, Oct 12 2022, 19:14:55)  [GCC 7.5.0]
2022-11-14 20:16:31,380:INFO:executable: /usr/bin/python3
2022-11-14 20:16:31,380:INFO:   machine: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-14 20:16:31,381:INFO:PyCaret required dependencies:
2022-11-14 20:16:31,381:INFO:                 pip: 21.1.3
2022-11-14 20:16:31,381:INFO:          setuptools: 57.4.0
2022-11-14 20:16:31,381:INFO:             pycaret: 3.0.0rc4
2022-11-14 20:16:31,381:INFO:             IPython: 7.9.0
2022-11-14 20:16:31,381:INFO:          ipywidgets: 7.7.1
2022-11-14 20:16:31,382:INFO:                tqdm: 4.64.1
2022-11-14 20:16:31,382:INFO:               numpy: 1.21.6
2022-11-14 20:16:31,382:INFO:              pandas: 1.3.5
2022-11-14 20:16:31,382:INFO:              jinja2: 3.0.0
2022-11-14 20:16:31,382:INFO:               scipy: 1.7.3
2022-11-14 20:16:31,382:INFO:              joblib: 1.2.0
2022-11-14 20:16:31,382:INFO:             sklearn: 1.0.2
2022-11-14 20:16:31,382:INFO:                pyod: 1.0.6
2022-11-14 20:16:31,383:INFO:            imblearn: 0.8.1
2022-11-14 20:16:31,383:INFO:   category_encoders: 2.5.1.post0
2022-11-14 20:16:31,383:INFO:            lightgbm: 3.3.3
2022-11-14 20:16:31,383:INFO:               numba: 0.55.2
2022-11-14 20:16:31,383:INFO:            requests: 2.28.1
2022-11-14 20:16:31,383:INFO:          matplotlib: 3.5.3
2022-11-14 20:16:31,383:INFO:          scikitplot: 0.3.7
2022-11-14 20:16:31,383:INFO:         yellowbrick: 1.5
2022-11-14 20:16:31,384:INFO:              plotly: 5.5.0
2022-11-14 20:16:31,384:INFO:             kaleido: 0.2.1
2022-11-14 20:16:31,384:INFO:         statsmodels: 0.12.2
2022-11-14 20:16:31,384:INFO:              sktime: 0.13.4
2022-11-14 20:16:31,384:INFO:               tbats: 1.1.1
2022-11-14 20:16:31,384:INFO:            pmdarima: 1.8.5
2022-11-14 20:16:31,384:INFO:              psutil: 5.9.4
2022-11-14 20:16:31,385:INFO:PyCaret optional dependencies:
2022-11-14 20:16:31,385:INFO:                shap: Not installed
2022-11-14 20:16:31,385:INFO:           interpret: Not installed
2022-11-14 20:16:31,385:INFO:                umap: Not installed
2022-11-14 20:16:31,385:INFO:    pandas_profiling: 1.4.1
2022-11-14 20:16:31,385:INFO:  explainerdashboard: Not installed
2022-11-14 20:16:31,385:INFO:             autoviz: Not installed
2022-11-14 20:16:31,386:INFO:           fairlearn: Not installed
2022-11-14 20:16:31,386:INFO:             xgboost: 0.90
2022-11-14 20:16:31,386:INFO:            catboost: Not installed
2022-11-14 20:16:31,386:INFO:              kmodes: Not installed
2022-11-14 20:16:31,386:INFO:             mlxtend: 0.14.0
2022-11-14 20:16:31,386:INFO:       statsforecast: Not installed
2022-11-14 20:16:31,386:INFO:        tune_sklearn: Not installed
2022-11-14 20:16:31,386:INFO:                 ray: Not installed
2022-11-14 20:16:31,387:INFO:            hyperopt: 0.1.2
2022-11-14 20:16:31,387:INFO:              optuna: Not installed
2022-11-14 20:16:31,387:INFO:               skopt: Not installed
2022-11-14 20:16:31,387:INFO:              mlflow: Not installed
2022-11-14 20:16:31,387:INFO:              gradio: Not installed
2022-11-14 20:16:31,387:INFO:             fastapi: Not installed
2022-11-14 20:16:31,387:INFO:             uvicorn: Not installed
2022-11-14 20:16:31,387:INFO:              m2cgen: Not installed
2022-11-14 20:16:31,388:INFO:           evidently: Not installed
2022-11-14 20:16:31,388:INFO:                nltk: 3.7
2022-11-14 20:16:31,388:INFO:            pyLDAvis: Not installed
2022-11-14 20:16:31,388:INFO:              gensim: 3.6.0
2022-11-14 20:16:31,388:INFO:               spacy: 3.4.2
2022-11-14 20:16:31,388:INFO:           wordcloud: 1.8.2.2
2022-11-14 20:16:31,388:INFO:            textblob: 0.15.3
2022-11-14 20:16:31,389:INFO:               fugue: Not installed
2022-11-14 20:16:31,389:INFO:           streamlit: Not installed
2022-11-14 20:16:31,389:INFO:             prophet: 1.1.1
2022-11-14 20:16:31,389:INFO:None
2022-11-14 20:16:31,389:INFO:Set up data.
2022-11-14 20:16:31,396:INFO:Set up train/test split.
2022-11-14 20:16:31,400:INFO:Set up index.
2022-11-14 20:16:31,401:INFO:Set up folding strategy.
2022-11-14 20:16:31,401:INFO:Assigning column types.
2022-11-14 20:16:31,407:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-14 20:16:31,408:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-14 20:16:31,414:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-14 20:16:31,420:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:16:31,485:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:16:31,536:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:16:31,538:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:31,538:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:31,538:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:31,540:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-14 20:16:31,546:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-14 20:16:31,551:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:16:31,615:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:16:31,665:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:16:31,666:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:31,666:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:31,667:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:31,668:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-14 20:16:31,674:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-14 20:16:31,680:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:16:31,745:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:16:31,807:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:16:31,808:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:31,808:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:31,808:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:31,814:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-14 20:16:31,819:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:16:31,884:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:16:31,935:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:16:31,936:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:31,937:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:31,937:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:31,938:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-14 20:16:31,948:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:16:32,012:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:16:32,062:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:16:32,063:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:32,064:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:32,064:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:32,075:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:16:32,139:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:16:32,188:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:16:32,190:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:32,190:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:32,191:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:32,191:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-14 20:16:32,266:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:16:32,317:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:16:32,322:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:32,323:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:32,324:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:32,397:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:16:32,450:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:16:32,451:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:32,452:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:32,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:32,452:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-14 20:16:32,528:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:16:32,581:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:32,582:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:32,584:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:32,660:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:16:32,710:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:32,711:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:32,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:32,711:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-14 20:16:32,851:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:32,852:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:32,852:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:32,978:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:32,979:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:32,980:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:32,981:INFO:Preparing preprocessing pipeline...
2022-11-14 20:16:32,982:INFO:Set up simple imputation.
2022-11-14 20:16:32,982:INFO:Set up variance threshold.
2022-11-14 20:16:33,025:INFO:Finished creating preprocessing pipeline.
2022-11-14 20:16:33,032:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-14 20:16:33,033:INFO:Creating final display dataframe.
2022-11-14 20:16:33,204:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 12)
4         Train data shape    (607, 12)
5          Test data shape    (261, 12)
6         Numeric features           11
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         8dc6
2022-11-14 20:16:33,355:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:33,355:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:33,356:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:33,482:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:16:33,483:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:16:33,484:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:16:33,495:INFO:setup() successfully completed in 2.12s...............
2022-11-14 20:16:33,495:INFO:Initializing compare_models()
2022-11-14 20:16:33,496:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2326b3d0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f3d2326b3d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-14 20:16:33,496:INFO:Checking exceptions
2022-11-14 20:16:33,498:INFO:Preparing display monitor
2022-11-14 20:16:33,596:INFO:Initializing Linear Regression
2022-11-14 20:16:33,596:INFO:Total runtime is 9.389718373616536e-06 minutes
2022-11-14 20:16:33,610:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:33,610:INFO:Initializing create_model()
2022-11-14 20:16:33,611:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2326b3d0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27506b50>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:33,611:INFO:Checking exceptions
2022-11-14 20:16:33,614:INFO:Importing libraries
2022-11-14 20:16:33,614:INFO:Copying training dataset
2022-11-14 20:16:33,618:INFO:Defining folds
2022-11-14 20:16:33,618:INFO:Declaring metric variables
2022-11-14 20:16:33,627:INFO:Importing untrained model
2022-11-14 20:16:33,636:INFO:Linear Regression Imported successfully
2022-11-14 20:16:33,654:INFO:Starting cross validation
2022-11-14 20:16:33,658:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:35,311:INFO:Calculating mean and std
2022-11-14 20:16:35,315:INFO:Creating metrics dataframe
2022-11-14 20:16:35,325:INFO:Uploading results into container
2022-11-14 20:16:35,327:INFO:Uploading model into container now
2022-11-14 20:16:35,329:INFO:master_model_container: 1
2022-11-14 20:16:35,329:INFO:display_container: 2
2022-11-14 20:16:35,329:INFO:LinearRegression(n_jobs=-1)
2022-11-14 20:16:35,334:INFO:create_model() successfully completed......................................
2022-11-14 20:16:35,506:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:35,506:INFO:Creating metrics dataframe
2022-11-14 20:16:35,525:INFO:Initializing Lasso Regression
2022-11-14 20:16:35,525:INFO:Total runtime is 0.03216058015823364 minutes
2022-11-14 20:16:35,535:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:35,536:INFO:Initializing create_model()
2022-11-14 20:16:35,536:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2326b3d0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27506b50>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:35,537:INFO:Checking exceptions
2022-11-14 20:16:35,539:INFO:Importing libraries
2022-11-14 20:16:35,540:INFO:Copying training dataset
2022-11-14 20:16:35,548:INFO:Defining folds
2022-11-14 20:16:35,548:INFO:Declaring metric variables
2022-11-14 20:16:35,557:INFO:Importing untrained model
2022-11-14 20:16:35,567:INFO:Lasso Regression Imported successfully
2022-11-14 20:16:35,584:INFO:Starting cross validation
2022-11-14 20:16:35,586:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:35,897:INFO:Calculating mean and std
2022-11-14 20:16:35,900:INFO:Creating metrics dataframe
2022-11-14 20:16:35,909:INFO:Uploading results into container
2022-11-14 20:16:35,910:INFO:Uploading model into container now
2022-11-14 20:16:35,915:INFO:master_model_container: 2
2022-11-14 20:16:35,915:INFO:display_container: 2
2022-11-14 20:16:35,916:INFO:Lasso(random_state=123)
2022-11-14 20:16:35,916:INFO:create_model() successfully completed......................................
2022-11-14 20:16:36,082:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:36,082:INFO:Creating metrics dataframe
2022-11-14 20:16:36,101:INFO:Initializing Ridge Regression
2022-11-14 20:16:36,102:INFO:Total runtime is 0.04176825682322184 minutes
2022-11-14 20:16:36,111:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:36,112:INFO:Initializing create_model()
2022-11-14 20:16:36,112:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2326b3d0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27506b50>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:36,112:INFO:Checking exceptions
2022-11-14 20:16:36,115:INFO:Importing libraries
2022-11-14 20:16:36,116:INFO:Copying training dataset
2022-11-14 20:16:36,125:INFO:Defining folds
2022-11-14 20:16:36,125:INFO:Declaring metric variables
2022-11-14 20:16:36,135:INFO:Importing untrained model
2022-11-14 20:16:36,147:INFO:Ridge Regression Imported successfully
2022-11-14 20:16:36,168:INFO:Starting cross validation
2022-11-14 20:16:36,170:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:36,494:INFO:Calculating mean and std
2022-11-14 20:16:36,497:INFO:Creating metrics dataframe
2022-11-14 20:16:36,520:INFO:Uploading results into container
2022-11-14 20:16:36,523:INFO:Uploading model into container now
2022-11-14 20:16:36,524:INFO:master_model_container: 3
2022-11-14 20:16:36,524:INFO:display_container: 2
2022-11-14 20:16:36,525:INFO:Ridge(random_state=123)
2022-11-14 20:16:36,525:INFO:create_model() successfully completed......................................
2022-11-14 20:16:36,693:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:36,694:INFO:Creating metrics dataframe
2022-11-14 20:16:36,713:INFO:Initializing Elastic Net
2022-11-14 20:16:36,714:INFO:Total runtime is 0.051967147986094156 minutes
2022-11-14 20:16:36,722:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:36,727:INFO:Initializing create_model()
2022-11-14 20:16:36,728:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2326b3d0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27506b50>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:36,728:INFO:Checking exceptions
2022-11-14 20:16:36,730:INFO:Importing libraries
2022-11-14 20:16:36,731:INFO:Copying training dataset
2022-11-14 20:16:36,735:INFO:Defining folds
2022-11-14 20:16:36,737:INFO:Declaring metric variables
2022-11-14 20:16:36,749:INFO:Importing untrained model
2022-11-14 20:16:36,765:INFO:Elastic Net Imported successfully
2022-11-14 20:16:36,781:INFO:Starting cross validation
2022-11-14 20:16:36,783:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:37,648:INFO:Calculating mean and std
2022-11-14 20:16:37,656:INFO:Creating metrics dataframe
2022-11-14 20:16:37,684:INFO:Uploading results into container
2022-11-14 20:16:37,690:INFO:Uploading model into container now
2022-11-14 20:16:37,691:INFO:master_model_container: 4
2022-11-14 20:16:37,691:INFO:display_container: 2
2022-11-14 20:16:37,692:INFO:ElasticNet(random_state=123)
2022-11-14 20:16:37,692:INFO:create_model() successfully completed......................................
2022-11-14 20:16:37,861:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:37,861:INFO:Creating metrics dataframe
2022-11-14 20:16:37,882:INFO:Initializing Least Angle Regression
2022-11-14 20:16:37,883:INFO:Total runtime is 0.07145084540049235 minutes
2022-11-14 20:16:37,892:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:37,893:INFO:Initializing create_model()
2022-11-14 20:16:37,894:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2326b3d0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27506b50>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:37,894:INFO:Checking exceptions
2022-11-14 20:16:37,899:INFO:Importing libraries
2022-11-14 20:16:37,899:INFO:Copying training dataset
2022-11-14 20:16:37,905:INFO:Defining folds
2022-11-14 20:16:37,906:INFO:Declaring metric variables
2022-11-14 20:16:37,917:INFO:Importing untrained model
2022-11-14 20:16:37,929:INFO:Least Angle Regression Imported successfully
2022-11-14 20:16:37,947:INFO:Starting cross validation
2022-11-14 20:16:37,949:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:38,023:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:38,036:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:38,084:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:38,122:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:38,153:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:38,195:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:38,204:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:38,241:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:38,269:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:38,288:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:38,304:INFO:Calculating mean and std
2022-11-14 20:16:38,307:INFO:Creating metrics dataframe
2022-11-14 20:16:38,320:INFO:Uploading results into container
2022-11-14 20:16:38,322:INFO:Uploading model into container now
2022-11-14 20:16:38,322:INFO:master_model_container: 5
2022-11-14 20:16:38,323:INFO:display_container: 2
2022-11-14 20:16:38,323:INFO:Lars(random_state=123)
2022-11-14 20:16:38,324:INFO:create_model() successfully completed......................................
2022-11-14 20:16:38,494:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:38,495:INFO:Creating metrics dataframe
2022-11-14 20:16:38,519:INFO:Initializing Lasso Least Angle Regression
2022-11-14 20:16:38,526:INFO:Total runtime is 0.08217865626017253 minutes
2022-11-14 20:16:38,536:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:38,537:INFO:Initializing create_model()
2022-11-14 20:16:38,538:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2326b3d0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27506b50>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:38,538:INFO:Checking exceptions
2022-11-14 20:16:38,541:INFO:Importing libraries
2022-11-14 20:16:38,542:INFO:Copying training dataset
2022-11-14 20:16:38,548:INFO:Defining folds
2022-11-14 20:16:38,549:INFO:Declaring metric variables
2022-11-14 20:16:38,568:INFO:Importing untrained model
2022-11-14 20:16:38,580:INFO:Lasso Least Angle Regression Imported successfully
2022-11-14 20:16:38,600:INFO:Starting cross validation
2022-11-14 20:16:38,605:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:38,658:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:16:38,683:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:16:38,722:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:16:38,755:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:16:38,792:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:16:38,842:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:16:38,845:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:16:38,890:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:16:38,912:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:16:38,935:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:16:38,949:INFO:Calculating mean and std
2022-11-14 20:16:38,954:INFO:Creating metrics dataframe
2022-11-14 20:16:38,969:INFO:Uploading results into container
2022-11-14 20:16:38,971:INFO:Uploading model into container now
2022-11-14 20:16:38,971:INFO:master_model_container: 6
2022-11-14 20:16:38,971:INFO:display_container: 2
2022-11-14 20:16:38,972:INFO:LassoLars(random_state=123)
2022-11-14 20:16:38,972:INFO:create_model() successfully completed......................................
2022-11-14 20:16:39,155:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:39,156:INFO:Creating metrics dataframe
2022-11-14 20:16:39,177:INFO:Initializing Orthogonal Matching Pursuit
2022-11-14 20:16:39,177:INFO:Total runtime is 0.09302611351013183 minutes
2022-11-14 20:16:39,188:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:39,190:INFO:Initializing create_model()
2022-11-14 20:16:39,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2326b3d0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27506b50>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:39,190:INFO:Checking exceptions
2022-11-14 20:16:39,194:INFO:Importing libraries
2022-11-14 20:16:39,194:INFO:Copying training dataset
2022-11-14 20:16:39,204:INFO:Defining folds
2022-11-14 20:16:39,205:INFO:Declaring metric variables
2022-11-14 20:16:39,218:INFO:Importing untrained model
2022-11-14 20:16:39,229:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-14 20:16:39,248:INFO:Starting cross validation
2022-11-14 20:16:39,251:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:39,304:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:39,342:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:39,368:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:39,398:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:39,436:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:39,478:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:39,482:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:39,524:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:39,543:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:39,568:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:39,584:INFO:Calculating mean and std
2022-11-14 20:16:39,586:INFO:Creating metrics dataframe
2022-11-14 20:16:39,599:INFO:Uploading results into container
2022-11-14 20:16:39,600:INFO:Uploading model into container now
2022-11-14 20:16:39,601:INFO:master_model_container: 7
2022-11-14 20:16:39,602:INFO:display_container: 2
2022-11-14 20:16:39,602:INFO:OrthogonalMatchingPursuit()
2022-11-14 20:16:39,603:INFO:create_model() successfully completed......................................
2022-11-14 20:16:39,772:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:39,773:INFO:Creating metrics dataframe
2022-11-14 20:16:39,794:INFO:Initializing Bayesian Ridge
2022-11-14 20:16:39,794:INFO:Total runtime is 0.10331172148386637 minutes
2022-11-14 20:16:39,805:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:39,810:INFO:Initializing create_model()
2022-11-14 20:16:39,811:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2326b3d0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27506b50>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:39,811:INFO:Checking exceptions
2022-11-14 20:16:39,813:INFO:Importing libraries
2022-11-14 20:16:39,813:INFO:Copying training dataset
2022-11-14 20:16:39,819:INFO:Defining folds
2022-11-14 20:16:39,819:INFO:Declaring metric variables
2022-11-14 20:16:39,829:INFO:Importing untrained model
2022-11-14 20:16:39,839:INFO:Bayesian Ridge Imported successfully
2022-11-14 20:16:39,858:INFO:Starting cross validation
2022-11-14 20:16:39,860:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:40,197:INFO:Calculating mean and std
2022-11-14 20:16:40,200:INFO:Creating metrics dataframe
2022-11-14 20:16:40,210:INFO:Uploading results into container
2022-11-14 20:16:40,211:INFO:Uploading model into container now
2022-11-14 20:16:40,212:INFO:master_model_container: 8
2022-11-14 20:16:40,212:INFO:display_container: 2
2022-11-14 20:16:40,213:INFO:BayesianRidge()
2022-11-14 20:16:40,213:INFO:create_model() successfully completed......................................
2022-11-14 20:16:40,374:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:40,375:INFO:Creating metrics dataframe
2022-11-14 20:16:40,405:INFO:Initializing Passive Aggressive Regressor
2022-11-14 20:16:40,409:INFO:Total runtime is 0.11354905366897583 minutes
2022-11-14 20:16:40,418:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:40,421:INFO:Initializing create_model()
2022-11-14 20:16:40,425:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2326b3d0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27506b50>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:40,425:INFO:Checking exceptions
2022-11-14 20:16:40,427:INFO:Importing libraries
2022-11-14 20:16:40,428:INFO:Copying training dataset
2022-11-14 20:16:40,432:INFO:Defining folds
2022-11-14 20:16:40,432:INFO:Declaring metric variables
2022-11-14 20:16:40,446:INFO:Importing untrained model
2022-11-14 20:16:40,459:INFO:Passive Aggressive Regressor Imported successfully
2022-11-14 20:16:40,481:INFO:Starting cross validation
2022-11-14 20:16:40,483:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:40,807:INFO:Calculating mean and std
2022-11-14 20:16:40,820:INFO:Creating metrics dataframe
2022-11-14 20:16:40,836:INFO:Uploading results into container
2022-11-14 20:16:40,838:INFO:Uploading model into container now
2022-11-14 20:16:40,839:INFO:master_model_container: 9
2022-11-14 20:16:40,839:INFO:display_container: 2
2022-11-14 20:16:40,840:INFO:PassiveAggressiveRegressor(random_state=123)
2022-11-14 20:16:40,840:INFO:create_model() successfully completed......................................
2022-11-14 20:16:41,003:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:41,004:INFO:Creating metrics dataframe
2022-11-14 20:16:41,025:INFO:Initializing Huber Regressor
2022-11-14 20:16:41,028:INFO:Total runtime is 0.12383904059727986 minutes
2022-11-14 20:16:41,037:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:41,038:INFO:Initializing create_model()
2022-11-14 20:16:41,038:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2326b3d0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27506b50>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:41,038:INFO:Checking exceptions
2022-11-14 20:16:41,041:INFO:Importing libraries
2022-11-14 20:16:41,042:INFO:Copying training dataset
2022-11-14 20:16:41,051:INFO:Defining folds
2022-11-14 20:16:41,051:INFO:Declaring metric variables
2022-11-14 20:16:41,064:INFO:Importing untrained model
2022-11-14 20:16:41,075:INFO:Huber Regressor Imported successfully
2022-11-14 20:16:41,096:INFO:Starting cross validation
2022-11-14 20:16:41,101:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:41,211:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:16:41,277:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:16:41,386:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:16:41,484:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:16:41,520:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:16:41,621:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:16:41,715:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-14 20:16:41,729:INFO:Calculating mean and std
2022-11-14 20:16:41,736:INFO:Creating metrics dataframe
2022-11-14 20:16:41,753:INFO:Uploading results into container
2022-11-14 20:16:41,753:INFO:Uploading model into container now
2022-11-14 20:16:41,754:INFO:master_model_container: 10
2022-11-14 20:16:41,754:INFO:display_container: 2
2022-11-14 20:16:41,755:INFO:HuberRegressor()
2022-11-14 20:16:41,755:INFO:create_model() successfully completed......................................
2022-11-14 20:16:41,932:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:41,933:INFO:Creating metrics dataframe
2022-11-14 20:16:41,955:INFO:Initializing K Neighbors Regressor
2022-11-14 20:16:41,956:INFO:Total runtime is 0.13933175007502238 minutes
2022-11-14 20:16:41,966:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:41,967:INFO:Initializing create_model()
2022-11-14 20:16:41,967:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2326b3d0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27506b50>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:41,967:INFO:Checking exceptions
2022-11-14 20:16:41,971:INFO:Importing libraries
2022-11-14 20:16:41,971:INFO:Copying training dataset
2022-11-14 20:16:41,979:INFO:Defining folds
2022-11-14 20:16:41,979:INFO:Declaring metric variables
2022-11-14 20:16:41,989:INFO:Importing untrained model
2022-11-14 20:16:41,999:INFO:K Neighbors Regressor Imported successfully
2022-11-14 20:16:42,018:INFO:Starting cross validation
2022-11-14 20:16:42,020:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:42,811:INFO:Calculating mean and std
2022-11-14 20:16:42,816:INFO:Creating metrics dataframe
2022-11-14 20:16:42,826:INFO:Uploading results into container
2022-11-14 20:16:42,828:INFO:Uploading model into container now
2022-11-14 20:16:42,828:INFO:master_model_container: 11
2022-11-14 20:16:42,829:INFO:display_container: 2
2022-11-14 20:16:42,830:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-14 20:16:42,830:INFO:create_model() successfully completed......................................
2022-11-14 20:16:43,001:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:43,001:INFO:Creating metrics dataframe
2022-11-14 20:16:43,023:INFO:Initializing Decision Tree Regressor
2022-11-14 20:16:43,024:INFO:Total runtime is 0.15714595317840577 minutes
2022-11-14 20:16:43,034:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:43,035:INFO:Initializing create_model()
2022-11-14 20:16:43,035:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2326b3d0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27506b50>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:43,035:INFO:Checking exceptions
2022-11-14 20:16:43,038:INFO:Importing libraries
2022-11-14 20:16:43,039:INFO:Copying training dataset
2022-11-14 20:16:43,047:INFO:Defining folds
2022-11-14 20:16:43,048:INFO:Declaring metric variables
2022-11-14 20:16:43,058:INFO:Importing untrained model
2022-11-14 20:16:43,069:INFO:Decision Tree Regressor Imported successfully
2022-11-14 20:16:43,088:INFO:Starting cross validation
2022-11-14 20:16:43,090:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:43,469:INFO:Calculating mean and std
2022-11-14 20:16:43,475:INFO:Creating metrics dataframe
2022-11-14 20:16:43,488:INFO:Uploading results into container
2022-11-14 20:16:43,489:INFO:Uploading model into container now
2022-11-14 20:16:43,490:INFO:master_model_container: 12
2022-11-14 20:16:43,490:INFO:display_container: 2
2022-11-14 20:16:43,491:INFO:DecisionTreeRegressor(random_state=123)
2022-11-14 20:16:43,491:INFO:create_model() successfully completed......................................
2022-11-14 20:16:43,656:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:43,657:INFO:Creating metrics dataframe
2022-11-14 20:16:43,682:INFO:Initializing Random Forest Regressor
2022-11-14 20:16:43,683:INFO:Total runtime is 0.16812325318654378 minutes
2022-11-14 20:16:43,694:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:43,695:INFO:Initializing create_model()
2022-11-14 20:16:43,695:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2326b3d0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27506b50>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:43,696:INFO:Checking exceptions
2022-11-14 20:16:43,698:INFO:Importing libraries
2022-11-14 20:16:43,698:INFO:Copying training dataset
2022-11-14 20:16:43,710:INFO:Defining folds
2022-11-14 20:16:43,712:INFO:Declaring metric variables
2022-11-14 20:16:43,721:INFO:Importing untrained model
2022-11-14 20:16:43,732:INFO:Random Forest Regressor Imported successfully
2022-11-14 20:16:43,754:INFO:Starting cross validation
2022-11-14 20:16:43,756:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:48,783:INFO:Calculating mean and std
2022-11-14 20:16:48,785:INFO:Creating metrics dataframe
2022-11-14 20:16:48,801:INFO:Uploading results into container
2022-11-14 20:16:48,806:INFO:Uploading model into container now
2022-11-14 20:16:48,807:INFO:master_model_container: 13
2022-11-14 20:16:48,808:INFO:display_container: 2
2022-11-14 20:16:48,808:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-14 20:16:48,808:INFO:create_model() successfully completed......................................
2022-11-14 20:16:48,973:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:48,973:INFO:Creating metrics dataframe
2022-11-14 20:16:48,996:INFO:Initializing Extra Trees Regressor
2022-11-14 20:16:48,996:INFO:Total runtime is 0.25667272408803304 minutes
2022-11-14 20:16:49,008:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:49,013:INFO:Initializing create_model()
2022-11-14 20:16:49,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2326b3d0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27506b50>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:49,014:INFO:Checking exceptions
2022-11-14 20:16:49,017:INFO:Importing libraries
2022-11-14 20:16:49,017:INFO:Copying training dataset
2022-11-14 20:16:49,024:INFO:Defining folds
2022-11-14 20:16:49,024:INFO:Declaring metric variables
2022-11-14 20:16:49,034:INFO:Importing untrained model
2022-11-14 20:16:49,043:INFO:Extra Trees Regressor Imported successfully
2022-11-14 20:16:49,061:INFO:Starting cross validation
2022-11-14 20:16:49,063:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:51,817:INFO:Calculating mean and std
2022-11-14 20:16:51,822:INFO:Creating metrics dataframe
2022-11-14 20:16:51,837:INFO:Uploading results into container
2022-11-14 20:16:51,838:INFO:Uploading model into container now
2022-11-14 20:16:51,838:INFO:master_model_container: 14
2022-11-14 20:16:51,839:INFO:display_container: 2
2022-11-14 20:16:51,839:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-14 20:16:51,840:INFO:create_model() successfully completed......................................
2022-11-14 20:16:51,995:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:51,996:INFO:Creating metrics dataframe
2022-11-14 20:16:52,018:INFO:Initializing AdaBoost Regressor
2022-11-14 20:16:52,020:INFO:Total runtime is 0.3070701599121094 minutes
2022-11-14 20:16:52,029:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:52,030:INFO:Initializing create_model()
2022-11-14 20:16:52,030:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2326b3d0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27506b50>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:52,030:INFO:Checking exceptions
2022-11-14 20:16:52,033:INFO:Importing libraries
2022-11-14 20:16:52,034:INFO:Copying training dataset
2022-11-14 20:16:52,040:INFO:Defining folds
2022-11-14 20:16:52,041:INFO:Declaring metric variables
2022-11-14 20:16:52,052:INFO:Importing untrained model
2022-11-14 20:16:52,065:INFO:AdaBoost Regressor Imported successfully
2022-11-14 20:16:52,086:INFO:Starting cross validation
2022-11-14 20:16:52,090:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:53,250:INFO:Calculating mean and std
2022-11-14 20:16:53,255:INFO:Creating metrics dataframe
2022-11-14 20:16:53,263:INFO:Uploading results into container
2022-11-14 20:16:53,264:INFO:Uploading model into container now
2022-11-14 20:16:53,265:INFO:master_model_container: 15
2022-11-14 20:16:53,265:INFO:display_container: 2
2022-11-14 20:16:53,266:INFO:AdaBoostRegressor(random_state=123)
2022-11-14 20:16:53,266:INFO:create_model() successfully completed......................................
2022-11-14 20:16:53,431:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:53,432:INFO:Creating metrics dataframe
2022-11-14 20:16:53,455:INFO:Initializing Gradient Boosting Regressor
2022-11-14 20:16:53,456:INFO:Total runtime is 0.3310003956158956 minutes
2022-11-14 20:16:53,468:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:53,469:INFO:Initializing create_model()
2022-11-14 20:16:53,469:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2326b3d0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27506b50>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:53,469:INFO:Checking exceptions
2022-11-14 20:16:53,472:INFO:Importing libraries
2022-11-14 20:16:53,473:INFO:Copying training dataset
2022-11-14 20:16:53,481:INFO:Defining folds
2022-11-14 20:16:53,482:INFO:Declaring metric variables
2022-11-14 20:16:53,491:INFO:Importing untrained model
2022-11-14 20:16:53,503:INFO:Gradient Boosting Regressor Imported successfully
2022-11-14 20:16:53,520:INFO:Starting cross validation
2022-11-14 20:16:53,522:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:55,396:INFO:Calculating mean and std
2022-11-14 20:16:55,399:INFO:Creating metrics dataframe
2022-11-14 20:16:55,413:INFO:Uploading results into container
2022-11-14 20:16:55,415:INFO:Uploading model into container now
2022-11-14 20:16:55,415:INFO:master_model_container: 16
2022-11-14 20:16:55,416:INFO:display_container: 2
2022-11-14 20:16:55,416:INFO:GradientBoostingRegressor(random_state=123)
2022-11-14 20:16:55,416:INFO:create_model() successfully completed......................................
2022-11-14 20:16:55,573:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:55,574:INFO:Creating metrics dataframe
2022-11-14 20:16:55,602:INFO:Initializing Light Gradient Boosting Machine
2022-11-14 20:16:55,603:INFO:Total runtime is 0.3667839845021566 minutes
2022-11-14 20:16:55,616:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:55,618:INFO:Initializing create_model()
2022-11-14 20:16:55,618:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2326b3d0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27506b50>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:55,618:INFO:Checking exceptions
2022-11-14 20:16:55,621:INFO:Importing libraries
2022-11-14 20:16:55,621:INFO:Copying training dataset
2022-11-14 20:16:55,628:INFO:Defining folds
2022-11-14 20:16:55,629:INFO:Declaring metric variables
2022-11-14 20:16:55,702:INFO:Importing untrained model
2022-11-14 20:16:55,748:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-14 20:16:55,839:INFO:Starting cross validation
2022-11-14 20:16:55,841:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:57,994:INFO:Calculating mean and std
2022-11-14 20:16:57,997:INFO:Creating metrics dataframe
2022-11-14 20:16:58,016:INFO:Uploading results into container
2022-11-14 20:16:58,017:INFO:Uploading model into container now
2022-11-14 20:16:58,017:INFO:master_model_container: 17
2022-11-14 20:16:58,018:INFO:display_container: 2
2022-11-14 20:16:58,018:INFO:LGBMRegressor(random_state=123)
2022-11-14 20:16:58,018:INFO:create_model() successfully completed......................................
2022-11-14 20:16:58,182:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:58,182:INFO:Creating metrics dataframe
2022-11-14 20:16:58,206:INFO:Initializing Dummy Regressor
2022-11-14 20:16:58,207:INFO:Total runtime is 0.41018217007319135 minutes
2022-11-14 20:16:58,220:INFO:SubProcess create_model() called ==================================
2022-11-14 20:16:58,221:INFO:Initializing create_model()
2022-11-14 20:16:58,227:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2326b3d0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d27506b50>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:58,227:INFO:Checking exceptions
2022-11-14 20:16:58,230:INFO:Importing libraries
2022-11-14 20:16:58,230:INFO:Copying training dataset
2022-11-14 20:16:58,235:INFO:Defining folds
2022-11-14 20:16:58,237:INFO:Declaring metric variables
2022-11-14 20:16:58,248:INFO:Importing untrained model
2022-11-14 20:16:58,259:INFO:Dummy Regressor Imported successfully
2022-11-14 20:16:58,277:INFO:Starting cross validation
2022-11-14 20:16:58,279:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:16:58,580:INFO:Calculating mean and std
2022-11-14 20:16:58,584:INFO:Creating metrics dataframe
2022-11-14 20:16:58,593:INFO:Uploading results into container
2022-11-14 20:16:58,595:INFO:Uploading model into container now
2022-11-14 20:16:58,595:INFO:master_model_container: 18
2022-11-14 20:16:58,596:INFO:display_container: 2
2022-11-14 20:16:58,596:INFO:DummyRegressor()
2022-11-14 20:16:58,596:INFO:create_model() successfully completed......................................
2022-11-14 20:16:58,766:INFO:SubProcess create_model() end ==================================
2022-11-14 20:16:58,767:INFO:Creating metrics dataframe
2022-11-14 20:16:58,825:INFO:Initializing create_model()
2022-11-14 20:16:58,832:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d2326b3d0>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:16:58,832:INFO:Checking exceptions
2022-11-14 20:16:58,838:INFO:Importing libraries
2022-11-14 20:16:58,841:INFO:Copying training dataset
2022-11-14 20:16:58,845:INFO:Defining folds
2022-11-14 20:16:58,846:INFO:Declaring metric variables
2022-11-14 20:16:58,846:INFO:Importing untrained model
2022-11-14 20:16:58,847:INFO:Declaring custom model
2022-11-14 20:16:58,848:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-14 20:16:58,849:INFO:Cross validation set to False
2022-11-14 20:16:58,849:INFO:Fitting Model
2022-11-14 20:16:58,882:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:16:58,886:INFO:OrthogonalMatchingPursuit()
2022-11-14 20:16:58,886:INFO:create_model() successfully completed......................................
2022-11-14 20:16:59,142:INFO:master_model_container: 18
2022-11-14 20:16:59,143:INFO:display_container: 2
2022-11-14 20:16:59,143:INFO:OrthogonalMatchingPursuit()
2022-11-14 20:16:59,144:INFO:compare_models() successfully completed......................................
2022-11-14 20:17:05,204:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  app.launch_new_instance()

2022-11-14 20:17:05,205:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:17:05,206:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:17:05,207:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:17:05,208:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:17:05,209:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:17:05,210:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:17:05,211:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:17:05,212:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:17:05,213:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:17:05,214:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-14 20:17:05,219:INFO:PyCaret RegressionExperiment
2022-11-14 20:17:05,219:INFO:Logging name: FullData
2022-11-14 20:17:05,219:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-14 20:17:05,219:INFO:version 3.0.0.rc4
2022-11-14 20:17:05,219:INFO:Initializing setup()
2022-11-14 20:17:05,219:INFO:self.USI: 7785
2022-11-14 20:17:05,219:INFO:self.variable_keys: {'fold_generator', 'fold_shuffle_param', '_ml_usecase', 'data', 'X_train', 'y', 'transform_target_method_param', 'idx', 'display_container', 'log_plots_param', 'gpu_param', 'y_train', '_available_plots', 'master_model_container', '_gpu_n_jobs_param', 'y_test', '_all_models_internal', 'X_test', 'transform_target_param', 'X', 'html_param', 'logging_param', '_all_metrics', 'exp_name_log', 'pipeline', 'variable_keys', 'seed', 'target_param', '_all_models', 'USI', 'fold_groups_param', 'exp_id', 'memory', 'n_jobs_param'}
2022-11-14 20:17:05,219:INFO:Checking environment
2022-11-14 20:17:05,220:INFO:python_version: 3.7.15
2022-11-14 20:17:05,220:INFO:python_build: ('default', 'Oct 12 2022 19:14:55')
2022-11-14 20:17:05,220:INFO:machine: x86_64
2022-11-14 20:17:05,220:INFO:platform: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-14 20:17:05,220:INFO:Memory: svmem(total=13616361472, available=11639189504, percent=14.5, used=1878941696, free=7507963904, active=923463680, inactive=4814307328, buffers=167534592, cached=4061921280, shared=1327104, slab=274083840)
2022-11-14 20:17:05,220:INFO:Physical Core: 1
2022-11-14 20:17:05,220:INFO:Logical Core: 2
2022-11-14 20:17:05,220:INFO:Checking libraries
2022-11-14 20:17:05,221:INFO:System:
2022-11-14 20:17:05,221:INFO:    python: 3.7.15 (default, Oct 12 2022, 19:14:55)  [GCC 7.5.0]
2022-11-14 20:17:05,221:INFO:executable: /usr/bin/python3
2022-11-14 20:17:05,221:INFO:   machine: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-14 20:17:05,221:INFO:PyCaret required dependencies:
2022-11-14 20:17:05,221:INFO:                 pip: 21.1.3
2022-11-14 20:17:05,221:INFO:          setuptools: 57.4.0
2022-11-14 20:17:05,221:INFO:             pycaret: 3.0.0rc4
2022-11-14 20:17:05,221:INFO:             IPython: 7.9.0
2022-11-14 20:17:05,221:INFO:          ipywidgets: 7.7.1
2022-11-14 20:17:05,221:INFO:                tqdm: 4.64.1
2022-11-14 20:17:05,222:INFO:               numpy: 1.21.6
2022-11-14 20:17:05,222:INFO:              pandas: 1.3.5
2022-11-14 20:17:05,222:INFO:              jinja2: 3.0.0
2022-11-14 20:17:05,222:INFO:               scipy: 1.7.3
2022-11-14 20:17:05,222:INFO:              joblib: 1.2.0
2022-11-14 20:17:05,222:INFO:             sklearn: 1.0.2
2022-11-14 20:17:05,222:INFO:                pyod: 1.0.6
2022-11-14 20:17:05,222:INFO:            imblearn: 0.8.1
2022-11-14 20:17:05,222:INFO:   category_encoders: 2.5.1.post0
2022-11-14 20:17:05,222:INFO:            lightgbm: 3.3.3
2022-11-14 20:17:05,222:INFO:               numba: 0.55.2
2022-11-14 20:17:05,222:INFO:            requests: 2.28.1
2022-11-14 20:17:05,222:INFO:          matplotlib: 3.5.3
2022-11-14 20:17:05,222:INFO:          scikitplot: 0.3.7
2022-11-14 20:17:05,223:INFO:         yellowbrick: 1.5
2022-11-14 20:17:05,223:INFO:              plotly: 5.5.0
2022-11-14 20:17:05,223:INFO:             kaleido: 0.2.1
2022-11-14 20:17:05,223:INFO:         statsmodels: 0.12.2
2022-11-14 20:17:05,223:INFO:              sktime: 0.13.4
2022-11-14 20:17:05,223:INFO:               tbats: 1.1.1
2022-11-14 20:17:05,223:INFO:            pmdarima: 1.8.5
2022-11-14 20:17:05,223:INFO:              psutil: 5.9.4
2022-11-14 20:17:05,223:INFO:PyCaret optional dependencies:
2022-11-14 20:17:05,223:INFO:                shap: Not installed
2022-11-14 20:17:05,223:INFO:           interpret: Not installed
2022-11-14 20:17:05,223:INFO:                umap: Not installed
2022-11-14 20:17:05,223:INFO:    pandas_profiling: 1.4.1
2022-11-14 20:17:05,223:INFO:  explainerdashboard: Not installed
2022-11-14 20:17:05,223:INFO:             autoviz: Not installed
2022-11-14 20:17:05,224:INFO:           fairlearn: Not installed
2022-11-14 20:17:05,224:INFO:             xgboost: 0.90
2022-11-14 20:17:05,224:INFO:            catboost: Not installed
2022-11-14 20:17:05,224:INFO:              kmodes: Not installed
2022-11-14 20:17:05,224:INFO:             mlxtend: 0.14.0
2022-11-14 20:17:05,224:INFO:       statsforecast: Not installed
2022-11-14 20:17:05,224:INFO:        tune_sklearn: Not installed
2022-11-14 20:17:05,224:INFO:                 ray: Not installed
2022-11-14 20:17:05,224:INFO:            hyperopt: 0.1.2
2022-11-14 20:17:05,224:INFO:              optuna: Not installed
2022-11-14 20:17:05,224:INFO:               skopt: Not installed
2022-11-14 20:17:05,224:INFO:              mlflow: Not installed
2022-11-14 20:17:05,224:INFO:              gradio: Not installed
2022-11-14 20:17:05,224:INFO:             fastapi: Not installed
2022-11-14 20:17:05,224:INFO:             uvicorn: Not installed
2022-11-14 20:17:05,224:INFO:              m2cgen: Not installed
2022-11-14 20:17:05,225:INFO:           evidently: Not installed
2022-11-14 20:17:05,225:INFO:                nltk: 3.7
2022-11-14 20:17:05,225:INFO:            pyLDAvis: Not installed
2022-11-14 20:17:05,225:INFO:              gensim: 3.6.0
2022-11-14 20:17:05,225:INFO:               spacy: 3.4.2
2022-11-14 20:17:05,225:INFO:           wordcloud: 1.8.2.2
2022-11-14 20:17:05,225:INFO:            textblob: 0.15.3
2022-11-14 20:17:05,225:INFO:               fugue: Not installed
2022-11-14 20:17:05,225:INFO:           streamlit: Not installed
2022-11-14 20:17:05,225:INFO:             prophet: 1.1.1
2022-11-14 20:17:05,225:INFO:None
2022-11-14 20:17:05,225:INFO:Set up data.
2022-11-14 20:17:05,233:INFO:Set up train/test split.
2022-11-14 20:17:05,236:INFO:Set up index.
2022-11-14 20:17:05,237:INFO:Set up folding strategy.
2022-11-14 20:17:05,237:INFO:Assigning column types.
2022-11-14 20:17:05,243:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-14 20:17:05,244:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-14 20:17:05,249:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-14 20:17:05,254:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:17:05,319:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:17:05,369:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:17:05,370:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:17:05,370:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:17:05,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:17:05,372:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-14 20:17:05,377:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-14 20:17:05,382:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:17:05,447:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:17:05,498:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:17:05,499:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:17:05,499:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:17:05,499:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:17:05,500:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-14 20:17:05,505:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-14 20:17:05,510:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:17:05,578:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:17:05,631:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:17:05,632:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:17:05,633:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:17:05,633:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:17:05,639:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-14 20:17:05,644:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:17:05,713:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:17:05,765:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:17:05,766:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:17:05,767:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:17:05,767:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:17:05,767:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-14 20:17:05,778:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:17:05,844:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:17:05,897:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:17:05,898:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:17:05,899:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:17:05,899:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:17:05,916:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-14 20:17:05,997:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:17:06,066:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:17:06,067:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:17:06,068:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:17:06,068:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:17:06,069:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-14 20:17:06,143:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:17:06,192:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:17:06,198:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:17:06,199:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:17:06,199:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:17:06,278:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:17:06,329:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-14 20:17:06,330:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:17:06,330:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:17:06,331:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:17:06,331:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-14 20:17:06,406:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:17:06,456:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:17:06,456:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:17:06,456:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:17:06,532:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-14 20:17:06,587:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:17:06,587:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:17:06,588:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:17:06,589:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-14 20:17:06,717:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:17:06,717:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:17:06,717:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:17:06,855:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:17:06,856:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:17:06,856:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:17:06,857:INFO:Preparing preprocessing pipeline...
2022-11-14 20:17:06,858:INFO:Set up simple imputation.
2022-11-14 20:17:06,859:INFO:Set up variance threshold.
2022-11-14 20:17:06,901:INFO:Finished creating preprocessing pipeline.
2022-11-14 20:17:06,907:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-14 20:17:06,907:INFO:Creating final display dataframe.
2022-11-14 20:17:07,093:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape   (1229, 12)
4         Train data shape    (860, 12)
5          Test data shape    (369, 12)
6         Numeric features           11
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         7785
2022-11-14 20:17:07,243:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:17:07,244:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:17:07,244:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:17:07,374:INFO:Soft dependency imported: xgboost: 0.90
2022-11-14 20:17:07,375:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-14 20:17:07,375:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-14 20:17:07,384:INFO:setup() successfully completed in 2.17s...............
2022-11-14 20:17:07,385:INFO:Initializing compare_models()
2022-11-14 20:17:07,385:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232cf410>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f3d232cf410>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-14 20:17:07,385:INFO:Checking exceptions
2022-11-14 20:17:07,388:INFO:Preparing display monitor
2022-11-14 20:17:07,479:INFO:Initializing Linear Regression
2022-11-14 20:17:07,480:INFO:Total runtime is 7.315476735432943e-06 minutes
2022-11-14 20:17:07,493:INFO:SubProcess create_model() called ==================================
2022-11-14 20:17:07,494:INFO:Initializing create_model()
2022-11-14 20:17:07,495:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232cf410>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2788a250>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:17:07,499:INFO:Checking exceptions
2022-11-14 20:17:07,502:INFO:Importing libraries
2022-11-14 20:17:07,503:INFO:Copying training dataset
2022-11-14 20:17:07,506:INFO:Defining folds
2022-11-14 20:17:07,511:INFO:Declaring metric variables
2022-11-14 20:17:07,521:INFO:Importing untrained model
2022-11-14 20:17:07,531:INFO:Linear Regression Imported successfully
2022-11-14 20:17:07,551:INFO:Starting cross validation
2022-11-14 20:17:07,556:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:17:09,134:INFO:Calculating mean and std
2022-11-14 20:17:09,140:INFO:Creating metrics dataframe
2022-11-14 20:17:09,156:INFO:Uploading results into container
2022-11-14 20:17:09,156:INFO:Uploading model into container now
2022-11-14 20:17:09,157:INFO:master_model_container: 1
2022-11-14 20:17:09,157:INFO:display_container: 2
2022-11-14 20:17:09,158:INFO:LinearRegression(n_jobs=-1)
2022-11-14 20:17:09,158:INFO:create_model() successfully completed......................................
2022-11-14 20:17:09,330:INFO:SubProcess create_model() end ==================================
2022-11-14 20:17:09,331:INFO:Creating metrics dataframe
2022-11-14 20:17:09,351:INFO:Initializing Lasso Regression
2022-11-14 20:17:09,352:INFO:Total runtime is 0.031222971280415852 minutes
2022-11-14 20:17:09,362:INFO:SubProcess create_model() called ==================================
2022-11-14 20:17:09,363:INFO:Initializing create_model()
2022-11-14 20:17:09,363:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232cf410>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2788a250>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:17:09,363:INFO:Checking exceptions
2022-11-14 20:17:09,367:INFO:Importing libraries
2022-11-14 20:17:09,367:INFO:Copying training dataset
2022-11-14 20:17:09,373:INFO:Defining folds
2022-11-14 20:17:09,373:INFO:Declaring metric variables
2022-11-14 20:17:09,387:INFO:Importing untrained model
2022-11-14 20:17:09,400:INFO:Lasso Regression Imported successfully
2022-11-14 20:17:09,421:INFO:Starting cross validation
2022-11-14 20:17:09,424:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:17:09,757:INFO:Calculating mean and std
2022-11-14 20:17:09,760:INFO:Creating metrics dataframe
2022-11-14 20:17:09,773:INFO:Uploading results into container
2022-11-14 20:17:09,774:INFO:Uploading model into container now
2022-11-14 20:17:09,775:INFO:master_model_container: 2
2022-11-14 20:17:09,776:INFO:display_container: 2
2022-11-14 20:17:09,776:INFO:Lasso(random_state=123)
2022-11-14 20:17:09,777:INFO:create_model() successfully completed......................................
2022-11-14 20:17:09,950:INFO:SubProcess create_model() end ==================================
2022-11-14 20:17:09,951:INFO:Creating metrics dataframe
2022-11-14 20:17:09,971:INFO:Initializing Ridge Regression
2022-11-14 20:17:09,971:INFO:Total runtime is 0.04153558810551961 minutes
2022-11-14 20:17:09,980:INFO:SubProcess create_model() called ==================================
2022-11-14 20:17:09,981:INFO:Initializing create_model()
2022-11-14 20:17:09,982:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232cf410>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2788a250>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:17:09,982:INFO:Checking exceptions
2022-11-14 20:17:09,985:INFO:Importing libraries
2022-11-14 20:17:09,986:INFO:Copying training dataset
2022-11-14 20:17:09,994:INFO:Defining folds
2022-11-14 20:17:09,998:INFO:Declaring metric variables
2022-11-14 20:17:10,010:INFO:Importing untrained model
2022-11-14 20:17:10,020:INFO:Ridge Regression Imported successfully
2022-11-14 20:17:10,044:INFO:Starting cross validation
2022-11-14 20:17:10,046:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:17:10,361:INFO:Calculating mean and std
2022-11-14 20:17:10,364:INFO:Creating metrics dataframe
2022-11-14 20:17:10,372:INFO:Uploading results into container
2022-11-14 20:17:10,373:INFO:Uploading model into container now
2022-11-14 20:17:10,374:INFO:master_model_container: 3
2022-11-14 20:17:10,374:INFO:display_container: 2
2022-11-14 20:17:10,374:INFO:Ridge(random_state=123)
2022-11-14 20:17:10,375:INFO:create_model() successfully completed......................................
2022-11-14 20:17:10,540:INFO:SubProcess create_model() end ==================================
2022-11-14 20:17:10,541:INFO:Creating metrics dataframe
2022-11-14 20:17:10,565:INFO:Initializing Elastic Net
2022-11-14 20:17:10,566:INFO:Total runtime is 0.051443819204966226 minutes
2022-11-14 20:17:10,575:INFO:SubProcess create_model() called ==================================
2022-11-14 20:17:10,575:INFO:Initializing create_model()
2022-11-14 20:17:10,576:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232cf410>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2788a250>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:17:10,576:INFO:Checking exceptions
2022-11-14 20:17:10,579:INFO:Importing libraries
2022-11-14 20:17:10,579:INFO:Copying training dataset
2022-11-14 20:17:10,590:INFO:Defining folds
2022-11-14 20:17:10,590:INFO:Declaring metric variables
2022-11-14 20:17:10,604:INFO:Importing untrained model
2022-11-14 20:17:10,615:INFO:Elastic Net Imported successfully
2022-11-14 20:17:10,636:INFO:Starting cross validation
2022-11-14 20:17:10,641:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:17:10,951:INFO:Calculating mean and std
2022-11-14 20:17:10,957:INFO:Creating metrics dataframe
2022-11-14 20:17:10,971:INFO:Uploading results into container
2022-11-14 20:17:10,972:INFO:Uploading model into container now
2022-11-14 20:17:10,973:INFO:master_model_container: 4
2022-11-14 20:17:10,973:INFO:display_container: 2
2022-11-14 20:17:10,973:INFO:ElasticNet(random_state=123)
2022-11-14 20:17:10,974:INFO:create_model() successfully completed......................................
2022-11-14 20:17:11,146:INFO:SubProcess create_model() end ==================================
2022-11-14 20:17:11,147:INFO:Creating metrics dataframe
2022-11-14 20:17:11,166:INFO:Initializing Least Angle Regression
2022-11-14 20:17:11,167:INFO:Total runtime is 0.061463924249013265 minutes
2022-11-14 20:17:11,176:INFO:SubProcess create_model() called ==================================
2022-11-14 20:17:11,179:INFO:Initializing create_model()
2022-11-14 20:17:11,179:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232cf410>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2788a250>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:17:11,180:INFO:Checking exceptions
2022-11-14 20:17:11,182:INFO:Importing libraries
2022-11-14 20:17:11,183:INFO:Copying training dataset
2022-11-14 20:17:11,191:INFO:Defining folds
2022-11-14 20:17:11,193:INFO:Declaring metric variables
2022-11-14 20:17:11,202:INFO:Importing untrained model
2022-11-14 20:17:11,215:INFO:Least Angle Regression Imported successfully
2022-11-14 20:17:11,234:INFO:Starting cross validation
2022-11-14 20:17:11,236:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:17:11,282:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:17:11,318:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:17:11,353:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:17:11,386:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:17:11,431:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:17:11,472:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:17:11,476:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:17:11,528:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:17:11,538:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:17:11,572:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:17:11,591:INFO:Calculating mean and std
2022-11-14 20:17:11,596:INFO:Creating metrics dataframe
2022-11-14 20:17:11,611:INFO:Uploading results into container
2022-11-14 20:17:11,612:INFO:Uploading model into container now
2022-11-14 20:17:11,613:INFO:master_model_container: 5
2022-11-14 20:17:11,614:INFO:display_container: 2
2022-11-14 20:17:11,614:INFO:Lars(random_state=123)
2022-11-14 20:17:11,615:INFO:create_model() successfully completed......................................
2022-11-14 20:17:11,840:INFO:SubProcess create_model() end ==================================
2022-11-14 20:17:11,841:INFO:Creating metrics dataframe
2022-11-14 20:17:11,872:INFO:Initializing Lasso Least Angle Regression
2022-11-14 20:17:11,872:INFO:Total runtime is 0.07321847677230835 minutes
2022-11-14 20:17:11,882:INFO:SubProcess create_model() called ==================================
2022-11-14 20:17:11,883:INFO:Initializing create_model()
2022-11-14 20:17:11,883:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232cf410>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2788a250>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:17:11,883:INFO:Checking exceptions
2022-11-14 20:17:11,887:INFO:Importing libraries
2022-11-14 20:17:11,887:INFO:Copying training dataset
2022-11-14 20:17:11,897:INFO:Defining folds
2022-11-14 20:17:11,897:INFO:Declaring metric variables
2022-11-14 20:17:11,907:INFO:Importing untrained model
2022-11-14 20:17:11,917:INFO:Lasso Least Angle Regression Imported successfully
2022-11-14 20:17:11,935:INFO:Starting cross validation
2022-11-14 20:17:11,937:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:17:12,025:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:17:12,049:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:17:12,165:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:17:12,186:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:17:12,279:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:17:12,334:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:17:12,404:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:17:12,442:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:17:12,506:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:17:12,534:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:17:12,560:INFO:Calculating mean and std
2022-11-14 20:17:12,566:INFO:Creating metrics dataframe
2022-11-14 20:17:12,586:INFO:Uploading results into container
2022-11-14 20:17:12,587:INFO:Uploading model into container now
2022-11-14 20:17:12,588:INFO:master_model_container: 6
2022-11-14 20:17:12,588:INFO:display_container: 2
2022-11-14 20:17:12,589:INFO:LassoLars(random_state=123)
2022-11-14 20:17:12,589:INFO:create_model() successfully completed......................................
2022-11-14 20:17:12,802:INFO:SubProcess create_model() end ==================================
2022-11-14 20:17:12,804:INFO:Creating metrics dataframe
2022-11-14 20:17:12,837:INFO:Initializing Orthogonal Matching Pursuit
2022-11-14 20:17:12,838:INFO:Total runtime is 0.0893121600151062 minutes
2022-11-14 20:17:12,855:INFO:SubProcess create_model() called ==================================
2022-11-14 20:17:12,856:INFO:Initializing create_model()
2022-11-14 20:17:12,856:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232cf410>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2788a250>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:17:12,856:INFO:Checking exceptions
2022-11-14 20:17:12,859:INFO:Importing libraries
2022-11-14 20:17:12,863:INFO:Copying training dataset
2022-11-14 20:17:12,877:INFO:Defining folds
2022-11-14 20:17:12,880:INFO:Declaring metric variables
2022-11-14 20:17:12,894:INFO:Importing untrained model
2022-11-14 20:17:12,906:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-14 20:17:12,936:INFO:Starting cross validation
2022-11-14 20:17:12,939:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:17:13,007:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:17:13,068:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:17:13,172:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:17:13,232:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:17:13,311:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:17:13,374:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:17:13,443:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:17:13,476:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:17:13,516:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:17:13,562:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-14 20:17:13,584:INFO:Calculating mean and std
2022-11-14 20:17:13,587:INFO:Creating metrics dataframe
2022-11-14 20:17:13,596:INFO:Uploading results into container
2022-11-14 20:17:13,605:INFO:Uploading model into container now
2022-11-14 20:17:13,606:INFO:master_model_container: 7
2022-11-14 20:17:13,609:INFO:display_container: 2
2022-11-14 20:17:13,610:INFO:OrthogonalMatchingPursuit()
2022-11-14 20:17:13,613:INFO:create_model() successfully completed......................................
2022-11-14 20:17:13,830:INFO:SubProcess create_model() end ==================================
2022-11-14 20:17:13,831:INFO:Creating metrics dataframe
2022-11-14 20:17:13,862:INFO:Initializing Bayesian Ridge
2022-11-14 20:17:13,867:INFO:Total runtime is 0.10645845333735147 minutes
2022-11-14 20:17:13,877:INFO:SubProcess create_model() called ==================================
2022-11-14 20:17:13,880:INFO:Initializing create_model()
2022-11-14 20:17:13,880:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232cf410>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2788a250>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:17:13,881:INFO:Checking exceptions
2022-11-14 20:17:13,884:INFO:Importing libraries
2022-11-14 20:17:13,885:INFO:Copying training dataset
2022-11-14 20:17:13,900:INFO:Defining folds
2022-11-14 20:17:13,900:INFO:Declaring metric variables
2022-11-14 20:17:13,909:INFO:Importing untrained model
2022-11-14 20:17:13,918:INFO:Bayesian Ridge Imported successfully
2022-11-14 20:17:13,936:INFO:Starting cross validation
2022-11-14 20:17:13,938:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:17:14,510:INFO:Calculating mean and std
2022-11-14 20:17:14,513:INFO:Creating metrics dataframe
2022-11-14 20:17:14,535:INFO:Uploading results into container
2022-11-14 20:17:14,537:INFO:Uploading model into container now
2022-11-14 20:17:14,537:INFO:master_model_container: 8
2022-11-14 20:17:14,538:INFO:display_container: 2
2022-11-14 20:17:14,538:INFO:BayesianRidge()
2022-11-14 20:17:14,538:INFO:create_model() successfully completed......................................
2022-11-14 20:17:14,752:INFO:SubProcess create_model() end ==================================
2022-11-14 20:17:14,753:INFO:Creating metrics dataframe
2022-11-14 20:17:14,786:INFO:Initializing Passive Aggressive Regressor
2022-11-14 20:17:14,790:INFO:Total runtime is 0.12184712092081705 minutes
2022-11-14 20:17:14,805:INFO:SubProcess create_model() called ==================================
2022-11-14 20:17:14,809:INFO:Initializing create_model()
2022-11-14 20:17:14,809:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232cf410>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2788a250>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:17:14,809:INFO:Checking exceptions
2022-11-14 20:17:14,812:INFO:Importing libraries
2022-11-14 20:17:14,814:INFO:Copying training dataset
2022-11-14 20:17:14,826:INFO:Defining folds
2022-11-14 20:17:14,830:INFO:Declaring metric variables
2022-11-14 20:17:14,844:INFO:Importing untrained model
2022-11-14 20:17:14,858:INFO:Passive Aggressive Regressor Imported successfully
2022-11-14 20:17:14,888:INFO:Starting cross validation
2022-11-14 20:17:14,890:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:17:15,521:INFO:Calculating mean and std
2022-11-14 20:17:15,531:INFO:Creating metrics dataframe
2022-11-14 20:17:15,542:INFO:Uploading results into container
2022-11-14 20:17:15,543:INFO:Uploading model into container now
2022-11-14 20:17:15,543:INFO:master_model_container: 9
2022-11-14 20:17:15,544:INFO:display_container: 2
2022-11-14 20:17:15,544:INFO:PassiveAggressiveRegressor(random_state=123)
2022-11-14 20:17:15,545:INFO:create_model() successfully completed......................................
2022-11-14 20:17:15,771:INFO:SubProcess create_model() end ==================================
2022-11-14 20:17:15,771:INFO:Creating metrics dataframe
2022-11-14 20:17:15,805:INFO:Initializing Huber Regressor
2022-11-14 20:17:15,806:INFO:Total runtime is 0.1387778321901957 minutes
2022-11-14 20:17:15,819:INFO:SubProcess create_model() called ==================================
2022-11-14 20:17:15,820:INFO:Initializing create_model()
2022-11-14 20:17:15,820:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232cf410>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2788a250>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:17:15,821:INFO:Checking exceptions
2022-11-14 20:17:15,824:INFO:Importing libraries
2022-11-14 20:17:15,824:INFO:Copying training dataset
2022-11-14 20:17:15,837:INFO:Defining folds
2022-11-14 20:17:15,838:INFO:Declaring metric variables
2022-11-14 20:17:15,853:INFO:Importing untrained model
2022-11-14 20:17:15,867:INFO:Huber Regressor Imported successfully
2022-11-14 20:17:15,884:INFO:Starting cross validation
2022-11-14 20:17:15,886:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:17:16,894:INFO:Calculating mean and std
2022-11-14 20:17:16,898:INFO:Creating metrics dataframe
2022-11-14 20:17:16,910:INFO:Uploading results into container
2022-11-14 20:17:16,916:INFO:Uploading model into container now
2022-11-14 20:17:16,919:INFO:master_model_container: 10
2022-11-14 20:17:16,920:INFO:display_container: 2
2022-11-14 20:17:16,921:INFO:HuberRegressor()
2022-11-14 20:17:16,922:INFO:create_model() successfully completed......................................
2022-11-14 20:17:17,153:INFO:SubProcess create_model() end ==================================
2022-11-14 20:17:17,153:INFO:Creating metrics dataframe
2022-11-14 20:17:17,189:INFO:Initializing K Neighbors Regressor
2022-11-14 20:17:17,189:INFO:Total runtime is 0.16183344920476278 minutes
2022-11-14 20:17:17,199:INFO:SubProcess create_model() called ==================================
2022-11-14 20:17:17,200:INFO:Initializing create_model()
2022-11-14 20:17:17,200:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232cf410>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2788a250>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:17:17,200:INFO:Checking exceptions
2022-11-14 20:17:17,203:INFO:Importing libraries
2022-11-14 20:17:17,203:INFO:Copying training dataset
2022-11-14 20:17:17,214:INFO:Defining folds
2022-11-14 20:17:17,215:INFO:Declaring metric variables
2022-11-14 20:17:17,225:INFO:Importing untrained model
2022-11-14 20:17:17,237:INFO:K Neighbors Regressor Imported successfully
2022-11-14 20:17:17,261:INFO:Starting cross validation
2022-11-14 20:17:17,266:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:17:18,376:INFO:Calculating mean and std
2022-11-14 20:17:18,380:INFO:Creating metrics dataframe
2022-11-14 20:17:18,399:INFO:Uploading results into container
2022-11-14 20:17:18,400:INFO:Uploading model into container now
2022-11-14 20:17:18,403:INFO:master_model_container: 11
2022-11-14 20:17:18,406:INFO:display_container: 2
2022-11-14 20:17:18,408:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-14 20:17:18,408:INFO:create_model() successfully completed......................................
2022-11-14 20:17:18,630:INFO:SubProcess create_model() end ==================================
2022-11-14 20:17:18,631:INFO:Creating metrics dataframe
2022-11-14 20:17:18,667:INFO:Initializing Decision Tree Regressor
2022-11-14 20:17:18,668:INFO:Total runtime is 0.1864882787068685 minutes
2022-11-14 20:17:18,678:INFO:SubProcess create_model() called ==================================
2022-11-14 20:17:18,679:INFO:Initializing create_model()
2022-11-14 20:17:18,679:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232cf410>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2788a250>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:17:18,680:INFO:Checking exceptions
2022-11-14 20:17:18,683:INFO:Importing libraries
2022-11-14 20:17:18,684:INFO:Copying training dataset
2022-11-14 20:17:18,692:INFO:Defining folds
2022-11-14 20:17:18,692:INFO:Declaring metric variables
2022-11-14 20:17:18,710:INFO:Importing untrained model
2022-11-14 20:17:18,724:INFO:Decision Tree Regressor Imported successfully
2022-11-14 20:17:18,750:INFO:Starting cross validation
2022-11-14 20:17:18,757:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:17:19,439:INFO:Calculating mean and std
2022-11-14 20:17:19,445:INFO:Creating metrics dataframe
2022-11-14 20:17:19,462:INFO:Uploading results into container
2022-11-14 20:17:19,463:INFO:Uploading model into container now
2022-11-14 20:17:19,464:INFO:master_model_container: 12
2022-11-14 20:17:19,465:INFO:display_container: 2
2022-11-14 20:17:19,466:INFO:DecisionTreeRegressor(random_state=123)
2022-11-14 20:17:19,466:INFO:create_model() successfully completed......................................
2022-11-14 20:17:19,650:INFO:SubProcess create_model() end ==================================
2022-11-14 20:17:19,650:INFO:Creating metrics dataframe
2022-11-14 20:17:19,681:INFO:Initializing Random Forest Regressor
2022-11-14 20:17:19,682:INFO:Total runtime is 0.2033840854962667 minutes
2022-11-14 20:17:19,694:INFO:SubProcess create_model() called ==================================
2022-11-14 20:17:19,698:INFO:Initializing create_model()
2022-11-14 20:17:19,701:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232cf410>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2788a250>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:17:19,701:INFO:Checking exceptions
2022-11-14 20:17:19,703:INFO:Importing libraries
2022-11-14 20:17:19,704:INFO:Copying training dataset
2022-11-14 20:17:19,709:INFO:Defining folds
2022-11-14 20:17:19,711:INFO:Declaring metric variables
2022-11-14 20:17:19,721:INFO:Importing untrained model
2022-11-14 20:17:19,731:INFO:Random Forest Regressor Imported successfully
2022-11-14 20:17:19,752:INFO:Starting cross validation
2022-11-14 20:17:19,754:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:17:26,094:INFO:Calculating mean and std
2022-11-14 20:17:26,099:INFO:Creating metrics dataframe
2022-11-14 20:17:26,109:INFO:Uploading results into container
2022-11-14 20:17:26,110:INFO:Uploading model into container now
2022-11-14 20:17:26,111:INFO:master_model_container: 13
2022-11-14 20:17:26,112:INFO:display_container: 2
2022-11-14 20:17:26,113:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-14 20:17:26,113:INFO:create_model() successfully completed......................................
2022-11-14 20:17:26,288:INFO:SubProcess create_model() end ==================================
2022-11-14 20:17:26,291:INFO:Creating metrics dataframe
2022-11-14 20:17:26,315:INFO:Initializing Extra Trees Regressor
2022-11-14 20:17:26,315:INFO:Total runtime is 0.3139362096786499 minutes
2022-11-14 20:17:26,326:INFO:SubProcess create_model() called ==================================
2022-11-14 20:17:26,327:INFO:Initializing create_model()
2022-11-14 20:17:26,328:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232cf410>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2788a250>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:17:26,329:INFO:Checking exceptions
2022-11-14 20:17:26,333:INFO:Importing libraries
2022-11-14 20:17:26,333:INFO:Copying training dataset
2022-11-14 20:17:26,340:INFO:Defining folds
2022-11-14 20:17:26,343:INFO:Declaring metric variables
2022-11-14 20:17:26,353:INFO:Importing untrained model
2022-11-14 20:17:26,364:INFO:Extra Trees Regressor Imported successfully
2022-11-14 20:17:26,382:INFO:Starting cross validation
2022-11-14 20:17:26,385:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:17:29,924:INFO:Calculating mean and std
2022-11-14 20:17:29,930:INFO:Creating metrics dataframe
2022-11-14 20:17:29,947:INFO:Uploading results into container
2022-11-14 20:17:29,948:INFO:Uploading model into container now
2022-11-14 20:17:29,948:INFO:master_model_container: 14
2022-11-14 20:17:29,948:INFO:display_container: 2
2022-11-14 20:17:29,949:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-14 20:17:29,949:INFO:create_model() successfully completed......................................
2022-11-14 20:17:30,120:INFO:SubProcess create_model() end ==================================
2022-11-14 20:17:30,120:INFO:Creating metrics dataframe
2022-11-14 20:17:30,143:INFO:Initializing AdaBoost Regressor
2022-11-14 20:17:30,144:INFO:Total runtime is 0.377755331993103 minutes
2022-11-14 20:17:30,158:INFO:SubProcess create_model() called ==================================
2022-11-14 20:17:30,159:INFO:Initializing create_model()
2022-11-14 20:17:30,159:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232cf410>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2788a250>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:17:30,159:INFO:Checking exceptions
2022-11-14 20:17:30,162:INFO:Importing libraries
2022-11-14 20:17:30,162:INFO:Copying training dataset
2022-11-14 20:17:30,171:INFO:Defining folds
2022-11-14 20:17:30,174:INFO:Declaring metric variables
2022-11-14 20:17:30,183:INFO:Importing untrained model
2022-11-14 20:17:30,196:INFO:AdaBoost Regressor Imported successfully
2022-11-14 20:17:30,217:INFO:Starting cross validation
2022-11-14 20:17:30,220:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:17:31,566:INFO:Calculating mean and std
2022-11-14 20:17:31,570:INFO:Creating metrics dataframe
2022-11-14 20:17:31,579:INFO:Uploading results into container
2022-11-14 20:17:31,580:INFO:Uploading model into container now
2022-11-14 20:17:31,581:INFO:master_model_container: 15
2022-11-14 20:17:31,581:INFO:display_container: 2
2022-11-14 20:17:31,582:INFO:AdaBoostRegressor(random_state=123)
2022-11-14 20:17:31,582:INFO:create_model() successfully completed......................................
2022-11-14 20:17:31,760:INFO:SubProcess create_model() end ==================================
2022-11-14 20:17:31,761:INFO:Creating metrics dataframe
2022-11-14 20:17:31,790:INFO:Initializing Gradient Boosting Regressor
2022-11-14 20:17:31,790:INFO:Total runtime is 0.40519022146860756 minutes
2022-11-14 20:17:31,800:INFO:SubProcess create_model() called ==================================
2022-11-14 20:17:31,802:INFO:Initializing create_model()
2022-11-14 20:17:31,806:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232cf410>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2788a250>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:17:31,806:INFO:Checking exceptions
2022-11-14 20:17:31,808:INFO:Importing libraries
2022-11-14 20:17:31,809:INFO:Copying training dataset
2022-11-14 20:17:31,817:INFO:Defining folds
2022-11-14 20:17:31,823:INFO:Declaring metric variables
2022-11-14 20:17:31,836:INFO:Importing untrained model
2022-11-14 20:17:31,846:INFO:Gradient Boosting Regressor Imported successfully
2022-11-14 20:17:31,866:INFO:Starting cross validation
2022-11-14 20:17:31,868:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:17:34,350:INFO:Calculating mean and std
2022-11-14 20:17:34,353:INFO:Creating metrics dataframe
2022-11-14 20:17:34,362:INFO:Uploading results into container
2022-11-14 20:17:34,363:INFO:Uploading model into container now
2022-11-14 20:17:34,364:INFO:master_model_container: 16
2022-11-14 20:17:34,364:INFO:display_container: 2
2022-11-14 20:17:34,365:INFO:GradientBoostingRegressor(random_state=123)
2022-11-14 20:17:34,365:INFO:create_model() successfully completed......................................
2022-11-14 20:17:34,535:INFO:SubProcess create_model() end ==================================
2022-11-14 20:17:34,536:INFO:Creating metrics dataframe
2022-11-14 20:17:34,569:INFO:Initializing Light Gradient Boosting Machine
2022-11-14 20:17:34,571:INFO:Total runtime is 0.4515300313631693 minutes
2022-11-14 20:17:34,581:INFO:SubProcess create_model() called ==================================
2022-11-14 20:17:34,582:INFO:Initializing create_model()
2022-11-14 20:17:34,583:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232cf410>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2788a250>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:17:34,583:INFO:Checking exceptions
2022-11-14 20:17:34,586:INFO:Importing libraries
2022-11-14 20:17:34,586:INFO:Copying training dataset
2022-11-14 20:17:34,595:INFO:Defining folds
2022-11-14 20:17:34,596:INFO:Declaring metric variables
2022-11-14 20:17:34,607:INFO:Importing untrained model
2022-11-14 20:17:34,618:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-14 20:17:34,638:INFO:Starting cross validation
2022-11-14 20:17:34,640:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:17:35,990:INFO:Calculating mean and std
2022-11-14 20:17:35,993:INFO:Creating metrics dataframe
2022-11-14 20:17:36,014:INFO:Uploading results into container
2022-11-14 20:17:36,018:INFO:Uploading model into container now
2022-11-14 20:17:36,020:INFO:master_model_container: 17
2022-11-14 20:17:36,022:INFO:display_container: 2
2022-11-14 20:17:36,023:INFO:LGBMRegressor(random_state=123)
2022-11-14 20:17:36,023:INFO:create_model() successfully completed......................................
2022-11-14 20:17:36,188:INFO:SubProcess create_model() end ==================================
2022-11-14 20:17:36,188:INFO:Creating metrics dataframe
2022-11-14 20:17:36,212:INFO:Initializing Dummy Regressor
2022-11-14 20:17:36,213:INFO:Total runtime is 0.4788923343022664 minutes
2022-11-14 20:17:36,223:INFO:SubProcess create_model() called ==================================
2022-11-14 20:17:36,224:INFO:Initializing create_model()
2022-11-14 20:17:36,224:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232cf410>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f3d2788a250>, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:17:36,224:INFO:Checking exceptions
2022-11-14 20:17:36,227:INFO:Importing libraries
2022-11-14 20:17:36,228:INFO:Copying training dataset
2022-11-14 20:17:36,237:INFO:Defining folds
2022-11-14 20:17:36,237:INFO:Declaring metric variables
2022-11-14 20:17:36,250:INFO:Importing untrained model
2022-11-14 20:17:36,262:INFO:Dummy Regressor Imported successfully
2022-11-14 20:17:36,286:INFO:Starting cross validation
2022-11-14 20:17:36,288:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-14 20:17:36,575:INFO:Calculating mean and std
2022-11-14 20:17:36,577:INFO:Creating metrics dataframe
2022-11-14 20:17:36,587:INFO:Uploading results into container
2022-11-14 20:17:36,593:INFO:Uploading model into container now
2022-11-14 20:17:36,596:INFO:master_model_container: 18
2022-11-14 20:17:36,597:INFO:display_container: 2
2022-11-14 20:17:36,597:INFO:DummyRegressor()
2022-11-14 20:17:36,597:INFO:create_model() successfully completed......................................
2022-11-14 20:17:36,760:INFO:SubProcess create_model() end ==================================
2022-11-14 20:17:36,760:INFO:Creating metrics dataframe
2022-11-14 20:17:36,815:INFO:Initializing create_model()
2022-11-14 20:17:36,815:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f3d232cf410>, estimator=LassoLars(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-14 20:17:36,815:INFO:Checking exceptions
2022-11-14 20:17:36,822:INFO:Importing libraries
2022-11-14 20:17:36,823:INFO:Copying training dataset
2022-11-14 20:17:36,828:INFO:Defining folds
2022-11-14 20:17:36,829:INFO:Declaring metric variables
2022-11-14 20:17:36,829:INFO:Importing untrained model
2022-11-14 20:17:36,830:INFO:Declaring custom model
2022-11-14 20:17:36,831:INFO:Least Angle Regression Imported successfully
2022-11-14 20:17:36,834:INFO:Cross validation set to False
2022-11-14 20:17:36,834:INFO:Fitting Model
2022-11-14 20:17:36,869:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-14 20:17:36,871:INFO:LassoLars(random_state=123)
2022-11-14 20:17:36,872:INFO:create_model() successfully completed......................................
2022-11-14 20:17:37,159:INFO:master_model_container: 18
2022-11-14 20:17:37,159:INFO:display_container: 2
2022-11-14 20:17:37,160:INFO:LassoLars(random_state=123)
2022-11-14 20:17:37,160:INFO:compare_models() successfully completed......................................
2022-11-16 19:44:06,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-16 19:44:07,153:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-16 19:44:07,153:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-16 19:44:07,153:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-16 19:44:09,492:INFO:Soft dependency imported: prophet: 1.1.1
2022-11-16 19:44:10,373:INFO:PyCaret RegressionExperiment
2022-11-16 19:44:10,374:INFO:Logging name: FullData
2022-11-16 19:44:10,374:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-16 19:44:10,375:INFO:version 3.0.0.rc4
2022-11-16 19:44:10,375:INFO:Initializing setup()
2022-11-16 19:44:10,375:INFO:self.USI: 05fc
2022-11-16 19:44:10,375:INFO:self.variable_keys: {'display_container', '_ml_usecase', 'y_train', 'X_train', 'y_test', '_all_metrics', 'pipeline', 'transform_target_param', '_all_models_internal', '_gpu_n_jobs_param', 'logging_param', 'log_plots_param', '_all_models', 'memory', 'target_param', 'data', 'gpu_param', 'X', 'fold_shuffle_param', 'X_test', 'html_param', 'master_model_container', 'n_jobs_param', 'fold_groups_param', 'y', 'exp_id', 'exp_name_log', '_available_plots', 'variable_keys', 'seed', 'fold_generator', 'USI', 'idx', 'transform_target_method_param'}
2022-11-16 19:44:10,375:INFO:Checking environment
2022-11-16 19:44:10,375:INFO:python_version: 3.7.15
2022-11-16 19:44:10,376:INFO:python_build: ('default', 'Oct 12 2022 19:14:55')
2022-11-16 19:44:10,376:INFO:machine: x86_64
2022-11-16 19:44:10,376:INFO:platform: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-16 19:44:10,376:INFO:Memory: svmem(total=13616361472, available=12090855424, percent=11.2, used=1288605696, free=6892187648, active=801361920, inactive=5539786752, buffers=165036032, cached=5270532096, shared=1302528, slab=285859840)
2022-11-16 19:44:10,377:INFO:Physical Core: 1
2022-11-16 19:44:10,377:INFO:Logical Core: 2
2022-11-16 19:44:10,377:INFO:Checking libraries
2022-11-16 19:44:10,377:INFO:System:
2022-11-16 19:44:10,379:INFO:    python: 3.7.15 (default, Oct 12 2022, 19:14:55)  [GCC 7.5.0]
2022-11-16 19:44:10,379:INFO:executable: /usr/bin/python3
2022-11-16 19:44:10,379:INFO:   machine: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-16 19:44:10,379:INFO:PyCaret required dependencies:
2022-11-16 19:44:10,379:INFO:                 pip: 21.1.3
2022-11-16 19:44:10,380:INFO:          setuptools: 57.4.0
2022-11-16 19:44:10,380:INFO:             pycaret: 3.0.0rc4
2022-11-16 19:44:10,380:INFO:             IPython: 7.9.0
2022-11-16 19:44:10,380:INFO:          ipywidgets: 7.7.1
2022-11-16 19:44:10,380:INFO:                tqdm: 4.64.1
2022-11-16 19:44:10,380:INFO:               numpy: 1.21.6
2022-11-16 19:44:10,380:INFO:              pandas: 1.3.5
2022-11-16 19:44:10,380:INFO:              jinja2: 3.0.0
2022-11-16 19:44:10,381:INFO:               scipy: 1.7.3
2022-11-16 19:44:10,381:INFO:              joblib: 1.2.0
2022-11-16 19:44:10,381:INFO:             sklearn: 1.0.2
2022-11-16 19:44:10,381:INFO:                pyod: 1.0.6
2022-11-16 19:44:10,381:INFO:            imblearn: 0.8.1
2022-11-16 19:44:10,381:INFO:   category_encoders: 2.5.1.post0
2022-11-16 19:44:10,381:INFO:            lightgbm: 3.3.3
2022-11-16 19:44:10,381:INFO:               numba: 0.55.2
2022-11-16 19:44:10,381:INFO:            requests: 2.28.1
2022-11-16 19:44:10,382:INFO:          matplotlib: 3.5.3
2022-11-16 19:44:10,382:INFO:          scikitplot: 0.3.7
2022-11-16 19:44:10,382:INFO:         yellowbrick: 1.5
2022-11-16 19:44:10,382:INFO:              plotly: 5.5.0
2022-11-16 19:44:10,382:INFO:             kaleido: 0.2.1
2022-11-16 19:44:10,382:INFO:         statsmodels: 0.12.2
2022-11-16 19:44:10,382:INFO:              sktime: 0.13.4
2022-11-16 19:44:10,382:INFO:               tbats: 1.1.1
2022-11-16 19:44:10,383:INFO:            pmdarima: 1.8.5
2022-11-16 19:44:10,383:INFO:              psutil: 5.9.4
2022-11-16 19:44:10,383:INFO:PyCaret optional dependencies:
2022-11-16 19:44:10,460:INFO:                shap: Not installed
2022-11-16 19:44:10,460:INFO:           interpret: Not installed
2022-11-16 19:44:10,464:INFO:                umap: Not installed
2022-11-16 19:44:10,465:INFO:    pandas_profiling: 1.4.1
2022-11-16 19:44:10,465:INFO:  explainerdashboard: Not installed
2022-11-16 19:44:10,465:INFO:             autoviz: Not installed
2022-11-16 19:44:10,465:INFO:           fairlearn: Not installed
2022-11-16 19:44:10,465:INFO:             xgboost: 0.90
2022-11-16 19:44:10,466:INFO:            catboost: Not installed
2022-11-16 19:44:10,466:INFO:              kmodes: Not installed
2022-11-16 19:44:10,466:INFO:             mlxtend: 0.14.0
2022-11-16 19:44:10,469:INFO:       statsforecast: Not installed
2022-11-16 19:44:10,470:INFO:        tune_sklearn: Not installed
2022-11-16 19:44:10,470:INFO:                 ray: Not installed
2022-11-16 19:44:10,470:INFO:            hyperopt: 0.1.2
2022-11-16 19:44:10,470:INFO:              optuna: Not installed
2022-11-16 19:44:10,470:INFO:               skopt: Not installed
2022-11-16 19:44:10,470:INFO:              mlflow: Not installed
2022-11-16 19:44:10,471:INFO:              gradio: Not installed
2022-11-16 19:44:10,471:INFO:             fastapi: Not installed
2022-11-16 19:44:10,471:INFO:             uvicorn: Not installed
2022-11-16 19:44:10,471:INFO:              m2cgen: Not installed
2022-11-16 19:44:10,471:INFO:           evidently: Not installed
2022-11-16 19:44:10,471:INFO:                nltk: 3.7
2022-11-16 19:44:10,471:INFO:            pyLDAvis: Not installed
2022-11-16 19:44:10,472:INFO:              gensim: 3.6.0
2022-11-16 19:44:10,472:INFO:               spacy: 3.4.2
2022-11-16 19:44:10,472:INFO:           wordcloud: 1.8.2.2
2022-11-16 19:44:10,475:INFO:            textblob: 0.15.3
2022-11-16 19:44:10,476:INFO:               fugue: Not installed
2022-11-16 19:44:10,476:INFO:           streamlit: Not installed
2022-11-16 19:44:10,476:INFO:             prophet: 1.1.1
2022-11-16 19:44:10,476:INFO:None
2022-11-16 19:44:10,476:INFO:Set up data.
2022-11-16 19:44:10,527:INFO:Set up train/test split.
2022-11-16 19:44:10,552:INFO:Set up index.
2022-11-16 19:44:10,565:INFO:Set up folding strategy.
2022-11-16 19:44:10,565:INFO:Assigning column types.
2022-11-16 19:44:10,609:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-16 19:44:10,609:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-16 19:44:10,626:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-16 19:44:10,652:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:44:10,887:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:44:11,048:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:44:11,050:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:11,050:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:11,361:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:11,362:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-16 19:44:11,373:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-16 19:44:11,384:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:44:11,593:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:44:11,727:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:44:11,734:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:11,737:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:11,738:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:11,738:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-16 19:44:11,769:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-16 19:44:11,793:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:44:12,000:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:44:12,162:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:44:12,167:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:12,167:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:12,168:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:12,180:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-16 19:44:12,191:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:44:12,310:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:44:12,421:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:44:12,423:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:12,423:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:12,424:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:12,424:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-16 19:44:12,467:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:44:12,643:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:44:12,760:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:44:12,768:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:12,768:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:12,769:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:12,805:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:44:13,008:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:44:13,115:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:44:13,116:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:13,116:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:13,117:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:13,118:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-16 19:44:13,367:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:44:13,616:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:44:13,622:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:13,623:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:13,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:13,839:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:44:13,943:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:44:13,945:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:13,945:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:13,946:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:13,946:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-16 19:44:14,135:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:44:14,321:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:14,321:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:14,322:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:14,478:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:44:14,572:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:14,573:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:14,574:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:14,575:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-16 19:44:14,864:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:14,864:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:14,865:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:15,516:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:15,516:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:15,517:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:15,519:INFO:Preparing preprocessing pipeline...
2022-11-16 19:44:15,521:INFO:Set up simple imputation.
2022-11-16 19:44:15,521:INFO:Set up variance threshold.
2022-11-16 19:44:15,606:INFO:Finished creating preprocessing pipeline.
2022-11-16 19:44:15,638:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-16 19:44:15,646:INFO:Creating final display dataframe.
2022-11-16 19:44:16,108:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 12)
4         Train data shape    (607, 12)
5          Test data shape    (261, 12)
6         Numeric features           11
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         05fc
2022-11-16 19:44:16,470:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:16,471:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:16,472:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:16,770:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:16,771:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:16,771:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:16,783:INFO:setup() successfully completed in 6.42s...............
2022-11-16 19:44:16,784:INFO:Initializing compare_models()
2022-11-16 19:44:16,784:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a41446fd0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f2a41446fd0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-16 19:44:16,784:INFO:Checking exceptions
2022-11-16 19:44:16,788:INFO:Preparing display monitor
2022-11-16 19:44:16,955:INFO:Initializing Linear Regression
2022-11-16 19:44:16,955:INFO:Total runtime is 6.3498814900716145e-06 minutes
2022-11-16 19:44:16,967:INFO:SubProcess create_model() called ==================================
2022-11-16 19:44:16,968:INFO:Initializing create_model()
2022-11-16 19:44:16,968:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a41446fd0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2ae754d0>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:44:16,968:INFO:Checking exceptions
2022-11-16 19:44:16,975:INFO:Importing libraries
2022-11-16 19:44:16,975:INFO:Copying training dataset
2022-11-16 19:44:16,979:INFO:Defining folds
2022-11-16 19:44:16,979:INFO:Declaring metric variables
2022-11-16 19:44:16,987:INFO:Importing untrained model
2022-11-16 19:44:16,999:INFO:Linear Regression Imported successfully
2022-11-16 19:44:17,032:INFO:Starting cross validation
2022-11-16 19:44:17,045:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:44:54,660:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  app.launch_new_instance()

2022-11-16 19:44:54,661:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:44:54,663:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:44:54,664:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:44:54,665:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:44:54,666:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:44:54,667:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:44:54,668:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:44:54,669:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:44:54,670:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:44:54,671:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:44:54,676:INFO:PyCaret RegressionExperiment
2022-11-16 19:44:54,677:INFO:Logging name: FullData
2022-11-16 19:44:54,677:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-16 19:44:54,677:INFO:version 3.0.0.rc4
2022-11-16 19:44:54,677:INFO:Initializing setup()
2022-11-16 19:44:54,677:INFO:self.USI: 15e6
2022-11-16 19:44:54,678:INFO:self.variable_keys: {'display_container', '_ml_usecase', 'y_train', 'X_train', 'y_test', '_all_metrics', 'pipeline', 'transform_target_param', '_all_models_internal', '_gpu_n_jobs_param', 'logging_param', 'log_plots_param', '_all_models', 'memory', 'target_param', 'data', 'gpu_param', 'X', 'fold_shuffle_param', 'X_test', 'html_param', 'master_model_container', 'n_jobs_param', 'fold_groups_param', 'y', 'exp_id', 'exp_name_log', '_available_plots', 'variable_keys', 'seed', 'fold_generator', 'USI', 'idx', 'transform_target_method_param'}
2022-11-16 19:44:54,678:INFO:Checking environment
2022-11-16 19:44:54,678:INFO:python_version: 3.7.15
2022-11-16 19:44:54,678:INFO:python_build: ('default', 'Oct 12 2022 19:14:55')
2022-11-16 19:44:54,678:INFO:machine: x86_64
2022-11-16 19:44:54,678:INFO:platform: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-16 19:44:54,679:INFO:Memory: svmem(total=13616361472, available=11782254592, percent=13.5, used=1626603520, free=6494302208, active=859918336, inactive=5873115136, buffers=165462016, cached=5329993728, shared=1331200, slab=289452032)
2022-11-16 19:44:54,679:INFO:Physical Core: 1
2022-11-16 19:44:54,679:INFO:Logical Core: 2
2022-11-16 19:44:54,679:INFO:Checking libraries
2022-11-16 19:44:54,679:INFO:System:
2022-11-16 19:44:54,680:INFO:    python: 3.7.15 (default, Oct 12 2022, 19:14:55)  [GCC 7.5.0]
2022-11-16 19:44:54,680:INFO:executable: /usr/bin/python3
2022-11-16 19:44:54,680:INFO:   machine: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-16 19:44:54,680:INFO:PyCaret required dependencies:
2022-11-16 19:44:54,680:INFO:                 pip: 21.1.3
2022-11-16 19:44:54,680:INFO:          setuptools: 57.4.0
2022-11-16 19:44:54,681:INFO:             pycaret: 3.0.0rc4
2022-11-16 19:44:54,681:INFO:             IPython: 7.9.0
2022-11-16 19:44:54,681:INFO:          ipywidgets: 7.7.1
2022-11-16 19:44:54,681:INFO:                tqdm: 4.64.1
2022-11-16 19:44:54,681:INFO:               numpy: 1.21.6
2022-11-16 19:44:54,681:INFO:              pandas: 1.3.5
2022-11-16 19:44:54,681:INFO:              jinja2: 3.0.0
2022-11-16 19:44:54,682:INFO:               scipy: 1.7.3
2022-11-16 19:44:54,682:INFO:              joblib: 1.2.0
2022-11-16 19:44:54,682:INFO:             sklearn: 1.0.2
2022-11-16 19:44:54,682:INFO:                pyod: 1.0.6
2022-11-16 19:44:54,682:INFO:            imblearn: 0.8.1
2022-11-16 19:44:54,682:INFO:   category_encoders: 2.5.1.post0
2022-11-16 19:44:54,682:INFO:            lightgbm: 3.3.3
2022-11-16 19:44:54,683:INFO:               numba: 0.55.2
2022-11-16 19:44:54,683:INFO:            requests: 2.28.1
2022-11-16 19:44:54,683:INFO:          matplotlib: 3.5.3
2022-11-16 19:44:54,683:INFO:          scikitplot: 0.3.7
2022-11-16 19:44:54,683:INFO:         yellowbrick: 1.5
2022-11-16 19:44:54,683:INFO:              plotly: 5.5.0
2022-11-16 19:44:54,683:INFO:             kaleido: 0.2.1
2022-11-16 19:44:54,683:INFO:         statsmodels: 0.12.2
2022-11-16 19:44:54,684:INFO:              sktime: 0.13.4
2022-11-16 19:44:54,684:INFO:               tbats: 1.1.1
2022-11-16 19:44:54,684:INFO:            pmdarima: 1.8.5
2022-11-16 19:44:54,684:INFO:              psutil: 5.9.4
2022-11-16 19:44:54,684:INFO:PyCaret optional dependencies:
2022-11-16 19:44:54,684:INFO:                shap: Not installed
2022-11-16 19:44:54,685:INFO:           interpret: Not installed
2022-11-16 19:44:54,685:INFO:                umap: Not installed
2022-11-16 19:44:54,685:INFO:    pandas_profiling: 1.4.1
2022-11-16 19:44:54,685:INFO:  explainerdashboard: Not installed
2022-11-16 19:44:54,685:INFO:             autoviz: Not installed
2022-11-16 19:44:54,685:INFO:           fairlearn: Not installed
2022-11-16 19:44:54,685:INFO:             xgboost: 0.90
2022-11-16 19:44:54,685:INFO:            catboost: Not installed
2022-11-16 19:44:54,686:INFO:              kmodes: Not installed
2022-11-16 19:44:54,686:INFO:             mlxtend: 0.14.0
2022-11-16 19:44:54,686:INFO:       statsforecast: Not installed
2022-11-16 19:44:54,686:INFO:        tune_sklearn: Not installed
2022-11-16 19:44:54,686:INFO:                 ray: Not installed
2022-11-16 19:44:54,687:INFO:            hyperopt: 0.1.2
2022-11-16 19:44:54,687:INFO:              optuna: Not installed
2022-11-16 19:44:54,687:INFO:               skopt: Not installed
2022-11-16 19:44:54,687:INFO:              mlflow: Not installed
2022-11-16 19:44:54,687:INFO:              gradio: Not installed
2022-11-16 19:44:54,688:INFO:             fastapi: Not installed
2022-11-16 19:44:54,688:INFO:             uvicorn: Not installed
2022-11-16 19:44:54,688:INFO:              m2cgen: Not installed
2022-11-16 19:44:54,688:INFO:           evidently: Not installed
2022-11-16 19:44:54,688:INFO:                nltk: 3.7
2022-11-16 19:44:54,688:INFO:            pyLDAvis: Not installed
2022-11-16 19:44:54,688:INFO:              gensim: 3.6.0
2022-11-16 19:44:54,689:INFO:               spacy: 3.4.2
2022-11-16 19:44:54,689:INFO:           wordcloud: 1.8.2.2
2022-11-16 19:44:54,689:INFO:            textblob: 0.15.3
2022-11-16 19:44:54,689:INFO:               fugue: Not installed
2022-11-16 19:44:54,689:INFO:           streamlit: Not installed
2022-11-16 19:44:54,689:INFO:             prophet: 1.1.1
2022-11-16 19:44:54,689:INFO:None
2022-11-16 19:44:54,690:INFO:Set up data.
2022-11-16 19:44:54,697:INFO:Set up train/test split.
2022-11-16 19:44:54,701:INFO:Set up index.
2022-11-16 19:44:54,702:INFO:Set up folding strategy.
2022-11-16 19:44:54,702:INFO:Assigning column types.
2022-11-16 19:44:54,708:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-16 19:44:54,709:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-16 19:44:54,714:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-16 19:44:54,720:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:44:54,785:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:44:54,837:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:44:54,838:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:54,838:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:54,838:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:54,839:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-16 19:44:54,844:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-16 19:44:54,851:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:44:54,919:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:44:54,971:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:44:54,972:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:54,972:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:54,973:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:54,973:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-16 19:44:54,979:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-16 19:44:54,984:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:44:55,052:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:44:55,102:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:44:55,103:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:55,103:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:55,104:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:55,109:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-16 19:44:55,115:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:44:55,185:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:44:55,245:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:44:55,246:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:55,246:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:55,247:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:55,247:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-16 19:44:55,258:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:44:55,323:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:44:55,373:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:44:55,375:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:55,375:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:55,375:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:55,386:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:44:55,450:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:44:55,513:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:44:55,516:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:55,516:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:55,517:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:55,517:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-16 19:44:55,595:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:44:55,654:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:44:55,656:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:55,656:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:55,656:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:55,733:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:44:55,784:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:44:55,785:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:55,785:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:55,786:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:55,787:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-16 19:44:55,863:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:44:55,916:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:55,917:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:55,918:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:55,995:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:44:56,048:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:56,048:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:56,048:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:56,049:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-16 19:44:56,176:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:56,176:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:56,176:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:56,304:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:56,304:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:56,304:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:56,305:INFO:Preparing preprocessing pipeline...
2022-11-16 19:44:56,306:INFO:Set up simple imputation.
2022-11-16 19:44:56,307:INFO:Set up variance threshold.
2022-11-16 19:44:56,319:INFO:Finished creating preprocessing pipeline.
2022-11-16 19:44:56,325:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-16 19:44:56,325:INFO:Creating final display dataframe.
2022-11-16 19:44:56,404:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 12)
4         Train data shape    (607, 12)
5          Test data shape    (261, 12)
6         Numeric features           11
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         15e6
2022-11-16 19:44:56,576:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:56,577:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:56,577:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:56,710:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:44:56,710:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:44:56,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:44:56,719:INFO:setup() successfully completed in 2.05s...............
2022-11-16 19:44:56,719:INFO:Initializing compare_models()
2022-11-16 19:44:56,720:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a60adfa10>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f2a60adfa10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-16 19:44:56,720:INFO:Checking exceptions
2022-11-16 19:44:56,722:INFO:Preparing display monitor
2022-11-16 19:44:56,811:INFO:Initializing Linear Regression
2022-11-16 19:44:56,811:INFO:Total runtime is 6.258487701416016e-06 minutes
2022-11-16 19:44:56,820:INFO:SubProcess create_model() called ==================================
2022-11-16 19:44:56,821:INFO:Initializing create_model()
2022-11-16 19:44:56,821:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a60adfa10>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a293f2190>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:44:56,821:INFO:Checking exceptions
2022-11-16 19:44:56,824:INFO:Importing libraries
2022-11-16 19:44:56,824:INFO:Copying training dataset
2022-11-16 19:44:56,828:INFO:Defining folds
2022-11-16 19:44:56,828:INFO:Declaring metric variables
2022-11-16 19:44:56,837:INFO:Importing untrained model
2022-11-16 19:44:56,845:INFO:Linear Regression Imported successfully
2022-11-16 19:44:56,863:INFO:Starting cross validation
2022-11-16 19:44:56,868:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:01,544:INFO:Calculating mean and std
2022-11-16 19:45:01,552:INFO:Creating metrics dataframe
2022-11-16 19:45:01,563:INFO:Uploading results into container
2022-11-16 19:45:01,564:INFO:Uploading model into container now
2022-11-16 19:45:01,565:INFO:master_model_container: 1
2022-11-16 19:45:01,565:INFO:display_container: 2
2022-11-16 19:45:01,565:INFO:LinearRegression(n_jobs=-1)
2022-11-16 19:45:01,565:INFO:create_model() successfully completed......................................
2022-11-16 19:45:01,757:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:01,758:INFO:Creating metrics dataframe
2022-11-16 19:45:01,775:INFO:Initializing Lasso Regression
2022-11-16 19:45:01,776:INFO:Total runtime is 0.08275893529256186 minutes
2022-11-16 19:45:01,785:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:01,786:INFO:Initializing create_model()
2022-11-16 19:45:01,786:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a60adfa10>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a293f2190>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:01,787:INFO:Checking exceptions
2022-11-16 19:45:01,789:INFO:Importing libraries
2022-11-16 19:45:01,790:INFO:Copying training dataset
2022-11-16 19:45:01,797:INFO:Defining folds
2022-11-16 19:45:01,798:INFO:Declaring metric variables
2022-11-16 19:45:01,808:INFO:Importing untrained model
2022-11-16 19:45:01,818:INFO:Lasso Regression Imported successfully
2022-11-16 19:45:01,837:INFO:Starting cross validation
2022-11-16 19:45:01,839:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:02,161:INFO:Calculating mean and std
2022-11-16 19:45:02,164:INFO:Creating metrics dataframe
2022-11-16 19:45:02,176:INFO:Uploading results into container
2022-11-16 19:45:02,178:INFO:Uploading model into container now
2022-11-16 19:45:02,179:INFO:master_model_container: 2
2022-11-16 19:45:02,179:INFO:display_container: 2
2022-11-16 19:45:02,181:INFO:Lasso(random_state=123)
2022-11-16 19:45:02,181:INFO:create_model() successfully completed......................................
2022-11-16 19:45:02,315:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:02,315:INFO:Creating metrics dataframe
2022-11-16 19:45:02,334:INFO:Initializing Ridge Regression
2022-11-16 19:45:02,335:INFO:Total runtime is 0.09206666151682537 minutes
2022-11-16 19:45:02,344:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:02,347:INFO:Initializing create_model()
2022-11-16 19:45:02,348:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a60adfa10>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a293f2190>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:02,348:INFO:Checking exceptions
2022-11-16 19:45:02,351:INFO:Importing libraries
2022-11-16 19:45:02,351:INFO:Copying training dataset
2022-11-16 19:45:02,358:INFO:Defining folds
2022-11-16 19:45:02,360:INFO:Declaring metric variables
2022-11-16 19:45:02,369:INFO:Importing untrained model
2022-11-16 19:45:02,378:INFO:Ridge Regression Imported successfully
2022-11-16 19:45:02,394:INFO:Starting cross validation
2022-11-16 19:45:02,399:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:02,799:INFO:Calculating mean and std
2022-11-16 19:45:02,806:INFO:Creating metrics dataframe
2022-11-16 19:45:02,814:INFO:Uploading results into container
2022-11-16 19:45:02,816:INFO:Uploading model into container now
2022-11-16 19:45:02,816:INFO:master_model_container: 3
2022-11-16 19:45:02,816:INFO:display_container: 2
2022-11-16 19:45:02,817:INFO:Ridge(random_state=123)
2022-11-16 19:45:02,817:INFO:create_model() successfully completed......................................
2022-11-16 19:45:02,988:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:02,991:INFO:Creating metrics dataframe
2022-11-16 19:45:03,021:INFO:Initializing Elastic Net
2022-11-16 19:45:03,025:INFO:Total runtime is 0.10356762409210206 minutes
2022-11-16 19:45:03,036:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:03,043:INFO:Initializing create_model()
2022-11-16 19:45:03,043:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a60adfa10>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a293f2190>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:03,043:INFO:Checking exceptions
2022-11-16 19:45:03,046:INFO:Importing libraries
2022-11-16 19:45:03,048:INFO:Copying training dataset
2022-11-16 19:45:03,060:INFO:Defining folds
2022-11-16 19:45:03,062:INFO:Declaring metric variables
2022-11-16 19:45:03,074:INFO:Importing untrained model
2022-11-16 19:45:03,089:INFO:Elastic Net Imported successfully
2022-11-16 19:45:03,111:INFO:Starting cross validation
2022-11-16 19:45:03,113:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:03,764:INFO:Calculating mean and std
2022-11-16 19:45:03,767:INFO:Creating metrics dataframe
2022-11-16 19:45:03,781:INFO:Uploading results into container
2022-11-16 19:45:03,784:INFO:Uploading model into container now
2022-11-16 19:45:03,785:INFO:master_model_container: 4
2022-11-16 19:45:03,785:INFO:display_container: 2
2022-11-16 19:45:03,786:INFO:ElasticNet(random_state=123)
2022-11-16 19:45:03,786:INFO:create_model() successfully completed......................................
2022-11-16 19:45:03,959:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:03,960:INFO:Creating metrics dataframe
2022-11-16 19:45:03,989:INFO:Initializing Least Angle Regression
2022-11-16 19:45:03,993:INFO:Total runtime is 0.11969932715098064 minutes
2022-11-16 19:45:04,007:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:04,011:INFO:Initializing create_model()
2022-11-16 19:45:04,011:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a60adfa10>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a293f2190>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:04,011:INFO:Checking exceptions
2022-11-16 19:45:04,014:INFO:Importing libraries
2022-11-16 19:45:04,015:INFO:Copying training dataset
2022-11-16 19:45:04,026:INFO:Defining folds
2022-11-16 19:45:04,029:INFO:Declaring metric variables
2022-11-16 19:45:04,040:INFO:Importing untrained model
2022-11-16 19:45:04,053:INFO:Least Angle Regression Imported successfully
2022-11-16 19:45:04,077:INFO:Starting cross validation
2022-11-16 19:45:04,081:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:04,156:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:04,192:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:04,306:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:04,308:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:04,378:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:04,439:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:04,470:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:04,525:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:04,555:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:04,588:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:04,619:INFO:Calculating mean and std
2022-11-16 19:45:04,628:INFO:Creating metrics dataframe
2022-11-16 19:45:04,643:INFO:Uploading results into container
2022-11-16 19:45:04,646:INFO:Uploading model into container now
2022-11-16 19:45:04,647:INFO:master_model_container: 5
2022-11-16 19:45:04,647:INFO:display_container: 2
2022-11-16 19:45:04,648:INFO:Lars(random_state=123)
2022-11-16 19:45:04,648:INFO:create_model() successfully completed......................................
2022-11-16 19:45:04,834:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:04,835:INFO:Creating metrics dataframe
2022-11-16 19:45:04,864:INFO:Initializing Lasso Least Angle Regression
2022-11-16 19:45:04,868:INFO:Total runtime is 0.13428572018941246 minutes
2022-11-16 19:45:04,877:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:04,880:INFO:Initializing create_model()
2022-11-16 19:45:04,880:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a60adfa10>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a293f2190>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:04,880:INFO:Checking exceptions
2022-11-16 19:45:04,883:INFO:Importing libraries
2022-11-16 19:45:04,883:INFO:Copying training dataset
2022-11-16 19:45:04,893:INFO:Defining folds
2022-11-16 19:45:04,893:INFO:Declaring metric variables
2022-11-16 19:45:04,903:INFO:Importing untrained model
2022-11-16 19:45:04,912:INFO:Lasso Least Angle Regression Imported successfully
2022-11-16 19:45:04,936:INFO:Starting cross validation
2022-11-16 19:45:04,938:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:05,013:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:45:05,035:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:45:05,171:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:45:05,209:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:45:05,251:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:45:05,297:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:45:05,325:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:45:05,372:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:45:05,402:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:45:05,453:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:45:05,474:INFO:Calculating mean and std
2022-11-16 19:45:05,496:INFO:Creating metrics dataframe
2022-11-16 19:45:05,505:INFO:Uploading results into container
2022-11-16 19:45:05,506:INFO:Uploading model into container now
2022-11-16 19:45:05,507:INFO:master_model_container: 6
2022-11-16 19:45:05,507:INFO:display_container: 2
2022-11-16 19:45:05,508:INFO:LassoLars(random_state=123)
2022-11-16 19:45:05,508:INFO:create_model() successfully completed......................................
2022-11-16 19:45:05,677:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:05,677:INFO:Creating metrics dataframe
2022-11-16 19:45:05,709:INFO:Initializing Orthogonal Matching Pursuit
2022-11-16 19:45:05,712:INFO:Total runtime is 0.14835817813873292 minutes
2022-11-16 19:45:05,722:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:05,722:INFO:Initializing create_model()
2022-11-16 19:45:05,726:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a60adfa10>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a293f2190>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:05,726:INFO:Checking exceptions
2022-11-16 19:45:05,729:INFO:Importing libraries
2022-11-16 19:45:05,729:INFO:Copying training dataset
2022-11-16 19:45:05,744:INFO:Defining folds
2022-11-16 19:45:05,744:INFO:Declaring metric variables
2022-11-16 19:45:05,755:INFO:Importing untrained model
2022-11-16 19:45:05,770:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-16 19:45:05,793:INFO:Starting cross validation
2022-11-16 19:45:05,795:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:05,868:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:05,921:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:06,022:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:06,070:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:06,165:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:06,226:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:06,259:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:06,306:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:06,341:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:06,381:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:06,405:INFO:Calculating mean and std
2022-11-16 19:45:06,409:INFO:Creating metrics dataframe
2022-11-16 19:45:06,418:INFO:Uploading results into container
2022-11-16 19:45:06,423:INFO:Uploading model into container now
2022-11-16 19:45:06,426:INFO:master_model_container: 7
2022-11-16 19:45:06,428:INFO:display_container: 2
2022-11-16 19:45:06,428:INFO:OrthogonalMatchingPursuit()
2022-11-16 19:45:06,428:INFO:create_model() successfully completed......................................
2022-11-16 19:45:06,599:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:06,600:INFO:Creating metrics dataframe
2022-11-16 19:45:06,631:INFO:Initializing Bayesian Ridge
2022-11-16 19:45:06,632:INFO:Total runtime is 0.16369696458180746 minutes
2022-11-16 19:45:06,643:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:06,644:INFO:Initializing create_model()
2022-11-16 19:45:06,647:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a60adfa10>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a293f2190>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:06,649:INFO:Checking exceptions
2022-11-16 19:45:06,652:INFO:Importing libraries
2022-11-16 19:45:06,654:INFO:Copying training dataset
2022-11-16 19:45:06,665:INFO:Defining folds
2022-11-16 19:45:06,665:INFO:Declaring metric variables
2022-11-16 19:45:06,680:INFO:Importing untrained model
2022-11-16 19:45:06,693:INFO:Bayesian Ridge Imported successfully
2022-11-16 19:45:06,720:INFO:Starting cross validation
2022-11-16 19:45:06,722:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:07,282:INFO:Calculating mean and std
2022-11-16 19:45:07,286:INFO:Creating metrics dataframe
2022-11-16 19:45:07,302:INFO:Uploading results into container
2022-11-16 19:45:07,303:INFO:Uploading model into container now
2022-11-16 19:45:07,304:INFO:master_model_container: 8
2022-11-16 19:45:07,304:INFO:display_container: 2
2022-11-16 19:45:07,305:INFO:BayesianRidge()
2022-11-16 19:45:07,305:INFO:create_model() successfully completed......................................
2022-11-16 19:45:07,482:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:07,482:INFO:Creating metrics dataframe
2022-11-16 19:45:07,515:INFO:Initializing Passive Aggressive Regressor
2022-11-16 19:45:07,515:INFO:Total runtime is 0.17841007709503176 minutes
2022-11-16 19:45:07,529:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:07,530:INFO:Initializing create_model()
2022-11-16 19:45:07,530:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a60adfa10>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a293f2190>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:07,530:INFO:Checking exceptions
2022-11-16 19:45:07,536:INFO:Importing libraries
2022-11-16 19:45:07,537:INFO:Copying training dataset
2022-11-16 19:45:07,549:INFO:Defining folds
2022-11-16 19:45:07,551:INFO:Declaring metric variables
2022-11-16 19:45:07,566:INFO:Importing untrained model
2022-11-16 19:45:07,580:INFO:Passive Aggressive Regressor Imported successfully
2022-11-16 19:45:07,601:INFO:Starting cross validation
2022-11-16 19:45:07,603:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:08,135:INFO:Calculating mean and std
2022-11-16 19:45:08,144:INFO:Creating metrics dataframe
2022-11-16 19:45:08,154:INFO:Uploading results into container
2022-11-16 19:45:08,155:INFO:Uploading model into container now
2022-11-16 19:45:08,156:INFO:master_model_container: 9
2022-11-16 19:45:08,156:INFO:display_container: 2
2022-11-16 19:45:08,157:INFO:PassiveAggressiveRegressor(random_state=123)
2022-11-16 19:45:08,157:INFO:create_model() successfully completed......................................
2022-11-16 19:45:08,332:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:08,332:INFO:Creating metrics dataframe
2022-11-16 19:45:08,366:INFO:Initializing Huber Regressor
2022-11-16 19:45:08,367:INFO:Total runtime is 0.19260494311650597 minutes
2022-11-16 19:45:08,375:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:08,376:INFO:Initializing create_model()
2022-11-16 19:45:08,376:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a60adfa10>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a293f2190>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:08,377:INFO:Checking exceptions
2022-11-16 19:45:08,380:INFO:Importing libraries
2022-11-16 19:45:08,380:INFO:Copying training dataset
2022-11-16 19:45:08,389:INFO:Defining folds
2022-11-16 19:45:08,389:INFO:Declaring metric variables
2022-11-16 19:45:08,399:INFO:Importing untrained model
2022-11-16 19:45:08,410:INFO:Huber Regressor Imported successfully
2022-11-16 19:45:08,431:INFO:Starting cross validation
2022-11-16 19:45:08,434:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:08,670:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:45:08,711:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:45:08,896:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:45:08,904:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:45:09,096:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:45:09,136:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:45:09,260:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:45:09,352:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:45:09,467:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:45:09,547:INFO:Calculating mean and std
2022-11-16 19:45:09,554:INFO:Creating metrics dataframe
2022-11-16 19:45:09,563:INFO:Uploading results into container
2022-11-16 19:45:09,564:INFO:Uploading model into container now
2022-11-16 19:45:09,565:INFO:master_model_container: 10
2022-11-16 19:45:09,565:INFO:display_container: 2
2022-11-16 19:45:09,566:INFO:HuberRegressor()
2022-11-16 19:45:09,566:INFO:create_model() successfully completed......................................
2022-11-16 19:45:09,741:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:09,743:INFO:Creating metrics dataframe
2022-11-16 19:45:09,778:INFO:Initializing K Neighbors Regressor
2022-11-16 19:45:09,778:INFO:Total runtime is 0.21613033612569177 minutes
2022-11-16 19:45:09,789:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:09,790:INFO:Initializing create_model()
2022-11-16 19:45:09,790:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a60adfa10>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a293f2190>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:09,790:INFO:Checking exceptions
2022-11-16 19:45:09,793:INFO:Importing libraries
2022-11-16 19:45:09,793:INFO:Copying training dataset
2022-11-16 19:45:09,802:INFO:Defining folds
2022-11-16 19:45:09,803:INFO:Declaring metric variables
2022-11-16 19:45:09,813:INFO:Importing untrained model
2022-11-16 19:45:09,824:INFO:K Neighbors Regressor Imported successfully
2022-11-16 19:45:09,853:INFO:Starting cross validation
2022-11-16 19:45:09,856:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:10,716:INFO:Calculating mean and std
2022-11-16 19:45:10,721:INFO:Creating metrics dataframe
2022-11-16 19:45:10,730:INFO:Uploading results into container
2022-11-16 19:45:10,732:INFO:Uploading model into container now
2022-11-16 19:45:10,733:INFO:master_model_container: 11
2022-11-16 19:45:10,733:INFO:display_container: 2
2022-11-16 19:45:10,734:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-16 19:45:10,734:INFO:create_model() successfully completed......................................
2022-11-16 19:45:10,870:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:10,870:INFO:Creating metrics dataframe
2022-11-16 19:45:10,891:INFO:Initializing Decision Tree Regressor
2022-11-16 19:45:10,892:INFO:Total runtime is 0.2346888621648153 minutes
2022-11-16 19:45:10,906:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:10,907:INFO:Initializing create_model()
2022-11-16 19:45:10,907:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a60adfa10>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a293f2190>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:10,907:INFO:Checking exceptions
2022-11-16 19:45:10,911:INFO:Importing libraries
2022-11-16 19:45:10,911:INFO:Copying training dataset
2022-11-16 19:45:10,920:INFO:Defining folds
2022-11-16 19:45:10,922:INFO:Declaring metric variables
2022-11-16 19:45:10,935:INFO:Importing untrained model
2022-11-16 19:45:10,946:INFO:Decision Tree Regressor Imported successfully
2022-11-16 19:45:10,966:INFO:Starting cross validation
2022-11-16 19:45:10,968:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:11,323:INFO:Calculating mean and std
2022-11-16 19:45:11,326:INFO:Creating metrics dataframe
2022-11-16 19:45:11,339:INFO:Uploading results into container
2022-11-16 19:45:11,340:INFO:Uploading model into container now
2022-11-16 19:45:11,341:INFO:master_model_container: 12
2022-11-16 19:45:11,341:INFO:display_container: 2
2022-11-16 19:45:11,341:INFO:DecisionTreeRegressor(random_state=123)
2022-11-16 19:45:11,342:INFO:create_model() successfully completed......................................
2022-11-16 19:45:11,469:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:11,470:INFO:Creating metrics dataframe
2022-11-16 19:45:11,490:INFO:Initializing Random Forest Regressor
2022-11-16 19:45:11,491:INFO:Total runtime is 0.2446721951166789 minutes
2022-11-16 19:45:11,500:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:11,501:INFO:Initializing create_model()
2022-11-16 19:45:11,502:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a60adfa10>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a293f2190>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:11,502:INFO:Checking exceptions
2022-11-16 19:45:11,505:INFO:Importing libraries
2022-11-16 19:45:11,506:INFO:Copying training dataset
2022-11-16 19:45:11,511:INFO:Defining folds
2022-11-16 19:45:11,512:INFO:Declaring metric variables
2022-11-16 19:45:11,521:INFO:Importing untrained model
2022-11-16 19:45:11,537:INFO:Random Forest Regressor Imported successfully
2022-11-16 19:45:11,567:INFO:Starting cross validation
2022-11-16 19:45:11,569:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:16,451:INFO:Calculating mean and std
2022-11-16 19:45:16,456:INFO:Creating metrics dataframe
2022-11-16 19:45:16,469:INFO:Uploading results into container
2022-11-16 19:45:16,470:INFO:Uploading model into container now
2022-11-16 19:45:16,471:INFO:master_model_container: 13
2022-11-16 19:45:16,471:INFO:display_container: 2
2022-11-16 19:45:16,471:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-16 19:45:16,472:INFO:create_model() successfully completed......................................
2022-11-16 19:45:16,607:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:16,607:INFO:Creating metrics dataframe
2022-11-16 19:45:16,630:INFO:Initializing Extra Trees Regressor
2022-11-16 19:45:16,631:INFO:Total runtime is 0.33034663995107016 minutes
2022-11-16 19:45:16,640:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:16,641:INFO:Initializing create_model()
2022-11-16 19:45:16,645:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a60adfa10>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a293f2190>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:16,646:INFO:Checking exceptions
2022-11-16 19:45:16,648:INFO:Importing libraries
2022-11-16 19:45:16,648:INFO:Copying training dataset
2022-11-16 19:45:16,653:INFO:Defining folds
2022-11-16 19:45:16,654:INFO:Declaring metric variables
2022-11-16 19:45:16,669:INFO:Importing untrained model
2022-11-16 19:45:16,682:INFO:Extra Trees Regressor Imported successfully
2022-11-16 19:45:16,710:INFO:Starting cross validation
2022-11-16 19:45:16,712:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:19,589:INFO:Calculating mean and std
2022-11-16 19:45:19,595:INFO:Creating metrics dataframe
2022-11-16 19:45:19,607:INFO:Uploading results into container
2022-11-16 19:45:19,608:INFO:Uploading model into container now
2022-11-16 19:45:19,609:INFO:master_model_container: 14
2022-11-16 19:45:19,609:INFO:display_container: 2
2022-11-16 19:45:19,609:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-16 19:45:19,610:INFO:create_model() successfully completed......................................
2022-11-16 19:45:19,743:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:19,743:INFO:Creating metrics dataframe
2022-11-16 19:45:19,765:INFO:Initializing AdaBoost Regressor
2022-11-16 19:45:19,767:INFO:Total runtime is 0.38259793917338053 minutes
2022-11-16 19:45:19,776:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:19,777:INFO:Initializing create_model()
2022-11-16 19:45:19,777:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a60adfa10>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a293f2190>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:19,778:INFO:Checking exceptions
2022-11-16 19:45:19,781:INFO:Importing libraries
2022-11-16 19:45:19,781:INFO:Copying training dataset
2022-11-16 19:45:19,787:INFO:Defining folds
2022-11-16 19:45:19,787:INFO:Declaring metric variables
2022-11-16 19:45:19,801:INFO:Importing untrained model
2022-11-16 19:45:19,811:INFO:AdaBoost Regressor Imported successfully
2022-11-16 19:45:19,826:INFO:Starting cross validation
2022-11-16 19:45:19,829:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:21,073:INFO:Calculating mean and std
2022-11-16 19:45:21,076:INFO:Creating metrics dataframe
2022-11-16 19:45:21,089:INFO:Uploading results into container
2022-11-16 19:45:21,090:INFO:Uploading model into container now
2022-11-16 19:45:21,091:INFO:master_model_container: 15
2022-11-16 19:45:21,091:INFO:display_container: 2
2022-11-16 19:45:21,092:INFO:AdaBoostRegressor(random_state=123)
2022-11-16 19:45:21,092:INFO:create_model() successfully completed......................................
2022-11-16 19:45:21,225:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:21,225:INFO:Creating metrics dataframe
2022-11-16 19:45:21,253:INFO:Initializing Gradient Boosting Regressor
2022-11-16 19:45:21,253:INFO:Total runtime is 0.4073801517486572 minutes
2022-11-16 19:45:21,263:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:21,264:INFO:Initializing create_model()
2022-11-16 19:45:21,264:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a60adfa10>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a293f2190>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:21,264:INFO:Checking exceptions
2022-11-16 19:45:21,267:INFO:Importing libraries
2022-11-16 19:45:21,267:INFO:Copying training dataset
2022-11-16 19:45:21,276:INFO:Defining folds
2022-11-16 19:45:21,276:INFO:Declaring metric variables
2022-11-16 19:45:21,287:INFO:Importing untrained model
2022-11-16 19:45:21,297:INFO:Gradient Boosting Regressor Imported successfully
2022-11-16 19:45:21,316:INFO:Starting cross validation
2022-11-16 19:45:21,318:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:23,134:INFO:Calculating mean and std
2022-11-16 19:45:23,138:INFO:Creating metrics dataframe
2022-11-16 19:45:23,146:INFO:Uploading results into container
2022-11-16 19:45:23,147:INFO:Uploading model into container now
2022-11-16 19:45:23,148:INFO:master_model_container: 16
2022-11-16 19:45:23,148:INFO:display_container: 2
2022-11-16 19:45:23,149:INFO:GradientBoostingRegressor(random_state=123)
2022-11-16 19:45:23,149:INFO:create_model() successfully completed......................................
2022-11-16 19:45:23,279:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:23,280:INFO:Creating metrics dataframe
2022-11-16 19:45:23,303:INFO:Initializing Light Gradient Boosting Machine
2022-11-16 19:45:23,303:INFO:Total runtime is 0.4415470441182454 minutes
2022-11-16 19:45:23,313:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:23,317:INFO:Initializing create_model()
2022-11-16 19:45:23,317:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a60adfa10>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a293f2190>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:23,318:INFO:Checking exceptions
2022-11-16 19:45:23,320:INFO:Importing libraries
2022-11-16 19:45:23,321:INFO:Copying training dataset
2022-11-16 19:45:23,326:INFO:Defining folds
2022-11-16 19:45:23,329:INFO:Declaring metric variables
2022-11-16 19:45:23,339:INFO:Importing untrained model
2022-11-16 19:45:23,348:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-16 19:45:23,365:INFO:Starting cross validation
2022-11-16 19:45:23,368:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:24,969:INFO:Calculating mean and std
2022-11-16 19:45:24,973:INFO:Creating metrics dataframe
2022-11-16 19:45:24,984:INFO:Uploading results into container
2022-11-16 19:45:24,985:INFO:Uploading model into container now
2022-11-16 19:45:24,986:INFO:master_model_container: 17
2022-11-16 19:45:24,986:INFO:display_container: 2
2022-11-16 19:45:24,987:INFO:LGBMRegressor(random_state=123)
2022-11-16 19:45:24,987:INFO:create_model() successfully completed......................................
2022-11-16 19:45:25,122:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:25,122:INFO:Creating metrics dataframe
2022-11-16 19:45:25,146:INFO:Initializing Dummy Regressor
2022-11-16 19:45:25,146:INFO:Total runtime is 0.4722626129786173 minutes
2022-11-16 19:45:25,154:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:25,155:INFO:Initializing create_model()
2022-11-16 19:45:25,155:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a60adfa10>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a293f2190>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:25,156:INFO:Checking exceptions
2022-11-16 19:45:25,159:INFO:Importing libraries
2022-11-16 19:45:25,159:INFO:Copying training dataset
2022-11-16 19:45:25,165:INFO:Defining folds
2022-11-16 19:45:25,166:INFO:Declaring metric variables
2022-11-16 19:45:25,177:INFO:Importing untrained model
2022-11-16 19:45:25,188:INFO:Dummy Regressor Imported successfully
2022-11-16 19:45:25,207:INFO:Starting cross validation
2022-11-16 19:45:25,209:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:25,501:INFO:Calculating mean and std
2022-11-16 19:45:25,510:INFO:Creating metrics dataframe
2022-11-16 19:45:25,520:INFO:Uploading results into container
2022-11-16 19:45:25,522:INFO:Uploading model into container now
2022-11-16 19:45:25,522:INFO:master_model_container: 18
2022-11-16 19:45:25,523:INFO:display_container: 2
2022-11-16 19:45:25,523:INFO:DummyRegressor()
2022-11-16 19:45:25,524:INFO:create_model() successfully completed......................................
2022-11-16 19:45:25,657:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:25,658:INFO:Creating metrics dataframe
2022-11-16 19:45:25,709:INFO:Initializing create_model()
2022-11-16 19:45:25,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a60adfa10>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:25,710:INFO:Checking exceptions
2022-11-16 19:45:25,717:INFO:Importing libraries
2022-11-16 19:45:25,718:INFO:Copying training dataset
2022-11-16 19:45:25,723:INFO:Defining folds
2022-11-16 19:45:25,723:INFO:Declaring metric variables
2022-11-16 19:45:25,724:INFO:Importing untrained model
2022-11-16 19:45:25,725:INFO:Declaring custom model
2022-11-16 19:45:25,725:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-16 19:45:25,727:INFO:Cross validation set to False
2022-11-16 19:45:25,727:INFO:Fitting Model
2022-11-16 19:45:25,759:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:25,762:INFO:OrthogonalMatchingPursuit()
2022-11-16 19:45:25,763:INFO:create_model() successfully completed......................................
2022-11-16 19:45:25,986:INFO:master_model_container: 18
2022-11-16 19:45:25,987:INFO:display_container: 2
2022-11-16 19:45:25,988:INFO:OrthogonalMatchingPursuit()
2022-11-16 19:45:25,988:INFO:compare_models() successfully completed......................................
2022-11-16 19:45:30,829:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  app.launch_new_instance()

2022-11-16 19:45:30,831:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:45:30,832:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:45:30,833:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:45:30,834:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:45:30,835:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:45:30,836:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:45:30,837:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:45:30,839:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:45:30,840:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:45:30,841:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:45:30,845:INFO:PyCaret RegressionExperiment
2022-11-16 19:45:30,846:INFO:Logging name: FullData
2022-11-16 19:45:30,846:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-16 19:45:30,846:INFO:version 3.0.0.rc4
2022-11-16 19:45:30,846:INFO:Initializing setup()
2022-11-16 19:45:30,846:INFO:self.USI: b027
2022-11-16 19:45:30,847:INFO:self.variable_keys: {'display_container', '_ml_usecase', 'y_train', 'X_train', 'y_test', '_all_metrics', 'pipeline', 'transform_target_param', '_all_models_internal', '_gpu_n_jobs_param', 'logging_param', 'log_plots_param', '_all_models', 'memory', 'target_param', 'data', 'gpu_param', 'X', 'fold_shuffle_param', 'X_test', 'html_param', 'master_model_container', 'n_jobs_param', 'fold_groups_param', 'y', 'exp_id', 'exp_name_log', '_available_plots', 'variable_keys', 'seed', 'fold_generator', 'USI', 'idx', 'transform_target_method_param'}
2022-11-16 19:45:30,847:INFO:Checking environment
2022-11-16 19:45:30,847:INFO:python_version: 3.7.15
2022-11-16 19:45:30,847:INFO:python_build: ('default', 'Oct 12 2022 19:14:55')
2022-11-16 19:45:30,847:INFO:machine: x86_64
2022-11-16 19:45:30,847:INFO:platform: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-16 19:45:30,848:INFO:Memory: svmem(total=13616361472, available=11540647936, percent=15.2, used=1922752512, free=6078083072, active=1002590208, inactive=6140510208, buffers=165666816, cached=5449859072, shared=1363968, slab=292110336)
2022-11-16 19:45:30,848:INFO:Physical Core: 1
2022-11-16 19:45:30,848:INFO:Logical Core: 2
2022-11-16 19:45:30,848:INFO:Checking libraries
2022-11-16 19:45:30,849:INFO:System:
2022-11-16 19:45:30,849:INFO:    python: 3.7.15 (default, Oct 12 2022, 19:14:55)  [GCC 7.5.0]
2022-11-16 19:45:30,849:INFO:executable: /usr/bin/python3
2022-11-16 19:45:30,849:INFO:   machine: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-16 19:45:30,849:INFO:PyCaret required dependencies:
2022-11-16 19:45:30,849:INFO:                 pip: 21.1.3
2022-11-16 19:45:30,849:INFO:          setuptools: 57.4.0
2022-11-16 19:45:30,850:INFO:             pycaret: 3.0.0rc4
2022-11-16 19:45:30,850:INFO:             IPython: 7.9.0
2022-11-16 19:45:30,850:INFO:          ipywidgets: 7.7.1
2022-11-16 19:45:30,850:INFO:                tqdm: 4.64.1
2022-11-16 19:45:30,850:INFO:               numpy: 1.21.6
2022-11-16 19:45:30,850:INFO:              pandas: 1.3.5
2022-11-16 19:45:30,850:INFO:              jinja2: 3.0.0
2022-11-16 19:45:30,850:INFO:               scipy: 1.7.3
2022-11-16 19:45:30,851:INFO:              joblib: 1.2.0
2022-11-16 19:45:30,851:INFO:             sklearn: 1.0.2
2022-11-16 19:45:30,851:INFO:                pyod: 1.0.6
2022-11-16 19:45:30,851:INFO:            imblearn: 0.8.1
2022-11-16 19:45:30,851:INFO:   category_encoders: 2.5.1.post0
2022-11-16 19:45:30,851:INFO:            lightgbm: 3.3.3
2022-11-16 19:45:30,851:INFO:               numba: 0.55.2
2022-11-16 19:45:30,852:INFO:            requests: 2.28.1
2022-11-16 19:45:30,852:INFO:          matplotlib: 3.5.3
2022-11-16 19:45:30,852:INFO:          scikitplot: 0.3.7
2022-11-16 19:45:30,852:INFO:         yellowbrick: 1.5
2022-11-16 19:45:30,852:INFO:              plotly: 5.5.0
2022-11-16 19:45:30,852:INFO:             kaleido: 0.2.1
2022-11-16 19:45:30,852:INFO:         statsmodels: 0.12.2
2022-11-16 19:45:30,852:INFO:              sktime: 0.13.4
2022-11-16 19:45:30,853:INFO:               tbats: 1.1.1
2022-11-16 19:45:30,853:INFO:            pmdarima: 1.8.5
2022-11-16 19:45:30,853:INFO:              psutil: 5.9.4
2022-11-16 19:45:30,853:INFO:PyCaret optional dependencies:
2022-11-16 19:45:30,853:INFO:                shap: Not installed
2022-11-16 19:45:30,853:INFO:           interpret: Not installed
2022-11-16 19:45:30,854:INFO:                umap: Not installed
2022-11-16 19:45:30,854:INFO:    pandas_profiling: 1.4.1
2022-11-16 19:45:30,854:INFO:  explainerdashboard: Not installed
2022-11-16 19:45:30,854:INFO:             autoviz: Not installed
2022-11-16 19:45:30,854:INFO:           fairlearn: Not installed
2022-11-16 19:45:30,854:INFO:             xgboost: 0.90
2022-11-16 19:45:30,855:INFO:            catboost: Not installed
2022-11-16 19:45:30,855:INFO:              kmodes: Not installed
2022-11-16 19:45:30,855:INFO:             mlxtend: 0.14.0
2022-11-16 19:45:30,855:INFO:       statsforecast: Not installed
2022-11-16 19:45:30,855:INFO:        tune_sklearn: Not installed
2022-11-16 19:45:30,856:INFO:                 ray: Not installed
2022-11-16 19:45:30,856:INFO:            hyperopt: 0.1.2
2022-11-16 19:45:30,856:INFO:              optuna: Not installed
2022-11-16 19:45:30,856:INFO:               skopt: Not installed
2022-11-16 19:45:30,856:INFO:              mlflow: Not installed
2022-11-16 19:45:30,856:INFO:              gradio: Not installed
2022-11-16 19:45:30,857:INFO:             fastapi: Not installed
2022-11-16 19:45:30,857:INFO:             uvicorn: Not installed
2022-11-16 19:45:30,857:INFO:              m2cgen: Not installed
2022-11-16 19:45:30,857:INFO:           evidently: Not installed
2022-11-16 19:45:30,857:INFO:                nltk: 3.7
2022-11-16 19:45:30,857:INFO:            pyLDAvis: Not installed
2022-11-16 19:45:30,857:INFO:              gensim: 3.6.0
2022-11-16 19:45:30,858:INFO:               spacy: 3.4.2
2022-11-16 19:45:30,858:INFO:           wordcloud: 1.8.2.2
2022-11-16 19:45:30,858:INFO:            textblob: 0.15.3
2022-11-16 19:45:30,858:INFO:               fugue: Not installed
2022-11-16 19:45:30,858:INFO:           streamlit: Not installed
2022-11-16 19:45:30,858:INFO:             prophet: 1.1.1
2022-11-16 19:45:30,858:INFO:None
2022-11-16 19:45:30,859:INFO:Set up data.
2022-11-16 19:45:30,867:INFO:Set up train/test split.
2022-11-16 19:45:30,870:INFO:Set up index.
2022-11-16 19:45:30,871:INFO:Set up folding strategy.
2022-11-16 19:45:30,871:INFO:Assigning column types.
2022-11-16 19:45:30,878:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-16 19:45:30,879:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-16 19:45:30,885:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-16 19:45:30,890:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:45:30,958:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,010:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,011:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:45:31,012:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:45:31,012:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:45:31,013:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,019:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,024:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,090:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,141:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,142:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:45:31,142:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:45:31,143:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:45:31,143:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-16 19:45:31,149:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,154:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,219:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,271:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,272:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:45:31,272:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:45:31,273:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:45:31,280:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,285:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,350:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,401:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,402:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:45:31,402:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:45:31,403:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:45:31,403:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-16 19:45:31,414:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,480:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,530:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,531:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:45:31,532:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:45:31,532:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:45:31,543:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,609:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,662:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,663:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:45:31,663:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:45:31,664:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:45:31,665:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-16 19:45:31,753:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,813:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,814:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:45:31,815:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:45:31,815:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:45:31,895:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,950:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:45:31,951:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:45:31,951:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:45:31,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:45:31,953:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-16 19:45:32,029:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:45:32,081:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:45:32,082:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:45:32,082:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:45:32,157:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:45:32,209:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:45:32,209:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:45:32,210:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:45:32,210:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-16 19:45:32,335:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:45:32,335:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:45:32,335:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:45:32,461:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:45:32,461:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:45:32,462:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:45:32,463:INFO:Preparing preprocessing pipeline...
2022-11-16 19:45:32,464:INFO:Set up simple imputation.
2022-11-16 19:45:32,464:INFO:Set up variance threshold.
2022-11-16 19:45:32,476:INFO:Finished creating preprocessing pipeline.
2022-11-16 19:45:32,482:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-16 19:45:32,483:INFO:Creating final display dataframe.
2022-11-16 19:45:32,563:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 12)
4         Train data shape    (607, 12)
5          Test data shape    (261, 12)
6         Numeric features           11
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         b027
2022-11-16 19:45:32,725:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:45:32,726:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:45:32,726:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:45:32,859:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:45:32,859:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:45:32,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:45:32,868:INFO:setup() successfully completed in 2.03s...............
2022-11-16 19:45:32,868:INFO:Initializing compare_models()
2022-11-16 19:45:32,868:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29b5eb50>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f2a29b5eb50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-16 19:45:32,868:INFO:Checking exceptions
2022-11-16 19:45:32,870:INFO:Preparing display monitor
2022-11-16 19:45:32,972:INFO:Initializing Linear Regression
2022-11-16 19:45:32,972:INFO:Total runtime is 8.507569630940754e-06 minutes
2022-11-16 19:45:32,986:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:32,987:INFO:Initializing create_model()
2022-11-16 19:45:32,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29b5eb50>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a29ae5e10>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:32,988:INFO:Checking exceptions
2022-11-16 19:45:32,991:INFO:Importing libraries
2022-11-16 19:45:32,992:INFO:Copying training dataset
2022-11-16 19:45:32,996:INFO:Defining folds
2022-11-16 19:45:32,997:INFO:Declaring metric variables
2022-11-16 19:45:33,005:INFO:Importing untrained model
2022-11-16 19:45:33,014:INFO:Linear Regression Imported successfully
2022-11-16 19:45:33,031:INFO:Starting cross validation
2022-11-16 19:45:33,037:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:33,339:INFO:Calculating mean and std
2022-11-16 19:45:33,340:INFO:Creating metrics dataframe
2022-11-16 19:45:33,345:INFO:Uploading results into container
2022-11-16 19:45:33,346:INFO:Uploading model into container now
2022-11-16 19:45:33,347:INFO:master_model_container: 1
2022-11-16 19:45:33,347:INFO:display_container: 2
2022-11-16 19:45:33,347:INFO:LinearRegression(n_jobs=-1)
2022-11-16 19:45:33,347:INFO:create_model() successfully completed......................................
2022-11-16 19:45:33,490:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:33,490:INFO:Creating metrics dataframe
2022-11-16 19:45:33,507:INFO:Initializing Lasso Regression
2022-11-16 19:45:33,508:INFO:Total runtime is 0.008934473991394043 minutes
2022-11-16 19:45:33,519:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:33,520:INFO:Initializing create_model()
2022-11-16 19:45:33,520:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29b5eb50>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a29ae5e10>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:33,520:INFO:Checking exceptions
2022-11-16 19:45:33,523:INFO:Importing libraries
2022-11-16 19:45:33,524:INFO:Copying training dataset
2022-11-16 19:45:33,526:INFO:Defining folds
2022-11-16 19:45:33,527:INFO:Declaring metric variables
2022-11-16 19:45:33,532:INFO:Importing untrained model
2022-11-16 19:45:33,543:INFO:Lasso Regression Imported successfully
2022-11-16 19:45:33,561:INFO:Starting cross validation
2022-11-16 19:45:33,563:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:33,890:INFO:Calculating mean and std
2022-11-16 19:45:33,893:INFO:Creating metrics dataframe
2022-11-16 19:45:33,901:INFO:Uploading results into container
2022-11-16 19:45:33,906:INFO:Uploading model into container now
2022-11-16 19:45:33,907:INFO:master_model_container: 2
2022-11-16 19:45:33,907:INFO:display_container: 2
2022-11-16 19:45:33,909:INFO:Lasso(random_state=123)
2022-11-16 19:45:33,914:INFO:create_model() successfully completed......................................
2022-11-16 19:45:34,047:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:34,048:INFO:Creating metrics dataframe
2022-11-16 19:45:34,067:INFO:Initializing Ridge Regression
2022-11-16 19:45:34,068:INFO:Total runtime is 0.01826153596242269 minutes
2022-11-16 19:45:34,074:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:34,078:INFO:Initializing create_model()
2022-11-16 19:45:34,078:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29b5eb50>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a29ae5e10>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:34,078:INFO:Checking exceptions
2022-11-16 19:45:34,083:INFO:Importing libraries
2022-11-16 19:45:34,083:INFO:Copying training dataset
2022-11-16 19:45:34,090:INFO:Defining folds
2022-11-16 19:45:34,090:INFO:Declaring metric variables
2022-11-16 19:45:34,108:INFO:Importing untrained model
2022-11-16 19:45:34,116:INFO:Ridge Regression Imported successfully
2022-11-16 19:45:34,135:INFO:Starting cross validation
2022-11-16 19:45:34,139:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:34,432:INFO:Calculating mean and std
2022-11-16 19:45:34,435:INFO:Creating metrics dataframe
2022-11-16 19:45:34,447:INFO:Uploading results into container
2022-11-16 19:45:34,449:INFO:Uploading model into container now
2022-11-16 19:45:34,450:INFO:master_model_container: 3
2022-11-16 19:45:34,450:INFO:display_container: 2
2022-11-16 19:45:34,451:INFO:Ridge(random_state=123)
2022-11-16 19:45:34,451:INFO:create_model() successfully completed......................................
2022-11-16 19:45:34,581:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:34,582:INFO:Creating metrics dataframe
2022-11-16 19:45:34,607:INFO:Initializing Elastic Net
2022-11-16 19:45:34,612:INFO:Total runtime is 0.027329842249552407 minutes
2022-11-16 19:45:34,618:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:34,619:INFO:Initializing create_model()
2022-11-16 19:45:34,619:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29b5eb50>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a29ae5e10>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:34,621:INFO:Checking exceptions
2022-11-16 19:45:34,624:INFO:Importing libraries
2022-11-16 19:45:34,625:INFO:Copying training dataset
2022-11-16 19:45:34,632:INFO:Defining folds
2022-11-16 19:45:34,633:INFO:Declaring metric variables
2022-11-16 19:45:34,645:INFO:Importing untrained model
2022-11-16 19:45:34,655:INFO:Elastic Net Imported successfully
2022-11-16 19:45:34,672:INFO:Starting cross validation
2022-11-16 19:45:34,678:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:34,993:INFO:Calculating mean and std
2022-11-16 19:45:34,996:INFO:Creating metrics dataframe
2022-11-16 19:45:35,010:INFO:Uploading results into container
2022-11-16 19:45:35,013:INFO:Uploading model into container now
2022-11-16 19:45:35,013:INFO:master_model_container: 4
2022-11-16 19:45:35,014:INFO:display_container: 2
2022-11-16 19:45:35,014:INFO:ElasticNet(random_state=123)
2022-11-16 19:45:35,015:INFO:create_model() successfully completed......................................
2022-11-16 19:45:35,166:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:35,166:INFO:Creating metrics dataframe
2022-11-16 19:45:35,186:INFO:Initializing Least Angle Regression
2022-11-16 19:45:35,187:INFO:Total runtime is 0.03691138426462809 minutes
2022-11-16 19:45:35,195:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:35,200:INFO:Initializing create_model()
2022-11-16 19:45:35,200:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29b5eb50>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a29ae5e10>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:35,200:INFO:Checking exceptions
2022-11-16 19:45:35,204:INFO:Importing libraries
2022-11-16 19:45:35,204:INFO:Copying training dataset
2022-11-16 19:45:35,208:INFO:Defining folds
2022-11-16 19:45:35,209:INFO:Declaring metric variables
2022-11-16 19:45:35,221:INFO:Importing untrained model
2022-11-16 19:45:35,232:INFO:Least Angle Regression Imported successfully
2022-11-16 19:45:35,249:INFO:Starting cross validation
2022-11-16 19:45:35,251:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:35,294:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:35,325:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:35,366:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:35,415:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:35,417:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:35,455:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:35,498:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:35,511:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:35,540:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:35,559:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:35,575:INFO:Calculating mean and std
2022-11-16 19:45:35,577:INFO:Creating metrics dataframe
2022-11-16 19:45:35,586:INFO:Uploading results into container
2022-11-16 19:45:35,587:INFO:Uploading model into container now
2022-11-16 19:45:35,588:INFO:master_model_container: 5
2022-11-16 19:45:35,588:INFO:display_container: 2
2022-11-16 19:45:35,589:INFO:Lars(random_state=123)
2022-11-16 19:45:35,589:INFO:create_model() successfully completed......................................
2022-11-16 19:45:35,725:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:35,725:INFO:Creating metrics dataframe
2022-11-16 19:45:35,745:INFO:Initializing Lasso Least Angle Regression
2022-11-16 19:45:35,746:INFO:Total runtime is 0.04623208840688069 minutes
2022-11-16 19:45:35,755:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:35,756:INFO:Initializing create_model()
2022-11-16 19:45:35,757:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29b5eb50>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a29ae5e10>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:35,757:INFO:Checking exceptions
2022-11-16 19:45:35,760:INFO:Importing libraries
2022-11-16 19:45:35,761:INFO:Copying training dataset
2022-11-16 19:45:35,766:INFO:Defining folds
2022-11-16 19:45:35,767:INFO:Declaring metric variables
2022-11-16 19:45:35,780:INFO:Importing untrained model
2022-11-16 19:45:35,796:INFO:Lasso Least Angle Regression Imported successfully
2022-11-16 19:45:35,820:INFO:Starting cross validation
2022-11-16 19:45:35,821:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:35,874:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:45:35,897:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:45:35,937:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:45:35,966:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:45:36,006:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:45:36,045:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:45:36,054:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:45:36,089:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:45:36,113:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:45:36,132:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:45:36,145:INFO:Calculating mean and std
2022-11-16 19:45:36,147:INFO:Creating metrics dataframe
2022-11-16 19:45:36,153:INFO:Uploading results into container
2022-11-16 19:45:36,158:INFO:Uploading model into container now
2022-11-16 19:45:36,159:INFO:master_model_container: 6
2022-11-16 19:45:36,160:INFO:display_container: 2
2022-11-16 19:45:36,160:INFO:LassoLars(random_state=123)
2022-11-16 19:45:36,163:INFO:create_model() successfully completed......................................
2022-11-16 19:45:36,295:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:36,295:INFO:Creating metrics dataframe
2022-11-16 19:45:36,320:INFO:Initializing Orthogonal Matching Pursuit
2022-11-16 19:45:36,321:INFO:Total runtime is 0.05581355094909668 minutes
2022-11-16 19:45:36,330:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:36,331:INFO:Initializing create_model()
2022-11-16 19:45:36,331:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29b5eb50>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a29ae5e10>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:36,331:INFO:Checking exceptions
2022-11-16 19:45:36,334:INFO:Importing libraries
2022-11-16 19:45:36,334:INFO:Copying training dataset
2022-11-16 19:45:36,339:INFO:Defining folds
2022-11-16 19:45:36,340:INFO:Declaring metric variables
2022-11-16 19:45:36,351:INFO:Importing untrained model
2022-11-16 19:45:36,362:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-16 19:45:36,382:INFO:Starting cross validation
2022-11-16 19:45:36,384:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:36,423:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:36,450:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:36,485:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:36,512:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:36,547:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:36,602:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:36,607:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:36,643:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:36,665:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:36,685:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:36,702:INFO:Calculating mean and std
2022-11-16 19:45:36,705:INFO:Creating metrics dataframe
2022-11-16 19:45:36,719:INFO:Uploading results into container
2022-11-16 19:45:36,720:INFO:Uploading model into container now
2022-11-16 19:45:36,721:INFO:master_model_container: 7
2022-11-16 19:45:36,721:INFO:display_container: 2
2022-11-16 19:45:36,721:INFO:OrthogonalMatchingPursuit()
2022-11-16 19:45:36,722:INFO:create_model() successfully completed......................................
2022-11-16 19:45:36,858:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:36,859:INFO:Creating metrics dataframe
2022-11-16 19:45:36,883:INFO:Initializing Bayesian Ridge
2022-11-16 19:45:36,883:INFO:Total runtime is 0.06518893241882324 minutes
2022-11-16 19:45:36,892:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:36,893:INFO:Initializing create_model()
2022-11-16 19:45:36,893:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29b5eb50>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a29ae5e10>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:36,893:INFO:Checking exceptions
2022-11-16 19:45:36,896:INFO:Importing libraries
2022-11-16 19:45:36,896:INFO:Copying training dataset
2022-11-16 19:45:36,908:INFO:Defining folds
2022-11-16 19:45:36,909:INFO:Declaring metric variables
2022-11-16 19:45:36,921:INFO:Importing untrained model
2022-11-16 19:45:36,930:INFO:Bayesian Ridge Imported successfully
2022-11-16 19:45:36,947:INFO:Starting cross validation
2022-11-16 19:45:36,950:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:37,275:INFO:Calculating mean and std
2022-11-16 19:45:37,278:INFO:Creating metrics dataframe
2022-11-16 19:45:37,291:INFO:Uploading results into container
2022-11-16 19:45:37,296:INFO:Uploading model into container now
2022-11-16 19:45:37,297:INFO:master_model_container: 8
2022-11-16 19:45:37,297:INFO:display_container: 2
2022-11-16 19:45:37,297:INFO:BayesianRidge()
2022-11-16 19:45:37,297:INFO:create_model() successfully completed......................................
2022-11-16 19:45:37,429:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:37,429:INFO:Creating metrics dataframe
2022-11-16 19:45:37,449:INFO:Initializing Passive Aggressive Regressor
2022-11-16 19:45:37,450:INFO:Total runtime is 0.07464136282602946 minutes
2022-11-16 19:45:37,460:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:37,461:INFO:Initializing create_model()
2022-11-16 19:45:37,461:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29b5eb50>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a29ae5e10>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:37,461:INFO:Checking exceptions
2022-11-16 19:45:37,467:INFO:Importing libraries
2022-11-16 19:45:37,467:INFO:Copying training dataset
2022-11-16 19:45:37,477:INFO:Defining folds
2022-11-16 19:45:37,483:INFO:Declaring metric variables
2022-11-16 19:45:37,492:INFO:Importing untrained model
2022-11-16 19:45:37,501:INFO:Passive Aggressive Regressor Imported successfully
2022-11-16 19:45:37,518:INFO:Starting cross validation
2022-11-16 19:45:37,520:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:37,835:INFO:Calculating mean and std
2022-11-16 19:45:37,838:INFO:Creating metrics dataframe
2022-11-16 19:45:37,850:INFO:Uploading results into container
2022-11-16 19:45:37,852:INFO:Uploading model into container now
2022-11-16 19:45:37,853:INFO:master_model_container: 9
2022-11-16 19:45:37,853:INFO:display_container: 2
2022-11-16 19:45:37,854:INFO:PassiveAggressiveRegressor(random_state=123)
2022-11-16 19:45:37,854:INFO:create_model() successfully completed......................................
2022-11-16 19:45:37,995:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:37,996:INFO:Creating metrics dataframe
2022-11-16 19:45:38,019:INFO:Initializing Huber Regressor
2022-11-16 19:45:38,020:INFO:Total runtime is 0.08413006862004598 minutes
2022-11-16 19:45:38,029:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:38,031:INFO:Initializing create_model()
2022-11-16 19:45:38,031:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29b5eb50>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a29ae5e10>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:38,032:INFO:Checking exceptions
2022-11-16 19:45:38,035:INFO:Importing libraries
2022-11-16 19:45:38,035:INFO:Copying training dataset
2022-11-16 19:45:38,041:INFO:Defining folds
2022-11-16 19:45:38,042:INFO:Declaring metric variables
2022-11-16 19:45:38,054:INFO:Importing untrained model
2022-11-16 19:45:38,066:INFO:Huber Regressor Imported successfully
2022-11-16 19:45:38,083:INFO:Starting cross validation
2022-11-16 19:45:38,085:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:38,182:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:45:38,272:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:45:38,297:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:45:38,384:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:45:38,430:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:45:38,502:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:45:38,529:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:45:38,598:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:45:38,630:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:45:38,692:INFO:Calculating mean and std
2022-11-16 19:45:38,694:INFO:Creating metrics dataframe
2022-11-16 19:45:38,704:INFO:Uploading results into container
2022-11-16 19:45:38,704:INFO:Uploading model into container now
2022-11-16 19:45:38,705:INFO:master_model_container: 10
2022-11-16 19:45:38,705:INFO:display_container: 2
2022-11-16 19:45:38,706:INFO:HuberRegressor()
2022-11-16 19:45:38,706:INFO:create_model() successfully completed......................................
2022-11-16 19:45:38,838:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:38,838:INFO:Creating metrics dataframe
2022-11-16 19:45:38,859:INFO:Initializing K Neighbors Regressor
2022-11-16 19:45:38,860:INFO:Total runtime is 0.09813474019368489 minutes
2022-11-16 19:45:38,869:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:38,872:INFO:Initializing create_model()
2022-11-16 19:45:38,872:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29b5eb50>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a29ae5e10>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:38,873:INFO:Checking exceptions
2022-11-16 19:45:38,875:INFO:Importing libraries
2022-11-16 19:45:38,876:INFO:Copying training dataset
2022-11-16 19:45:38,880:INFO:Defining folds
2022-11-16 19:45:38,881:INFO:Declaring metric variables
2022-11-16 19:45:38,895:INFO:Importing untrained model
2022-11-16 19:45:38,907:INFO:K Neighbors Regressor Imported successfully
2022-11-16 19:45:38,933:INFO:Starting cross validation
2022-11-16 19:45:38,935:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:39,687:INFO:Calculating mean and std
2022-11-16 19:45:39,707:INFO:Creating metrics dataframe
2022-11-16 19:45:39,717:INFO:Uploading results into container
2022-11-16 19:45:39,717:INFO:Uploading model into container now
2022-11-16 19:45:39,718:INFO:master_model_container: 11
2022-11-16 19:45:39,719:INFO:display_container: 2
2022-11-16 19:45:39,719:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-16 19:45:39,719:INFO:create_model() successfully completed......................................
2022-11-16 19:45:39,864:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:39,865:INFO:Creating metrics dataframe
2022-11-16 19:45:39,888:INFO:Initializing Decision Tree Regressor
2022-11-16 19:45:39,888:INFO:Total runtime is 0.11527464389801025 minutes
2022-11-16 19:45:39,897:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:39,898:INFO:Initializing create_model()
2022-11-16 19:45:39,898:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29b5eb50>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a29ae5e10>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:39,898:INFO:Checking exceptions
2022-11-16 19:45:39,901:INFO:Importing libraries
2022-11-16 19:45:39,901:INFO:Copying training dataset
2022-11-16 19:45:39,909:INFO:Defining folds
2022-11-16 19:45:39,910:INFO:Declaring metric variables
2022-11-16 19:45:39,925:INFO:Importing untrained model
2022-11-16 19:45:39,933:INFO:Decision Tree Regressor Imported successfully
2022-11-16 19:45:39,955:INFO:Starting cross validation
2022-11-16 19:45:39,956:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:40,313:INFO:Calculating mean and std
2022-11-16 19:45:40,319:INFO:Creating metrics dataframe
2022-11-16 19:45:40,325:INFO:Uploading results into container
2022-11-16 19:45:40,327:INFO:Uploading model into container now
2022-11-16 19:45:40,328:INFO:master_model_container: 12
2022-11-16 19:45:40,328:INFO:display_container: 2
2022-11-16 19:45:40,329:INFO:DecisionTreeRegressor(random_state=123)
2022-11-16 19:45:40,329:INFO:create_model() successfully completed......................................
2022-11-16 19:45:40,460:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:40,461:INFO:Creating metrics dataframe
2022-11-16 19:45:40,483:INFO:Initializing Random Forest Regressor
2022-11-16 19:45:40,483:INFO:Total runtime is 0.12518708308537801 minutes
2022-11-16 19:45:40,491:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:40,493:INFO:Initializing create_model()
2022-11-16 19:45:40,499:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29b5eb50>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a29ae5e10>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:40,499:INFO:Checking exceptions
2022-11-16 19:45:40,502:INFO:Importing libraries
2022-11-16 19:45:40,502:INFO:Copying training dataset
2022-11-16 19:45:40,506:INFO:Defining folds
2022-11-16 19:45:40,507:INFO:Declaring metric variables
2022-11-16 19:45:40,517:INFO:Importing untrained model
2022-11-16 19:45:40,530:INFO:Random Forest Regressor Imported successfully
2022-11-16 19:45:40,545:INFO:Starting cross validation
2022-11-16 19:45:40,548:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:45,262:INFO:Calculating mean and std
2022-11-16 19:45:45,268:INFO:Creating metrics dataframe
2022-11-16 19:45:45,283:INFO:Uploading results into container
2022-11-16 19:45:45,284:INFO:Uploading model into container now
2022-11-16 19:45:45,285:INFO:master_model_container: 13
2022-11-16 19:45:45,285:INFO:display_container: 2
2022-11-16 19:45:45,286:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-16 19:45:45,286:INFO:create_model() successfully completed......................................
2022-11-16 19:45:45,419:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:45,420:INFO:Creating metrics dataframe
2022-11-16 19:45:45,445:INFO:Initializing Extra Trees Regressor
2022-11-16 19:45:45,446:INFO:Total runtime is 0.2079017440478007 minutes
2022-11-16 19:45:45,456:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:45,457:INFO:Initializing create_model()
2022-11-16 19:45:45,457:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29b5eb50>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a29ae5e10>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:45,457:INFO:Checking exceptions
2022-11-16 19:45:45,460:INFO:Importing libraries
2022-11-16 19:45:45,461:INFO:Copying training dataset
2022-11-16 19:45:45,466:INFO:Defining folds
2022-11-16 19:45:45,467:INFO:Declaring metric variables
2022-11-16 19:45:45,478:INFO:Importing untrained model
2022-11-16 19:45:45,492:INFO:Extra Trees Regressor Imported successfully
2022-11-16 19:45:45,512:INFO:Starting cross validation
2022-11-16 19:45:45,514:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:48,296:INFO:Calculating mean and std
2022-11-16 19:45:48,301:INFO:Creating metrics dataframe
2022-11-16 19:45:48,314:INFO:Uploading results into container
2022-11-16 19:45:48,315:INFO:Uploading model into container now
2022-11-16 19:45:48,316:INFO:master_model_container: 14
2022-11-16 19:45:48,316:INFO:display_container: 2
2022-11-16 19:45:48,317:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-16 19:45:48,317:INFO:create_model() successfully completed......................................
2022-11-16 19:45:48,457:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:48,457:INFO:Creating metrics dataframe
2022-11-16 19:45:48,485:INFO:Initializing AdaBoost Regressor
2022-11-16 19:45:48,487:INFO:Total runtime is 0.25859336455663046 minutes
2022-11-16 19:45:48,498:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:48,503:INFO:Initializing create_model()
2022-11-16 19:45:48,505:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29b5eb50>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a29ae5e10>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:48,505:INFO:Checking exceptions
2022-11-16 19:45:48,507:INFO:Importing libraries
2022-11-16 19:45:48,507:INFO:Copying training dataset
2022-11-16 19:45:48,514:INFO:Defining folds
2022-11-16 19:45:48,517:INFO:Declaring metric variables
2022-11-16 19:45:48,527:INFO:Importing untrained model
2022-11-16 19:45:48,536:INFO:AdaBoost Regressor Imported successfully
2022-11-16 19:45:48,559:INFO:Starting cross validation
2022-11-16 19:45:48,561:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:49,821:INFO:Calculating mean and std
2022-11-16 19:45:49,823:INFO:Creating metrics dataframe
2022-11-16 19:45:49,832:INFO:Uploading results into container
2022-11-16 19:45:49,833:INFO:Uploading model into container now
2022-11-16 19:45:49,834:INFO:master_model_container: 15
2022-11-16 19:45:49,834:INFO:display_container: 2
2022-11-16 19:45:49,834:INFO:AdaBoostRegressor(random_state=123)
2022-11-16 19:45:49,835:INFO:create_model() successfully completed......................................
2022-11-16 19:45:49,969:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:49,970:INFO:Creating metrics dataframe
2022-11-16 19:45:49,995:INFO:Initializing Gradient Boosting Regressor
2022-11-16 19:45:49,996:INFO:Total runtime is 0.28373606204986573 minutes
2022-11-16 19:45:50,007:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:50,008:INFO:Initializing create_model()
2022-11-16 19:45:50,008:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29b5eb50>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a29ae5e10>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:50,008:INFO:Checking exceptions
2022-11-16 19:45:50,012:INFO:Importing libraries
2022-11-16 19:45:50,012:INFO:Copying training dataset
2022-11-16 19:45:50,018:INFO:Defining folds
2022-11-16 19:45:50,018:INFO:Declaring metric variables
2022-11-16 19:45:50,030:INFO:Importing untrained model
2022-11-16 19:45:50,046:INFO:Gradient Boosting Regressor Imported successfully
2022-11-16 19:45:50,063:INFO:Starting cross validation
2022-11-16 19:45:50,064:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:51,886:INFO:Calculating mean and std
2022-11-16 19:45:51,889:INFO:Creating metrics dataframe
2022-11-16 19:45:51,906:INFO:Uploading results into container
2022-11-16 19:45:51,907:INFO:Uploading model into container now
2022-11-16 19:45:51,907:INFO:master_model_container: 16
2022-11-16 19:45:51,908:INFO:display_container: 2
2022-11-16 19:45:51,908:INFO:GradientBoostingRegressor(random_state=123)
2022-11-16 19:45:51,908:INFO:create_model() successfully completed......................................
2022-11-16 19:45:52,040:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:52,040:INFO:Creating metrics dataframe
2022-11-16 19:45:52,062:INFO:Initializing Light Gradient Boosting Machine
2022-11-16 19:45:52,062:INFO:Total runtime is 0.318170169989268 minutes
2022-11-16 19:45:52,072:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:52,073:INFO:Initializing create_model()
2022-11-16 19:45:52,073:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29b5eb50>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a29ae5e10>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:52,073:INFO:Checking exceptions
2022-11-16 19:45:52,076:INFO:Importing libraries
2022-11-16 19:45:52,077:INFO:Copying training dataset
2022-11-16 19:45:52,085:INFO:Defining folds
2022-11-16 19:45:52,086:INFO:Declaring metric variables
2022-11-16 19:45:52,096:INFO:Importing untrained model
2022-11-16 19:45:52,106:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-16 19:45:52,122:INFO:Starting cross validation
2022-11-16 19:45:52,124:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:53,507:INFO:Calculating mean and std
2022-11-16 19:45:53,510:INFO:Creating metrics dataframe
2022-11-16 19:45:53,520:INFO:Uploading results into container
2022-11-16 19:45:53,521:INFO:Uploading model into container now
2022-11-16 19:45:53,522:INFO:master_model_container: 17
2022-11-16 19:45:53,524:INFO:display_container: 2
2022-11-16 19:45:53,525:INFO:LGBMRegressor(random_state=123)
2022-11-16 19:45:53,525:INFO:create_model() successfully completed......................................
2022-11-16 19:45:53,658:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:53,658:INFO:Creating metrics dataframe
2022-11-16 19:45:53,686:INFO:Initializing Dummy Regressor
2022-11-16 19:45:53,686:INFO:Total runtime is 0.34524288574854534 minutes
2022-11-16 19:45:53,699:INFO:SubProcess create_model() called ==================================
2022-11-16 19:45:53,700:INFO:Initializing create_model()
2022-11-16 19:45:53,701:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29b5eb50>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a29ae5e10>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:53,702:INFO:Checking exceptions
2022-11-16 19:45:53,705:INFO:Importing libraries
2022-11-16 19:45:53,705:INFO:Copying training dataset
2022-11-16 19:45:53,713:INFO:Defining folds
2022-11-16 19:45:53,714:INFO:Declaring metric variables
2022-11-16 19:45:53,729:INFO:Importing untrained model
2022-11-16 19:45:53,738:INFO:Dummy Regressor Imported successfully
2022-11-16 19:45:53,755:INFO:Starting cross validation
2022-11-16 19:45:53,757:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:45:54,050:INFO:Calculating mean and std
2022-11-16 19:45:54,056:INFO:Creating metrics dataframe
2022-11-16 19:45:54,065:INFO:Uploading results into container
2022-11-16 19:45:54,070:INFO:Uploading model into container now
2022-11-16 19:45:54,072:INFO:master_model_container: 18
2022-11-16 19:45:54,073:INFO:display_container: 2
2022-11-16 19:45:54,073:INFO:DummyRegressor()
2022-11-16 19:45:54,073:INFO:create_model() successfully completed......................................
2022-11-16 19:45:54,203:INFO:SubProcess create_model() end ==================================
2022-11-16 19:45:54,204:INFO:Creating metrics dataframe
2022-11-16 19:45:54,258:INFO:Initializing create_model()
2022-11-16 19:45:54,259:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29b5eb50>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:45:54,259:INFO:Checking exceptions
2022-11-16 19:45:54,269:INFO:Importing libraries
2022-11-16 19:45:54,270:INFO:Copying training dataset
2022-11-16 19:45:54,273:INFO:Defining folds
2022-11-16 19:45:54,273:INFO:Declaring metric variables
2022-11-16 19:45:54,274:INFO:Importing untrained model
2022-11-16 19:45:54,274:INFO:Declaring custom model
2022-11-16 19:45:54,275:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-16 19:45:54,276:INFO:Cross validation set to False
2022-11-16 19:45:54,276:INFO:Fitting Model
2022-11-16 19:45:54,288:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:45:54,291:INFO:OrthogonalMatchingPursuit()
2022-11-16 19:45:54,291:INFO:create_model() successfully completed......................................
2022-11-16 19:45:54,537:INFO:master_model_container: 18
2022-11-16 19:45:54,538:INFO:display_container: 2
2022-11-16 19:45:54,538:INFO:OrthogonalMatchingPursuit()
2022-11-16 19:45:54,539:INFO:compare_models() successfully completed......................................
2022-11-16 19:45:58,848:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  app.launch_new_instance()

2022-11-16 19:45:58,850:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:45:58,851:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:45:58,852:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:45:58,853:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:45:58,854:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:45:58,855:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:45:58,857:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:45:58,858:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:45:58,859:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:45:58,860:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:45:58,865:INFO:PyCaret RegressionExperiment
2022-11-16 19:45:58,865:INFO:Logging name: FullData
2022-11-16 19:45:58,865:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-16 19:45:58,865:INFO:version 3.0.0.rc4
2022-11-16 19:45:58,865:INFO:Initializing setup()
2022-11-16 19:45:58,865:INFO:self.USI: 9a48
2022-11-16 19:45:58,866:INFO:self.variable_keys: {'display_container', '_ml_usecase', 'y_train', 'X_train', 'y_test', '_all_metrics', 'pipeline', 'transform_target_param', '_all_models_internal', '_gpu_n_jobs_param', 'logging_param', 'log_plots_param', '_all_models', 'memory', 'target_param', 'data', 'gpu_param', 'X', 'fold_shuffle_param', 'X_test', 'html_param', 'master_model_container', 'n_jobs_param', 'fold_groups_param', 'y', 'exp_id', 'exp_name_log', '_available_plots', 'variable_keys', 'seed', 'fold_generator', 'USI', 'idx', 'transform_target_method_param'}
2022-11-16 19:45:58,866:INFO:Checking environment
2022-11-16 19:45:58,866:INFO:python_version: 3.7.15
2022-11-16 19:45:58,866:INFO:python_build: ('default', 'Oct 12 2022 19:14:55')
2022-11-16 19:45:58,866:INFO:machine: x86_64
2022-11-16 19:45:58,866:INFO:platform: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-16 19:45:58,867:INFO:Memory: svmem(total=13616361472, available=11613843456, percent=14.7, used=1871609856, free=6125355008, active=1002745856, inactive=6095523840, buffers=165797888, cached=5453598720, shared=1363968, slab=292098048)
2022-11-16 19:45:58,867:INFO:Physical Core: 1
2022-11-16 19:45:58,867:INFO:Logical Core: 2
2022-11-16 19:45:58,867:INFO:Checking libraries
2022-11-16 19:45:58,867:INFO:System:
2022-11-16 19:45:58,868:INFO:    python: 3.7.15 (default, Oct 12 2022, 19:14:55)  [GCC 7.5.0]
2022-11-16 19:45:58,868:INFO:executable: /usr/bin/python3
2022-11-16 19:45:58,868:INFO:   machine: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-16 19:45:58,868:INFO:PyCaret required dependencies:
2022-11-16 19:45:58,868:INFO:                 pip: 21.1.3
2022-11-16 19:45:58,868:INFO:          setuptools: 57.4.0
2022-11-16 19:45:58,868:INFO:             pycaret: 3.0.0rc4
2022-11-16 19:45:58,869:INFO:             IPython: 7.9.0
2022-11-16 19:45:58,869:INFO:          ipywidgets: 7.7.1
2022-11-16 19:45:58,869:INFO:                tqdm: 4.64.1
2022-11-16 19:45:58,869:INFO:               numpy: 1.21.6
2022-11-16 19:45:58,869:INFO:              pandas: 1.3.5
2022-11-16 19:45:58,869:INFO:              jinja2: 3.0.0
2022-11-16 19:45:58,869:INFO:               scipy: 1.7.3
2022-11-16 19:45:58,870:INFO:              joblib: 1.2.0
2022-11-16 19:45:58,870:INFO:             sklearn: 1.0.2
2022-11-16 19:45:58,870:INFO:                pyod: 1.0.6
2022-11-16 19:45:58,870:INFO:            imblearn: 0.8.1
2022-11-16 19:45:58,870:INFO:   category_encoders: 2.5.1.post0
2022-11-16 19:45:58,870:INFO:            lightgbm: 3.3.3
2022-11-16 19:45:58,870:INFO:               numba: 0.55.2
2022-11-16 19:45:58,871:INFO:            requests: 2.28.1
2022-11-16 19:45:58,871:INFO:          matplotlib: 3.5.3
2022-11-16 19:45:58,871:INFO:          scikitplot: 0.3.7
2022-11-16 19:45:58,871:INFO:         yellowbrick: 1.5
2022-11-16 19:45:58,871:INFO:              plotly: 5.5.0
2022-11-16 19:45:58,871:INFO:             kaleido: 0.2.1
2022-11-16 19:45:58,871:INFO:         statsmodels: 0.12.2
2022-11-16 19:45:58,871:INFO:              sktime: 0.13.4
2022-11-16 19:45:58,872:INFO:               tbats: 1.1.1
2022-11-16 19:45:58,872:INFO:            pmdarima: 1.8.5
2022-11-16 19:45:58,872:INFO:              psutil: 5.9.4
2022-11-16 19:45:58,872:INFO:PyCaret optional dependencies:
2022-11-16 19:45:58,872:INFO:                shap: Not installed
2022-11-16 19:45:58,872:INFO:           interpret: Not installed
2022-11-16 19:45:58,872:INFO:                umap: Not installed
2022-11-16 19:45:58,873:INFO:    pandas_profiling: 1.4.1
2022-11-16 19:45:58,873:INFO:  explainerdashboard: Not installed
2022-11-16 19:45:58,873:INFO:             autoviz: Not installed
2022-11-16 19:45:58,873:INFO:           fairlearn: Not installed
2022-11-16 19:45:58,873:INFO:             xgboost: 0.90
2022-11-16 19:45:58,873:INFO:            catboost: Not installed
2022-11-16 19:45:58,873:INFO:              kmodes: Not installed
2022-11-16 19:45:58,874:INFO:             mlxtend: 0.14.0
2022-11-16 19:45:58,874:INFO:       statsforecast: Not installed
2022-11-16 19:45:58,874:INFO:        tune_sklearn: Not installed
2022-11-16 19:45:58,874:INFO:                 ray: Not installed
2022-11-16 19:45:58,874:INFO:            hyperopt: 0.1.2
2022-11-16 19:45:58,874:INFO:              optuna: Not installed
2022-11-16 19:45:58,874:INFO:               skopt: Not installed
2022-11-16 19:45:58,874:INFO:              mlflow: Not installed
2022-11-16 19:45:58,875:INFO:              gradio: Not installed
2022-11-16 19:45:58,875:INFO:             fastapi: Not installed
2022-11-16 19:45:58,875:INFO:             uvicorn: Not installed
2022-11-16 19:45:58,875:INFO:              m2cgen: Not installed
2022-11-16 19:45:58,875:INFO:           evidently: Not installed
2022-11-16 19:45:58,875:INFO:                nltk: 3.7
2022-11-16 19:45:58,875:INFO:            pyLDAvis: Not installed
2022-11-16 19:45:58,876:INFO:              gensim: 3.6.0
2022-11-16 19:45:58,876:INFO:               spacy: 3.4.2
2022-11-16 19:45:58,876:INFO:           wordcloud: 1.8.2.2
2022-11-16 19:45:58,876:INFO:            textblob: 0.15.3
2022-11-16 19:45:58,876:INFO:               fugue: Not installed
2022-11-16 19:45:58,876:INFO:           streamlit: Not installed
2022-11-16 19:45:58,876:INFO:             prophet: 1.1.1
2022-11-16 19:45:58,877:INFO:None
2022-11-16 19:45:58,877:INFO:Set up data.
2022-11-16 19:45:58,884:INFO:Set up train/test split.
2022-11-16 19:45:58,888:INFO:Set up index.
2022-11-16 19:45:58,888:INFO:Set up folding strategy.
2022-11-16 19:45:58,888:INFO:Assigning column types.
2022-11-16 19:45:58,895:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-16 19:45:58,895:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-16 19:45:58,901:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-16 19:45:58,907:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:45:58,974:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,025:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,027:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:45:59,027:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:45:59,028:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:45:59,028:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,034:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,039:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,106:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,157:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,158:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:45:59,158:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:45:59,159:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:45:59,159:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-16 19:45:59,165:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,171:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,237:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,288:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,289:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:45:59,289:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:45:59,289:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:45:59,295:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,300:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,365:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,415:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,416:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:45:59,416:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:45:59,417:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:45:59,417:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-16 19:45:59,427:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,492:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,557:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,558:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:45:59,559:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:45:59,559:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:45:59,571:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,635:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,685:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,689:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:45:59,690:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:45:59,690:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:45:59,691:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-16 19:45:59,774:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,825:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,826:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:45:59,826:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:45:59,827:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:45:59,904:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,957:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:45:59,958:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:45:59,959:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:45:59,959:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:45:59,960:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-16 19:46:00,035:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:46:00,086:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:46:00,087:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:46:00,087:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:46:00,167:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:46:00,218:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:46:00,218:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:46:00,219:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:46:00,219:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-16 19:46:00,350:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:46:00,350:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:46:00,351:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:46:00,479:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:46:00,480:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:46:00,482:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:46:00,486:INFO:Preparing preprocessing pipeline...
2022-11-16 19:46:00,487:INFO:Set up simple imputation.
2022-11-16 19:46:00,488:INFO:Set up variance threshold.
2022-11-16 19:46:00,529:INFO:Finished creating preprocessing pipeline.
2022-11-16 19:46:00,536:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-16 19:46:00,537:INFO:Creating final display dataframe.
2022-11-16 19:46:00,727:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 12)
4         Train data shape    (607, 12)
5          Test data shape    (261, 12)
6         Numeric features           11
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         9a48
2022-11-16 19:46:00,888:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:46:00,888:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:46:00,888:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:46:01,019:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:46:01,019:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:46:01,020:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:46:01,027:INFO:setup() successfully completed in 2.17s...............
2022-11-16 19:46:01,027:INFO:Initializing compare_models()
2022-11-16 19:46:01,027:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29ae5950>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f2a29ae5950>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-16 19:46:01,027:INFO:Checking exceptions
2022-11-16 19:46:01,029:INFO:Preparing display monitor
2022-11-16 19:46:01,127:INFO:Initializing Linear Regression
2022-11-16 19:46:01,128:INFO:Total runtime is 6.945927937825521e-06 minutes
2022-11-16 19:46:01,137:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:01,137:INFO:Initializing create_model()
2022-11-16 19:46:01,138:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29ae5950>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2b35ead0>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:01,138:INFO:Checking exceptions
2022-11-16 19:46:01,141:INFO:Importing libraries
2022-11-16 19:46:01,141:INFO:Copying training dataset
2022-11-16 19:46:01,145:INFO:Defining folds
2022-11-16 19:46:01,146:INFO:Declaring metric variables
2022-11-16 19:46:01,155:INFO:Importing untrained model
2022-11-16 19:46:01,164:INFO:Linear Regression Imported successfully
2022-11-16 19:46:01,182:INFO:Starting cross validation
2022-11-16 19:46:01,186:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:02,801:INFO:Calculating mean and std
2022-11-16 19:46:02,808:INFO:Creating metrics dataframe
2022-11-16 19:46:02,817:INFO:Uploading results into container
2022-11-16 19:46:02,818:INFO:Uploading model into container now
2022-11-16 19:46:02,819:INFO:master_model_container: 1
2022-11-16 19:46:02,819:INFO:display_container: 2
2022-11-16 19:46:02,820:INFO:LinearRegression(n_jobs=-1)
2022-11-16 19:46:02,820:INFO:create_model() successfully completed......................................
2022-11-16 19:46:02,964:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:02,964:INFO:Creating metrics dataframe
2022-11-16 19:46:02,982:INFO:Initializing Lasso Regression
2022-11-16 19:46:02,983:INFO:Total runtime is 0.030922186374664307 minutes
2022-11-16 19:46:02,995:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:02,997:INFO:Initializing create_model()
2022-11-16 19:46:03,001:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29ae5950>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2b35ead0>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:03,002:INFO:Checking exceptions
2022-11-16 19:46:03,004:INFO:Importing libraries
2022-11-16 19:46:03,004:INFO:Copying training dataset
2022-11-16 19:46:03,010:INFO:Defining folds
2022-11-16 19:46:03,010:INFO:Declaring metric variables
2022-11-16 19:46:03,025:INFO:Importing untrained model
2022-11-16 19:46:03,039:INFO:Lasso Regression Imported successfully
2022-11-16 19:46:03,056:INFO:Starting cross validation
2022-11-16 19:46:03,058:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:03,834:INFO:Calculating mean and std
2022-11-16 19:46:03,838:INFO:Creating metrics dataframe
2022-11-16 19:46:03,885:INFO:Uploading results into container
2022-11-16 19:46:03,886:INFO:Uploading model into container now
2022-11-16 19:46:03,887:INFO:master_model_container: 2
2022-11-16 19:46:03,887:INFO:display_container: 2
2022-11-16 19:46:03,888:INFO:Lasso(random_state=123)
2022-11-16 19:46:03,888:INFO:create_model() successfully completed......................................
2022-11-16 19:46:04,026:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:04,027:INFO:Creating metrics dataframe
2022-11-16 19:46:04,045:INFO:Initializing Ridge Regression
2022-11-16 19:46:04,047:INFO:Total runtime is 0.0486554225285848 minutes
2022-11-16 19:46:04,055:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:04,056:INFO:Initializing create_model()
2022-11-16 19:46:04,056:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29ae5950>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2b35ead0>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:04,057:INFO:Checking exceptions
2022-11-16 19:46:04,059:INFO:Importing libraries
2022-11-16 19:46:04,059:INFO:Copying training dataset
2022-11-16 19:46:04,067:INFO:Defining folds
2022-11-16 19:46:04,067:INFO:Declaring metric variables
2022-11-16 19:46:04,076:INFO:Importing untrained model
2022-11-16 19:46:04,086:INFO:Ridge Regression Imported successfully
2022-11-16 19:46:04,103:INFO:Starting cross validation
2022-11-16 19:46:04,105:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:04,409:INFO:Calculating mean and std
2022-11-16 19:46:04,413:INFO:Creating metrics dataframe
2022-11-16 19:46:04,423:INFO:Uploading results into container
2022-11-16 19:46:04,424:INFO:Uploading model into container now
2022-11-16 19:46:04,425:INFO:master_model_container: 3
2022-11-16 19:46:04,425:INFO:display_container: 2
2022-11-16 19:46:04,426:INFO:Ridge(random_state=123)
2022-11-16 19:46:04,426:INFO:create_model() successfully completed......................................
2022-11-16 19:46:04,563:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:04,564:INFO:Creating metrics dataframe
2022-11-16 19:46:04,591:INFO:Initializing Elastic Net
2022-11-16 19:46:04,592:INFO:Total runtime is 0.05774068037668864 minutes
2022-11-16 19:46:04,600:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:04,601:INFO:Initializing create_model()
2022-11-16 19:46:04,602:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29ae5950>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2b35ead0>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:04,605:INFO:Checking exceptions
2022-11-16 19:46:04,608:INFO:Importing libraries
2022-11-16 19:46:04,609:INFO:Copying training dataset
2022-11-16 19:46:04,614:INFO:Defining folds
2022-11-16 19:46:04,616:INFO:Declaring metric variables
2022-11-16 19:46:04,626:INFO:Importing untrained model
2022-11-16 19:46:04,636:INFO:Elastic Net Imported successfully
2022-11-16 19:46:04,657:INFO:Starting cross validation
2022-11-16 19:46:04,659:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:04,993:INFO:Calculating mean and std
2022-11-16 19:46:04,995:INFO:Creating metrics dataframe
2022-11-16 19:46:05,011:INFO:Uploading results into container
2022-11-16 19:46:05,012:INFO:Uploading model into container now
2022-11-16 19:46:05,013:INFO:master_model_container: 4
2022-11-16 19:46:05,013:INFO:display_container: 2
2022-11-16 19:46:05,014:INFO:ElasticNet(random_state=123)
2022-11-16 19:46:05,014:INFO:create_model() successfully completed......................................
2022-11-16 19:46:05,152:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:05,152:INFO:Creating metrics dataframe
2022-11-16 19:46:05,173:INFO:Initializing Least Angle Regression
2022-11-16 19:46:05,174:INFO:Total runtime is 0.06743893623352051 minutes
2022-11-16 19:46:05,181:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:05,182:INFO:Initializing create_model()
2022-11-16 19:46:05,183:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29ae5950>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2b35ead0>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:05,183:INFO:Checking exceptions
2022-11-16 19:46:05,186:INFO:Importing libraries
2022-11-16 19:46:05,186:INFO:Copying training dataset
2022-11-16 19:46:05,195:INFO:Defining folds
2022-11-16 19:46:05,196:INFO:Declaring metric variables
2022-11-16 19:46:05,206:INFO:Importing untrained model
2022-11-16 19:46:05,214:INFO:Least Angle Regression Imported successfully
2022-11-16 19:46:05,234:INFO:Starting cross validation
2022-11-16 19:46:05,236:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:05,283:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:05,314:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:05,363:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:05,414:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:05,418:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:05,461:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:05,491:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:05,521:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:05,537:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:05,564:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:05,578:INFO:Calculating mean and std
2022-11-16 19:46:05,581:INFO:Creating metrics dataframe
2022-11-16 19:46:05,591:INFO:Uploading results into container
2022-11-16 19:46:05,592:INFO:Uploading model into container now
2022-11-16 19:46:05,593:INFO:master_model_container: 5
2022-11-16 19:46:05,593:INFO:display_container: 2
2022-11-16 19:46:05,594:INFO:Lars(random_state=123)
2022-11-16 19:46:05,594:INFO:create_model() successfully completed......................................
2022-11-16 19:46:05,730:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:05,731:INFO:Creating metrics dataframe
2022-11-16 19:46:05,755:INFO:Initializing Lasso Least Angle Regression
2022-11-16 19:46:05,755:INFO:Total runtime is 0.07713538805643719 minutes
2022-11-16 19:46:05,763:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:05,764:INFO:Initializing create_model()
2022-11-16 19:46:05,765:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29ae5950>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2b35ead0>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:05,765:INFO:Checking exceptions
2022-11-16 19:46:05,768:INFO:Importing libraries
2022-11-16 19:46:05,768:INFO:Copying training dataset
2022-11-16 19:46:05,775:INFO:Defining folds
2022-11-16 19:46:05,775:INFO:Declaring metric variables
2022-11-16 19:46:05,788:INFO:Importing untrained model
2022-11-16 19:46:05,799:INFO:Lasso Least Angle Regression Imported successfully
2022-11-16 19:46:05,815:INFO:Starting cross validation
2022-11-16 19:46:05,817:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:05,867:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:46:05,898:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:46:05,934:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:46:05,964:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:46:05,999:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:46:06,037:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:46:06,045:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:46:06,092:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:46:06,101:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:46:06,131:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:46:06,145:INFO:Calculating mean and std
2022-11-16 19:46:06,148:INFO:Creating metrics dataframe
2022-11-16 19:46:06,164:INFO:Uploading results into container
2022-11-16 19:46:06,165:INFO:Uploading model into container now
2022-11-16 19:46:06,166:INFO:master_model_container: 6
2022-11-16 19:46:06,166:INFO:display_container: 2
2022-11-16 19:46:06,167:INFO:LassoLars(random_state=123)
2022-11-16 19:46:06,167:INFO:create_model() successfully completed......................................
2022-11-16 19:46:06,299:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:06,299:INFO:Creating metrics dataframe
2022-11-16 19:46:06,319:INFO:Initializing Orthogonal Matching Pursuit
2022-11-16 19:46:06,320:INFO:Total runtime is 0.08654422760009767 minutes
2022-11-16 19:46:06,330:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:06,331:INFO:Initializing create_model()
2022-11-16 19:46:06,331:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29ae5950>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2b35ead0>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:06,331:INFO:Checking exceptions
2022-11-16 19:46:06,334:INFO:Importing libraries
2022-11-16 19:46:06,334:INFO:Copying training dataset
2022-11-16 19:46:06,339:INFO:Defining folds
2022-11-16 19:46:06,340:INFO:Declaring metric variables
2022-11-16 19:46:06,351:INFO:Importing untrained model
2022-11-16 19:46:06,363:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-16 19:46:06,382:INFO:Starting cross validation
2022-11-16 19:46:06,384:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:06,424:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:06,457:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:06,498:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:06,520:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:06,554:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:06,598:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:06,602:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:06,639:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:06,641:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:06,674:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:06,694:INFO:Calculating mean and std
2022-11-16 19:46:06,697:INFO:Creating metrics dataframe
2022-11-16 19:46:06,703:INFO:Uploading results into container
2022-11-16 19:46:06,711:INFO:Uploading model into container now
2022-11-16 19:46:06,721:INFO:master_model_container: 7
2022-11-16 19:46:06,721:INFO:display_container: 2
2022-11-16 19:46:06,722:INFO:OrthogonalMatchingPursuit()
2022-11-16 19:46:06,722:INFO:create_model() successfully completed......................................
2022-11-16 19:46:06,857:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:06,858:INFO:Creating metrics dataframe
2022-11-16 19:46:06,881:INFO:Initializing Bayesian Ridge
2022-11-16 19:46:06,881:INFO:Total runtime is 0.09590310255686443 minutes
2022-11-16 19:46:06,891:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:06,892:INFO:Initializing create_model()
2022-11-16 19:46:06,892:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29ae5950>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2b35ead0>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:06,893:INFO:Checking exceptions
2022-11-16 19:46:06,896:INFO:Importing libraries
2022-11-16 19:46:06,896:INFO:Copying training dataset
2022-11-16 19:46:06,906:INFO:Defining folds
2022-11-16 19:46:06,909:INFO:Declaring metric variables
2022-11-16 19:46:06,922:INFO:Importing untrained model
2022-11-16 19:46:06,932:INFO:Bayesian Ridge Imported successfully
2022-11-16 19:46:06,948:INFO:Starting cross validation
2022-11-16 19:46:06,951:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:07,267:INFO:Calculating mean and std
2022-11-16 19:46:07,270:INFO:Creating metrics dataframe
2022-11-16 19:46:07,287:INFO:Uploading results into container
2022-11-16 19:46:07,288:INFO:Uploading model into container now
2022-11-16 19:46:07,289:INFO:master_model_container: 8
2022-11-16 19:46:07,289:INFO:display_container: 2
2022-11-16 19:46:07,290:INFO:BayesianRidge()
2022-11-16 19:46:07,290:INFO:create_model() successfully completed......................................
2022-11-16 19:46:07,421:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:07,421:INFO:Creating metrics dataframe
2022-11-16 19:46:07,441:INFO:Initializing Passive Aggressive Regressor
2022-11-16 19:46:07,442:INFO:Total runtime is 0.10524472792943321 minutes
2022-11-16 19:46:07,451:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:07,451:INFO:Initializing create_model()
2022-11-16 19:46:07,452:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29ae5950>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2b35ead0>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:07,452:INFO:Checking exceptions
2022-11-16 19:46:07,454:INFO:Importing libraries
2022-11-16 19:46:07,455:INFO:Copying training dataset
2022-11-16 19:46:07,463:INFO:Defining folds
2022-11-16 19:46:07,463:INFO:Declaring metric variables
2022-11-16 19:46:07,474:INFO:Importing untrained model
2022-11-16 19:46:07,483:INFO:Passive Aggressive Regressor Imported successfully
2022-11-16 19:46:07,499:INFO:Starting cross validation
2022-11-16 19:46:07,502:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:07,845:INFO:Calculating mean and std
2022-11-16 19:46:07,848:INFO:Creating metrics dataframe
2022-11-16 19:46:07,866:INFO:Uploading results into container
2022-11-16 19:46:07,867:INFO:Uploading model into container now
2022-11-16 19:46:07,868:INFO:master_model_container: 9
2022-11-16 19:46:07,868:INFO:display_container: 2
2022-11-16 19:46:07,869:INFO:PassiveAggressiveRegressor(random_state=123)
2022-11-16 19:46:07,869:INFO:create_model() successfully completed......................................
2022-11-16 19:46:08,004:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:08,006:INFO:Creating metrics dataframe
2022-11-16 19:46:08,027:INFO:Initializing Huber Regressor
2022-11-16 19:46:08,029:INFO:Total runtime is 0.11502253214518231 minutes
2022-11-16 19:46:08,038:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:08,039:INFO:Initializing create_model()
2022-11-16 19:46:08,039:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29ae5950>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2b35ead0>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:08,039:INFO:Checking exceptions
2022-11-16 19:46:08,042:INFO:Importing libraries
2022-11-16 19:46:08,043:INFO:Copying training dataset
2022-11-16 19:46:08,051:INFO:Defining folds
2022-11-16 19:46:08,052:INFO:Declaring metric variables
2022-11-16 19:46:08,063:INFO:Importing untrained model
2022-11-16 19:46:08,073:INFO:Huber Regressor Imported successfully
2022-11-16 19:46:08,088:INFO:Starting cross validation
2022-11-16 19:46:08,091:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:08,198:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:46:08,283:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:46:08,306:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:46:08,438:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:46:08,504:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:46:08,538:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:46:08,679:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-16 19:46:08,691:INFO:Calculating mean and std
2022-11-16 19:46:08,694:INFO:Creating metrics dataframe
2022-11-16 19:46:08,702:INFO:Uploading results into container
2022-11-16 19:46:08,703:INFO:Uploading model into container now
2022-11-16 19:46:08,704:INFO:master_model_container: 10
2022-11-16 19:46:08,704:INFO:display_container: 2
2022-11-16 19:46:08,705:INFO:HuberRegressor()
2022-11-16 19:46:08,705:INFO:create_model() successfully completed......................................
2022-11-16 19:46:08,848:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:08,849:INFO:Creating metrics dataframe
2022-11-16 19:46:08,877:INFO:Initializing K Neighbors Regressor
2022-11-16 19:46:08,878:INFO:Total runtime is 0.1291774670283 minutes
2022-11-16 19:46:08,888:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:08,889:INFO:Initializing create_model()
2022-11-16 19:46:08,889:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29ae5950>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2b35ead0>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:08,889:INFO:Checking exceptions
2022-11-16 19:46:08,891:INFO:Importing libraries
2022-11-16 19:46:08,892:INFO:Copying training dataset
2022-11-16 19:46:08,902:INFO:Defining folds
2022-11-16 19:46:08,903:INFO:Declaring metric variables
2022-11-16 19:46:08,920:INFO:Importing untrained model
2022-11-16 19:46:08,931:INFO:K Neighbors Regressor Imported successfully
2022-11-16 19:46:08,951:INFO:Starting cross validation
2022-11-16 19:46:08,954:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:09,705:INFO:Calculating mean and std
2022-11-16 19:46:09,707:INFO:Creating metrics dataframe
2022-11-16 19:46:09,726:INFO:Uploading results into container
2022-11-16 19:46:09,727:INFO:Uploading model into container now
2022-11-16 19:46:09,728:INFO:master_model_container: 11
2022-11-16 19:46:09,728:INFO:display_container: 2
2022-11-16 19:46:09,729:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-16 19:46:09,729:INFO:create_model() successfully completed......................................
2022-11-16 19:46:09,876:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:09,876:INFO:Creating metrics dataframe
2022-11-16 19:46:09,897:INFO:Initializing Decision Tree Regressor
2022-11-16 19:46:09,897:INFO:Total runtime is 0.14617144664128623 minutes
2022-11-16 19:46:09,909:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:09,909:INFO:Initializing create_model()
2022-11-16 19:46:09,910:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29ae5950>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2b35ead0>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:09,910:INFO:Checking exceptions
2022-11-16 19:46:09,918:INFO:Importing libraries
2022-11-16 19:46:09,918:INFO:Copying training dataset
2022-11-16 19:46:09,924:INFO:Defining folds
2022-11-16 19:46:09,925:INFO:Declaring metric variables
2022-11-16 19:46:09,936:INFO:Importing untrained model
2022-11-16 19:46:09,950:INFO:Decision Tree Regressor Imported successfully
2022-11-16 19:46:09,968:INFO:Starting cross validation
2022-11-16 19:46:09,970:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:10,351:INFO:Calculating mean and std
2022-11-16 19:46:10,354:INFO:Creating metrics dataframe
2022-11-16 19:46:10,366:INFO:Uploading results into container
2022-11-16 19:46:10,368:INFO:Uploading model into container now
2022-11-16 19:46:10,369:INFO:master_model_container: 12
2022-11-16 19:46:10,369:INFO:display_container: 2
2022-11-16 19:46:10,370:INFO:DecisionTreeRegressor(random_state=123)
2022-11-16 19:46:10,370:INFO:create_model() successfully completed......................................
2022-11-16 19:46:10,502:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:10,503:INFO:Creating metrics dataframe
2022-11-16 19:46:10,530:INFO:Initializing Random Forest Regressor
2022-11-16 19:46:10,533:INFO:Total runtime is 0.15676132837931317 minutes
2022-11-16 19:46:10,542:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:10,545:INFO:Initializing create_model()
2022-11-16 19:46:10,545:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29ae5950>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2b35ead0>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:10,546:INFO:Checking exceptions
2022-11-16 19:46:10,548:INFO:Importing libraries
2022-11-16 19:46:10,551:INFO:Copying training dataset
2022-11-16 19:46:10,556:INFO:Defining folds
2022-11-16 19:46:10,557:INFO:Declaring metric variables
2022-11-16 19:46:10,570:INFO:Importing untrained model
2022-11-16 19:46:10,585:INFO:Random Forest Regressor Imported successfully
2022-11-16 19:46:10,604:INFO:Starting cross validation
2022-11-16 19:46:10,606:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:15,658:INFO:Calculating mean and std
2022-11-16 19:46:15,665:INFO:Creating metrics dataframe
2022-11-16 19:46:15,681:INFO:Uploading results into container
2022-11-16 19:46:15,682:INFO:Uploading model into container now
2022-11-16 19:46:15,683:INFO:master_model_container: 13
2022-11-16 19:46:15,683:INFO:display_container: 2
2022-11-16 19:46:15,684:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-16 19:46:15,684:INFO:create_model() successfully completed......................................
2022-11-16 19:46:15,847:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:15,848:INFO:Creating metrics dataframe
2022-11-16 19:46:15,870:INFO:Initializing Extra Trees Regressor
2022-11-16 19:46:15,871:INFO:Total runtime is 0.24572205940882366 minutes
2022-11-16 19:46:15,881:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:15,882:INFO:Initializing create_model()
2022-11-16 19:46:15,882:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29ae5950>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2b35ead0>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:15,882:INFO:Checking exceptions
2022-11-16 19:46:15,885:INFO:Importing libraries
2022-11-16 19:46:15,886:INFO:Copying training dataset
2022-11-16 19:46:15,902:INFO:Defining folds
2022-11-16 19:46:15,903:INFO:Declaring metric variables
2022-11-16 19:46:15,913:INFO:Importing untrained model
2022-11-16 19:46:15,929:INFO:Extra Trees Regressor Imported successfully
2022-11-16 19:46:15,949:INFO:Starting cross validation
2022-11-16 19:46:15,953:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:18,960:INFO:Calculating mean and std
2022-11-16 19:46:18,966:INFO:Creating metrics dataframe
2022-11-16 19:46:18,979:INFO:Uploading results into container
2022-11-16 19:46:18,980:INFO:Uploading model into container now
2022-11-16 19:46:18,980:INFO:master_model_container: 14
2022-11-16 19:46:18,981:INFO:display_container: 2
2022-11-16 19:46:18,981:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-16 19:46:18,981:INFO:create_model() successfully completed......................................
2022-11-16 19:46:19,116:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:19,117:INFO:Creating metrics dataframe
2022-11-16 19:46:19,139:INFO:Initializing AdaBoost Regressor
2022-11-16 19:46:19,140:INFO:Total runtime is 0.30021055142084757 minutes
2022-11-16 19:46:19,149:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:19,150:INFO:Initializing create_model()
2022-11-16 19:46:19,151:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29ae5950>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2b35ead0>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:19,151:INFO:Checking exceptions
2022-11-16 19:46:19,154:INFO:Importing libraries
2022-11-16 19:46:19,154:INFO:Copying training dataset
2022-11-16 19:46:19,160:INFO:Defining folds
2022-11-16 19:46:19,161:INFO:Declaring metric variables
2022-11-16 19:46:19,170:INFO:Importing untrained model
2022-11-16 19:46:19,186:INFO:AdaBoost Regressor Imported successfully
2022-11-16 19:46:19,206:INFO:Starting cross validation
2022-11-16 19:46:19,212:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:20,392:INFO:Calculating mean and std
2022-11-16 19:46:20,394:INFO:Creating metrics dataframe
2022-11-16 19:46:20,406:INFO:Uploading results into container
2022-11-16 19:46:20,407:INFO:Uploading model into container now
2022-11-16 19:46:20,408:INFO:master_model_container: 15
2022-11-16 19:46:20,408:INFO:display_container: 2
2022-11-16 19:46:20,408:INFO:AdaBoostRegressor(random_state=123)
2022-11-16 19:46:20,409:INFO:create_model() successfully completed......................................
2022-11-16 19:46:20,543:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:20,544:INFO:Creating metrics dataframe
2022-11-16 19:46:20,567:INFO:Initializing Gradient Boosting Regressor
2022-11-16 19:46:20,568:INFO:Total runtime is 0.3240099350611369 minutes
2022-11-16 19:46:20,577:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:20,578:INFO:Initializing create_model()
2022-11-16 19:46:20,578:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29ae5950>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2b35ead0>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:20,578:INFO:Checking exceptions
2022-11-16 19:46:20,581:INFO:Importing libraries
2022-11-16 19:46:20,581:INFO:Copying training dataset
2022-11-16 19:46:20,590:INFO:Defining folds
2022-11-16 19:46:20,590:INFO:Declaring metric variables
2022-11-16 19:46:20,599:INFO:Importing untrained model
2022-11-16 19:46:20,614:INFO:Gradient Boosting Regressor Imported successfully
2022-11-16 19:46:20,632:INFO:Starting cross validation
2022-11-16 19:46:20,634:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:22,514:INFO:Calculating mean and std
2022-11-16 19:46:22,519:INFO:Creating metrics dataframe
2022-11-16 19:46:22,529:INFO:Uploading results into container
2022-11-16 19:46:22,530:INFO:Uploading model into container now
2022-11-16 19:46:22,531:INFO:master_model_container: 16
2022-11-16 19:46:22,531:INFO:display_container: 2
2022-11-16 19:46:22,532:INFO:GradientBoostingRegressor(random_state=123)
2022-11-16 19:46:22,532:INFO:create_model() successfully completed......................................
2022-11-16 19:46:22,666:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:22,667:INFO:Creating metrics dataframe
2022-11-16 19:46:22,695:INFO:Initializing Light Gradient Boosting Machine
2022-11-16 19:46:22,704:INFO:Total runtime is 0.359608805179596 minutes
2022-11-16 19:46:22,710:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:22,711:INFO:Initializing create_model()
2022-11-16 19:46:22,716:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29ae5950>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2b35ead0>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:22,717:INFO:Checking exceptions
2022-11-16 19:46:22,719:INFO:Importing libraries
2022-11-16 19:46:22,719:INFO:Copying training dataset
2022-11-16 19:46:22,724:INFO:Defining folds
2022-11-16 19:46:22,724:INFO:Declaring metric variables
2022-11-16 19:46:22,743:INFO:Importing untrained model
2022-11-16 19:46:22,756:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-16 19:46:22,776:INFO:Starting cross validation
2022-11-16 19:46:22,779:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:23,654:INFO:Calculating mean and std
2022-11-16 19:46:23,658:INFO:Creating metrics dataframe
2022-11-16 19:46:23,668:INFO:Uploading results into container
2022-11-16 19:46:23,669:INFO:Uploading model into container now
2022-11-16 19:46:23,670:INFO:master_model_container: 17
2022-11-16 19:46:23,670:INFO:display_container: 2
2022-11-16 19:46:23,671:INFO:LGBMRegressor(random_state=123)
2022-11-16 19:46:23,671:INFO:create_model() successfully completed......................................
2022-11-16 19:46:23,807:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:23,807:INFO:Creating metrics dataframe
2022-11-16 19:46:23,835:INFO:Initializing Dummy Regressor
2022-11-16 19:46:23,836:INFO:Total runtime is 0.37847910324732464 minutes
2022-11-16 19:46:23,847:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:23,848:INFO:Initializing create_model()
2022-11-16 19:46:23,848:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29ae5950>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2b35ead0>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:23,849:INFO:Checking exceptions
2022-11-16 19:46:23,852:INFO:Importing libraries
2022-11-16 19:46:23,853:INFO:Copying training dataset
2022-11-16 19:46:23,860:INFO:Defining folds
2022-11-16 19:46:23,860:INFO:Declaring metric variables
2022-11-16 19:46:23,871:INFO:Importing untrained model
2022-11-16 19:46:23,880:INFO:Dummy Regressor Imported successfully
2022-11-16 19:46:23,897:INFO:Starting cross validation
2022-11-16 19:46:23,898:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:24,184:INFO:Calculating mean and std
2022-11-16 19:46:24,187:INFO:Creating metrics dataframe
2022-11-16 19:46:24,201:INFO:Uploading results into container
2022-11-16 19:46:24,203:INFO:Uploading model into container now
2022-11-16 19:46:24,204:INFO:master_model_container: 18
2022-11-16 19:46:24,204:INFO:display_container: 2
2022-11-16 19:46:24,205:INFO:DummyRegressor()
2022-11-16 19:46:24,205:INFO:create_model() successfully completed......................................
2022-11-16 19:46:24,347:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:24,348:INFO:Creating metrics dataframe
2022-11-16 19:46:24,393:INFO:Initializing create_model()
2022-11-16 19:46:24,393:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a29ae5950>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:24,393:INFO:Checking exceptions
2022-11-16 19:46:24,399:INFO:Importing libraries
2022-11-16 19:46:24,400:INFO:Copying training dataset
2022-11-16 19:46:24,404:INFO:Defining folds
2022-11-16 19:46:24,404:INFO:Declaring metric variables
2022-11-16 19:46:24,405:INFO:Importing untrained model
2022-11-16 19:46:24,405:INFO:Declaring custom model
2022-11-16 19:46:24,406:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-16 19:46:24,408:INFO:Cross validation set to False
2022-11-16 19:46:24,408:INFO:Fitting Model
2022-11-16 19:46:24,448:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:24,452:INFO:OrthogonalMatchingPursuit()
2022-11-16 19:46:24,453:INFO:create_model() successfully completed......................................
2022-11-16 19:46:24,691:INFO:master_model_container: 18
2022-11-16 19:46:24,697:INFO:display_container: 2
2022-11-16 19:46:24,700:INFO:OrthogonalMatchingPursuit()
2022-11-16 19:46:24,701:INFO:compare_models() successfully completed......................................
2022-11-16 19:46:30,789:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  app.launch_new_instance()

2022-11-16 19:46:30,791:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:46:30,792:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:46:30,793:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:46:30,794:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:46:30,794:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:46:30,795:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:46:30,796:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:46:30,797:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:46:30,798:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:46:30,799:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 19:46:30,804:INFO:PyCaret RegressionExperiment
2022-11-16 19:46:30,804:INFO:Logging name: FullData
2022-11-16 19:46:30,804:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-16 19:46:30,804:INFO:version 3.0.0.rc4
2022-11-16 19:46:30,804:INFO:Initializing setup()
2022-11-16 19:46:30,804:INFO:self.USI: e4c8
2022-11-16 19:46:30,804:INFO:self.variable_keys: {'display_container', '_ml_usecase', 'y_train', 'X_train', 'y_test', '_all_metrics', 'pipeline', 'transform_target_param', '_all_models_internal', '_gpu_n_jobs_param', 'logging_param', 'log_plots_param', '_all_models', 'memory', 'target_param', 'data', 'gpu_param', 'X', 'fold_shuffle_param', 'X_test', 'html_param', 'master_model_container', 'n_jobs_param', 'fold_groups_param', 'y', 'exp_id', 'exp_name_log', '_available_plots', 'variable_keys', 'seed', 'fold_generator', 'USI', 'idx', 'transform_target_method_param'}
2022-11-16 19:46:30,804:INFO:Checking environment
2022-11-16 19:46:30,805:INFO:python_version: 3.7.15
2022-11-16 19:46:30,805:INFO:python_build: ('default', 'Oct 12 2022 19:14:55')
2022-11-16 19:46:30,805:INFO:machine: x86_64
2022-11-16 19:46:30,805:INFO:platform: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-16 19:46:30,805:INFO:Memory: svmem(total=13616361472, available=11720548352, percent=13.9, used=1775095808, free=6213664768, active=1004732416, inactive=6004822016, buffers=166117376, cached=5461483520, shared=1363968, slab=293109760)
2022-11-16 19:46:30,805:INFO:Physical Core: 1
2022-11-16 19:46:30,805:INFO:Logical Core: 2
2022-11-16 19:46:30,806:INFO:Checking libraries
2022-11-16 19:46:30,806:INFO:System:
2022-11-16 19:46:30,806:INFO:    python: 3.7.15 (default, Oct 12 2022, 19:14:55)  [GCC 7.5.0]
2022-11-16 19:46:30,806:INFO:executable: /usr/bin/python3
2022-11-16 19:46:30,806:INFO:   machine: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-16 19:46:30,806:INFO:PyCaret required dependencies:
2022-11-16 19:46:30,807:INFO:                 pip: 21.1.3
2022-11-16 19:46:30,807:INFO:          setuptools: 57.4.0
2022-11-16 19:46:30,807:INFO:             pycaret: 3.0.0rc4
2022-11-16 19:46:30,807:INFO:             IPython: 7.9.0
2022-11-16 19:46:30,807:INFO:          ipywidgets: 7.7.1
2022-11-16 19:46:30,807:INFO:                tqdm: 4.64.1
2022-11-16 19:46:30,807:INFO:               numpy: 1.21.6
2022-11-16 19:46:30,807:INFO:              pandas: 1.3.5
2022-11-16 19:46:30,808:INFO:              jinja2: 3.0.0
2022-11-16 19:46:30,808:INFO:               scipy: 1.7.3
2022-11-16 19:46:30,808:INFO:              joblib: 1.2.0
2022-11-16 19:46:30,809:INFO:             sklearn: 1.0.2
2022-11-16 19:46:30,809:INFO:                pyod: 1.0.6
2022-11-16 19:46:30,809:INFO:            imblearn: 0.8.1
2022-11-16 19:46:30,809:INFO:   category_encoders: 2.5.1.post0
2022-11-16 19:46:30,810:INFO:            lightgbm: 3.3.3
2022-11-16 19:46:30,810:INFO:               numba: 0.55.2
2022-11-16 19:46:30,810:INFO:            requests: 2.28.1
2022-11-16 19:46:30,810:INFO:          matplotlib: 3.5.3
2022-11-16 19:46:30,810:INFO:          scikitplot: 0.3.7
2022-11-16 19:46:30,810:INFO:         yellowbrick: 1.5
2022-11-16 19:46:30,810:INFO:              plotly: 5.5.0
2022-11-16 19:46:30,811:INFO:             kaleido: 0.2.1
2022-11-16 19:46:30,811:INFO:         statsmodels: 0.12.2
2022-11-16 19:46:30,811:INFO:              sktime: 0.13.4
2022-11-16 19:46:30,811:INFO:               tbats: 1.1.1
2022-11-16 19:46:30,811:INFO:            pmdarima: 1.8.5
2022-11-16 19:46:30,811:INFO:              psutil: 5.9.4
2022-11-16 19:46:30,811:INFO:PyCaret optional dependencies:
2022-11-16 19:46:30,812:INFO:                shap: Not installed
2022-11-16 19:46:30,812:INFO:           interpret: Not installed
2022-11-16 19:46:30,812:INFO:                umap: Not installed
2022-11-16 19:46:30,812:INFO:    pandas_profiling: 1.4.1
2022-11-16 19:46:30,812:INFO:  explainerdashboard: Not installed
2022-11-16 19:46:30,812:INFO:             autoviz: Not installed
2022-11-16 19:46:30,812:INFO:           fairlearn: Not installed
2022-11-16 19:46:30,812:INFO:             xgboost: 0.90
2022-11-16 19:46:30,813:INFO:            catboost: Not installed
2022-11-16 19:46:30,813:INFO:              kmodes: Not installed
2022-11-16 19:46:30,813:INFO:             mlxtend: 0.14.0
2022-11-16 19:46:30,813:INFO:       statsforecast: Not installed
2022-11-16 19:46:30,813:INFO:        tune_sklearn: Not installed
2022-11-16 19:46:30,813:INFO:                 ray: Not installed
2022-11-16 19:46:30,813:INFO:            hyperopt: 0.1.2
2022-11-16 19:46:30,814:INFO:              optuna: Not installed
2022-11-16 19:46:30,814:INFO:               skopt: Not installed
2022-11-16 19:46:30,814:INFO:              mlflow: Not installed
2022-11-16 19:46:30,814:INFO:              gradio: Not installed
2022-11-16 19:46:30,814:INFO:             fastapi: Not installed
2022-11-16 19:46:30,814:INFO:             uvicorn: Not installed
2022-11-16 19:46:30,814:INFO:              m2cgen: Not installed
2022-11-16 19:46:30,814:INFO:           evidently: Not installed
2022-11-16 19:46:30,815:INFO:                nltk: 3.7
2022-11-16 19:46:30,815:INFO:            pyLDAvis: Not installed
2022-11-16 19:46:30,815:INFO:              gensim: 3.6.0
2022-11-16 19:46:30,815:INFO:               spacy: 3.4.2
2022-11-16 19:46:30,815:INFO:           wordcloud: 1.8.2.2
2022-11-16 19:46:30,815:INFO:            textblob: 0.15.3
2022-11-16 19:46:30,815:INFO:               fugue: Not installed
2022-11-16 19:46:30,816:INFO:           streamlit: Not installed
2022-11-16 19:46:30,816:INFO:             prophet: 1.1.1
2022-11-16 19:46:30,816:INFO:None
2022-11-16 19:46:30,816:INFO:Set up data.
2022-11-16 19:46:30,823:INFO:Set up train/test split.
2022-11-16 19:46:30,827:INFO:Set up index.
2022-11-16 19:46:30,828:INFO:Set up folding strategy.
2022-11-16 19:46:30,828:INFO:Assigning column types.
2022-11-16 19:46:30,834:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-16 19:46:30,834:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-16 19:46:30,840:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-16 19:46:30,845:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:46:30,914:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:46:30,967:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:46:30,968:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:46:30,968:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:46:30,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:46:30,969:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-16 19:46:30,975:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-16 19:46:30,980:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:46:31,046:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:46:31,096:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:46:31,097:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:46:31,097:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:46:31,097:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:46:31,097:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-16 19:46:31,103:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-16 19:46:31,109:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:46:31,175:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:46:31,224:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:46:31,226:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:46:31,226:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:46:31,226:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:46:31,232:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-16 19:46:31,238:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:46:31,302:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:46:31,353:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:46:31,354:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:46:31,354:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:46:31,354:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:46:31,355:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-16 19:46:31,365:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:46:31,430:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:46:31,494:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:46:31,495:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:46:31,495:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:46:31,496:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:46:31,506:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-16 19:46:31,577:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:46:31,628:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:46:31,629:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:46:31,630:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:46:31,630:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:46:31,631:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-16 19:46:31,707:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:46:31,759:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:46:31,760:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:46:31,761:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:46:31,761:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:46:31,839:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:46:31,890:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-16 19:46:31,891:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:46:31,891:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:46:31,892:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:46:31,892:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-16 19:46:31,969:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:46:32,021:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:46:32,021:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:46:32,022:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:46:32,101:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-16 19:46:32,157:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:46:32,157:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:46:32,158:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:46:32,158:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-16 19:46:32,285:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:46:32,286:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:46:32,286:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:46:32,413:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:46:32,413:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:46:32,414:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:46:32,415:INFO:Preparing preprocessing pipeline...
2022-11-16 19:46:32,416:INFO:Set up simple imputation.
2022-11-16 19:46:32,416:INFO:Set up variance threshold.
2022-11-16 19:46:32,464:INFO:Finished creating preprocessing pipeline.
2022-11-16 19:46:32,475:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-16 19:46:32,475:INFO:Creating final display dataframe.
2022-11-16 19:46:32,650:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape   (1229, 12)
4         Train data shape    (860, 12)
5          Test data shape    (369, 12)
6         Numeric features           11
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         e4c8
2022-11-16 19:46:32,818:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:46:32,818:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:46:32,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:46:32,954:INFO:Soft dependency imported: xgboost: 0.90
2022-11-16 19:46:32,954:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-16 19:46:32,955:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-16 19:46:32,962:INFO:setup() successfully completed in 2.16s...............
2022-11-16 19:46:32,962:INFO:Initializing compare_models()
2022-11-16 19:46:32,963:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a319b6650>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f2a319b6650>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-16 19:46:32,963:INFO:Checking exceptions
2022-11-16 19:46:32,964:INFO:Preparing display monitor
2022-11-16 19:46:33,051:INFO:Initializing Linear Regression
2022-11-16 19:46:33,052:INFO:Total runtime is 1.6836325327555337e-05 minutes
2022-11-16 19:46:33,062:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:33,062:INFO:Initializing create_model()
2022-11-16 19:46:33,062:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a319b6650>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2bde9990>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:33,063:INFO:Checking exceptions
2022-11-16 19:46:33,065:INFO:Importing libraries
2022-11-16 19:46:33,066:INFO:Copying training dataset
2022-11-16 19:46:33,070:INFO:Defining folds
2022-11-16 19:46:33,070:INFO:Declaring metric variables
2022-11-16 19:46:33,078:INFO:Importing untrained model
2022-11-16 19:46:33,087:INFO:Linear Regression Imported successfully
2022-11-16 19:46:33,104:INFO:Starting cross validation
2022-11-16 19:46:33,109:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:35,197:INFO:Calculating mean and std
2022-11-16 19:46:35,204:INFO:Creating metrics dataframe
2022-11-16 19:46:35,211:INFO:Uploading results into container
2022-11-16 19:46:35,212:INFO:Uploading model into container now
2022-11-16 19:46:35,213:INFO:master_model_container: 1
2022-11-16 19:46:35,213:INFO:display_container: 2
2022-11-16 19:46:35,213:INFO:LinearRegression(n_jobs=-1)
2022-11-16 19:46:35,214:INFO:create_model() successfully completed......................................
2022-11-16 19:46:35,359:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:35,360:INFO:Creating metrics dataframe
2022-11-16 19:46:35,377:INFO:Initializing Lasso Regression
2022-11-16 19:46:35,378:INFO:Total runtime is 0.03877936204274496 minutes
2022-11-16 19:46:35,386:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:35,387:INFO:Initializing create_model()
2022-11-16 19:46:35,387:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a319b6650>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2bde9990>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:35,387:INFO:Checking exceptions
2022-11-16 19:46:35,391:INFO:Importing libraries
2022-11-16 19:46:35,391:INFO:Copying training dataset
2022-11-16 19:46:35,397:INFO:Defining folds
2022-11-16 19:46:35,398:INFO:Declaring metric variables
2022-11-16 19:46:35,409:INFO:Importing untrained model
2022-11-16 19:46:35,421:INFO:Lasso Regression Imported successfully
2022-11-16 19:46:35,445:INFO:Starting cross validation
2022-11-16 19:46:35,447:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:36,209:INFO:Calculating mean and std
2022-11-16 19:46:36,221:INFO:Creating metrics dataframe
2022-11-16 19:46:36,265:INFO:Uploading results into container
2022-11-16 19:46:36,273:INFO:Uploading model into container now
2022-11-16 19:46:36,277:INFO:master_model_container: 2
2022-11-16 19:46:36,277:INFO:display_container: 2
2022-11-16 19:46:36,278:INFO:Lasso(random_state=123)
2022-11-16 19:46:36,278:INFO:create_model() successfully completed......................................
2022-11-16 19:46:36,421:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:36,422:INFO:Creating metrics dataframe
2022-11-16 19:46:36,450:INFO:Initializing Ridge Regression
2022-11-16 19:46:36,451:INFO:Total runtime is 0.05666590134302775 minutes
2022-11-16 19:46:36,460:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:36,461:INFO:Initializing create_model()
2022-11-16 19:46:36,461:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a319b6650>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2bde9990>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:36,461:INFO:Checking exceptions
2022-11-16 19:46:36,467:INFO:Importing libraries
2022-11-16 19:46:36,468:INFO:Copying training dataset
2022-11-16 19:46:36,478:INFO:Defining folds
2022-11-16 19:46:36,479:INFO:Declaring metric variables
2022-11-16 19:46:36,494:INFO:Importing untrained model
2022-11-16 19:46:36,506:INFO:Ridge Regression Imported successfully
2022-11-16 19:46:36,526:INFO:Starting cross validation
2022-11-16 19:46:36,528:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:36,853:INFO:Calculating mean and std
2022-11-16 19:46:36,855:INFO:Creating metrics dataframe
2022-11-16 19:46:36,863:INFO:Uploading results into container
2022-11-16 19:46:36,864:INFO:Uploading model into container now
2022-11-16 19:46:36,866:INFO:master_model_container: 3
2022-11-16 19:46:36,866:INFO:display_container: 2
2022-11-16 19:46:36,867:INFO:Ridge(random_state=123)
2022-11-16 19:46:36,868:INFO:create_model() successfully completed......................................
2022-11-16 19:46:37,007:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:37,008:INFO:Creating metrics dataframe
2022-11-16 19:46:37,028:INFO:Initializing Elastic Net
2022-11-16 19:46:37,029:INFO:Total runtime is 0.06629615624745687 minutes
2022-11-16 19:46:37,039:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:37,040:INFO:Initializing create_model()
2022-11-16 19:46:37,040:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a319b6650>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2bde9990>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:37,040:INFO:Checking exceptions
2022-11-16 19:46:37,043:INFO:Importing libraries
2022-11-16 19:46:37,043:INFO:Copying training dataset
2022-11-16 19:46:37,049:INFO:Defining folds
2022-11-16 19:46:37,050:INFO:Declaring metric variables
2022-11-16 19:46:37,064:INFO:Importing untrained model
2022-11-16 19:46:37,077:INFO:Elastic Net Imported successfully
2022-11-16 19:46:37,095:INFO:Starting cross validation
2022-11-16 19:46:37,099:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:37,396:INFO:Calculating mean and std
2022-11-16 19:46:37,398:INFO:Creating metrics dataframe
2022-11-16 19:46:37,413:INFO:Uploading results into container
2022-11-16 19:46:37,414:INFO:Uploading model into container now
2022-11-16 19:46:37,414:INFO:master_model_container: 4
2022-11-16 19:46:37,415:INFO:display_container: 2
2022-11-16 19:46:37,415:INFO:ElasticNet(random_state=123)
2022-11-16 19:46:37,415:INFO:create_model() successfully completed......................................
2022-11-16 19:46:37,548:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:37,549:INFO:Creating metrics dataframe
2022-11-16 19:46:37,568:INFO:Initializing Least Angle Regression
2022-11-16 19:46:37,568:INFO:Total runtime is 0.07528977394104004 minutes
2022-11-16 19:46:37,578:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:37,579:INFO:Initializing create_model()
2022-11-16 19:46:37,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a319b6650>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2bde9990>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:37,585:INFO:Checking exceptions
2022-11-16 19:46:37,588:INFO:Importing libraries
2022-11-16 19:46:37,588:INFO:Copying training dataset
2022-11-16 19:46:37,595:INFO:Defining folds
2022-11-16 19:46:37,595:INFO:Declaring metric variables
2022-11-16 19:46:37,603:INFO:Importing untrained model
2022-11-16 19:46:37,612:INFO:Least Angle Regression Imported successfully
2022-11-16 19:46:37,630:INFO:Starting cross validation
2022-11-16 19:46:37,632:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:37,698:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:37,735:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:37,761:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:37,807:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:37,832:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:37,877:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:37,898:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:37,927:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:37,955:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:37,972:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:37,992:INFO:Calculating mean and std
2022-11-16 19:46:37,997:INFO:Creating metrics dataframe
2022-11-16 19:46:38,006:INFO:Uploading results into container
2022-11-16 19:46:38,008:INFO:Uploading model into container now
2022-11-16 19:46:38,009:INFO:master_model_container: 5
2022-11-16 19:46:38,010:INFO:display_container: 2
2022-11-16 19:46:38,010:INFO:Lars(random_state=123)
2022-11-16 19:46:38,010:INFO:create_model() successfully completed......................................
2022-11-16 19:46:38,143:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:38,143:INFO:Creating metrics dataframe
2022-11-16 19:46:38,167:INFO:Initializing Lasso Least Angle Regression
2022-11-16 19:46:38,168:INFO:Total runtime is 0.08529193798700968 minutes
2022-11-16 19:46:38,179:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:38,180:INFO:Initializing create_model()
2022-11-16 19:46:38,180:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a319b6650>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2bde9990>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:38,181:INFO:Checking exceptions
2022-11-16 19:46:38,184:INFO:Importing libraries
2022-11-16 19:46:38,184:INFO:Copying training dataset
2022-11-16 19:46:38,193:INFO:Defining folds
2022-11-16 19:46:38,193:INFO:Declaring metric variables
2022-11-16 19:46:38,204:INFO:Importing untrained model
2022-11-16 19:46:38,216:INFO:Lasso Least Angle Regression Imported successfully
2022-11-16 19:46:38,235:INFO:Starting cross validation
2022-11-16 19:46:38,237:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:38,281:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:46:38,308:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:46:38,341:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:46:38,371:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:46:38,412:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:46:38,449:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:46:38,452:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:46:38,489:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:46:38,514:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:46:38,533:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:46:38,548:INFO:Calculating mean and std
2022-11-16 19:46:38,551:INFO:Creating metrics dataframe
2022-11-16 19:46:38,565:INFO:Uploading results into container
2022-11-16 19:46:38,566:INFO:Uploading model into container now
2022-11-16 19:46:38,567:INFO:master_model_container: 6
2022-11-16 19:46:38,567:INFO:display_container: 2
2022-11-16 19:46:38,568:INFO:LassoLars(random_state=123)
2022-11-16 19:46:38,568:INFO:create_model() successfully completed......................................
2022-11-16 19:46:38,706:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:38,706:INFO:Creating metrics dataframe
2022-11-16 19:46:38,738:INFO:Initializing Orthogonal Matching Pursuit
2022-11-16 19:46:38,738:INFO:Total runtime is 0.09478487571080525 minutes
2022-11-16 19:46:38,744:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:38,745:INFO:Initializing create_model()
2022-11-16 19:46:38,745:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a319b6650>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2bde9990>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:38,746:INFO:Checking exceptions
2022-11-16 19:46:38,749:INFO:Importing libraries
2022-11-16 19:46:38,750:INFO:Copying training dataset
2022-11-16 19:46:38,761:INFO:Defining folds
2022-11-16 19:46:38,762:INFO:Declaring metric variables
2022-11-16 19:46:38,774:INFO:Importing untrained model
2022-11-16 19:46:38,784:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-16 19:46:38,801:INFO:Starting cross validation
2022-11-16 19:46:38,804:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:38,848:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:38,876:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:38,911:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:38,948:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:38,983:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:39,024:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:39,040:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:39,078:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:39,083:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:39,114:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-16 19:46:39,129:INFO:Calculating mean and std
2022-11-16 19:46:39,131:INFO:Creating metrics dataframe
2022-11-16 19:46:39,145:INFO:Uploading results into container
2022-11-16 19:46:39,147:INFO:Uploading model into container now
2022-11-16 19:46:39,148:INFO:master_model_container: 7
2022-11-16 19:46:39,148:INFO:display_container: 2
2022-11-16 19:46:39,149:INFO:OrthogonalMatchingPursuit()
2022-11-16 19:46:39,149:INFO:create_model() successfully completed......................................
2022-11-16 19:46:39,281:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:39,281:INFO:Creating metrics dataframe
2022-11-16 19:46:39,301:INFO:Initializing Bayesian Ridge
2022-11-16 19:46:39,301:INFO:Total runtime is 0.10417464574178059 minutes
2022-11-16 19:46:39,311:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:39,312:INFO:Initializing create_model()
2022-11-16 19:46:39,312:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a319b6650>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2bde9990>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:39,318:INFO:Checking exceptions
2022-11-16 19:46:39,320:INFO:Importing libraries
2022-11-16 19:46:39,320:INFO:Copying training dataset
2022-11-16 19:46:39,324:INFO:Defining folds
2022-11-16 19:46:39,325:INFO:Declaring metric variables
2022-11-16 19:46:39,338:INFO:Importing untrained model
2022-11-16 19:46:39,352:INFO:Bayesian Ridge Imported successfully
2022-11-16 19:46:39,371:INFO:Starting cross validation
2022-11-16 19:46:39,374:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:39,707:INFO:Calculating mean and std
2022-11-16 19:46:39,715:INFO:Creating metrics dataframe
2022-11-16 19:46:39,730:INFO:Uploading results into container
2022-11-16 19:46:39,743:INFO:Uploading model into container now
2022-11-16 19:46:39,744:INFO:master_model_container: 8
2022-11-16 19:46:39,744:INFO:display_container: 2
2022-11-16 19:46:39,745:INFO:BayesianRidge()
2022-11-16 19:46:39,745:INFO:create_model() successfully completed......................................
2022-11-16 19:46:39,877:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:39,877:INFO:Creating metrics dataframe
2022-11-16 19:46:39,898:INFO:Initializing Passive Aggressive Regressor
2022-11-16 19:46:39,899:INFO:Total runtime is 0.11412980953852335 minutes
2022-11-16 19:46:39,910:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:39,911:INFO:Initializing create_model()
2022-11-16 19:46:39,911:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a319b6650>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2bde9990>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:39,912:INFO:Checking exceptions
2022-11-16 19:46:39,915:INFO:Importing libraries
2022-11-16 19:46:39,916:INFO:Copying training dataset
2022-11-16 19:46:39,923:INFO:Defining folds
2022-11-16 19:46:39,924:INFO:Declaring metric variables
2022-11-16 19:46:39,936:INFO:Importing untrained model
2022-11-16 19:46:39,950:INFO:Passive Aggressive Regressor Imported successfully
2022-11-16 19:46:39,972:INFO:Starting cross validation
2022-11-16 19:46:39,975:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:40,281:INFO:Calculating mean and std
2022-11-16 19:46:40,283:INFO:Creating metrics dataframe
2022-11-16 19:46:40,301:INFO:Uploading results into container
2022-11-16 19:46:40,302:INFO:Uploading model into container now
2022-11-16 19:46:40,303:INFO:master_model_container: 9
2022-11-16 19:46:40,303:INFO:display_container: 2
2022-11-16 19:46:40,304:INFO:PassiveAggressiveRegressor(random_state=123)
2022-11-16 19:46:40,304:INFO:create_model() successfully completed......................................
2022-11-16 19:46:40,432:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:40,432:INFO:Creating metrics dataframe
2022-11-16 19:46:40,452:INFO:Initializing Huber Regressor
2022-11-16 19:46:40,453:INFO:Total runtime is 0.12336510419845581 minutes
2022-11-16 19:46:40,463:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:40,465:INFO:Initializing create_model()
2022-11-16 19:46:40,465:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a319b6650>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2bde9990>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:40,465:INFO:Checking exceptions
2022-11-16 19:46:40,468:INFO:Importing libraries
2022-11-16 19:46:40,468:INFO:Copying training dataset
2022-11-16 19:46:40,474:INFO:Defining folds
2022-11-16 19:46:40,475:INFO:Declaring metric variables
2022-11-16 19:46:40,486:INFO:Importing untrained model
2022-11-16 19:46:40,503:INFO:Huber Regressor Imported successfully
2022-11-16 19:46:40,525:INFO:Starting cross validation
2022-11-16 19:46:40,527:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:41,063:INFO:Calculating mean and std
2022-11-16 19:46:41,065:INFO:Creating metrics dataframe
2022-11-16 19:46:41,081:INFO:Uploading results into container
2022-11-16 19:46:41,082:INFO:Uploading model into container now
2022-11-16 19:46:41,083:INFO:master_model_container: 10
2022-11-16 19:46:41,083:INFO:display_container: 2
2022-11-16 19:46:41,084:INFO:HuberRegressor()
2022-11-16 19:46:41,084:INFO:create_model() successfully completed......................................
2022-11-16 19:46:41,215:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:41,216:INFO:Creating metrics dataframe
2022-11-16 19:46:41,236:INFO:Initializing K Neighbors Regressor
2022-11-16 19:46:41,237:INFO:Total runtime is 0.1364286422729492 minutes
2022-11-16 19:46:41,248:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:41,249:INFO:Initializing create_model()
2022-11-16 19:46:41,250:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a319b6650>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2bde9990>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:41,251:INFO:Checking exceptions
2022-11-16 19:46:41,253:INFO:Importing libraries
2022-11-16 19:46:41,253:INFO:Copying training dataset
2022-11-16 19:46:41,259:INFO:Defining folds
2022-11-16 19:46:41,260:INFO:Declaring metric variables
2022-11-16 19:46:41,273:INFO:Importing untrained model
2022-11-16 19:46:41,285:INFO:K Neighbors Regressor Imported successfully
2022-11-16 19:46:41,304:INFO:Starting cross validation
2022-11-16 19:46:41,306:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:42,058:INFO:Calculating mean and std
2022-11-16 19:46:42,063:INFO:Creating metrics dataframe
2022-11-16 19:46:42,077:INFO:Uploading results into container
2022-11-16 19:46:42,078:INFO:Uploading model into container now
2022-11-16 19:46:42,079:INFO:master_model_container: 11
2022-11-16 19:46:42,079:INFO:display_container: 2
2022-11-16 19:46:42,079:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-16 19:46:42,079:INFO:create_model() successfully completed......................................
2022-11-16 19:46:42,209:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:42,209:INFO:Creating metrics dataframe
2022-11-16 19:46:42,231:INFO:Initializing Decision Tree Regressor
2022-11-16 19:46:42,232:INFO:Total runtime is 0.15301160415013632 minutes
2022-11-16 19:46:42,240:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:42,241:INFO:Initializing create_model()
2022-11-16 19:46:42,241:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a319b6650>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2bde9990>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:42,242:INFO:Checking exceptions
2022-11-16 19:46:42,244:INFO:Importing libraries
2022-11-16 19:46:42,245:INFO:Copying training dataset
2022-11-16 19:46:42,251:INFO:Defining folds
2022-11-16 19:46:42,256:INFO:Declaring metric variables
2022-11-16 19:46:42,268:INFO:Importing untrained model
2022-11-16 19:46:42,277:INFO:Decision Tree Regressor Imported successfully
2022-11-16 19:46:42,298:INFO:Starting cross validation
2022-11-16 19:46:42,300:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:42,677:INFO:Calculating mean and std
2022-11-16 19:46:42,679:INFO:Creating metrics dataframe
2022-11-16 19:46:42,688:INFO:Uploading results into container
2022-11-16 19:46:42,689:INFO:Uploading model into container now
2022-11-16 19:46:42,689:INFO:master_model_container: 12
2022-11-16 19:46:42,690:INFO:display_container: 2
2022-11-16 19:46:42,690:INFO:DecisionTreeRegressor(random_state=123)
2022-11-16 19:46:42,690:INFO:create_model() successfully completed......................................
2022-11-16 19:46:42,831:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:42,831:INFO:Creating metrics dataframe
2022-11-16 19:46:42,855:INFO:Initializing Random Forest Regressor
2022-11-16 19:46:42,859:INFO:Total runtime is 0.1634213964144389 minutes
2022-11-16 19:46:42,868:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:42,872:INFO:Initializing create_model()
2022-11-16 19:46:42,872:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a319b6650>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2bde9990>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:42,873:INFO:Checking exceptions
2022-11-16 19:46:42,876:INFO:Importing libraries
2022-11-16 19:46:42,876:INFO:Copying training dataset
2022-11-16 19:46:42,883:INFO:Defining folds
2022-11-16 19:46:42,883:INFO:Declaring metric variables
2022-11-16 19:46:42,895:INFO:Importing untrained model
2022-11-16 19:46:42,904:INFO:Random Forest Regressor Imported successfully
2022-11-16 19:46:42,921:INFO:Starting cross validation
2022-11-16 19:46:42,923:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:49,232:INFO:Calculating mean and std
2022-11-16 19:46:49,236:INFO:Creating metrics dataframe
2022-11-16 19:46:49,251:INFO:Uploading results into container
2022-11-16 19:46:49,252:INFO:Uploading model into container now
2022-11-16 19:46:49,253:INFO:master_model_container: 13
2022-11-16 19:46:49,253:INFO:display_container: 2
2022-11-16 19:46:49,254:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-16 19:46:49,254:INFO:create_model() successfully completed......................................
2022-11-16 19:46:49,390:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:49,391:INFO:Creating metrics dataframe
2022-11-16 19:46:49,412:INFO:Initializing Extra Trees Regressor
2022-11-16 19:46:49,412:INFO:Total runtime is 0.27269330819447835 minutes
2022-11-16 19:46:49,423:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:49,424:INFO:Initializing create_model()
2022-11-16 19:46:49,424:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a319b6650>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2bde9990>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:49,424:INFO:Checking exceptions
2022-11-16 19:46:49,428:INFO:Importing libraries
2022-11-16 19:46:49,428:INFO:Copying training dataset
2022-11-16 19:46:49,435:INFO:Defining folds
2022-11-16 19:46:49,440:INFO:Declaring metric variables
2022-11-16 19:46:49,455:INFO:Importing untrained model
2022-11-16 19:46:49,467:INFO:Extra Trees Regressor Imported successfully
2022-11-16 19:46:49,488:INFO:Starting cross validation
2022-11-16 19:46:49,490:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:52,915:INFO:Calculating mean and std
2022-11-16 19:46:52,920:INFO:Creating metrics dataframe
2022-11-16 19:46:52,936:INFO:Uploading results into container
2022-11-16 19:46:52,937:INFO:Uploading model into container now
2022-11-16 19:46:52,938:INFO:master_model_container: 14
2022-11-16 19:46:52,938:INFO:display_container: 2
2022-11-16 19:46:52,939:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-16 19:46:52,939:INFO:create_model() successfully completed......................................
2022-11-16 19:46:53,072:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:53,073:INFO:Creating metrics dataframe
2022-11-16 19:46:53,099:INFO:Initializing AdaBoost Regressor
2022-11-16 19:46:53,100:INFO:Total runtime is 0.3341465353965759 minutes
2022-11-16 19:46:53,110:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:53,110:INFO:Initializing create_model()
2022-11-16 19:46:53,111:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a319b6650>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2bde9990>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:53,111:INFO:Checking exceptions
2022-11-16 19:46:53,114:INFO:Importing libraries
2022-11-16 19:46:53,114:INFO:Copying training dataset
2022-11-16 19:46:53,121:INFO:Defining folds
2022-11-16 19:46:53,126:INFO:Declaring metric variables
2022-11-16 19:46:53,135:INFO:Importing untrained model
2022-11-16 19:46:53,145:INFO:AdaBoost Regressor Imported successfully
2022-11-16 19:46:53,162:INFO:Starting cross validation
2022-11-16 19:46:53,164:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:54,516:INFO:Calculating mean and std
2022-11-16 19:46:54,518:INFO:Creating metrics dataframe
2022-11-16 19:46:54,527:INFO:Uploading results into container
2022-11-16 19:46:54,531:INFO:Uploading model into container now
2022-11-16 19:46:54,532:INFO:master_model_container: 15
2022-11-16 19:46:54,532:INFO:display_container: 2
2022-11-16 19:46:54,533:INFO:AdaBoostRegressor(random_state=123)
2022-11-16 19:46:54,533:INFO:create_model() successfully completed......................................
2022-11-16 19:46:54,668:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:54,669:INFO:Creating metrics dataframe
2022-11-16 19:46:54,698:INFO:Initializing Gradient Boosting Regressor
2022-11-16 19:46:54,699:INFO:Total runtime is 0.3607981046040853 minutes
2022-11-16 19:46:54,709:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:54,710:INFO:Initializing create_model()
2022-11-16 19:46:54,710:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a319b6650>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2bde9990>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:54,710:INFO:Checking exceptions
2022-11-16 19:46:54,713:INFO:Importing libraries
2022-11-16 19:46:54,714:INFO:Copying training dataset
2022-11-16 19:46:54,720:INFO:Defining folds
2022-11-16 19:46:54,721:INFO:Declaring metric variables
2022-11-16 19:46:54,737:INFO:Importing untrained model
2022-11-16 19:46:54,754:INFO:Gradient Boosting Regressor Imported successfully
2022-11-16 19:46:54,772:INFO:Starting cross validation
2022-11-16 19:46:54,775:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:57,239:INFO:Calculating mean and std
2022-11-16 19:46:57,241:INFO:Creating metrics dataframe
2022-11-16 19:46:57,254:INFO:Uploading results into container
2022-11-16 19:46:57,255:INFO:Uploading model into container now
2022-11-16 19:46:57,256:INFO:master_model_container: 16
2022-11-16 19:46:57,256:INFO:display_container: 2
2022-11-16 19:46:57,257:INFO:GradientBoostingRegressor(random_state=123)
2022-11-16 19:46:57,257:INFO:create_model() successfully completed......................................
2022-11-16 19:46:57,399:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:57,399:INFO:Creating metrics dataframe
2022-11-16 19:46:57,422:INFO:Initializing Light Gradient Boosting Machine
2022-11-16 19:46:57,423:INFO:Total runtime is 0.4062028686205546 minutes
2022-11-16 19:46:57,434:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:57,437:INFO:Initializing create_model()
2022-11-16 19:46:57,437:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a319b6650>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2bde9990>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:57,437:INFO:Checking exceptions
2022-11-16 19:46:57,440:INFO:Importing libraries
2022-11-16 19:46:57,441:INFO:Copying training dataset
2022-11-16 19:46:57,445:INFO:Defining folds
2022-11-16 19:46:57,446:INFO:Declaring metric variables
2022-11-16 19:46:57,459:INFO:Importing untrained model
2022-11-16 19:46:57,474:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-16 19:46:57,493:INFO:Starting cross validation
2022-11-16 19:46:57,495:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:58,790:INFO:Calculating mean and std
2022-11-16 19:46:58,792:INFO:Creating metrics dataframe
2022-11-16 19:46:58,809:INFO:Uploading results into container
2022-11-16 19:46:58,811:INFO:Uploading model into container now
2022-11-16 19:46:58,813:INFO:master_model_container: 17
2022-11-16 19:46:58,815:INFO:display_container: 2
2022-11-16 19:46:58,816:INFO:LGBMRegressor(random_state=123)
2022-11-16 19:46:58,816:INFO:create_model() successfully completed......................................
2022-11-16 19:46:58,951:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:58,951:INFO:Creating metrics dataframe
2022-11-16 19:46:58,974:INFO:Initializing Dummy Regressor
2022-11-16 19:46:58,974:INFO:Total runtime is 0.43205520311991374 minutes
2022-11-16 19:46:58,986:INFO:SubProcess create_model() called ==================================
2022-11-16 19:46:58,988:INFO:Initializing create_model()
2022-11-16 19:46:58,990:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a319b6650>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f2a2bde9990>, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:58,991:INFO:Checking exceptions
2022-11-16 19:46:58,994:INFO:Importing libraries
2022-11-16 19:46:58,994:INFO:Copying training dataset
2022-11-16 19:46:59,001:INFO:Defining folds
2022-11-16 19:46:59,001:INFO:Declaring metric variables
2022-11-16 19:46:59,012:INFO:Importing untrained model
2022-11-16 19:46:59,022:INFO:Dummy Regressor Imported successfully
2022-11-16 19:46:59,040:INFO:Starting cross validation
2022-11-16 19:46:59,042:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-16 19:46:59,323:INFO:Calculating mean and std
2022-11-16 19:46:59,325:INFO:Creating metrics dataframe
2022-11-16 19:46:59,337:INFO:Uploading results into container
2022-11-16 19:46:59,338:INFO:Uploading model into container now
2022-11-16 19:46:59,341:INFO:master_model_container: 18
2022-11-16 19:46:59,341:INFO:display_container: 2
2022-11-16 19:46:59,342:INFO:DummyRegressor()
2022-11-16 19:46:59,342:INFO:create_model() successfully completed......................................
2022-11-16 19:46:59,478:INFO:SubProcess create_model() end ==================================
2022-11-16 19:46:59,479:INFO:Creating metrics dataframe
2022-11-16 19:46:59,528:INFO:Initializing create_model()
2022-11-16 19:46:59,528:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f2a319b6650>, estimator=LassoLars(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-16 19:46:59,529:INFO:Checking exceptions
2022-11-16 19:46:59,536:INFO:Importing libraries
2022-11-16 19:46:59,536:INFO:Copying training dataset
2022-11-16 19:46:59,541:INFO:Defining folds
2022-11-16 19:46:59,542:INFO:Declaring metric variables
2022-11-16 19:46:59,543:INFO:Importing untrained model
2022-11-16 19:46:59,543:INFO:Declaring custom model
2022-11-16 19:46:59,545:INFO:Least Angle Regression Imported successfully
2022-11-16 19:46:59,547:INFO:Cross validation set to False
2022-11-16 19:46:59,547:INFO:Fitting Model
2022-11-16 19:46:59,589:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-16 19:46:59,591:INFO:LassoLars(random_state=123)
2022-11-16 19:46:59,591:INFO:create_model() successfully completed......................................
2022-11-16 19:46:59,856:INFO:master_model_container: 18
2022-11-16 19:46:59,856:INFO:display_container: 2
2022-11-16 19:46:59,857:INFO:LassoLars(random_state=123)
2022-11-16 19:46:59,858:INFO:compare_models() successfully completed......................................
2022-11-16 20:01:05,164:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  import sys

2022-11-16 20:01:05,165:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  

2022-11-16 20:01:05,166:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  if __name__ == '__main__':

2022-11-16 20:01:05,168:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  # Remove the CWD from sys.path while we load stuff.

2022-11-16 20:01:05,169:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  if sys.path[0] == '':

2022-11-16 20:01:05,170:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  del sys.path[0]

2022-11-16 20:01:05,171:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  

2022-11-16 20:01:05,172:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  from ipykernel import kernelapp as app

2022-11-16 20:01:05,174:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  app.launch_new_instance()

2022-11-16 20:01:05,175:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 20:01:05,176:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 20:01:32,040:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  import sys

2022-11-16 20:01:32,042:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  

2022-11-16 20:01:32,043:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  if __name__ == '__main__':

2022-11-16 20:01:32,045:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  # Remove the CWD from sys.path while we load stuff.

2022-11-16 20:01:32,046:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  if sys.path[0] == '':

2022-11-16 20:01:32,048:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  del sys.path[0]

2022-11-16 20:01:32,049:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  

2022-11-16 20:01:32,050:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  from ipykernel import kernelapp as app

2022-11-16 20:01:32,051:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  app.launch_new_instance()

2022-11-16 20:01:32,052:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 20:01:32,054:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-16 20:02:36,581:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2022-11-16 20:07:22,895:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2022-11-16 20:08:40,962:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2022-11-16 20:08:58,827:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2022-11-16 20:09:09,215:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2022-11-16 20:09:16,768:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2022-11-16 20:09:30,772:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2022-11-16 20:09:34,838:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2022-11-16 20:09:38,467:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2022-11-18 21:19:03,827:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-18 21:19:04,183:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-18 21:19:04,183:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-18 21:19:04,183:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-11-18 21:19:05,555:INFO:Soft dependency imported: prophet: 1.1.1
2022-11-18 21:19:06,127:INFO:PyCaret RegressionExperiment
2022-11-18 21:19:06,128:INFO:Logging name: FullData
2022-11-18 21:19:06,129:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-18 21:19:06,129:INFO:version 3.0.0.rc4
2022-11-18 21:19:06,129:INFO:Initializing setup()
2022-11-18 21:19:06,129:INFO:self.USI: fcaa
2022-11-18 21:19:06,130:INFO:self.variable_keys: {'_available_plots', 'seed', 'log_plots_param', '_gpu_n_jobs_param', 'USI', 'pipeline', '_all_models_internal', 'fold_generator', 'variable_keys', 'gpu_param', 'exp_id', 'X_test', 'memory', '_ml_usecase', 'y', 'fold_groups_param', 'transform_target_method_param', 'display_container', 'logging_param', '_all_metrics', 'fold_shuffle_param', 'n_jobs_param', 'exp_name_log', 'data', 'y_test', 'html_param', 'target_param', 'transform_target_param', '_all_models', 'y_train', 'X_train', 'X', 'master_model_container', 'idx'}
2022-11-18 21:19:06,130:INFO:Checking environment
2022-11-18 21:19:06,130:INFO:python_version: 3.7.15
2022-11-18 21:19:06,130:INFO:python_build: ('default', 'Oct 12 2022 19:14:55')
2022-11-18 21:19:06,131:INFO:machine: x86_64
2022-11-18 21:19:06,131:INFO:platform: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-18 21:19:06,131:INFO:Memory: svmem(total=13616353280, available=11800801280, percent=13.3, used=1626673152, free=7849627648, active=1036324864, inactive=4371595264, buffers=166055936, cached=3973996544, shared=1290240, slab=265089024)
2022-11-18 21:19:06,132:INFO:Physical Core: 1
2022-11-18 21:19:06,132:INFO:Logical Core: 2
2022-11-18 21:19:06,132:INFO:Checking libraries
2022-11-18 21:19:06,132:INFO:System:
2022-11-18 21:19:06,133:INFO:    python: 3.7.15 (default, Oct 12 2022, 19:14:55)  [GCC 7.5.0]
2022-11-18 21:19:06,133:INFO:executable: /usr/bin/python3
2022-11-18 21:19:06,133:INFO:   machine: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-18 21:19:06,133:INFO:PyCaret required dependencies:
2022-11-18 21:19:06,133:INFO:                 pip: 21.1.3
2022-11-18 21:19:06,133:INFO:          setuptools: 57.4.0
2022-11-18 21:19:06,134:INFO:             pycaret: 3.0.0rc4
2022-11-18 21:19:06,134:INFO:             IPython: 7.9.0
2022-11-18 21:19:06,134:INFO:          ipywidgets: 7.7.1
2022-11-18 21:19:06,134:INFO:                tqdm: 4.64.1
2022-11-18 21:19:06,134:INFO:               numpy: 1.21.6
2022-11-18 21:19:06,134:INFO:              pandas: 1.3.5
2022-11-18 21:19:06,135:INFO:              jinja2: 3.0.0
2022-11-18 21:19:06,135:INFO:               scipy: 1.7.3
2022-11-18 21:19:06,135:INFO:              joblib: 1.2.0
2022-11-18 21:19:06,135:INFO:             sklearn: 1.0.2
2022-11-18 21:19:06,135:INFO:                pyod: 1.0.6
2022-11-18 21:19:06,135:INFO:            imblearn: 0.8.1
2022-11-18 21:19:06,136:INFO:   category_encoders: 2.5.1.post0
2022-11-18 21:19:06,136:INFO:            lightgbm: 3.3.3
2022-11-18 21:19:06,136:INFO:               numba: 0.55.2
2022-11-18 21:19:06,136:INFO:            requests: 2.28.1
2022-11-18 21:19:06,136:INFO:          matplotlib: 3.5.3
2022-11-18 21:19:06,136:INFO:          scikitplot: 0.3.7
2022-11-18 21:19:06,136:INFO:         yellowbrick: 1.5
2022-11-18 21:19:06,137:INFO:              plotly: 5.5.0
2022-11-18 21:19:06,137:INFO:             kaleido: 0.2.1
2022-11-18 21:19:06,137:INFO:         statsmodels: 0.12.2
2022-11-18 21:19:06,137:INFO:              sktime: 0.13.4
2022-11-18 21:19:06,137:INFO:               tbats: 1.1.1
2022-11-18 21:19:06,137:INFO:            pmdarima: 1.8.5
2022-11-18 21:19:06,138:INFO:              psutil: 5.9.4
2022-11-18 21:19:06,138:INFO:PyCaret optional dependencies:
2022-11-18 21:19:06,148:INFO:                shap: Not installed
2022-11-18 21:19:06,148:INFO:           interpret: Not installed
2022-11-18 21:19:06,148:INFO:                umap: Not installed
2022-11-18 21:19:06,149:INFO:    pandas_profiling: 1.4.1
2022-11-18 21:19:06,149:INFO:  explainerdashboard: Not installed
2022-11-18 21:19:06,149:INFO:             autoviz: Not installed
2022-11-18 21:19:06,149:INFO:           fairlearn: Not installed
2022-11-18 21:19:06,149:INFO:             xgboost: 0.90
2022-11-18 21:19:06,149:INFO:            catboost: Not installed
2022-11-18 21:19:06,150:INFO:              kmodes: Not installed
2022-11-18 21:19:06,150:INFO:             mlxtend: 0.14.0
2022-11-18 21:19:06,150:INFO:       statsforecast: Not installed
2022-11-18 21:19:06,150:INFO:        tune_sklearn: Not installed
2022-11-18 21:19:06,150:INFO:                 ray: Not installed
2022-11-18 21:19:06,150:INFO:            hyperopt: 0.1.2
2022-11-18 21:19:06,150:INFO:              optuna: Not installed
2022-11-18 21:19:06,151:INFO:               skopt: Not installed
2022-11-18 21:19:06,151:INFO:              mlflow: Not installed
2022-11-18 21:19:06,151:INFO:              gradio: Not installed
2022-11-18 21:19:06,151:INFO:             fastapi: Not installed
2022-11-18 21:19:06,151:INFO:             uvicorn: Not installed
2022-11-18 21:19:06,151:INFO:              m2cgen: Not installed
2022-11-18 21:19:06,151:INFO:           evidently: Not installed
2022-11-18 21:19:06,152:INFO:                nltk: 3.7
2022-11-18 21:19:06,152:INFO:            pyLDAvis: Not installed
2022-11-18 21:19:06,152:INFO:              gensim: 3.6.0
2022-11-18 21:19:06,152:INFO:               spacy: 3.4.2
2022-11-18 21:19:06,152:INFO:           wordcloud: 1.8.2.2
2022-11-18 21:19:06,152:INFO:            textblob: 0.15.3
2022-11-18 21:19:06,153:INFO:               fugue: Not installed
2022-11-18 21:19:06,153:INFO:           streamlit: Not installed
2022-11-18 21:19:06,153:INFO:             prophet: 1.1.1
2022-11-18 21:19:06,153:INFO:None
2022-11-18 21:19:06,153:INFO:Set up data.
2022-11-18 21:19:06,169:INFO:Set up train/test split.
2022-11-18 21:19:06,175:INFO:Set up index.
2022-11-18 21:19:06,175:INFO:Set up folding strategy.
2022-11-18 21:19:06,176:INFO:Assigning column types.
2022-11-18 21:19:06,183:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-18 21:19:06,184:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-18 21:19:06,190:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:19:06,197:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:19:06,272:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:19:06,329:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:19:06,330:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:19:06,331:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:19:06,489:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:19:06,490:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-18 21:19:06,497:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:19:06,503:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:19:06,583:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:19:06,649:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:19:06,651:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:19:06,651:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:19:06,652:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:19:06,652:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-18 21:19:06,658:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:19:06,664:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:19:06,741:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:19:06,801:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:19:06,802:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:19:06,803:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:19:06,803:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:19:06,810:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:19:06,816:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:19:06,890:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:19:06,950:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:19:06,951:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:19:06,952:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:19:06,952:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:19:06,953:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-18 21:19:06,965:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:19:07,038:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:19:07,105:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:19:07,107:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:19:07,107:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:19:07,107:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:19:07,120:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:19:07,193:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:19:07,249:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:19:07,250:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:19:07,251:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:19:07,251:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:19:07,251:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-18 21:19:07,336:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:19:07,392:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:19:07,393:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:19:07,393:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:19:07,393:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:19:07,477:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:19:07,537:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:19:07,539:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:19:07,539:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:19:07,541:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:19:07,542:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-18 21:19:07,635:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:19:07,697:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:19:07,697:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:19:07,698:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:19:07,783:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:19:07,847:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:19:07,847:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:19:07,848:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:19:07,849:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-18 21:19:07,995:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:19:07,995:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:19:07,996:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:19:08,145:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:19:08,145:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:19:08,146:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:19:08,148:INFO:Preparing preprocessing pipeline...
2022-11-18 21:19:08,150:INFO:Set up simple imputation.
2022-11-18 21:19:08,150:INFO:Set up variance threshold.
2022-11-18 21:19:08,205:INFO:Finished creating preprocessing pipeline.
2022-11-18 21:19:08,212:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO',
                                             'Average_Line_ML_x',
                                             'Average_Line_ML_y'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-18 21:19:08,212:INFO:Creating final display dataframe.
2022-11-18 21:19:08,411:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 14)
4         Train data shape    (607, 14)
5          Test data shape    (261, 14)
6         Numeric features           13
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         fcaa
2022-11-18 21:19:08,580:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:19:08,581:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:19:08,582:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:19:08,731:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:19:08,731:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:19:08,732:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:19:08,741:INFO:setup() successfully completed in 2.62s...............
2022-11-18 21:19:08,742:INFO:Initializing compare_models()
2022-11-18 21:19:08,742:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa09bd26910>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fa09bd26910>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-18 21:19:08,742:INFO:Checking exceptions
2022-11-18 21:19:08,744:INFO:Preparing display monitor
2022-11-18 21:19:08,841:INFO:Initializing Linear Regression
2022-11-18 21:19:08,842:INFO:Total runtime is 1.8266836802164712e-05 minutes
2022-11-18 21:19:08,855:INFO:SubProcess create_model() called ==================================
2022-11-18 21:19:08,856:INFO:Initializing create_model()
2022-11-18 21:19:08,856:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa09bd26910>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa086b2fc90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:19:08,857:INFO:Checking exceptions
2022-11-18 21:19:08,861:INFO:Importing libraries
2022-11-18 21:19:08,861:INFO:Copying training dataset
2022-11-18 21:19:08,866:INFO:Defining folds
2022-11-18 21:19:08,872:INFO:Declaring metric variables
2022-11-18 21:19:08,882:INFO:Importing untrained model
2022-11-18 21:19:08,892:INFO:Linear Regression Imported successfully
2022-11-18 21:19:08,915:INFO:Starting cross validation
2022-11-18 21:19:08,931:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:19:15,096:INFO:Calculating mean and std
2022-11-18 21:19:15,103:INFO:Creating metrics dataframe
2022-11-18 21:19:15,115:INFO:Uploading results into container
2022-11-18 21:19:15,116:INFO:Uploading model into container now
2022-11-18 21:19:15,117:INFO:master_model_container: 1
2022-11-18 21:19:15,117:INFO:display_container: 2
2022-11-18 21:19:15,118:INFO:LinearRegression(n_jobs=-1)
2022-11-18 21:19:15,118:INFO:create_model() successfully completed......................................
2022-11-18 21:19:15,324:INFO:SubProcess create_model() end ==================================
2022-11-18 21:19:15,324:INFO:Creating metrics dataframe
2022-11-18 21:19:15,354:INFO:Initializing Lasso Regression
2022-11-18 21:19:15,354:INFO:Total runtime is 0.10856084823608397 minutes
2022-11-18 21:19:15,366:INFO:SubProcess create_model() called ==================================
2022-11-18 21:19:15,367:INFO:Initializing create_model()
2022-11-18 21:19:15,368:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa09bd26910>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa086b2fc90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:19:15,368:INFO:Checking exceptions
2022-11-18 21:19:15,372:INFO:Importing libraries
2022-11-18 21:19:15,373:INFO:Copying training dataset
2022-11-18 21:19:15,379:INFO:Defining folds
2022-11-18 21:19:15,380:INFO:Declaring metric variables
2022-11-18 21:19:15,391:INFO:Importing untrained model
2022-11-18 21:19:15,407:INFO:Lasso Regression Imported successfully
2022-11-18 21:19:15,425:INFO:Starting cross validation
2022-11-18 21:19:15,427:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:19:15,778:INFO:Calculating mean and std
2022-11-18 21:19:15,781:INFO:Creating metrics dataframe
2022-11-18 21:19:15,795:INFO:Uploading results into container
2022-11-18 21:19:15,796:INFO:Uploading model into container now
2022-11-18 21:19:15,797:INFO:master_model_container: 2
2022-11-18 21:19:15,798:INFO:display_container: 2
2022-11-18 21:19:15,799:INFO:Lasso(random_state=123)
2022-11-18 21:19:15,799:INFO:create_model() successfully completed......................................
2022-11-18 21:19:15,987:INFO:SubProcess create_model() end ==================================
2022-11-18 21:19:15,987:INFO:Creating metrics dataframe
2022-11-18 21:19:16,008:INFO:Initializing Ridge Regression
2022-11-18 21:19:16,009:INFO:Total runtime is 0.11946942806243896 minutes
2022-11-18 21:19:16,018:INFO:SubProcess create_model() called ==================================
2022-11-18 21:19:16,019:INFO:Initializing create_model()
2022-11-18 21:19:16,019:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa09bd26910>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa086b2fc90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:19:16,020:INFO:Checking exceptions
2022-11-18 21:19:16,024:INFO:Importing libraries
2022-11-18 21:19:16,026:INFO:Copying training dataset
2022-11-18 21:19:16,033:INFO:Defining folds
2022-11-18 21:19:16,033:INFO:Declaring metric variables
2022-11-18 21:19:16,047:INFO:Importing untrained model
2022-11-18 21:19:16,062:INFO:Ridge Regression Imported successfully
2022-11-18 21:19:16,078:INFO:Starting cross validation
2022-11-18 21:19:16,079:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:19:16,145:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.42906e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:19:16,151:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.41383e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:19:16,201:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.43321e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:19:16,241:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.44943e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:19:16,272:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.39321e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:19:16,314:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.45984e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:19:16,320:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.43104e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:19:16,357:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.41601e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:19:16,391:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.4057e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:19:16,415:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.41441e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:19:16,430:INFO:Calculating mean and std
2022-11-18 21:19:16,436:INFO:Creating metrics dataframe
2022-11-18 21:19:16,449:INFO:Uploading results into container
2022-11-18 21:19:16,450:INFO:Uploading model into container now
2022-11-18 21:19:16,451:INFO:master_model_container: 3
2022-11-18 21:19:16,451:INFO:display_container: 2
2022-11-18 21:19:16,451:INFO:Ridge(random_state=123)
2022-11-18 21:19:16,452:INFO:create_model() successfully completed......................................
2022-11-18 21:19:16,640:INFO:SubProcess create_model() end ==================================
2022-11-18 21:19:16,641:INFO:Creating metrics dataframe
2022-11-18 21:19:16,665:INFO:Initializing Elastic Net
2022-11-18 21:19:16,665:INFO:Total runtime is 0.1304125150044759 minutes
2022-11-18 21:19:16,674:INFO:SubProcess create_model() called ==================================
2022-11-18 21:19:16,675:INFO:Initializing create_model()
2022-11-18 21:19:16,675:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa09bd26910>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa086b2fc90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:19:16,675:INFO:Checking exceptions
2022-11-18 21:19:16,679:INFO:Importing libraries
2022-11-18 21:19:16,679:INFO:Copying training dataset
2022-11-18 21:19:16,688:INFO:Defining folds
2022-11-18 21:19:16,689:INFO:Declaring metric variables
2022-11-18 21:19:16,706:INFO:Importing untrained model
2022-11-18 21:19:16,720:INFO:Elastic Net Imported successfully
2022-11-18 21:19:16,739:INFO:Starting cross validation
2022-11-18 21:19:16,741:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:19:17,045:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.202e+03, tolerance: 2.923e+03
  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive

2022-11-18 21:19:17,091:INFO:Calculating mean and std
2022-11-18 21:19:17,094:INFO:Creating metrics dataframe
2022-11-18 21:19:17,107:INFO:Uploading results into container
2022-11-18 21:19:17,108:INFO:Uploading model into container now
2022-11-18 21:19:17,109:INFO:master_model_container: 4
2022-11-18 21:19:17,110:INFO:display_container: 2
2022-11-18 21:19:17,110:INFO:ElasticNet(random_state=123)
2022-11-18 21:19:17,111:INFO:create_model() successfully completed......................................
2022-11-18 21:19:17,299:INFO:SubProcess create_model() end ==================================
2022-11-18 21:19:17,300:INFO:Creating metrics dataframe
2022-11-18 21:19:17,320:INFO:Initializing Least Angle Regression
2022-11-18 21:19:17,322:INFO:Total runtime is 0.14134916067123413 minutes
2022-11-18 21:19:17,330:INFO:SubProcess create_model() called ==================================
2022-11-18 21:19:17,331:INFO:Initializing create_model()
2022-11-18 21:19:17,332:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa09bd26910>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa086b2fc90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:19:17,332:INFO:Checking exceptions
2022-11-18 21:19:17,335:INFO:Importing libraries
2022-11-18 21:19:17,336:INFO:Copying training dataset
2022-11-18 21:19:17,342:INFO:Defining folds
2022-11-18 21:19:17,343:INFO:Declaring metric variables
2022-11-18 21:19:17,357:INFO:Importing untrained model
2022-11-18 21:19:17,367:INFO:Least Angle Regression Imported successfully
2022-11-18 21:19:17,388:INFO:Starting cross validation
2022-11-18 21:19:17,390:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:19:17,442:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:19:17,478:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:19:17,513:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:19:17,549:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:19:17,588:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:19:17,631:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:19:17,638:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:19:17,687:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:19:17,710:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:19:17,736:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:19:17,751:INFO:Calculating mean and std
2022-11-18 21:19:17,757:INFO:Creating metrics dataframe
2022-11-18 21:19:17,770:INFO:Uploading results into container
2022-11-18 21:19:17,771:INFO:Uploading model into container now
2022-11-18 21:19:17,772:INFO:master_model_container: 5
2022-11-18 21:19:17,772:INFO:display_container: 2
2022-11-18 21:19:17,772:INFO:Lars(random_state=123)
2022-11-18 21:19:17,773:INFO:create_model() successfully completed......................................
2022-11-18 21:19:17,969:INFO:SubProcess create_model() end ==================================
2022-11-18 21:19:17,969:INFO:Creating metrics dataframe
2022-11-18 21:19:17,989:INFO:Initializing Lasso Least Angle Regression
2022-11-18 21:19:17,990:INFO:Total runtime is 0.15248778661092122 minutes
2022-11-18 21:19:18,000:INFO:SubProcess create_model() called ==================================
2022-11-18 21:19:18,001:INFO:Initializing create_model()
2022-11-18 21:19:18,001:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa09bd26910>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa086b2fc90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:19:18,002:INFO:Checking exceptions
2022-11-18 21:19:18,004:INFO:Importing libraries
2022-11-18 21:19:18,006:INFO:Copying training dataset
2022-11-18 21:19:18,014:INFO:Defining folds
2022-11-18 21:19:18,015:INFO:Declaring metric variables
2022-11-18 21:19:18,026:INFO:Importing untrained model
2022-11-18 21:19:18,036:INFO:Lasso Least Angle Regression Imported successfully
2022-11-18 21:19:18,053:INFO:Starting cross validation
2022-11-18 21:19:18,058:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:19:18,099:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:19:18,135:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:19:18,165:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:19:18,197:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:19:18,233:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:19:18,274:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:19:18,277:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:19:18,321:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:19:18,345:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:19:18,360:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:19:18,376:INFO:Calculating mean and std
2022-11-18 21:19:18,380:INFO:Creating metrics dataframe
2022-11-18 21:19:18,390:INFO:Uploading results into container
2022-11-18 21:19:18,391:INFO:Uploading model into container now
2022-11-18 21:19:18,392:INFO:master_model_container: 6
2022-11-18 21:19:18,392:INFO:display_container: 2
2022-11-18 21:19:18,393:INFO:LassoLars(random_state=123)
2022-11-18 21:19:18,393:INFO:create_model() successfully completed......................................
2022-11-18 21:19:18,591:INFO:SubProcess create_model() end ==================================
2022-11-18 21:19:18,592:INFO:Creating metrics dataframe
2022-11-18 21:19:18,624:INFO:Initializing Orthogonal Matching Pursuit
2022-11-18 21:19:18,624:INFO:Total runtime is 0.16306379636128743 minutes
2022-11-18 21:19:18,636:INFO:SubProcess create_model() called ==================================
2022-11-18 21:19:18,637:INFO:Initializing create_model()
2022-11-18 21:19:18,638:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa09bd26910>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa086b2fc90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:19:18,638:INFO:Checking exceptions
2022-11-18 21:19:18,642:INFO:Importing libraries
2022-11-18 21:19:18,642:INFO:Copying training dataset
2022-11-18 21:19:18,648:INFO:Defining folds
2022-11-18 21:19:18,649:INFO:Declaring metric variables
2022-11-18 21:19:18,666:INFO:Importing untrained model
2022-11-18 21:19:18,681:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-18 21:19:18,703:INFO:Starting cross validation
2022-11-18 21:19:18,708:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:19:18,747:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:19:18,798:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:19:18,865:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:19:18,869:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:19:18,922:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:19:18,932:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:19:18,962:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:19:18,985:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:19:19,007:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:19:19,031:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:19:19,045:INFO:Calculating mean and std
2022-11-18 21:19:19,048:INFO:Creating metrics dataframe
2022-11-18 21:19:19,059:INFO:Uploading results into container
2022-11-18 21:19:19,060:INFO:Uploading model into container now
2022-11-18 21:19:19,061:INFO:master_model_container: 7
2022-11-18 21:19:19,062:INFO:display_container: 2
2022-11-18 21:19:19,063:INFO:OrthogonalMatchingPursuit()
2022-11-18 21:19:19,063:INFO:create_model() successfully completed......................................
2022-11-18 21:19:19,259:INFO:SubProcess create_model() end ==================================
2022-11-18 21:19:19,260:INFO:Creating metrics dataframe
2022-11-18 21:19:19,283:INFO:Initializing Bayesian Ridge
2022-11-18 21:19:19,283:INFO:Total runtime is 0.17404542366663614 minutes
2022-11-18 21:19:19,294:INFO:SubProcess create_model() called ==================================
2022-11-18 21:19:19,295:INFO:Initializing create_model()
2022-11-18 21:19:19,295:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa09bd26910>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa086b2fc90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:19:19,295:INFO:Checking exceptions
2022-11-18 21:19:19,298:INFO:Importing libraries
2022-11-18 21:19:19,299:INFO:Copying training dataset
2022-11-18 21:19:19,305:INFO:Defining folds
2022-11-18 21:19:19,306:INFO:Declaring metric variables
2022-11-18 21:19:19,320:INFO:Importing untrained model
2022-11-18 21:19:19,331:INFO:Bayesian Ridge Imported successfully
2022-11-18 21:19:19,350:INFO:Starting cross validation
2022-11-18 21:19:19,352:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:19:19,692:INFO:Calculating mean and std
2022-11-18 21:19:19,695:INFO:Creating metrics dataframe
2022-11-18 21:19:19,703:INFO:Uploading results into container
2022-11-18 21:19:19,711:INFO:Uploading model into container now
2022-11-18 21:19:19,712:INFO:master_model_container: 8
2022-11-18 21:19:19,712:INFO:display_container: 2
2022-11-18 21:19:19,713:INFO:BayesianRidge()
2022-11-18 21:19:19,713:INFO:create_model() successfully completed......................................
2022-11-18 21:19:19,904:INFO:SubProcess create_model() end ==================================
2022-11-18 21:19:19,905:INFO:Creating metrics dataframe
2022-11-18 21:19:19,932:INFO:Initializing Passive Aggressive Regressor
2022-11-18 21:19:19,932:INFO:Total runtime is 0.18486140569051107 minutes
2022-11-18 21:19:19,942:INFO:SubProcess create_model() called ==================================
2022-11-18 21:19:19,944:INFO:Initializing create_model()
2022-11-18 21:19:19,944:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa09bd26910>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa086b2fc90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:19:19,944:INFO:Checking exceptions
2022-11-18 21:19:19,947:INFO:Importing libraries
2022-11-18 21:19:19,951:INFO:Copying training dataset
2022-11-18 21:19:19,957:INFO:Defining folds
2022-11-18 21:19:19,960:INFO:Declaring metric variables
2022-11-18 21:19:19,975:INFO:Importing untrained model
2022-11-18 21:19:19,984:INFO:Passive Aggressive Regressor Imported successfully
2022-11-18 21:19:20,004:INFO:Starting cross validation
2022-11-18 21:19:20,006:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:19:20,332:INFO:Calculating mean and std
2022-11-18 21:19:20,334:INFO:Creating metrics dataframe
2022-11-18 21:19:20,355:INFO:Uploading results into container
2022-11-18 21:19:20,356:INFO:Uploading model into container now
2022-11-18 21:19:20,357:INFO:master_model_container: 9
2022-11-18 21:19:20,357:INFO:display_container: 2
2022-11-18 21:19:20,357:INFO:PassiveAggressiveRegressor(random_state=123)
2022-11-18 21:19:20,357:INFO:create_model() successfully completed......................................
2022-11-18 21:19:20,550:INFO:SubProcess create_model() end ==================================
2022-11-18 21:19:20,551:INFO:Creating metrics dataframe
2022-11-18 21:19:20,580:INFO:Initializing Huber Regressor
2022-11-18 21:19:20,583:INFO:Total runtime is 0.19570656617482504 minutes
2022-11-18 21:19:20,592:INFO:SubProcess create_model() called ==================================
2022-11-18 21:19:20,593:INFO:Initializing create_model()
2022-11-18 21:19:20,593:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa09bd26910>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa086b2fc90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:19:20,593:INFO:Checking exceptions
2022-11-18 21:19:20,596:INFO:Importing libraries
2022-11-18 21:19:20,597:INFO:Copying training dataset
2022-11-18 21:19:20,605:INFO:Defining folds
2022-11-18 21:19:20,605:INFO:Declaring metric variables
2022-11-18 21:19:20,615:INFO:Importing untrained model
2022-11-18 21:19:20,626:INFO:Huber Regressor Imported successfully
2022-11-18 21:19:20,644:INFO:Starting cross validation
2022-11-18 21:19:20,652:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:19:20,771:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:19:20,799:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:19:20,915:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:19:20,921:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:19:21,021:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:19:21,066:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:19:21,114:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:19:21,164:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:19:21,212:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:19:21,250:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:19:21,263:INFO:Calculating mean and std
2022-11-18 21:19:21,271:INFO:Creating metrics dataframe
2022-11-18 21:19:21,282:INFO:Uploading results into container
2022-11-18 21:19:21,283:INFO:Uploading model into container now
2022-11-18 21:19:21,284:INFO:master_model_container: 10
2022-11-18 21:19:21,284:INFO:display_container: 2
2022-11-18 21:19:21,285:INFO:HuberRegressor()
2022-11-18 21:19:21,286:INFO:create_model() successfully completed......................................
2022-11-18 21:19:21,469:INFO:SubProcess create_model() end ==================================
2022-11-18 21:19:21,470:INFO:Creating metrics dataframe
2022-11-18 21:19:21,495:INFO:Initializing K Neighbors Regressor
2022-11-18 21:19:21,499:INFO:Total runtime is 0.21096877654393514 minutes
2022-11-18 21:19:21,511:INFO:SubProcess create_model() called ==================================
2022-11-18 21:19:21,511:INFO:Initializing create_model()
2022-11-18 21:19:21,512:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa09bd26910>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa086b2fc90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:19:21,512:INFO:Checking exceptions
2022-11-18 21:19:21,516:INFO:Importing libraries
2022-11-18 21:19:21,520:INFO:Copying training dataset
2022-11-18 21:19:21,529:INFO:Defining folds
2022-11-18 21:19:21,530:INFO:Declaring metric variables
2022-11-18 21:19:21,549:INFO:Importing untrained model
2022-11-18 21:19:21,564:INFO:K Neighbors Regressor Imported successfully
2022-11-18 21:19:21,581:INFO:Starting cross validation
2022-11-18 21:19:21,584:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:19:22,364:INFO:Calculating mean and std
2022-11-18 21:19:22,370:INFO:Creating metrics dataframe
2022-11-18 21:19:22,382:INFO:Uploading results into container
2022-11-18 21:19:22,383:INFO:Uploading model into container now
2022-11-18 21:19:22,384:INFO:master_model_container: 11
2022-11-18 21:19:22,384:INFO:display_container: 2
2022-11-18 21:19:22,385:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-18 21:19:22,385:INFO:create_model() successfully completed......................................
2022-11-18 21:19:22,576:INFO:SubProcess create_model() end ==================================
2022-11-18 21:19:22,577:INFO:Creating metrics dataframe
2022-11-18 21:19:22,600:INFO:Initializing Decision Tree Regressor
2022-11-18 21:19:22,601:INFO:Total runtime is 0.22933802604675294 minutes
2022-11-18 21:19:22,611:INFO:SubProcess create_model() called ==================================
2022-11-18 21:19:22,612:INFO:Initializing create_model()
2022-11-18 21:19:22,612:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa09bd26910>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa086b2fc90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:19:22,613:INFO:Checking exceptions
2022-11-18 21:19:22,617:INFO:Importing libraries
2022-11-18 21:19:22,617:INFO:Copying training dataset
2022-11-18 21:19:22,622:INFO:Defining folds
2022-11-18 21:19:22,623:INFO:Declaring metric variables
2022-11-18 21:19:22,637:INFO:Importing untrained model
2022-11-18 21:19:22,648:INFO:Decision Tree Regressor Imported successfully
2022-11-18 21:19:22,674:INFO:Starting cross validation
2022-11-18 21:19:22,676:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:19:23,041:INFO:Calculating mean and std
2022-11-18 21:19:23,044:INFO:Creating metrics dataframe
2022-11-18 21:19:23,062:INFO:Uploading results into container
2022-11-18 21:19:23,063:INFO:Uploading model into container now
2022-11-18 21:19:23,064:INFO:master_model_container: 12
2022-11-18 21:19:23,064:INFO:display_container: 2
2022-11-18 21:19:23,064:INFO:DecisionTreeRegressor(random_state=123)
2022-11-18 21:19:23,065:INFO:create_model() successfully completed......................................
2022-11-18 21:19:23,248:INFO:SubProcess create_model() end ==================================
2022-11-18 21:19:23,248:INFO:Creating metrics dataframe
2022-11-18 21:19:23,272:INFO:Initializing Random Forest Regressor
2022-11-18 21:19:23,273:INFO:Total runtime is 0.24053508043289185 minutes
2022-11-18 21:19:23,283:INFO:SubProcess create_model() called ==================================
2022-11-18 21:19:23,284:INFO:Initializing create_model()
2022-11-18 21:19:23,284:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa09bd26910>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa086b2fc90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:19:23,284:INFO:Checking exceptions
2022-11-18 21:19:23,287:INFO:Importing libraries
2022-11-18 21:19:23,288:INFO:Copying training dataset
2022-11-18 21:19:23,294:INFO:Defining folds
2022-11-18 21:19:23,294:INFO:Declaring metric variables
2022-11-18 21:19:23,309:INFO:Importing untrained model
2022-11-18 21:19:23,320:INFO:Random Forest Regressor Imported successfully
2022-11-18 21:19:23,340:INFO:Starting cross validation
2022-11-18 21:19:23,342:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:19:28,003:INFO:Calculating mean and std
2022-11-18 21:19:28,009:INFO:Creating metrics dataframe
2022-11-18 21:19:28,020:INFO:Uploading results into container
2022-11-18 21:19:28,022:INFO:Uploading model into container now
2022-11-18 21:19:28,023:INFO:master_model_container: 13
2022-11-18 21:19:28,023:INFO:display_container: 2
2022-11-18 21:19:28,024:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-18 21:19:28,024:INFO:create_model() successfully completed......................................
2022-11-18 21:19:28,209:INFO:SubProcess create_model() end ==================================
2022-11-18 21:19:28,210:INFO:Creating metrics dataframe
2022-11-18 21:19:28,232:INFO:Initializing Extra Trees Regressor
2022-11-18 21:19:28,233:INFO:Total runtime is 0.32321009238560994 minutes
2022-11-18 21:19:28,244:INFO:SubProcess create_model() called ==================================
2022-11-18 21:19:28,245:INFO:Initializing create_model()
2022-11-18 21:19:28,245:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa09bd26910>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa086b2fc90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:19:28,245:INFO:Checking exceptions
2022-11-18 21:19:28,249:INFO:Importing libraries
2022-11-18 21:19:28,250:INFO:Copying training dataset
2022-11-18 21:19:28,259:INFO:Defining folds
2022-11-18 21:19:28,259:INFO:Declaring metric variables
2022-11-18 21:19:28,270:INFO:Importing untrained model
2022-11-18 21:19:28,283:INFO:Extra Trees Regressor Imported successfully
2022-11-18 21:19:28,303:INFO:Starting cross validation
2022-11-18 21:19:28,308:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:19:30,937:INFO:Calculating mean and std
2022-11-18 21:19:30,945:INFO:Creating metrics dataframe
2022-11-18 21:19:30,958:INFO:Uploading results into container
2022-11-18 21:19:30,959:INFO:Uploading model into container now
2022-11-18 21:19:30,959:INFO:master_model_container: 14
2022-11-18 21:19:30,959:INFO:display_container: 2
2022-11-18 21:19:30,960:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-18 21:19:30,960:INFO:create_model() successfully completed......................................
2022-11-18 21:19:31,143:INFO:SubProcess create_model() end ==================================
2022-11-18 21:19:31,144:INFO:Creating metrics dataframe
2022-11-18 21:19:31,167:INFO:Initializing AdaBoost Regressor
2022-11-18 21:19:31,168:INFO:Total runtime is 0.3721221844355265 minutes
2022-11-18 21:19:31,178:INFO:SubProcess create_model() called ==================================
2022-11-18 21:19:31,183:INFO:Initializing create_model()
2022-11-18 21:19:31,183:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa09bd26910>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa086b2fc90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:19:31,183:INFO:Checking exceptions
2022-11-18 21:19:31,186:INFO:Importing libraries
2022-11-18 21:19:31,186:INFO:Copying training dataset
2022-11-18 21:19:31,193:INFO:Defining folds
2022-11-18 21:19:31,193:INFO:Declaring metric variables
2022-11-18 21:19:31,205:INFO:Importing untrained model
2022-11-18 21:19:31,214:INFO:AdaBoost Regressor Imported successfully
2022-11-18 21:19:31,239:INFO:Starting cross validation
2022-11-18 21:19:31,241:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:19:32,627:INFO:Calculating mean and std
2022-11-18 21:19:32,633:INFO:Creating metrics dataframe
2022-11-18 21:19:32,669:INFO:Uploading results into container
2022-11-18 21:19:32,670:INFO:Uploading model into container now
2022-11-18 21:19:32,671:INFO:master_model_container: 15
2022-11-18 21:19:32,676:INFO:display_container: 2
2022-11-18 21:19:32,681:INFO:AdaBoostRegressor(random_state=123)
2022-11-18 21:19:32,682:INFO:create_model() successfully completed......................................
2022-11-18 21:19:33,447:INFO:SubProcess create_model() end ==================================
2022-11-18 21:19:33,453:INFO:Creating metrics dataframe
2022-11-18 21:19:33,523:INFO:Initializing Gradient Boosting Regressor
2022-11-18 21:19:33,523:INFO:Total runtime is 0.41137982209523516 minutes
2022-11-18 21:19:33,545:INFO:SubProcess create_model() called ==================================
2022-11-18 21:19:33,546:INFO:Initializing create_model()
2022-11-18 21:19:33,546:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa09bd26910>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa086b2fc90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:19:33,547:INFO:Checking exceptions
2022-11-18 21:19:33,555:INFO:Importing libraries
2022-11-18 21:19:33,555:INFO:Copying training dataset
2022-11-18 21:19:33,584:INFO:Defining folds
2022-11-18 21:19:33,585:INFO:Declaring metric variables
2022-11-18 21:19:33,628:INFO:Importing untrained model
2022-11-18 21:19:33,659:INFO:Gradient Boosting Regressor Imported successfully
2022-11-18 21:19:33,704:INFO:Starting cross validation
2022-11-18 21:19:33,708:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:19:36,578:INFO:Calculating mean and std
2022-11-18 21:19:36,583:INFO:Creating metrics dataframe
2022-11-18 21:19:36,592:INFO:Uploading results into container
2022-11-18 21:19:36,594:INFO:Uploading model into container now
2022-11-18 21:19:36,595:INFO:master_model_container: 16
2022-11-18 21:19:36,595:INFO:display_container: 2
2022-11-18 21:19:36,596:INFO:GradientBoostingRegressor(random_state=123)
2022-11-18 21:19:36,596:INFO:create_model() successfully completed......................................
2022-11-18 21:19:36,789:INFO:SubProcess create_model() end ==================================
2022-11-18 21:19:36,790:INFO:Creating metrics dataframe
2022-11-18 21:19:36,816:INFO:Initializing Light Gradient Boosting Machine
2022-11-18 21:19:36,817:INFO:Total runtime is 0.4662656227747599 minutes
2022-11-18 21:19:36,829:INFO:SubProcess create_model() called ==================================
2022-11-18 21:19:36,830:INFO:Initializing create_model()
2022-11-18 21:19:36,830:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa09bd26910>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa086b2fc90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:19:36,831:INFO:Checking exceptions
2022-11-18 21:19:36,835:INFO:Importing libraries
2022-11-18 21:19:36,835:INFO:Copying training dataset
2022-11-18 21:19:36,843:INFO:Defining folds
2022-11-18 21:19:36,843:INFO:Declaring metric variables
2022-11-18 21:19:36,858:INFO:Importing untrained model
2022-11-18 21:19:36,869:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-18 21:19:36,889:INFO:Starting cross validation
2022-11-18 21:19:36,892:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:19:38,579:INFO:Calculating mean and std
2022-11-18 21:19:38,582:INFO:Creating metrics dataframe
2022-11-18 21:19:38,591:INFO:Uploading results into container
2022-11-18 21:19:38,592:INFO:Uploading model into container now
2022-11-18 21:19:38,593:INFO:master_model_container: 17
2022-11-18 21:19:38,593:INFO:display_container: 2
2022-11-18 21:19:38,594:INFO:LGBMRegressor(random_state=123)
2022-11-18 21:19:38,594:INFO:create_model() successfully completed......................................
2022-11-18 21:19:38,786:INFO:SubProcess create_model() end ==================================
2022-11-18 21:19:38,787:INFO:Creating metrics dataframe
2022-11-18 21:19:38,814:INFO:Initializing Dummy Regressor
2022-11-18 21:19:38,815:INFO:Total runtime is 0.4995755076408386 minutes
2022-11-18 21:19:38,825:INFO:SubProcess create_model() called ==================================
2022-11-18 21:19:38,825:INFO:Initializing create_model()
2022-11-18 21:19:38,826:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa09bd26910>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa086b2fc90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:19:38,826:INFO:Checking exceptions
2022-11-18 21:19:38,830:INFO:Importing libraries
2022-11-18 21:19:38,830:INFO:Copying training dataset
2022-11-18 21:19:38,839:INFO:Defining folds
2022-11-18 21:19:38,839:INFO:Declaring metric variables
2022-11-18 21:19:38,848:INFO:Importing untrained model
2022-11-18 21:19:38,858:INFO:Dummy Regressor Imported successfully
2022-11-18 21:19:38,878:INFO:Starting cross validation
2022-11-18 21:19:38,880:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:19:39,197:INFO:Calculating mean and std
2022-11-18 21:19:39,200:INFO:Creating metrics dataframe
2022-11-18 21:19:39,206:INFO:Uploading results into container
2022-11-18 21:19:39,214:INFO:Uploading model into container now
2022-11-18 21:19:39,215:INFO:master_model_container: 18
2022-11-18 21:19:39,215:INFO:display_container: 2
2022-11-18 21:19:39,216:INFO:DummyRegressor()
2022-11-18 21:19:39,216:INFO:create_model() successfully completed......................................
2022-11-18 21:19:39,404:INFO:SubProcess create_model() end ==================================
2022-11-18 21:19:39,405:INFO:Creating metrics dataframe
2022-11-18 21:19:39,461:INFO:Initializing create_model()
2022-11-18 21:19:39,462:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa09bd26910>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:19:39,462:INFO:Checking exceptions
2022-11-18 21:19:39,469:INFO:Importing libraries
2022-11-18 21:19:39,469:INFO:Copying training dataset
2022-11-18 21:19:39,473:INFO:Defining folds
2022-11-18 21:19:39,474:INFO:Declaring metric variables
2022-11-18 21:19:39,474:INFO:Importing untrained model
2022-11-18 21:19:39,475:INFO:Declaring custom model
2022-11-18 21:19:39,476:INFO:Extra Trees Regressor Imported successfully
2022-11-18 21:19:39,477:INFO:Cross validation set to False
2022-11-18 21:19:39,477:INFO:Fitting Model
2022-11-18 21:19:39,852:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-18 21:19:39,853:INFO:create_model() successfully completed......................................
2022-11-18 21:19:40,128:INFO:master_model_container: 18
2022-11-18 21:19:40,129:INFO:display_container: 2
2022-11-18 21:19:40,130:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-18 21:19:40,130:INFO:compare_models() successfully completed......................................
2022-11-18 21:21:51,960:INFO:PyCaret RegressionExperiment
2022-11-18 21:21:51,960:INFO:Logging name: FullData
2022-11-18 21:21:51,960:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-18 21:21:51,960:INFO:version 3.0.0.rc4
2022-11-18 21:21:51,961:INFO:Initializing setup()
2022-11-18 21:21:51,961:INFO:self.USI: 27ae
2022-11-18 21:21:51,961:INFO:self.variable_keys: {'_available_plots', 'seed', 'log_plots_param', '_gpu_n_jobs_param', 'USI', 'pipeline', '_all_models_internal', 'fold_generator', 'variable_keys', 'gpu_param', 'exp_id', 'X_test', 'memory', '_ml_usecase', 'y', 'fold_groups_param', 'transform_target_method_param', 'display_container', 'logging_param', '_all_metrics', 'fold_shuffle_param', 'n_jobs_param', 'exp_name_log', 'data', 'y_test', 'html_param', 'target_param', 'transform_target_param', '_all_models', 'y_train', 'X_train', 'X', 'master_model_container', 'idx'}
2022-11-18 21:21:51,961:INFO:Checking environment
2022-11-18 21:21:51,961:INFO:python_version: 3.7.15
2022-11-18 21:21:51,962:INFO:python_build: ('default', 'Oct 12 2022 19:14:55')
2022-11-18 21:21:51,962:INFO:machine: x86_64
2022-11-18 21:21:51,962:INFO:platform: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-18 21:21:51,962:INFO:Memory: svmem(total=13616353280, available=11435933696, percent=16.0, used=2037563392, free=7386353664, active=1073942528, inactive=4791300096, buffers=166916096, cached=4025520128, shared=1327104, slab=268021760)
2022-11-18 21:21:51,963:INFO:Physical Core: 1
2022-11-18 21:21:51,963:INFO:Logical Core: 2
2022-11-18 21:21:51,963:INFO:Checking libraries
2022-11-18 21:21:51,964:INFO:System:
2022-11-18 21:21:51,964:INFO:    python: 3.7.15 (default, Oct 12 2022, 19:14:55)  [GCC 7.5.0]
2022-11-18 21:21:51,964:INFO:executable: /usr/bin/python3
2022-11-18 21:21:51,964:INFO:   machine: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-18 21:21:51,964:INFO:PyCaret required dependencies:
2022-11-18 21:21:51,965:INFO:                 pip: 21.1.3
2022-11-18 21:21:51,965:INFO:          setuptools: 57.4.0
2022-11-18 21:21:51,965:INFO:             pycaret: 3.0.0rc4
2022-11-18 21:21:51,966:INFO:             IPython: 7.9.0
2022-11-18 21:21:51,966:INFO:          ipywidgets: 7.7.1
2022-11-18 21:21:51,967:INFO:                tqdm: 4.64.1
2022-11-18 21:21:51,967:INFO:               numpy: 1.21.6
2022-11-18 21:21:51,967:INFO:              pandas: 1.3.5
2022-11-18 21:21:51,967:INFO:              jinja2: 3.0.0
2022-11-18 21:21:51,968:INFO:               scipy: 1.7.3
2022-11-18 21:21:51,968:INFO:              joblib: 1.2.0
2022-11-18 21:21:51,968:INFO:             sklearn: 1.0.2
2022-11-18 21:21:51,968:INFO:                pyod: 1.0.6
2022-11-18 21:21:51,968:INFO:            imblearn: 0.8.1
2022-11-18 21:21:51,968:INFO:   category_encoders: 2.5.1.post0
2022-11-18 21:21:51,968:INFO:            lightgbm: 3.3.3
2022-11-18 21:21:51,968:INFO:               numba: 0.55.2
2022-11-18 21:21:51,969:INFO:            requests: 2.28.1
2022-11-18 21:21:51,969:INFO:          matplotlib: 3.5.3
2022-11-18 21:21:51,969:INFO:          scikitplot: 0.3.7
2022-11-18 21:21:51,969:INFO:         yellowbrick: 1.5
2022-11-18 21:21:51,969:INFO:              plotly: 5.5.0
2022-11-18 21:21:51,969:INFO:             kaleido: 0.2.1
2022-11-18 21:21:51,969:INFO:         statsmodels: 0.12.2
2022-11-18 21:21:51,969:INFO:              sktime: 0.13.4
2022-11-18 21:21:51,970:INFO:               tbats: 1.1.1
2022-11-18 21:21:51,970:INFO:            pmdarima: 1.8.5
2022-11-18 21:21:51,970:INFO:              psutil: 5.9.4
2022-11-18 21:21:51,970:INFO:PyCaret optional dependencies:
2022-11-18 21:21:51,970:INFO:                shap: Not installed
2022-11-18 21:21:51,970:INFO:           interpret: Not installed
2022-11-18 21:21:51,971:INFO:                umap: Not installed
2022-11-18 21:21:51,971:INFO:    pandas_profiling: 1.4.1
2022-11-18 21:21:51,971:INFO:  explainerdashboard: Not installed
2022-11-18 21:21:51,971:INFO:             autoviz: Not installed
2022-11-18 21:21:51,971:INFO:           fairlearn: Not installed
2022-11-18 21:21:51,971:INFO:             xgboost: 0.90
2022-11-18 21:21:51,971:INFO:            catboost: Not installed
2022-11-18 21:21:51,971:INFO:              kmodes: Not installed
2022-11-18 21:21:51,972:INFO:             mlxtend: 0.14.0
2022-11-18 21:21:51,972:INFO:       statsforecast: Not installed
2022-11-18 21:21:51,972:INFO:        tune_sklearn: Not installed
2022-11-18 21:21:51,972:INFO:                 ray: Not installed
2022-11-18 21:21:51,972:INFO:            hyperopt: 0.1.2
2022-11-18 21:21:51,973:INFO:              optuna: Not installed
2022-11-18 21:21:51,973:INFO:               skopt: Not installed
2022-11-18 21:21:51,973:INFO:              mlflow: Not installed
2022-11-18 21:21:51,973:INFO:              gradio: Not installed
2022-11-18 21:21:51,973:INFO:             fastapi: Not installed
2022-11-18 21:21:51,973:INFO:             uvicorn: Not installed
2022-11-18 21:21:51,973:INFO:              m2cgen: Not installed
2022-11-18 21:21:51,974:INFO:           evidently: Not installed
2022-11-18 21:21:51,974:INFO:                nltk: 3.7
2022-11-18 21:21:51,974:INFO:            pyLDAvis: Not installed
2022-11-18 21:21:51,974:INFO:              gensim: 3.6.0
2022-11-18 21:21:51,974:INFO:               spacy: 3.4.2
2022-11-18 21:21:51,974:INFO:           wordcloud: 1.8.2.2
2022-11-18 21:21:51,974:INFO:            textblob: 0.15.3
2022-11-18 21:21:51,975:INFO:               fugue: Not installed
2022-11-18 21:21:51,975:INFO:           streamlit: Not installed
2022-11-18 21:21:51,975:INFO:             prophet: 1.1.1
2022-11-18 21:21:51,975:INFO:None
2022-11-18 21:21:51,975:INFO:Set up data.
2022-11-18 21:21:51,983:INFO:Set up train/test split.
2022-11-18 21:21:51,987:INFO:Set up index.
2022-11-18 21:21:51,988:INFO:Set up folding strategy.
2022-11-18 21:21:51,988:INFO:Assigning column types.
2022-11-18 21:21:51,995:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-18 21:21:51,996:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-18 21:21:52,002:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:21:52,008:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:21:52,085:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:21:52,139:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:21:52,141:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:21:52,142:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:21:52,142:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:21:52,143:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-18 21:21:52,148:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:21:52,154:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:21:52,226:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:21:52,285:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:21:52,287:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:21:52,287:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:21:52,288:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:21:52,288:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-18 21:21:52,295:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:21:52,304:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:21:52,375:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:21:52,432:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:21:52,434:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:21:52,434:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:21:52,435:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:21:52,443:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:21:52,449:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:21:52,520:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:21:52,586:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:21:52,587:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:21:52,587:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:21:52,588:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:21:52,589:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-18 21:21:52,600:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:21:52,674:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:21:52,733:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:21:52,734:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:21:52,735:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:21:52,735:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:21:52,751:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:21:52,825:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:21:52,886:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:21:52,887:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:21:52,887:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:21:52,888:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:21:52,889:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-18 21:21:52,977:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:21:53,039:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:21:53,041:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:21:53,041:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:21:53,041:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:21:53,126:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:21:53,187:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:21:53,188:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:21:53,189:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:21:53,190:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:21:53,190:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-18 21:21:53,282:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:21:53,339:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:21:53,339:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:21:53,340:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:21:53,423:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:21:53,480:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:21:53,480:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:21:53,481:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:21:53,482:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-18 21:21:53,637:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:21:53,637:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:21:53,638:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:21:53,784:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:21:53,785:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:21:53,786:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:21:53,787:INFO:Preparing preprocessing pipeline...
2022-11-18 21:21:53,789:INFO:Set up simple imputation.
2022-11-18 21:21:53,790:INFO:Set up variance threshold.
2022-11-18 21:21:53,833:INFO:Finished creating preprocessing pipeline.
2022-11-18 21:21:53,839:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-18 21:21:53,840:INFO:Creating final display dataframe.
2022-11-18 21:21:54,009:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 12)
4         Train data shape    (607, 12)
5          Test data shape    (261, 12)
6         Numeric features           11
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         27ae
2022-11-18 21:21:54,171:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:21:54,172:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:21:54,173:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:21:54,319:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:21:54,320:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:21:54,321:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:21:54,329:INFO:setup() successfully completed in 2.38s...............
2022-11-18 21:21:54,329:INFO:Initializing compare_models()
2022-11-18 21:21:54,329:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085a82590>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fa085a82590>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-18 21:21:54,330:INFO:Checking exceptions
2022-11-18 21:21:54,331:INFO:Preparing display monitor
2022-11-18 21:21:54,426:INFO:Initializing Linear Regression
2022-11-18 21:21:54,431:INFO:Total runtime is 7.524490356445313e-05 minutes
2022-11-18 21:21:54,440:INFO:SubProcess create_model() called ==================================
2022-11-18 21:21:54,441:INFO:Initializing create_model()
2022-11-18 21:21:54,441:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085a82590>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859b2ed0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:21:54,441:INFO:Checking exceptions
2022-11-18 21:21:54,445:INFO:Importing libraries
2022-11-18 21:21:54,445:INFO:Copying training dataset
2022-11-18 21:21:54,449:INFO:Defining folds
2022-11-18 21:21:54,450:INFO:Declaring metric variables
2022-11-18 21:21:54,459:INFO:Importing untrained model
2022-11-18 21:21:54,470:INFO:Linear Regression Imported successfully
2022-11-18 21:21:54,490:INFO:Starting cross validation
2022-11-18 21:21:54,495:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:21:56,111:INFO:Calculating mean and std
2022-11-18 21:21:56,114:INFO:Creating metrics dataframe
2022-11-18 21:21:56,128:INFO:Uploading results into container
2022-11-18 21:21:56,129:INFO:Uploading model into container now
2022-11-18 21:21:56,130:INFO:master_model_container: 1
2022-11-18 21:21:56,131:INFO:display_container: 2
2022-11-18 21:21:56,131:INFO:LinearRegression(n_jobs=-1)
2022-11-18 21:21:56,131:INFO:create_model() successfully completed......................................
2022-11-18 21:21:56,338:INFO:SubProcess create_model() end ==================================
2022-11-18 21:21:56,339:INFO:Creating metrics dataframe
2022-11-18 21:21:56,357:INFO:Initializing Lasso Regression
2022-11-18 21:21:56,358:INFO:Total runtime is 0.03219259182612101 minutes
2022-11-18 21:21:56,367:INFO:SubProcess create_model() called ==================================
2022-11-18 21:21:56,370:INFO:Initializing create_model()
2022-11-18 21:21:56,371:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085a82590>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859b2ed0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:21:56,371:INFO:Checking exceptions
2022-11-18 21:21:56,374:INFO:Importing libraries
2022-11-18 21:21:56,374:INFO:Copying training dataset
2022-11-18 21:21:56,384:INFO:Defining folds
2022-11-18 21:21:56,385:INFO:Declaring metric variables
2022-11-18 21:21:56,397:INFO:Importing untrained model
2022-11-18 21:21:56,410:INFO:Lasso Regression Imported successfully
2022-11-18 21:21:56,430:INFO:Starting cross validation
2022-11-18 21:21:56,432:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:21:56,762:INFO:Calculating mean and std
2022-11-18 21:21:56,765:INFO:Creating metrics dataframe
2022-11-18 21:21:56,773:INFO:Uploading results into container
2022-11-18 21:21:56,774:INFO:Uploading model into container now
2022-11-18 21:21:56,775:INFO:master_model_container: 2
2022-11-18 21:21:56,775:INFO:display_container: 2
2022-11-18 21:21:56,776:INFO:Lasso(random_state=123)
2022-11-18 21:21:56,776:INFO:create_model() successfully completed......................................
2022-11-18 21:21:56,970:INFO:SubProcess create_model() end ==================================
2022-11-18 21:21:56,976:INFO:Creating metrics dataframe
2022-11-18 21:21:56,999:INFO:Initializing Ridge Regression
2022-11-18 21:21:57,000:INFO:Total runtime is 0.04288871685663859 minutes
2022-11-18 21:21:57,008:INFO:SubProcess create_model() called ==================================
2022-11-18 21:21:57,010:INFO:Initializing create_model()
2022-11-18 21:21:57,011:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085a82590>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859b2ed0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:21:57,013:INFO:Checking exceptions
2022-11-18 21:21:57,016:INFO:Importing libraries
2022-11-18 21:21:57,018:INFO:Copying training dataset
2022-11-18 21:21:57,023:INFO:Defining folds
2022-11-18 21:21:57,025:INFO:Declaring metric variables
2022-11-18 21:21:57,035:INFO:Importing untrained model
2022-11-18 21:21:57,045:INFO:Ridge Regression Imported successfully
2022-11-18 21:21:57,062:INFO:Starting cross validation
2022-11-18 21:21:57,064:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:21:57,396:INFO:Calculating mean and std
2022-11-18 21:21:57,401:INFO:Creating metrics dataframe
2022-11-18 21:21:57,411:INFO:Uploading results into container
2022-11-18 21:21:57,412:INFO:Uploading model into container now
2022-11-18 21:21:57,414:INFO:master_model_container: 3
2022-11-18 21:21:57,414:INFO:display_container: 2
2022-11-18 21:21:57,414:INFO:Ridge(random_state=123)
2022-11-18 21:21:57,415:INFO:create_model() successfully completed......................................
2022-11-18 21:21:57,605:INFO:SubProcess create_model() end ==================================
2022-11-18 21:21:57,606:INFO:Creating metrics dataframe
2022-11-18 21:21:57,626:INFO:Initializing Elastic Net
2022-11-18 21:21:57,627:INFO:Total runtime is 0.05333680709203084 minutes
2022-11-18 21:21:57,635:INFO:SubProcess create_model() called ==================================
2022-11-18 21:21:57,637:INFO:Initializing create_model()
2022-11-18 21:21:57,637:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085a82590>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859b2ed0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:21:57,637:INFO:Checking exceptions
2022-11-18 21:21:57,640:INFO:Importing libraries
2022-11-18 21:21:57,643:INFO:Copying training dataset
2022-11-18 21:21:57,649:INFO:Defining folds
2022-11-18 21:21:57,651:INFO:Declaring metric variables
2022-11-18 21:21:57,673:INFO:Importing untrained model
2022-11-18 21:21:57,685:INFO:Elastic Net Imported successfully
2022-11-18 21:21:57,709:INFO:Starting cross validation
2022-11-18 21:21:57,711:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:21:58,030:INFO:Calculating mean and std
2022-11-18 21:21:58,034:INFO:Creating metrics dataframe
2022-11-18 21:21:58,048:INFO:Uploading results into container
2022-11-18 21:21:58,048:INFO:Uploading model into container now
2022-11-18 21:21:58,049:INFO:master_model_container: 4
2022-11-18 21:21:58,049:INFO:display_container: 2
2022-11-18 21:21:58,050:INFO:ElasticNet(random_state=123)
2022-11-18 21:21:58,050:INFO:create_model() successfully completed......................................
2022-11-18 21:21:58,233:INFO:SubProcess create_model() end ==================================
2022-11-18 21:21:58,234:INFO:Creating metrics dataframe
2022-11-18 21:21:58,254:INFO:Initializing Least Angle Regression
2022-11-18 21:21:58,255:INFO:Total runtime is 0.06379892031351725 minutes
2022-11-18 21:21:58,266:INFO:SubProcess create_model() called ==================================
2022-11-18 21:21:58,266:INFO:Initializing create_model()
2022-11-18 21:21:58,267:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085a82590>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859b2ed0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:21:58,267:INFO:Checking exceptions
2022-11-18 21:21:58,271:INFO:Importing libraries
2022-11-18 21:21:58,271:INFO:Copying training dataset
2022-11-18 21:21:58,276:INFO:Defining folds
2022-11-18 21:21:58,278:INFO:Declaring metric variables
2022-11-18 21:21:58,290:INFO:Importing untrained model
2022-11-18 21:21:58,301:INFO:Least Angle Regression Imported successfully
2022-11-18 21:21:58,319:INFO:Starting cross validation
2022-11-18 21:21:58,321:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:21:58,364:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:21:58,394:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:21:58,428:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:21:58,467:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:21:58,501:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:21:58,542:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:21:58,551:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:21:58,593:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:21:58,620:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:21:58,637:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:21:58,654:INFO:Calculating mean and std
2022-11-18 21:21:58,660:INFO:Creating metrics dataframe
2022-11-18 21:21:58,673:INFO:Uploading results into container
2022-11-18 21:21:58,674:INFO:Uploading model into container now
2022-11-18 21:21:58,674:INFO:master_model_container: 5
2022-11-18 21:21:58,675:INFO:display_container: 2
2022-11-18 21:21:58,675:INFO:Lars(random_state=123)
2022-11-18 21:21:58,675:INFO:create_model() successfully completed......................................
2022-11-18 21:21:58,870:INFO:SubProcess create_model() end ==================================
2022-11-18 21:21:58,870:INFO:Creating metrics dataframe
2022-11-18 21:21:58,891:INFO:Initializing Lasso Least Angle Regression
2022-11-18 21:21:58,892:INFO:Total runtime is 0.07442297935485839 minutes
2022-11-18 21:21:58,902:INFO:SubProcess create_model() called ==================================
2022-11-18 21:21:58,905:INFO:Initializing create_model()
2022-11-18 21:21:58,906:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085a82590>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859b2ed0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:21:58,906:INFO:Checking exceptions
2022-11-18 21:21:58,909:INFO:Importing libraries
2022-11-18 21:21:58,909:INFO:Copying training dataset
2022-11-18 21:21:58,915:INFO:Defining folds
2022-11-18 21:21:58,915:INFO:Declaring metric variables
2022-11-18 21:21:58,932:INFO:Importing untrained model
2022-11-18 21:21:58,940:INFO:Lasso Least Angle Regression Imported successfully
2022-11-18 21:21:58,956:INFO:Starting cross validation
2022-11-18 21:21:58,961:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:21:59,001:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:21:59,033:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:21:59,067:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:21:59,097:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:21:59,133:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:21:59,177:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:21:59,184:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:21:59,217:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:21:59,245:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:21:59,257:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:21:59,273:INFO:Calculating mean and std
2022-11-18 21:21:59,276:INFO:Creating metrics dataframe
2022-11-18 21:21:59,282:INFO:Uploading results into container
2022-11-18 21:21:59,283:INFO:Uploading model into container now
2022-11-18 21:21:59,284:INFO:master_model_container: 6
2022-11-18 21:21:59,285:INFO:display_container: 2
2022-11-18 21:21:59,286:INFO:LassoLars(random_state=123)
2022-11-18 21:21:59,292:INFO:create_model() successfully completed......................................
2022-11-18 21:21:59,478:INFO:SubProcess create_model() end ==================================
2022-11-18 21:21:59,479:INFO:Creating metrics dataframe
2022-11-18 21:21:59,510:INFO:Initializing Orthogonal Matching Pursuit
2022-11-18 21:21:59,510:INFO:Total runtime is 0.08473098675409953 minutes
2022-11-18 21:21:59,516:INFO:SubProcess create_model() called ==================================
2022-11-18 21:21:59,517:INFO:Initializing create_model()
2022-11-18 21:21:59,517:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085a82590>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859b2ed0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:21:59,517:INFO:Checking exceptions
2022-11-18 21:21:59,520:INFO:Importing libraries
2022-11-18 21:21:59,520:INFO:Copying training dataset
2022-11-18 21:21:59,532:INFO:Defining folds
2022-11-18 21:21:59,533:INFO:Declaring metric variables
2022-11-18 21:21:59,542:INFO:Importing untrained model
2022-11-18 21:21:59,552:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-18 21:21:59,571:INFO:Starting cross validation
2022-11-18 21:21:59,573:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:21:59,612:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:21:59,641:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:21:59,692:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:21:59,706:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:21:59,758:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:21:59,800:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:21:59,814:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:21:59,841:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:21:59,868:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:21:59,882:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:21:59,900:INFO:Calculating mean and std
2022-11-18 21:21:59,903:INFO:Creating metrics dataframe
2022-11-18 21:21:59,920:INFO:Uploading results into container
2022-11-18 21:21:59,924:INFO:Uploading model into container now
2022-11-18 21:21:59,925:INFO:master_model_container: 7
2022-11-18 21:21:59,925:INFO:display_container: 2
2022-11-18 21:21:59,926:INFO:OrthogonalMatchingPursuit()
2022-11-18 21:21:59,926:INFO:create_model() successfully completed......................................
2022-11-18 21:22:00,114:INFO:SubProcess create_model() end ==================================
2022-11-18 21:22:00,115:INFO:Creating metrics dataframe
2022-11-18 21:22:00,136:INFO:Initializing Bayesian Ridge
2022-11-18 21:22:00,137:INFO:Total runtime is 0.09517613252003987 minutes
2022-11-18 21:22:00,148:INFO:SubProcess create_model() called ==================================
2022-11-18 21:22:00,150:INFO:Initializing create_model()
2022-11-18 21:22:00,150:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085a82590>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859b2ed0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:22:00,151:INFO:Checking exceptions
2022-11-18 21:22:00,154:INFO:Importing libraries
2022-11-18 21:22:00,154:INFO:Copying training dataset
2022-11-18 21:22:00,158:INFO:Defining folds
2022-11-18 21:22:00,159:INFO:Declaring metric variables
2022-11-18 21:22:00,173:INFO:Importing untrained model
2022-11-18 21:22:00,184:INFO:Bayesian Ridge Imported successfully
2022-11-18 21:22:00,203:INFO:Starting cross validation
2022-11-18 21:22:00,205:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:22:00,527:INFO:Calculating mean and std
2022-11-18 21:22:00,530:INFO:Creating metrics dataframe
2022-11-18 21:22:00,541:INFO:Uploading results into container
2022-11-18 21:22:00,543:INFO:Uploading model into container now
2022-11-18 21:22:00,543:INFO:master_model_container: 8
2022-11-18 21:22:00,546:INFO:display_container: 2
2022-11-18 21:22:00,546:INFO:BayesianRidge()
2022-11-18 21:22:00,547:INFO:create_model() successfully completed......................................
2022-11-18 21:22:00,732:INFO:SubProcess create_model() end ==================================
2022-11-18 21:22:00,733:INFO:Creating metrics dataframe
2022-11-18 21:22:00,760:INFO:Initializing Passive Aggressive Regressor
2022-11-18 21:22:00,763:INFO:Total runtime is 0.10561534961064656 minutes
2022-11-18 21:22:00,772:INFO:SubProcess create_model() called ==================================
2022-11-18 21:22:00,773:INFO:Initializing create_model()
2022-11-18 21:22:00,773:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085a82590>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859b2ed0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:22:00,773:INFO:Checking exceptions
2022-11-18 21:22:00,776:INFO:Importing libraries
2022-11-18 21:22:00,777:INFO:Copying training dataset
2022-11-18 21:22:00,785:INFO:Defining folds
2022-11-18 21:22:00,785:INFO:Declaring metric variables
2022-11-18 21:22:00,797:INFO:Importing untrained model
2022-11-18 21:22:00,810:INFO:Passive Aggressive Regressor Imported successfully
2022-11-18 21:22:00,836:INFO:Starting cross validation
2022-11-18 21:22:00,838:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:22:01,165:INFO:Calculating mean and std
2022-11-18 21:22:01,168:INFO:Creating metrics dataframe
2022-11-18 21:22:01,176:INFO:Uploading results into container
2022-11-18 21:22:01,177:INFO:Uploading model into container now
2022-11-18 21:22:01,177:INFO:master_model_container: 9
2022-11-18 21:22:01,178:INFO:display_container: 2
2022-11-18 21:22:01,178:INFO:PassiveAggressiveRegressor(random_state=123)
2022-11-18 21:22:01,179:INFO:create_model() successfully completed......................................
2022-11-18 21:22:01,368:INFO:SubProcess create_model() end ==================================
2022-11-18 21:22:01,368:INFO:Creating metrics dataframe
2022-11-18 21:22:01,393:INFO:Initializing Huber Regressor
2022-11-18 21:22:01,394:INFO:Total runtime is 0.11612821420033773 minutes
2022-11-18 21:22:01,404:INFO:SubProcess create_model() called ==================================
2022-11-18 21:22:01,406:INFO:Initializing create_model()
2022-11-18 21:22:01,406:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085a82590>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859b2ed0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:22:01,406:INFO:Checking exceptions
2022-11-18 21:22:01,411:INFO:Importing libraries
2022-11-18 21:22:01,411:INFO:Copying training dataset
2022-11-18 21:22:01,415:INFO:Defining folds
2022-11-18 21:22:01,416:INFO:Declaring metric variables
2022-11-18 21:22:01,426:INFO:Importing untrained model
2022-11-18 21:22:01,436:INFO:Huber Regressor Imported successfully
2022-11-18 21:22:01,452:INFO:Starting cross validation
2022-11-18 21:22:01,454:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:22:01,555:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:22:01,613:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:22:01,710:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:22:01,730:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:22:01,822:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:22:01,862:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:22:01,928:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:22:01,968:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:22:02,032:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:22:02,071:INFO:Calculating mean and std
2022-11-18 21:22:02,075:INFO:Creating metrics dataframe
2022-11-18 21:22:02,088:INFO:Uploading results into container
2022-11-18 21:22:02,090:INFO:Uploading model into container now
2022-11-18 21:22:02,091:INFO:master_model_container: 10
2022-11-18 21:22:02,091:INFO:display_container: 2
2022-11-18 21:22:02,092:INFO:HuberRegressor()
2022-11-18 21:22:02,092:INFO:create_model() successfully completed......................................
2022-11-18 21:22:02,291:INFO:SubProcess create_model() end ==================================
2022-11-18 21:22:02,292:INFO:Creating metrics dataframe
2022-11-18 21:22:02,315:INFO:Initializing K Neighbors Regressor
2022-11-18 21:22:02,316:INFO:Total runtime is 0.13148711125055948 minutes
2022-11-18 21:22:02,323:INFO:SubProcess create_model() called ==================================
2022-11-18 21:22:02,324:INFO:Initializing create_model()
2022-11-18 21:22:02,329:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085a82590>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859b2ed0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:22:02,329:INFO:Checking exceptions
2022-11-18 21:22:02,333:INFO:Importing libraries
2022-11-18 21:22:02,333:INFO:Copying training dataset
2022-11-18 21:22:02,341:INFO:Defining folds
2022-11-18 21:22:02,342:INFO:Declaring metric variables
2022-11-18 21:22:02,355:INFO:Importing untrained model
2022-11-18 21:22:02,363:INFO:K Neighbors Regressor Imported successfully
2022-11-18 21:22:02,380:INFO:Starting cross validation
2022-11-18 21:22:02,383:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:22:03,115:INFO:Calculating mean and std
2022-11-18 21:22:03,118:INFO:Creating metrics dataframe
2022-11-18 21:22:03,124:INFO:Uploading results into container
2022-11-18 21:22:03,125:INFO:Uploading model into container now
2022-11-18 21:22:03,126:INFO:master_model_container: 11
2022-11-18 21:22:03,126:INFO:display_container: 2
2022-11-18 21:22:03,127:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-18 21:22:03,128:INFO:create_model() successfully completed......................................
2022-11-18 21:22:03,315:INFO:SubProcess create_model() end ==================================
2022-11-18 21:22:03,316:INFO:Creating metrics dataframe
2022-11-18 21:22:03,344:INFO:Initializing Decision Tree Regressor
2022-11-18 21:22:03,345:INFO:Total runtime is 0.14863709211349485 minutes
2022-11-18 21:22:03,355:INFO:SubProcess create_model() called ==================================
2022-11-18 21:22:03,355:INFO:Initializing create_model()
2022-11-18 21:22:03,356:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085a82590>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859b2ed0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:22:03,356:INFO:Checking exceptions
2022-11-18 21:22:03,360:INFO:Importing libraries
2022-11-18 21:22:03,361:INFO:Copying training dataset
2022-11-18 21:22:03,368:INFO:Defining folds
2022-11-18 21:22:03,369:INFO:Declaring metric variables
2022-11-18 21:22:03,380:INFO:Importing untrained model
2022-11-18 21:22:03,388:INFO:Decision Tree Regressor Imported successfully
2022-11-18 21:22:03,404:INFO:Starting cross validation
2022-11-18 21:22:03,409:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:22:03,762:INFO:Calculating mean and std
2022-11-18 21:22:03,765:INFO:Creating metrics dataframe
2022-11-18 21:22:03,779:INFO:Uploading results into container
2022-11-18 21:22:03,786:INFO:Uploading model into container now
2022-11-18 21:22:03,787:INFO:master_model_container: 12
2022-11-18 21:22:03,787:INFO:display_container: 2
2022-11-18 21:22:03,787:INFO:DecisionTreeRegressor(random_state=123)
2022-11-18 21:22:03,788:INFO:create_model() successfully completed......................................
2022-11-18 21:22:03,981:INFO:SubProcess create_model() end ==================================
2022-11-18 21:22:03,981:INFO:Creating metrics dataframe
2022-11-18 21:22:04,006:INFO:Initializing Random Forest Regressor
2022-11-18 21:22:04,007:INFO:Total runtime is 0.15967199007670083 minutes
2022-11-18 21:22:04,017:INFO:SubProcess create_model() called ==================================
2022-11-18 21:22:04,017:INFO:Initializing create_model()
2022-11-18 21:22:04,021:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085a82590>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859b2ed0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:22:04,022:INFO:Checking exceptions
2022-11-18 21:22:04,024:INFO:Importing libraries
2022-11-18 21:22:04,026:INFO:Copying training dataset
2022-11-18 21:22:04,031:INFO:Defining folds
2022-11-18 21:22:04,031:INFO:Declaring metric variables
2022-11-18 21:22:04,041:INFO:Importing untrained model
2022-11-18 21:22:04,052:INFO:Random Forest Regressor Imported successfully
2022-11-18 21:22:04,070:INFO:Starting cross validation
2022-11-18 21:22:04,072:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:22:08,746:INFO:Calculating mean and std
2022-11-18 21:22:08,749:INFO:Creating metrics dataframe
2022-11-18 21:22:08,756:INFO:Uploading results into container
2022-11-18 21:22:08,757:INFO:Uploading model into container now
2022-11-18 21:22:08,758:INFO:master_model_container: 13
2022-11-18 21:22:08,758:INFO:display_container: 2
2022-11-18 21:22:08,759:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-18 21:22:08,759:INFO:create_model() successfully completed......................................
2022-11-18 21:22:08,949:INFO:SubProcess create_model() end ==================================
2022-11-18 21:22:08,950:INFO:Creating metrics dataframe
2022-11-18 21:22:08,980:INFO:Initializing Extra Trees Regressor
2022-11-18 21:22:08,980:INFO:Total runtime is 0.2425615588823954 minutes
2022-11-18 21:22:08,988:INFO:SubProcess create_model() called ==================================
2022-11-18 21:22:08,989:INFO:Initializing create_model()
2022-11-18 21:22:08,989:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085a82590>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859b2ed0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:22:08,989:INFO:Checking exceptions
2022-11-18 21:22:08,992:INFO:Importing libraries
2022-11-18 21:22:08,992:INFO:Copying training dataset
2022-11-18 21:22:08,997:INFO:Defining folds
2022-11-18 21:22:08,998:INFO:Declaring metric variables
2022-11-18 21:22:09,012:INFO:Importing untrained model
2022-11-18 21:22:09,021:INFO:Extra Trees Regressor Imported successfully
2022-11-18 21:22:09,037:INFO:Starting cross validation
2022-11-18 21:22:09,041:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:22:11,783:INFO:Calculating mean and std
2022-11-18 21:22:11,787:INFO:Creating metrics dataframe
2022-11-18 21:22:11,803:INFO:Uploading results into container
2022-11-18 21:22:11,804:INFO:Uploading model into container now
2022-11-18 21:22:11,805:INFO:master_model_container: 14
2022-11-18 21:22:11,805:INFO:display_container: 2
2022-11-18 21:22:11,806:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-18 21:22:11,806:INFO:create_model() successfully completed......................................
2022-11-18 21:22:11,997:INFO:SubProcess create_model() end ==================================
2022-11-18 21:22:11,997:INFO:Creating metrics dataframe
2022-11-18 21:22:12,019:INFO:Initializing AdaBoost Regressor
2022-11-18 21:22:12,020:INFO:Total runtime is 0.29322651227315266 minutes
2022-11-18 21:22:12,032:INFO:SubProcess create_model() called ==================================
2022-11-18 21:22:12,033:INFO:Initializing create_model()
2022-11-18 21:22:12,034:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085a82590>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859b2ed0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:22:12,041:INFO:Checking exceptions
2022-11-18 21:22:12,044:INFO:Importing libraries
2022-11-18 21:22:12,044:INFO:Copying training dataset
2022-11-18 21:22:12,049:INFO:Defining folds
2022-11-18 21:22:12,050:INFO:Declaring metric variables
2022-11-18 21:22:12,061:INFO:Importing untrained model
2022-11-18 21:22:12,073:INFO:AdaBoost Regressor Imported successfully
2022-11-18 21:22:12,094:INFO:Starting cross validation
2022-11-18 21:22:12,098:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:22:13,290:INFO:Calculating mean and std
2022-11-18 21:22:13,293:INFO:Creating metrics dataframe
2022-11-18 21:22:13,303:INFO:Uploading results into container
2022-11-18 21:22:13,305:INFO:Uploading model into container now
2022-11-18 21:22:13,306:INFO:master_model_container: 15
2022-11-18 21:22:13,306:INFO:display_container: 2
2022-11-18 21:22:13,307:INFO:AdaBoostRegressor(random_state=123)
2022-11-18 21:22:13,307:INFO:create_model() successfully completed......................................
2022-11-18 21:22:13,493:INFO:SubProcess create_model() end ==================================
2022-11-18 21:22:13,494:INFO:Creating metrics dataframe
2022-11-18 21:22:13,523:INFO:Initializing Gradient Boosting Regressor
2022-11-18 21:22:13,523:INFO:Total runtime is 0.31827922264734904 minutes
2022-11-18 21:22:13,535:INFO:SubProcess create_model() called ==================================
2022-11-18 21:22:13,542:INFO:Initializing create_model()
2022-11-18 21:22:13,543:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085a82590>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859b2ed0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:22:13,543:INFO:Checking exceptions
2022-11-18 21:22:13,545:INFO:Importing libraries
2022-11-18 21:22:13,546:INFO:Copying training dataset
2022-11-18 21:22:13,552:INFO:Defining folds
2022-11-18 21:22:13,552:INFO:Declaring metric variables
2022-11-18 21:22:13,566:INFO:Importing untrained model
2022-11-18 21:22:13,576:INFO:Gradient Boosting Regressor Imported successfully
2022-11-18 21:22:13,599:INFO:Starting cross validation
2022-11-18 21:22:13,601:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:22:15,375:INFO:Calculating mean and std
2022-11-18 21:22:15,381:INFO:Creating metrics dataframe
2022-11-18 21:22:15,397:INFO:Uploading results into container
2022-11-18 21:22:15,398:INFO:Uploading model into container now
2022-11-18 21:22:15,399:INFO:master_model_container: 16
2022-11-18 21:22:15,399:INFO:display_container: 2
2022-11-18 21:22:15,400:INFO:GradientBoostingRegressor(random_state=123)
2022-11-18 21:22:15,400:INFO:create_model() successfully completed......................................
2022-11-18 21:22:15,584:INFO:SubProcess create_model() end ==================================
2022-11-18 21:22:15,584:INFO:Creating metrics dataframe
2022-11-18 21:22:15,608:INFO:Initializing Light Gradient Boosting Machine
2022-11-18 21:22:15,609:INFO:Total runtime is 0.35304030577341716 minutes
2022-11-18 21:22:15,618:INFO:SubProcess create_model() called ==================================
2022-11-18 21:22:15,620:INFO:Initializing create_model()
2022-11-18 21:22:15,620:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085a82590>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859b2ed0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:22:15,621:INFO:Checking exceptions
2022-11-18 21:22:15,624:INFO:Importing libraries
2022-11-18 21:22:15,624:INFO:Copying training dataset
2022-11-18 21:22:15,630:INFO:Defining folds
2022-11-18 21:22:15,630:INFO:Declaring metric variables
2022-11-18 21:22:15,650:INFO:Importing untrained model
2022-11-18 21:22:15,659:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-18 21:22:15,679:INFO:Starting cross validation
2022-11-18 21:22:15,680:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:22:16,527:INFO:Calculating mean and std
2022-11-18 21:22:16,538:INFO:Creating metrics dataframe
2022-11-18 21:22:16,546:INFO:Uploading results into container
2022-11-18 21:22:16,547:INFO:Uploading model into container now
2022-11-18 21:22:16,548:INFO:master_model_container: 17
2022-11-18 21:22:16,548:INFO:display_container: 2
2022-11-18 21:22:16,549:INFO:LGBMRegressor(random_state=123)
2022-11-18 21:22:16,549:INFO:create_model() successfully completed......................................
2022-11-18 21:22:16,736:INFO:SubProcess create_model() end ==================================
2022-11-18 21:22:16,737:INFO:Creating metrics dataframe
2022-11-18 21:22:16,768:INFO:Initializing Dummy Regressor
2022-11-18 21:22:16,774:INFO:Total runtime is 0.3724555055300395 minutes
2022-11-18 21:22:16,781:INFO:SubProcess create_model() called ==================================
2022-11-18 21:22:16,782:INFO:Initializing create_model()
2022-11-18 21:22:16,783:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085a82590>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859b2ed0>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:22:16,783:INFO:Checking exceptions
2022-11-18 21:22:16,786:INFO:Importing libraries
2022-11-18 21:22:16,786:INFO:Copying training dataset
2022-11-18 21:22:16,794:INFO:Defining folds
2022-11-18 21:22:16,795:INFO:Declaring metric variables
2022-11-18 21:22:16,811:INFO:Importing untrained model
2022-11-18 21:22:16,823:INFO:Dummy Regressor Imported successfully
2022-11-18 21:22:16,843:INFO:Starting cross validation
2022-11-18 21:22:16,844:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:22:17,128:INFO:Calculating mean and std
2022-11-18 21:22:17,131:INFO:Creating metrics dataframe
2022-11-18 21:22:17,137:INFO:Uploading results into container
2022-11-18 21:22:17,138:INFO:Uploading model into container now
2022-11-18 21:22:17,139:INFO:master_model_container: 18
2022-11-18 21:22:17,143:INFO:display_container: 2
2022-11-18 21:22:17,144:INFO:DummyRegressor()
2022-11-18 21:22:17,145:INFO:create_model() successfully completed......................................
2022-11-18 21:22:17,343:INFO:SubProcess create_model() end ==================================
2022-11-18 21:22:17,344:INFO:Creating metrics dataframe
2022-11-18 21:22:17,398:INFO:Initializing create_model()
2022-11-18 21:22:17,398:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085a82590>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:22:17,399:INFO:Checking exceptions
2022-11-18 21:22:17,406:INFO:Importing libraries
2022-11-18 21:22:17,406:INFO:Copying training dataset
2022-11-18 21:22:17,411:INFO:Defining folds
2022-11-18 21:22:17,411:INFO:Declaring metric variables
2022-11-18 21:22:17,412:INFO:Importing untrained model
2022-11-18 21:22:17,413:INFO:Declaring custom model
2022-11-18 21:22:17,414:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-18 21:22:17,416:INFO:Cross validation set to False
2022-11-18 21:22:17,416:INFO:Fitting Model
2022-11-18 21:22:17,444:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:22:17,447:INFO:OrthogonalMatchingPursuit()
2022-11-18 21:22:17,448:INFO:create_model() successfully completed......................................
2022-11-18 21:22:17,729:INFO:master_model_container: 18
2022-11-18 21:22:17,730:INFO:display_container: 2
2022-11-18 21:22:17,731:INFO:OrthogonalMatchingPursuit()
2022-11-18 21:22:17,731:INFO:compare_models() successfully completed......................................
2022-11-18 21:25:52,640:INFO:PyCaret RegressionExperiment
2022-11-18 21:25:52,641:INFO:Logging name: FullData
2022-11-18 21:25:52,641:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-18 21:25:52,641:INFO:version 3.0.0.rc4
2022-11-18 21:25:52,641:INFO:Initializing setup()
2022-11-18 21:25:52,641:INFO:self.USI: b57e
2022-11-18 21:25:52,641:INFO:self.variable_keys: {'_available_plots', 'seed', 'log_plots_param', '_gpu_n_jobs_param', 'USI', 'pipeline', '_all_models_internal', 'fold_generator', 'variable_keys', 'gpu_param', 'exp_id', 'X_test', 'memory', '_ml_usecase', 'y', 'fold_groups_param', 'transform_target_method_param', 'display_container', 'logging_param', '_all_metrics', 'fold_shuffle_param', 'n_jobs_param', 'exp_name_log', 'data', 'y_test', 'html_param', 'target_param', 'transform_target_param', '_all_models', 'y_train', 'X_train', 'X', 'master_model_container', 'idx'}
2022-11-18 21:25:52,642:INFO:Checking environment
2022-11-18 21:25:52,642:INFO:python_version: 3.7.15
2022-11-18 21:25:52,642:INFO:python_build: ('default', 'Oct 12 2022 19:14:55')
2022-11-18 21:25:52,642:INFO:machine: x86_64
2022-11-18 21:25:52,643:INFO:platform: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-18 21:25:52,643:INFO:Memory: svmem(total=13616353280, available=11384037376, percent=16.4, used=2119745536, free=7294726144, active=1076719616, inactive=4877565952, buffers=167997440, cached=4033884160, shared=1327104, slab=268644352)
2022-11-18 21:25:52,644:INFO:Physical Core: 1
2022-11-18 21:25:52,645:INFO:Logical Core: 2
2022-11-18 21:25:52,645:INFO:Checking libraries
2022-11-18 21:25:52,645:INFO:System:
2022-11-18 21:25:52,645:INFO:    python: 3.7.15 (default, Oct 12 2022, 19:14:55)  [GCC 7.5.0]
2022-11-18 21:25:52,645:INFO:executable: /usr/bin/python3
2022-11-18 21:25:52,646:INFO:   machine: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-18 21:25:52,647:INFO:PyCaret required dependencies:
2022-11-18 21:25:52,648:INFO:                 pip: 21.1.3
2022-11-18 21:25:52,648:INFO:          setuptools: 57.4.0
2022-11-18 21:25:52,648:INFO:             pycaret: 3.0.0rc4
2022-11-18 21:25:52,648:INFO:             IPython: 7.9.0
2022-11-18 21:25:52,648:INFO:          ipywidgets: 7.7.1
2022-11-18 21:25:52,648:INFO:                tqdm: 4.64.1
2022-11-18 21:25:52,648:INFO:               numpy: 1.21.6
2022-11-18 21:25:52,648:INFO:              pandas: 1.3.5
2022-11-18 21:25:52,648:INFO:              jinja2: 3.0.0
2022-11-18 21:25:52,649:INFO:               scipy: 1.7.3
2022-11-18 21:25:52,649:INFO:              joblib: 1.2.0
2022-11-18 21:25:52,649:INFO:             sklearn: 1.0.2
2022-11-18 21:25:52,649:INFO:                pyod: 1.0.6
2022-11-18 21:25:52,649:INFO:            imblearn: 0.8.1
2022-11-18 21:25:52,649:INFO:   category_encoders: 2.5.1.post0
2022-11-18 21:25:52,649:INFO:            lightgbm: 3.3.3
2022-11-18 21:25:52,649:INFO:               numba: 0.55.2
2022-11-18 21:25:52,649:INFO:            requests: 2.28.1
2022-11-18 21:25:52,650:INFO:          matplotlib: 3.5.3
2022-11-18 21:25:52,650:INFO:          scikitplot: 0.3.7
2022-11-18 21:25:52,650:INFO:         yellowbrick: 1.5
2022-11-18 21:25:52,650:INFO:              plotly: 5.5.0
2022-11-18 21:25:52,650:INFO:             kaleido: 0.2.1
2022-11-18 21:25:52,650:INFO:         statsmodels: 0.12.2
2022-11-18 21:25:52,650:INFO:              sktime: 0.13.4
2022-11-18 21:25:52,650:INFO:               tbats: 1.1.1
2022-11-18 21:25:52,650:INFO:            pmdarima: 1.8.5
2022-11-18 21:25:52,650:INFO:              psutil: 5.9.4
2022-11-18 21:25:52,651:INFO:PyCaret optional dependencies:
2022-11-18 21:25:52,651:INFO:                shap: Not installed
2022-11-18 21:25:52,651:INFO:           interpret: Not installed
2022-11-18 21:25:52,651:INFO:                umap: Not installed
2022-11-18 21:25:52,652:INFO:    pandas_profiling: 1.4.1
2022-11-18 21:25:52,652:INFO:  explainerdashboard: Not installed
2022-11-18 21:25:52,652:INFO:             autoviz: Not installed
2022-11-18 21:25:52,652:INFO:           fairlearn: Not installed
2022-11-18 21:25:52,653:INFO:             xgboost: 0.90
2022-11-18 21:25:52,653:INFO:            catboost: Not installed
2022-11-18 21:25:52,653:INFO:              kmodes: Not installed
2022-11-18 21:25:52,653:INFO:             mlxtend: 0.14.0
2022-11-18 21:25:52,653:INFO:       statsforecast: Not installed
2022-11-18 21:25:52,653:INFO:        tune_sklearn: Not installed
2022-11-18 21:25:52,653:INFO:                 ray: Not installed
2022-11-18 21:25:52,653:INFO:            hyperopt: 0.1.2
2022-11-18 21:25:52,654:INFO:              optuna: Not installed
2022-11-18 21:25:52,654:INFO:               skopt: Not installed
2022-11-18 21:25:52,654:INFO:              mlflow: Not installed
2022-11-18 21:25:52,654:INFO:              gradio: Not installed
2022-11-18 21:25:52,656:INFO:             fastapi: Not installed
2022-11-18 21:25:52,656:INFO:             uvicorn: Not installed
2022-11-18 21:25:52,657:INFO:              m2cgen: Not installed
2022-11-18 21:25:52,657:INFO:           evidently: Not installed
2022-11-18 21:25:52,657:INFO:                nltk: 3.7
2022-11-18 21:25:52,657:INFO:            pyLDAvis: Not installed
2022-11-18 21:25:52,657:INFO:              gensim: 3.6.0
2022-11-18 21:25:52,657:INFO:               spacy: 3.4.2
2022-11-18 21:25:52,657:INFO:           wordcloud: 1.8.2.2
2022-11-18 21:25:52,657:INFO:            textblob: 0.15.3
2022-11-18 21:25:52,657:INFO:               fugue: Not installed
2022-11-18 21:25:52,657:INFO:           streamlit: Not installed
2022-11-18 21:25:52,658:INFO:             prophet: 1.1.1
2022-11-18 21:25:52,658:INFO:None
2022-11-18 21:25:52,658:INFO:Set up data.
2022-11-18 21:25:52,673:INFO:Set up train/test split.
2022-11-18 21:25:52,679:INFO:Set up index.
2022-11-18 21:25:52,680:INFO:Set up folding strategy.
2022-11-18 21:25:52,680:INFO:Assigning column types.
2022-11-18 21:25:52,695:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-18 21:25:52,696:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-18 21:25:52,708:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:25:52,718:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:25:52,850:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:25:52,963:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:25:52,965:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:25:52,965:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:25:52,966:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:25:52,967:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-18 21:25:52,978:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:25:52,990:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:25:53,125:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:25:53,232:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:25:53,233:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:25:53,234:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:25:53,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:25:53,235:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-18 21:25:53,246:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:25:53,258:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:25:53,395:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:25:53,508:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:25:53,510:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:25:53,510:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:25:53,511:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:25:53,528:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:25:53,543:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:25:53,690:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:25:53,793:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:25:53,794:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:25:53,795:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:25:53,795:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:25:53,796:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-18 21:25:53,818:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:25:53,954:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:25:54,057:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:25:54,058:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:25:54,059:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:25:54,059:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:25:54,081:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:25:54,212:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:25:54,310:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:25:54,311:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:25:54,312:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:25:54,312:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:25:54,313:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-18 21:25:54,452:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:25:54,565:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:25:54,566:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:25:54,567:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:25:54,568:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:25:54,716:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:25:54,813:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:25:54,814:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:25:54,815:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:25:54,815:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:25:54,816:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-18 21:25:54,959:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:25:55,055:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:25:55,056:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:25:55,056:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:25:55,213:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:25:55,319:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:25:55,320:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:25:55,320:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:25:55,321:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-18 21:25:55,560:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:25:55,561:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:25:55,562:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:25:55,812:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:25:55,812:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:25:55,813:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:25:55,815:INFO:Preparing preprocessing pipeline...
2022-11-18 21:25:55,817:INFO:Set up simple imputation.
2022-11-18 21:25:55,818:INFO:Set up variance threshold.
2022-11-18 21:25:55,893:INFO:Finished creating preprocessing pipeline.
2022-11-18 21:25:55,905:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO',
                                             'Open_Line_ML_x'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-18 21:25:55,906:INFO:Creating final display dataframe.
2022-11-18 21:25:56,210:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 13)
4         Train data shape    (607, 13)
5          Test data shape    (261, 13)
6         Numeric features           12
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         b57e
2022-11-18 21:25:56,477:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:25:56,478:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:25:56,479:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:25:56,739:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:25:56,739:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:25:56,740:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:25:56,753:INFO:setup() successfully completed in 4.13s...............
2022-11-18 21:25:56,754:INFO:Initializing compare_models()
2022-11-18 21:25:56,754:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085cb45d0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fa085cb45d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-18 21:25:56,754:INFO:Checking exceptions
2022-11-18 21:25:56,757:INFO:Preparing display monitor
2022-11-18 21:25:56,865:INFO:Initializing Linear Regression
2022-11-18 21:25:56,866:INFO:Total runtime is 8.416175842285156e-06 minutes
2022-11-18 21:25:56,878:INFO:SubProcess create_model() called ==================================
2022-11-18 21:25:56,878:INFO:Initializing create_model()
2022-11-18 21:25:56,879:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085cb45d0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859f6e90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:25:56,879:INFO:Checking exceptions
2022-11-18 21:25:56,882:INFO:Importing libraries
2022-11-18 21:25:56,883:INFO:Copying training dataset
2022-11-18 21:25:56,886:INFO:Defining folds
2022-11-18 21:25:56,887:INFO:Declaring metric variables
2022-11-18 21:25:56,900:INFO:Importing untrained model
2022-11-18 21:25:56,911:INFO:Linear Regression Imported successfully
2022-11-18 21:25:56,936:INFO:Starting cross validation
2022-11-18 21:25:56,942:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:25:58,679:INFO:Calculating mean and std
2022-11-18 21:25:58,682:INFO:Creating metrics dataframe
2022-11-18 21:25:58,688:INFO:Uploading results into container
2022-11-18 21:25:58,689:INFO:Uploading model into container now
2022-11-18 21:25:58,690:INFO:master_model_container: 1
2022-11-18 21:25:58,690:INFO:display_container: 2
2022-11-18 21:25:58,691:INFO:LinearRegression(n_jobs=-1)
2022-11-18 21:25:58,691:INFO:create_model() successfully completed......................................
2022-11-18 21:25:58,911:INFO:SubProcess create_model() end ==================================
2022-11-18 21:25:58,912:INFO:Creating metrics dataframe
2022-11-18 21:25:58,938:INFO:Initializing Lasso Regression
2022-11-18 21:25:58,939:INFO:Total runtime is 0.03456175724665324 minutes
2022-11-18 21:25:58,950:INFO:SubProcess create_model() called ==================================
2022-11-18 21:25:58,951:INFO:Initializing create_model()
2022-11-18 21:25:58,951:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085cb45d0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859f6e90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:25:58,952:INFO:Checking exceptions
2022-11-18 21:25:58,955:INFO:Importing libraries
2022-11-18 21:25:58,955:INFO:Copying training dataset
2022-11-18 21:25:58,960:INFO:Defining folds
2022-11-18 21:25:58,961:INFO:Declaring metric variables
2022-11-18 21:25:58,970:INFO:Importing untrained model
2022-11-18 21:25:58,980:INFO:Lasso Regression Imported successfully
2022-11-18 21:25:58,999:INFO:Starting cross validation
2022-11-18 21:25:59,001:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:25:59,316:INFO:Calculating mean and std
2022-11-18 21:25:59,318:INFO:Creating metrics dataframe
2022-11-18 21:25:59,330:INFO:Uploading results into container
2022-11-18 21:25:59,334:INFO:Uploading model into container now
2022-11-18 21:25:59,335:INFO:master_model_container: 2
2022-11-18 21:25:59,335:INFO:display_container: 2
2022-11-18 21:25:59,335:INFO:Lasso(random_state=123)
2022-11-18 21:25:59,336:INFO:create_model() successfully completed......................................
2022-11-18 21:25:59,522:INFO:SubProcess create_model() end ==================================
2022-11-18 21:25:59,523:INFO:Creating metrics dataframe
2022-11-18 21:25:59,549:INFO:Initializing Ridge Regression
2022-11-18 21:25:59,553:INFO:Total runtime is 0.044800305366516115 minutes
2022-11-18 21:25:59,562:INFO:SubProcess create_model() called ==================================
2022-11-18 21:25:59,562:INFO:Initializing create_model()
2022-11-18 21:25:59,563:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085cb45d0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859f6e90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:25:59,563:INFO:Checking exceptions
2022-11-18 21:25:59,567:INFO:Importing libraries
2022-11-18 21:25:59,567:INFO:Copying training dataset
2022-11-18 21:25:59,576:INFO:Defining folds
2022-11-18 21:25:59,576:INFO:Declaring metric variables
2022-11-18 21:25:59,587:INFO:Importing untrained model
2022-11-18 21:25:59,598:INFO:Ridge Regression Imported successfully
2022-11-18 21:25:59,613:INFO:Starting cross validation
2022-11-18 21:25:59,618:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:25:59,660:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.19612e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:25:59,687:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1832e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:25:59,741:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.25596e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:25:59,767:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.27134e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:25:59,819:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1563e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:25:59,833:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.25177e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:25:59,875:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.30751e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:25:59,886:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1922e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:25:59,922:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.19532e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:25:59,928:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.20778e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:25:59,944:INFO:Calculating mean and std
2022-11-18 21:25:59,947:INFO:Creating metrics dataframe
2022-11-18 21:25:59,954:INFO:Uploading results into container
2022-11-18 21:25:59,958:INFO:Uploading model into container now
2022-11-18 21:25:59,963:INFO:master_model_container: 3
2022-11-18 21:25:59,964:INFO:display_container: 2
2022-11-18 21:25:59,964:INFO:Ridge(random_state=123)
2022-11-18 21:25:59,965:INFO:create_model() successfully completed......................................
2022-11-18 21:26:00,143:INFO:SubProcess create_model() end ==================================
2022-11-18 21:26:00,143:INFO:Creating metrics dataframe
2022-11-18 21:26:00,164:INFO:Initializing Elastic Net
2022-11-18 21:26:00,165:INFO:Total runtime is 0.0549923578898112 minutes
2022-11-18 21:26:00,173:INFO:SubProcess create_model() called ==================================
2022-11-18 21:26:00,176:INFO:Initializing create_model()
2022-11-18 21:26:00,176:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085cb45d0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859f6e90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:26:00,176:INFO:Checking exceptions
2022-11-18 21:26:00,179:INFO:Importing libraries
2022-11-18 21:26:00,179:INFO:Copying training dataset
2022-11-18 21:26:00,184:INFO:Defining folds
2022-11-18 21:26:00,190:INFO:Declaring metric variables
2022-11-18 21:26:00,199:INFO:Importing untrained model
2022-11-18 21:26:00,208:INFO:Elastic Net Imported successfully
2022-11-18 21:26:00,226:INFO:Starting cross validation
2022-11-18 21:26:00,229:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:26:00,534:INFO:Calculating mean and std
2022-11-18 21:26:00,537:INFO:Creating metrics dataframe
2022-11-18 21:26:00,547:INFO:Uploading results into container
2022-11-18 21:26:00,548:INFO:Uploading model into container now
2022-11-18 21:26:00,549:INFO:master_model_container: 4
2022-11-18 21:26:00,549:INFO:display_container: 2
2022-11-18 21:26:00,554:INFO:ElasticNet(random_state=123)
2022-11-18 21:26:00,555:INFO:create_model() successfully completed......................................
2022-11-18 21:26:00,734:INFO:SubProcess create_model() end ==================================
2022-11-18 21:26:00,734:INFO:Creating metrics dataframe
2022-11-18 21:26:00,754:INFO:Initializing Least Angle Regression
2022-11-18 21:26:00,755:INFO:Total runtime is 0.06483506759007772 minutes
2022-11-18 21:26:00,764:INFO:SubProcess create_model() called ==================================
2022-11-18 21:26:00,765:INFO:Initializing create_model()
2022-11-18 21:26:00,765:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085cb45d0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859f6e90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:26:00,765:INFO:Checking exceptions
2022-11-18 21:26:00,769:INFO:Importing libraries
2022-11-18 21:26:00,769:INFO:Copying training dataset
2022-11-18 21:26:00,776:INFO:Defining folds
2022-11-18 21:26:00,777:INFO:Declaring metric variables
2022-11-18 21:26:00,786:INFO:Importing untrained model
2022-11-18 21:26:00,794:INFO:Least Angle Regression Imported successfully
2022-11-18 21:26:00,810:INFO:Starting cross validation
2022-11-18 21:26:00,814:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:26:00,869:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:26:00,901:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:26:00,967:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:26:01,003:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:26:01,036:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:26:01,074:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:26:01,079:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:26:01,116:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:26:01,141:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:26:01,164:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:26:01,178:INFO:Calculating mean and std
2022-11-18 21:26:01,181:INFO:Creating metrics dataframe
2022-11-18 21:26:01,191:INFO:Uploading results into container
2022-11-18 21:26:01,192:INFO:Uploading model into container now
2022-11-18 21:26:01,193:INFO:master_model_container: 5
2022-11-18 21:26:01,193:INFO:display_container: 2
2022-11-18 21:26:01,193:INFO:Lars(random_state=123)
2022-11-18 21:26:01,194:INFO:create_model() successfully completed......................................
2022-11-18 21:26:01,374:INFO:SubProcess create_model() end ==================================
2022-11-18 21:26:01,375:INFO:Creating metrics dataframe
2022-11-18 21:26:01,394:INFO:Initializing Lasso Least Angle Regression
2022-11-18 21:26:01,395:INFO:Total runtime is 0.07549464305241903 minutes
2022-11-18 21:26:01,403:INFO:SubProcess create_model() called ==================================
2022-11-18 21:26:01,403:INFO:Initializing create_model()
2022-11-18 21:26:01,404:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085cb45d0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859f6e90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:26:01,404:INFO:Checking exceptions
2022-11-18 21:26:01,406:INFO:Importing libraries
2022-11-18 21:26:01,407:INFO:Copying training dataset
2022-11-18 21:26:01,414:INFO:Defining folds
2022-11-18 21:26:01,414:INFO:Declaring metric variables
2022-11-18 21:26:01,422:INFO:Importing untrained model
2022-11-18 21:26:01,432:INFO:Lasso Least Angle Regression Imported successfully
2022-11-18 21:26:01,449:INFO:Starting cross validation
2022-11-18 21:26:01,451:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:26:01,490:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:26:01,517:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:26:01,551:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:26:01,588:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:26:01,621:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:26:01,658:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:26:01,668:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:26:01,699:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:26:01,730:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:26:01,746:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:26:01,761:INFO:Calculating mean and std
2022-11-18 21:26:01,764:INFO:Creating metrics dataframe
2022-11-18 21:26:01,771:INFO:Uploading results into container
2022-11-18 21:26:01,774:INFO:Uploading model into container now
2022-11-18 21:26:01,778:INFO:master_model_container: 6
2022-11-18 21:26:01,780:INFO:display_container: 2
2022-11-18 21:26:01,781:INFO:LassoLars(random_state=123)
2022-11-18 21:26:01,782:INFO:create_model() successfully completed......................................
2022-11-18 21:26:01,972:INFO:SubProcess create_model() end ==================================
2022-11-18 21:26:01,972:INFO:Creating metrics dataframe
2022-11-18 21:26:01,997:INFO:Initializing Orthogonal Matching Pursuit
2022-11-18 21:26:01,998:INFO:Total runtime is 0.08554383118947347 minutes
2022-11-18 21:26:02,010:INFO:SubProcess create_model() called ==================================
2022-11-18 21:26:02,011:INFO:Initializing create_model()
2022-11-18 21:26:02,012:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085cb45d0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859f6e90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:26:02,012:INFO:Checking exceptions
2022-11-18 21:26:02,016:INFO:Importing libraries
2022-11-18 21:26:02,016:INFO:Copying training dataset
2022-11-18 21:26:02,021:INFO:Defining folds
2022-11-18 21:26:02,021:INFO:Declaring metric variables
2022-11-18 21:26:02,033:INFO:Importing untrained model
2022-11-18 21:26:02,046:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-18 21:26:02,066:INFO:Starting cross validation
2022-11-18 21:26:02,068:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:26:02,115:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:26:02,131:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:26:02,174:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:26:02,209:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:26:02,244:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:26:02,284:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:26:02,293:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:26:02,325:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:26:02,351:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:26:02,374:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:26:02,389:INFO:Calculating mean and std
2022-11-18 21:26:02,397:INFO:Creating metrics dataframe
2022-11-18 21:26:02,409:INFO:Uploading results into container
2022-11-18 21:26:02,410:INFO:Uploading model into container now
2022-11-18 21:26:02,411:INFO:master_model_container: 7
2022-11-18 21:26:02,411:INFO:display_container: 2
2022-11-18 21:26:02,411:INFO:OrthogonalMatchingPursuit()
2022-11-18 21:26:02,412:INFO:create_model() successfully completed......................................
2022-11-18 21:26:02,600:INFO:SubProcess create_model() end ==================================
2022-11-18 21:26:02,601:INFO:Creating metrics dataframe
2022-11-18 21:26:02,627:INFO:Initializing Bayesian Ridge
2022-11-18 21:26:02,632:INFO:Total runtime is 0.09611101150512695 minutes
2022-11-18 21:26:02,639:INFO:SubProcess create_model() called ==================================
2022-11-18 21:26:02,641:INFO:Initializing create_model()
2022-11-18 21:26:02,641:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085cb45d0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859f6e90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:26:02,641:INFO:Checking exceptions
2022-11-18 21:26:02,644:INFO:Importing libraries
2022-11-18 21:26:02,645:INFO:Copying training dataset
2022-11-18 21:26:02,652:INFO:Defining folds
2022-11-18 21:26:02,655:INFO:Declaring metric variables
2022-11-18 21:26:02,668:INFO:Importing untrained model
2022-11-18 21:26:02,677:INFO:Bayesian Ridge Imported successfully
2022-11-18 21:26:02,693:INFO:Starting cross validation
2022-11-18 21:26:02,695:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:26:03,016:INFO:Calculating mean and std
2022-11-18 21:26:03,018:INFO:Creating metrics dataframe
2022-11-18 21:26:03,032:INFO:Uploading results into container
2022-11-18 21:26:03,037:INFO:Uploading model into container now
2022-11-18 21:26:03,038:INFO:master_model_container: 8
2022-11-18 21:26:03,039:INFO:display_container: 2
2022-11-18 21:26:03,039:INFO:BayesianRidge()
2022-11-18 21:26:03,039:INFO:create_model() successfully completed......................................
2022-11-18 21:26:03,216:INFO:SubProcess create_model() end ==================================
2022-11-18 21:26:03,217:INFO:Creating metrics dataframe
2022-11-18 21:26:03,238:INFO:Initializing Passive Aggressive Regressor
2022-11-18 21:26:03,239:INFO:Total runtime is 0.10623625914255777 minutes
2022-11-18 21:26:03,248:INFO:SubProcess create_model() called ==================================
2022-11-18 21:26:03,249:INFO:Initializing create_model()
2022-11-18 21:26:03,249:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085cb45d0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859f6e90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:26:03,249:INFO:Checking exceptions
2022-11-18 21:26:03,253:INFO:Importing libraries
2022-11-18 21:26:03,253:INFO:Copying training dataset
2022-11-18 21:26:03,261:INFO:Defining folds
2022-11-18 21:26:03,261:INFO:Declaring metric variables
2022-11-18 21:26:03,271:INFO:Importing untrained model
2022-11-18 21:26:03,280:INFO:Passive Aggressive Regressor Imported successfully
2022-11-18 21:26:03,298:INFO:Starting cross validation
2022-11-18 21:26:03,300:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:26:03,604:INFO:Calculating mean and std
2022-11-18 21:26:03,607:INFO:Creating metrics dataframe
2022-11-18 21:26:03,622:INFO:Uploading results into container
2022-11-18 21:26:03,624:INFO:Uploading model into container now
2022-11-18 21:26:03,624:INFO:master_model_container: 9
2022-11-18 21:26:03,624:INFO:display_container: 2
2022-11-18 21:26:03,625:INFO:PassiveAggressiveRegressor(random_state=123)
2022-11-18 21:26:03,625:INFO:create_model() successfully completed......................................
2022-11-18 21:26:03,807:INFO:SubProcess create_model() end ==================================
2022-11-18 21:26:03,807:INFO:Creating metrics dataframe
2022-11-18 21:26:03,828:INFO:Initializing Huber Regressor
2022-11-18 21:26:03,828:INFO:Total runtime is 0.11605288585027058 minutes
2022-11-18 21:26:03,841:INFO:SubProcess create_model() called ==================================
2022-11-18 21:26:03,841:INFO:Initializing create_model()
2022-11-18 21:26:03,842:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085cb45d0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859f6e90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:26:03,842:INFO:Checking exceptions
2022-11-18 21:26:03,845:INFO:Importing libraries
2022-11-18 21:26:03,845:INFO:Copying training dataset
2022-11-18 21:26:03,850:INFO:Defining folds
2022-11-18 21:26:03,854:INFO:Declaring metric variables
2022-11-18 21:26:03,868:INFO:Importing untrained model
2022-11-18 21:26:03,876:INFO:Huber Regressor Imported successfully
2022-11-18 21:26:03,892:INFO:Starting cross validation
2022-11-18 21:26:03,894:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:26:04,022:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:26:04,040:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:26:04,140:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:26:04,169:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:26:04,251:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:26:04,289:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:26:04,349:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:26:04,378:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:26:04,441:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:26:04,470:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:26:04,482:INFO:Calculating mean and std
2022-11-18 21:26:04,485:INFO:Creating metrics dataframe
2022-11-18 21:26:04,498:INFO:Uploading results into container
2022-11-18 21:26:04,499:INFO:Uploading model into container now
2022-11-18 21:26:04,500:INFO:master_model_container: 10
2022-11-18 21:26:04,501:INFO:display_container: 2
2022-11-18 21:26:04,501:INFO:HuberRegressor()
2022-11-18 21:26:04,502:INFO:create_model() successfully completed......................................
2022-11-18 21:26:04,681:INFO:SubProcess create_model() end ==================================
2022-11-18 21:26:04,681:INFO:Creating metrics dataframe
2022-11-18 21:26:04,703:INFO:Initializing K Neighbors Regressor
2022-11-18 21:26:04,703:INFO:Total runtime is 0.13063413699467977 minutes
2022-11-18 21:26:04,714:INFO:SubProcess create_model() called ==================================
2022-11-18 21:26:04,714:INFO:Initializing create_model()
2022-11-18 21:26:04,715:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085cb45d0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859f6e90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:26:04,715:INFO:Checking exceptions
2022-11-18 21:26:04,718:INFO:Importing libraries
2022-11-18 21:26:04,718:INFO:Copying training dataset
2022-11-18 21:26:04,724:INFO:Defining folds
2022-11-18 21:26:04,725:INFO:Declaring metric variables
2022-11-18 21:26:04,735:INFO:Importing untrained model
2022-11-18 21:26:04,747:INFO:K Neighbors Regressor Imported successfully
2022-11-18 21:26:04,764:INFO:Starting cross validation
2022-11-18 21:26:04,766:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:26:05,535:INFO:Calculating mean and std
2022-11-18 21:26:05,540:INFO:Creating metrics dataframe
2022-11-18 21:26:05,549:INFO:Uploading results into container
2022-11-18 21:26:05,550:INFO:Uploading model into container now
2022-11-18 21:26:05,551:INFO:master_model_container: 11
2022-11-18 21:26:05,551:INFO:display_container: 2
2022-11-18 21:26:05,552:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-18 21:26:05,552:INFO:create_model() successfully completed......................................
2022-11-18 21:26:05,734:INFO:SubProcess create_model() end ==================================
2022-11-18 21:26:05,735:INFO:Creating metrics dataframe
2022-11-18 21:26:05,762:INFO:Initializing Decision Tree Regressor
2022-11-18 21:26:05,762:INFO:Total runtime is 0.14828290144602457 minutes
2022-11-18 21:26:05,770:INFO:SubProcess create_model() called ==================================
2022-11-18 21:26:05,771:INFO:Initializing create_model()
2022-11-18 21:26:05,771:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085cb45d0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859f6e90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:26:05,771:INFO:Checking exceptions
2022-11-18 21:26:05,774:INFO:Importing libraries
2022-11-18 21:26:05,774:INFO:Copying training dataset
2022-11-18 21:26:05,781:INFO:Defining folds
2022-11-18 21:26:05,781:INFO:Declaring metric variables
2022-11-18 21:26:05,792:INFO:Importing untrained model
2022-11-18 21:26:05,801:INFO:Decision Tree Regressor Imported successfully
2022-11-18 21:26:05,818:INFO:Starting cross validation
2022-11-18 21:26:05,820:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:26:06,187:INFO:Calculating mean and std
2022-11-18 21:26:06,192:INFO:Creating metrics dataframe
2022-11-18 21:26:06,204:INFO:Uploading results into container
2022-11-18 21:26:06,205:INFO:Uploading model into container now
2022-11-18 21:26:06,206:INFO:master_model_container: 12
2022-11-18 21:26:06,206:INFO:display_container: 2
2022-11-18 21:26:06,206:INFO:DecisionTreeRegressor(random_state=123)
2022-11-18 21:26:06,207:INFO:create_model() successfully completed......................................
2022-11-18 21:26:06,386:INFO:SubProcess create_model() end ==================================
2022-11-18 21:26:06,386:INFO:Creating metrics dataframe
2022-11-18 21:26:06,409:INFO:Initializing Random Forest Regressor
2022-11-18 21:26:06,409:INFO:Total runtime is 0.1590684731801351 minutes
2022-11-18 21:26:06,418:INFO:SubProcess create_model() called ==================================
2022-11-18 21:26:06,420:INFO:Initializing create_model()
2022-11-18 21:26:06,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085cb45d0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859f6e90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:26:06,421:INFO:Checking exceptions
2022-11-18 21:26:06,423:INFO:Importing libraries
2022-11-18 21:26:06,424:INFO:Copying training dataset
2022-11-18 21:26:06,429:INFO:Defining folds
2022-11-18 21:26:06,430:INFO:Declaring metric variables
2022-11-18 21:26:06,441:INFO:Importing untrained model
2022-11-18 21:26:06,452:INFO:Random Forest Regressor Imported successfully
2022-11-18 21:26:06,472:INFO:Starting cross validation
2022-11-18 21:26:06,474:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:26:11,024:INFO:Calculating mean and std
2022-11-18 21:26:11,027:INFO:Creating metrics dataframe
2022-11-18 21:26:11,042:INFO:Uploading results into container
2022-11-18 21:26:11,043:INFO:Uploading model into container now
2022-11-18 21:26:11,044:INFO:master_model_container: 13
2022-11-18 21:26:11,044:INFO:display_container: 2
2022-11-18 21:26:11,044:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-18 21:26:11,044:INFO:create_model() successfully completed......................................
2022-11-18 21:26:11,249:INFO:SubProcess create_model() end ==================================
2022-11-18 21:26:11,250:INFO:Creating metrics dataframe
2022-11-18 21:26:11,274:INFO:Initializing Extra Trees Regressor
2022-11-18 21:26:11,278:INFO:Total runtime is 0.240220574537913 minutes
2022-11-18 21:26:11,287:INFO:SubProcess create_model() called ==================================
2022-11-18 21:26:11,288:INFO:Initializing create_model()
2022-11-18 21:26:11,288:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085cb45d0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859f6e90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:26:11,288:INFO:Checking exceptions
2022-11-18 21:26:11,292:INFO:Importing libraries
2022-11-18 21:26:11,292:INFO:Copying training dataset
2022-11-18 21:26:11,300:INFO:Defining folds
2022-11-18 21:26:11,302:INFO:Declaring metric variables
2022-11-18 21:26:11,313:INFO:Importing untrained model
2022-11-18 21:26:11,321:INFO:Extra Trees Regressor Imported successfully
2022-11-18 21:26:11,337:INFO:Starting cross validation
2022-11-18 21:26:11,344:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:26:13,959:INFO:Calculating mean and std
2022-11-18 21:26:13,964:INFO:Creating metrics dataframe
2022-11-18 21:26:13,974:INFO:Uploading results into container
2022-11-18 21:26:13,975:INFO:Uploading model into container now
2022-11-18 21:26:13,976:INFO:master_model_container: 14
2022-11-18 21:26:13,976:INFO:display_container: 2
2022-11-18 21:26:13,977:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-18 21:26:13,977:INFO:create_model() successfully completed......................................
2022-11-18 21:26:14,159:INFO:SubProcess create_model() end ==================================
2022-11-18 21:26:14,160:INFO:Creating metrics dataframe
2022-11-18 21:26:14,182:INFO:Initializing AdaBoost Regressor
2022-11-18 21:26:14,183:INFO:Total runtime is 0.288637646039327 minutes
2022-11-18 21:26:14,192:INFO:SubProcess create_model() called ==================================
2022-11-18 21:26:14,192:INFO:Initializing create_model()
2022-11-18 21:26:14,193:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085cb45d0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859f6e90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:26:14,193:INFO:Checking exceptions
2022-11-18 21:26:14,195:INFO:Importing libraries
2022-11-18 21:26:14,196:INFO:Copying training dataset
2022-11-18 21:26:14,204:INFO:Defining folds
2022-11-18 21:26:14,204:INFO:Declaring metric variables
2022-11-18 21:26:14,213:INFO:Importing untrained model
2022-11-18 21:26:14,221:INFO:AdaBoost Regressor Imported successfully
2022-11-18 21:26:14,240:INFO:Starting cross validation
2022-11-18 21:26:14,242:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:26:15,482:INFO:Calculating mean and std
2022-11-18 21:26:15,485:INFO:Creating metrics dataframe
2022-11-18 21:26:15,491:INFO:Uploading results into container
2022-11-18 21:26:15,492:INFO:Uploading model into container now
2022-11-18 21:26:15,492:INFO:master_model_container: 15
2022-11-18 21:26:15,493:INFO:display_container: 2
2022-11-18 21:26:15,493:INFO:AdaBoostRegressor(random_state=123)
2022-11-18 21:26:15,493:INFO:create_model() successfully completed......................................
2022-11-18 21:26:15,680:INFO:SubProcess create_model() end ==================================
2022-11-18 21:26:15,681:INFO:Creating metrics dataframe
2022-11-18 21:26:15,709:INFO:Initializing Gradient Boosting Regressor
2022-11-18 21:26:15,711:INFO:Total runtime is 0.3140925447146098 minutes
2022-11-18 21:26:15,722:INFO:SubProcess create_model() called ==================================
2022-11-18 21:26:15,723:INFO:Initializing create_model()
2022-11-18 21:26:15,723:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085cb45d0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859f6e90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:26:15,723:INFO:Checking exceptions
2022-11-18 21:26:15,726:INFO:Importing libraries
2022-11-18 21:26:15,726:INFO:Copying training dataset
2022-11-18 21:26:15,735:INFO:Defining folds
2022-11-18 21:26:15,736:INFO:Declaring metric variables
2022-11-18 21:26:15,748:INFO:Importing untrained model
2022-11-18 21:26:15,760:INFO:Gradient Boosting Regressor Imported successfully
2022-11-18 21:26:15,781:INFO:Starting cross validation
2022-11-18 21:26:15,783:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:26:17,575:INFO:Calculating mean and std
2022-11-18 21:26:17,581:INFO:Creating metrics dataframe
2022-11-18 21:26:17,596:INFO:Uploading results into container
2022-11-18 21:26:17,597:INFO:Uploading model into container now
2022-11-18 21:26:17,597:INFO:master_model_container: 16
2022-11-18 21:26:17,598:INFO:display_container: 2
2022-11-18 21:26:17,598:INFO:GradientBoostingRegressor(random_state=123)
2022-11-18 21:26:17,598:INFO:create_model() successfully completed......................................
2022-11-18 21:26:17,778:INFO:SubProcess create_model() end ==================================
2022-11-18 21:26:17,779:INFO:Creating metrics dataframe
2022-11-18 21:26:17,807:INFO:Initializing Light Gradient Boosting Machine
2022-11-18 21:26:17,812:INFO:Total runtime is 0.34911750952402754 minutes
2022-11-18 21:26:17,819:INFO:SubProcess create_model() called ==================================
2022-11-18 21:26:17,820:INFO:Initializing create_model()
2022-11-18 21:26:17,820:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085cb45d0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859f6e90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:26:17,820:INFO:Checking exceptions
2022-11-18 21:26:17,823:INFO:Importing libraries
2022-11-18 21:26:17,823:INFO:Copying training dataset
2022-11-18 21:26:17,830:INFO:Defining folds
2022-11-18 21:26:17,835:INFO:Declaring metric variables
2022-11-18 21:26:17,845:INFO:Importing untrained model
2022-11-18 21:26:17,854:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-18 21:26:17,869:INFO:Starting cross validation
2022-11-18 21:26:17,872:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:26:18,734:INFO:Calculating mean and std
2022-11-18 21:26:18,737:INFO:Creating metrics dataframe
2022-11-18 21:26:18,751:INFO:Uploading results into container
2022-11-18 21:26:18,752:INFO:Uploading model into container now
2022-11-18 21:26:18,753:INFO:master_model_container: 17
2022-11-18 21:26:18,753:INFO:display_container: 2
2022-11-18 21:26:18,754:INFO:LGBMRegressor(random_state=123)
2022-11-18 21:26:18,754:INFO:create_model() successfully completed......................................
2022-11-18 21:26:18,931:INFO:SubProcess create_model() end ==================================
2022-11-18 21:26:18,932:INFO:Creating metrics dataframe
2022-11-18 21:26:18,957:INFO:Initializing Dummy Regressor
2022-11-18 21:26:18,958:INFO:Total runtime is 0.36821585893630987 minutes
2022-11-18 21:26:18,972:INFO:SubProcess create_model() called ==================================
2022-11-18 21:26:18,973:INFO:Initializing create_model()
2022-11-18 21:26:18,973:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085cb45d0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0859f6e90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:26:18,973:INFO:Checking exceptions
2022-11-18 21:26:18,976:INFO:Importing libraries
2022-11-18 21:26:18,977:INFO:Copying training dataset
2022-11-18 21:26:18,984:INFO:Defining folds
2022-11-18 21:26:18,984:INFO:Declaring metric variables
2022-11-18 21:26:18,995:INFO:Importing untrained model
2022-11-18 21:26:19,005:INFO:Dummy Regressor Imported successfully
2022-11-18 21:26:19,020:INFO:Starting cross validation
2022-11-18 21:26:19,024:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:26:19,286:INFO:Calculating mean and std
2022-11-18 21:26:19,288:INFO:Creating metrics dataframe
2022-11-18 21:26:19,294:INFO:Uploading results into container
2022-11-18 21:26:19,297:INFO:Uploading model into container now
2022-11-18 21:26:19,302:INFO:master_model_container: 18
2022-11-18 21:26:19,302:INFO:display_container: 2
2022-11-18 21:26:19,303:INFO:DummyRegressor()
2022-11-18 21:26:19,303:INFO:create_model() successfully completed......................................
2022-11-18 21:26:19,488:INFO:SubProcess create_model() end ==================================
2022-11-18 21:26:19,489:INFO:Creating metrics dataframe
2022-11-18 21:26:19,546:INFO:Initializing create_model()
2022-11-18 21:26:19,546:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085cb45d0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:26:19,546:INFO:Checking exceptions
2022-11-18 21:26:19,553:INFO:Importing libraries
2022-11-18 21:26:19,553:INFO:Copying training dataset
2022-11-18 21:26:19,555:INFO:Defining folds
2022-11-18 21:26:19,556:INFO:Declaring metric variables
2022-11-18 21:26:19,556:INFO:Importing untrained model
2022-11-18 21:26:19,557:INFO:Declaring custom model
2022-11-18 21:26:19,558:INFO:Random Forest Regressor Imported successfully
2022-11-18 21:26:19,560:INFO:Cross validation set to False
2022-11-18 21:26:19,560:INFO:Fitting Model
2022-11-18 21:26:20,031:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-18 21:26:20,032:INFO:create_model() successfully completed......................................
2022-11-18 21:26:20,297:INFO:master_model_container: 18
2022-11-18 21:26:20,298:INFO:display_container: 2
2022-11-18 21:26:20,300:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-18 21:26:20,301:INFO:compare_models() successfully completed......................................
2022-11-18 21:40:19,168:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2022-11-18 21:40:20,861:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  ConvergenceWarning,

2022-11-18 21:44:23,020:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  app.launch_new_instance()

2022-11-18 21:44:23,022:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:44:23,023:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:44:23,024:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:44:23,025:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:44:23,026:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:44:23,027:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:44:23,028:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:44:23,029:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:44:23,030:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:44:23,031:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:44:23,037:INFO:PyCaret RegressionExperiment
2022-11-18 21:44:23,038:INFO:Logging name: FullData
2022-11-18 21:44:23,038:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-18 21:44:23,038:INFO:version 3.0.0.rc4
2022-11-18 21:44:23,038:INFO:Initializing setup()
2022-11-18 21:44:23,038:INFO:self.USI: 52a8
2022-11-18 21:44:23,039:INFO:self.variable_keys: {'_available_plots', 'seed', 'log_plots_param', '_gpu_n_jobs_param', 'USI', 'pipeline', '_all_models_internal', 'fold_generator', 'variable_keys', 'gpu_param', 'exp_id', 'X_test', 'memory', '_ml_usecase', 'y', 'fold_groups_param', 'transform_target_method_param', 'display_container', 'logging_param', '_all_metrics', 'fold_shuffle_param', 'n_jobs_param', 'exp_name_log', 'data', 'y_test', 'html_param', 'target_param', 'transform_target_param', '_all_models', 'y_train', 'X_train', 'X', 'master_model_container', 'idx'}
2022-11-18 21:44:23,039:INFO:Checking environment
2022-11-18 21:44:23,039:INFO:python_version: 3.7.15
2022-11-18 21:44:23,039:INFO:python_build: ('default', 'Oct 12 2022 19:14:55')
2022-11-18 21:44:23,039:INFO:machine: x86_64
2022-11-18 21:44:23,039:INFO:platform: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-18 21:44:23,040:INFO:Memory: svmem(total=13616353280, available=11583967232, percent=14.9, used=1865994240, free=9338101760, active=972271616, inactive=2983092224, buffers=170098688, cached=2242158592, shared=1318912, slab=225460224)
2022-11-18 21:44:23,040:INFO:Physical Core: 1
2022-11-18 21:44:23,041:INFO:Logical Core: 2
2022-11-18 21:44:23,041:INFO:Checking libraries
2022-11-18 21:44:23,041:INFO:System:
2022-11-18 21:44:23,041:INFO:    python: 3.7.15 (default, Oct 12 2022, 19:14:55)  [GCC 7.5.0]
2022-11-18 21:44:23,041:INFO:executable: /usr/bin/python3
2022-11-18 21:44:23,042:INFO:   machine: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-18 21:44:23,042:INFO:PyCaret required dependencies:
2022-11-18 21:44:23,042:INFO:                 pip: 21.1.3
2022-11-18 21:44:23,042:INFO:          setuptools: 57.4.0
2022-11-18 21:44:23,042:INFO:             pycaret: 3.0.0rc4
2022-11-18 21:44:23,042:INFO:             IPython: 7.9.0
2022-11-18 21:44:23,043:INFO:          ipywidgets: 7.7.1
2022-11-18 21:44:23,043:INFO:                tqdm: 4.64.1
2022-11-18 21:44:23,043:INFO:               numpy: 1.21.6
2022-11-18 21:44:23,043:INFO:              pandas: 1.3.5
2022-11-18 21:44:23,043:INFO:              jinja2: 3.0.0
2022-11-18 21:44:23,043:INFO:               scipy: 1.7.3
2022-11-18 21:44:23,044:INFO:              joblib: 1.2.0
2022-11-18 21:44:23,044:INFO:             sklearn: 1.0.2
2022-11-18 21:44:23,044:INFO:                pyod: 1.0.6
2022-11-18 21:44:23,044:INFO:            imblearn: 0.8.1
2022-11-18 21:44:23,044:INFO:   category_encoders: 2.5.1.post0
2022-11-18 21:44:23,044:INFO:            lightgbm: 3.3.3
2022-11-18 21:44:23,045:INFO:               numba: 0.55.2
2022-11-18 21:44:23,045:INFO:            requests: 2.28.1
2022-11-18 21:44:23,045:INFO:          matplotlib: 3.5.3
2022-11-18 21:44:23,045:INFO:          scikitplot: 0.3.7
2022-11-18 21:44:23,045:INFO:         yellowbrick: 1.5
2022-11-18 21:44:23,045:INFO:              plotly: 5.5.0
2022-11-18 21:44:23,045:INFO:             kaleido: 0.2.1
2022-11-18 21:44:23,046:INFO:         statsmodels: 0.12.2
2022-11-18 21:44:23,046:INFO:              sktime: 0.13.4
2022-11-18 21:44:23,046:INFO:               tbats: 1.1.1
2022-11-18 21:44:23,046:INFO:            pmdarima: 1.8.5
2022-11-18 21:44:23,046:INFO:              psutil: 5.9.4
2022-11-18 21:44:23,046:INFO:PyCaret optional dependencies:
2022-11-18 21:44:23,047:INFO:                shap: Not installed
2022-11-18 21:44:23,047:INFO:           interpret: Not installed
2022-11-18 21:44:23,047:INFO:                umap: Not installed
2022-11-18 21:44:23,047:INFO:    pandas_profiling: 1.4.1
2022-11-18 21:44:23,047:INFO:  explainerdashboard: Not installed
2022-11-18 21:44:23,047:INFO:             autoviz: Not installed
2022-11-18 21:44:23,048:INFO:           fairlearn: Not installed
2022-11-18 21:44:23,048:INFO:             xgboost: 0.90
2022-11-18 21:44:23,048:INFO:            catboost: Not installed
2022-11-18 21:44:23,048:INFO:              kmodes: Not installed
2022-11-18 21:44:23,048:INFO:             mlxtend: 0.14.0
2022-11-18 21:44:23,048:INFO:       statsforecast: Not installed
2022-11-18 21:44:23,048:INFO:        tune_sklearn: Not installed
2022-11-18 21:44:23,049:INFO:                 ray: Not installed
2022-11-18 21:44:23,049:INFO:            hyperopt: 0.1.2
2022-11-18 21:44:23,049:INFO:              optuna: Not installed
2022-11-18 21:44:23,049:INFO:               skopt: Not installed
2022-11-18 21:44:23,049:INFO:              mlflow: Not installed
2022-11-18 21:44:23,049:INFO:              gradio: Not installed
2022-11-18 21:44:23,049:INFO:             fastapi: Not installed
2022-11-18 21:44:23,050:INFO:             uvicorn: Not installed
2022-11-18 21:44:23,050:INFO:              m2cgen: Not installed
2022-11-18 21:44:23,050:INFO:           evidently: Not installed
2022-11-18 21:44:23,050:INFO:                nltk: 3.7
2022-11-18 21:44:23,050:INFO:            pyLDAvis: Not installed
2022-11-18 21:44:23,050:INFO:              gensim: 3.6.0
2022-11-18 21:44:23,050:INFO:               spacy: 3.4.2
2022-11-18 21:44:23,051:INFO:           wordcloud: 1.8.2.2
2022-11-18 21:44:23,051:INFO:            textblob: 0.15.3
2022-11-18 21:44:23,051:INFO:               fugue: Not installed
2022-11-18 21:44:23,051:INFO:           streamlit: Not installed
2022-11-18 21:44:23,051:INFO:             prophet: 1.1.1
2022-11-18 21:44:23,051:INFO:None
2022-11-18 21:44:23,052:INFO:Set up data.
2022-11-18 21:44:23,061:INFO:Set up train/test split.
2022-11-18 21:44:23,065:INFO:Set up index.
2022-11-18 21:44:23,066:INFO:Set up folding strategy.
2022-11-18 21:44:23,066:INFO:Assigning column types.
2022-11-18 21:44:23,074:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-18 21:44:23,075:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-18 21:44:23,081:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:44:23,087:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:44:23,159:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:44:23,215:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:44:23,216:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:44:23,217:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:44:23,217:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:44:23,218:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-18 21:44:23,224:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:44:23,230:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:44:23,303:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:44:23,358:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:44:23,359:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:44:23,360:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:44:23,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:44:23,361:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-18 21:44:23,366:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:44:23,372:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:44:23,445:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:44:23,500:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:44:23,501:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:44:23,502:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:44:23,502:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:44:23,508:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:44:23,514:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:44:23,592:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:44:23,655:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:44:23,657:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:44:23,658:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:44:23,659:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:44:23,660:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-18 21:44:23,674:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:44:23,766:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:44:23,824:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:44:23,825:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:44:23,825:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:44:23,826:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:44:23,838:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:44:23,911:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:44:23,970:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:44:23,971:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:44:23,972:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:44:23,972:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:44:23,973:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-18 21:44:24,055:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:44:24,111:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:44:24,112:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:44:24,112:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:44:24,113:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:44:24,196:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:44:24,252:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:44:24,253:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:44:24,253:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:44:24,254:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:44:24,255:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-18 21:44:24,339:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:44:24,396:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:44:24,397:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:44:24,397:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:44:24,481:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:44:24,538:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:44:24,538:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:44:24,539:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:44:24,540:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-18 21:44:24,700:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:44:24,701:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:44:24,701:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:44:24,854:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:44:24,855:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:44:24,855:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:44:24,857:INFO:Preparing preprocessing pipeline...
2022-11-18 21:44:24,858:INFO:Set up simple imputation.
2022-11-18 21:44:24,859:INFO:Set up variance threshold.
2022-11-18 21:44:24,873:INFO:Finished creating preprocessing pipeline.
2022-11-18 21:44:24,880:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO',
                                             'Open_Line_ML_x'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-18 21:44:24,881:INFO:Creating final display dataframe.
2022-11-18 21:44:24,969:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 13)
4         Train data shape    (607, 13)
5          Test data shape    (261, 13)
6         Numeric features           12
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         52a8
2022-11-18 21:44:25,131:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:44:25,132:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:44:25,132:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:44:25,278:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:44:25,278:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:44:25,278:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:44:25,286:INFO:setup() successfully completed in 2.25s...............
2022-11-18 21:44:25,287:INFO:Initializing compare_models()
2022-11-18 21:44:25,287:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085e30ad0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fa085e30ad0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-18 21:44:25,287:INFO:Checking exceptions
2022-11-18 21:44:25,289:INFO:Preparing display monitor
2022-11-18 21:44:25,380:INFO:Initializing Linear Regression
2022-11-18 21:44:25,381:INFO:Total runtime is 9.091695149739583e-06 minutes
2022-11-18 21:44:25,391:INFO:SubProcess create_model() called ==================================
2022-11-18 21:44:25,392:INFO:Initializing create_model()
2022-11-18 21:44:25,392:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085e30ad0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085be7350>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:44:25,393:INFO:Checking exceptions
2022-11-18 21:44:25,396:INFO:Importing libraries
2022-11-18 21:44:25,397:INFO:Copying training dataset
2022-11-18 21:44:25,401:INFO:Defining folds
2022-11-18 21:44:25,402:INFO:Declaring metric variables
2022-11-18 21:44:25,415:INFO:Importing untrained model
2022-11-18 21:44:25,427:INFO:Linear Regression Imported successfully
2022-11-18 21:44:25,446:INFO:Starting cross validation
2022-11-18 21:44:25,451:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:44:29,648:INFO:Calculating mean and std
2022-11-18 21:44:29,657:INFO:Creating metrics dataframe
2022-11-18 21:44:29,667:INFO:Uploading results into container
2022-11-18 21:44:29,668:INFO:Uploading model into container now
2022-11-18 21:44:29,669:INFO:master_model_container: 1
2022-11-18 21:44:29,670:INFO:display_container: 2
2022-11-18 21:44:29,670:INFO:LinearRegression(n_jobs=-1)
2022-11-18 21:44:29,670:INFO:create_model() successfully completed......................................
2022-11-18 21:44:29,974:INFO:SubProcess create_model() end ==================================
2022-11-18 21:44:29,975:INFO:Creating metrics dataframe
2022-11-18 21:44:29,995:INFO:Initializing Lasso Regression
2022-11-18 21:44:29,996:INFO:Total runtime is 0.07692641019821167 minutes
2022-11-18 21:44:30,007:INFO:SubProcess create_model() called ==================================
2022-11-18 21:44:30,008:INFO:Initializing create_model()
2022-11-18 21:44:30,008:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085e30ad0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085be7350>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:44:30,008:INFO:Checking exceptions
2022-11-18 21:44:30,012:INFO:Importing libraries
2022-11-18 21:44:30,012:INFO:Copying training dataset
2022-11-18 21:44:30,021:INFO:Defining folds
2022-11-18 21:44:30,021:INFO:Declaring metric variables
2022-11-18 21:44:30,033:INFO:Importing untrained model
2022-11-18 21:44:30,043:INFO:Lasso Regression Imported successfully
2022-11-18 21:44:30,060:INFO:Starting cross validation
2022-11-18 21:44:30,066:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:44:30,406:INFO:Calculating mean and std
2022-11-18 21:44:30,410:INFO:Creating metrics dataframe
2022-11-18 21:44:30,419:INFO:Uploading results into container
2022-11-18 21:44:30,421:INFO:Uploading model into container now
2022-11-18 21:44:30,422:INFO:master_model_container: 2
2022-11-18 21:44:30,422:INFO:display_container: 2
2022-11-18 21:44:30,423:INFO:Lasso(random_state=123)
2022-11-18 21:44:30,423:INFO:create_model() successfully completed......................................
2022-11-18 21:44:30,616:INFO:SubProcess create_model() end ==================================
2022-11-18 21:44:30,618:INFO:Creating metrics dataframe
2022-11-18 21:44:30,640:INFO:Initializing Ridge Regression
2022-11-18 21:44:30,641:INFO:Total runtime is 0.08767285346984863 minutes
2022-11-18 21:44:30,650:INFO:SubProcess create_model() called ==================================
2022-11-18 21:44:30,651:INFO:Initializing create_model()
2022-11-18 21:44:30,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085e30ad0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085be7350>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:44:30,652:INFO:Checking exceptions
2022-11-18 21:44:30,656:INFO:Importing libraries
2022-11-18 21:44:30,656:INFO:Copying training dataset
2022-11-18 21:44:30,665:INFO:Defining folds
2022-11-18 21:44:30,665:INFO:Declaring metric variables
2022-11-18 21:44:30,678:INFO:Importing untrained model
2022-11-18 21:44:30,691:INFO:Ridge Regression Imported successfully
2022-11-18 21:44:30,716:INFO:Starting cross validation
2022-11-18 21:44:30,718:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:44:30,766:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.19612e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:44:30,795:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1832e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:44:30,845:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.25596e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:44:30,875:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.27134e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:44:30,900:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1563e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:44:30,967:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.30751e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:44:30,972:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.25177e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:44:31,017:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.19532e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:44:31,039:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1922e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:44:31,061:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.20778e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:44:31,075:INFO:Calculating mean and std
2022-11-18 21:44:31,077:INFO:Creating metrics dataframe
2022-11-18 21:44:31,087:INFO:Uploading results into container
2022-11-18 21:44:31,088:INFO:Uploading model into container now
2022-11-18 21:44:31,089:INFO:master_model_container: 3
2022-11-18 21:44:31,090:INFO:display_container: 2
2022-11-18 21:44:31,091:INFO:Ridge(random_state=123)
2022-11-18 21:44:31,091:INFO:create_model() successfully completed......................................
2022-11-18 21:44:31,290:INFO:SubProcess create_model() end ==================================
2022-11-18 21:44:31,291:INFO:Creating metrics dataframe
2022-11-18 21:44:31,311:INFO:Initializing Elastic Net
2022-11-18 21:44:31,312:INFO:Total runtime is 0.09886425733566284 minutes
2022-11-18 21:44:31,321:INFO:SubProcess create_model() called ==================================
2022-11-18 21:44:31,322:INFO:Initializing create_model()
2022-11-18 21:44:31,323:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085e30ad0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085be7350>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:44:31,323:INFO:Checking exceptions
2022-11-18 21:44:31,327:INFO:Importing libraries
2022-11-18 21:44:31,327:INFO:Copying training dataset
2022-11-18 21:44:31,333:INFO:Defining folds
2022-11-18 21:44:31,334:INFO:Declaring metric variables
2022-11-18 21:44:31,345:INFO:Importing untrained model
2022-11-18 21:44:31,359:INFO:Elastic Net Imported successfully
2022-11-18 21:44:31,380:INFO:Starting cross validation
2022-11-18 21:44:31,382:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:44:31,739:INFO:Calculating mean and std
2022-11-18 21:44:31,741:INFO:Creating metrics dataframe
2022-11-18 21:44:31,755:INFO:Uploading results into container
2022-11-18 21:44:31,757:INFO:Uploading model into container now
2022-11-18 21:44:31,758:INFO:master_model_container: 4
2022-11-18 21:44:31,758:INFO:display_container: 2
2022-11-18 21:44:31,759:INFO:ElasticNet(random_state=123)
2022-11-18 21:44:31,759:INFO:create_model() successfully completed......................................
2022-11-18 21:44:31,954:INFO:SubProcess create_model() end ==================================
2022-11-18 21:44:31,954:INFO:Creating metrics dataframe
2022-11-18 21:44:31,978:INFO:Initializing Least Angle Regression
2022-11-18 21:44:31,978:INFO:Total runtime is 0.10996729930241902 minutes
2022-11-18 21:44:31,989:INFO:SubProcess create_model() called ==================================
2022-11-18 21:44:31,990:INFO:Initializing create_model()
2022-11-18 21:44:31,990:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085e30ad0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085be7350>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:44:31,991:INFO:Checking exceptions
2022-11-18 21:44:31,994:INFO:Importing libraries
2022-11-18 21:44:31,994:INFO:Copying training dataset
2022-11-18 21:44:32,004:INFO:Defining folds
2022-11-18 21:44:32,004:INFO:Declaring metric variables
2022-11-18 21:44:32,014:INFO:Importing untrained model
2022-11-18 21:44:32,025:INFO:Least Angle Regression Imported successfully
2022-11-18 21:44:32,045:INFO:Starting cross validation
2022-11-18 21:44:32,047:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:44:32,097:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:44:32,123:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:44:32,169:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:44:32,205:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:44:32,240:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:44:32,292:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:44:32,296:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:44:32,337:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:44:32,362:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:44:32,384:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:44:32,400:INFO:Calculating mean and std
2022-11-18 21:44:32,405:INFO:Creating metrics dataframe
2022-11-18 21:44:32,417:INFO:Uploading results into container
2022-11-18 21:44:32,418:INFO:Uploading model into container now
2022-11-18 21:44:32,419:INFO:master_model_container: 5
2022-11-18 21:44:32,420:INFO:display_container: 2
2022-11-18 21:44:32,420:INFO:Lars(random_state=123)
2022-11-18 21:44:32,421:INFO:create_model() successfully completed......................................
2022-11-18 21:44:32,612:INFO:SubProcess create_model() end ==================================
2022-11-18 21:44:32,612:INFO:Creating metrics dataframe
2022-11-18 21:44:32,641:INFO:Initializing Lasso Least Angle Regression
2022-11-18 21:44:32,642:INFO:Total runtime is 0.12102231582005818 minutes
2022-11-18 21:44:32,654:INFO:SubProcess create_model() called ==================================
2022-11-18 21:44:32,655:INFO:Initializing create_model()
2022-11-18 21:44:32,656:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085e30ad0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085be7350>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:44:32,656:INFO:Checking exceptions
2022-11-18 21:44:32,660:INFO:Importing libraries
2022-11-18 21:44:32,663:INFO:Copying training dataset
2022-11-18 21:44:32,670:INFO:Defining folds
2022-11-18 21:44:32,671:INFO:Declaring metric variables
2022-11-18 21:44:32,687:INFO:Importing untrained model
2022-11-18 21:44:32,698:INFO:Lasso Least Angle Regression Imported successfully
2022-11-18 21:44:32,720:INFO:Starting cross validation
2022-11-18 21:44:32,722:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:44:32,769:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:44:32,802:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:44:32,840:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:44:32,873:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:44:32,913:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:44:32,963:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:44:32,969:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:44:33,009:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:44:33,034:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:44:33,063:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:44:33,099:INFO:Calculating mean and std
2022-11-18 21:44:33,106:INFO:Creating metrics dataframe
2022-11-18 21:44:33,118:INFO:Uploading results into container
2022-11-18 21:44:33,119:INFO:Uploading model into container now
2022-11-18 21:44:33,120:INFO:master_model_container: 6
2022-11-18 21:44:33,121:INFO:display_container: 2
2022-11-18 21:44:33,122:INFO:LassoLars(random_state=123)
2022-11-18 21:44:33,122:INFO:create_model() successfully completed......................................
2022-11-18 21:44:33,320:INFO:SubProcess create_model() end ==================================
2022-11-18 21:44:33,321:INFO:Creating metrics dataframe
2022-11-18 21:44:33,344:INFO:Initializing Orthogonal Matching Pursuit
2022-11-18 21:44:33,345:INFO:Total runtime is 0.13273843924204506 minutes
2022-11-18 21:44:33,356:INFO:SubProcess create_model() called ==================================
2022-11-18 21:44:33,356:INFO:Initializing create_model()
2022-11-18 21:44:33,357:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085e30ad0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085be7350>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:44:33,357:INFO:Checking exceptions
2022-11-18 21:44:33,360:INFO:Importing libraries
2022-11-18 21:44:33,361:INFO:Copying training dataset
2022-11-18 21:44:33,369:INFO:Defining folds
2022-11-18 21:44:33,370:INFO:Declaring metric variables
2022-11-18 21:44:33,380:INFO:Importing untrained model
2022-11-18 21:44:33,391:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-18 21:44:33,418:INFO:Starting cross validation
2022-11-18 21:44:33,420:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:44:33,466:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:44:33,496:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:44:33,533:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:44:33,569:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:44:33,609:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:44:33,658:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:44:33,661:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:44:33,711:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:44:33,739:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:44:33,759:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:44:33,777:INFO:Calculating mean and std
2022-11-18 21:44:33,783:INFO:Creating metrics dataframe
2022-11-18 21:44:33,798:INFO:Uploading results into container
2022-11-18 21:44:33,799:INFO:Uploading model into container now
2022-11-18 21:44:33,800:INFO:master_model_container: 7
2022-11-18 21:44:33,800:INFO:display_container: 2
2022-11-18 21:44:33,801:INFO:OrthogonalMatchingPursuit()
2022-11-18 21:44:33,801:INFO:create_model() successfully completed......................................
2022-11-18 21:44:33,999:INFO:SubProcess create_model() end ==================================
2022-11-18 21:44:34,000:INFO:Creating metrics dataframe
2022-11-18 21:44:34,024:INFO:Initializing Bayesian Ridge
2022-11-18 21:44:34,025:INFO:Total runtime is 0.14407252073287963 minutes
2022-11-18 21:44:34,037:INFO:SubProcess create_model() called ==================================
2022-11-18 21:44:34,038:INFO:Initializing create_model()
2022-11-18 21:44:34,038:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085e30ad0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085be7350>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:44:34,038:INFO:Checking exceptions
2022-11-18 21:44:34,046:INFO:Importing libraries
2022-11-18 21:44:34,047:INFO:Copying training dataset
2022-11-18 21:44:34,052:INFO:Defining folds
2022-11-18 21:44:34,053:INFO:Declaring metric variables
2022-11-18 21:44:34,069:INFO:Importing untrained model
2022-11-18 21:44:34,081:INFO:Bayesian Ridge Imported successfully
2022-11-18 21:44:34,103:INFO:Starting cross validation
2022-11-18 21:44:34,105:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:44:34,471:INFO:Calculating mean and std
2022-11-18 21:44:34,474:INFO:Creating metrics dataframe
2022-11-18 21:44:34,482:INFO:Uploading results into container
2022-11-18 21:44:34,486:INFO:Uploading model into container now
2022-11-18 21:44:34,488:INFO:master_model_container: 8
2022-11-18 21:44:34,488:INFO:display_container: 2
2022-11-18 21:44:34,489:INFO:BayesianRidge()
2022-11-18 21:44:34,489:INFO:create_model() successfully completed......................................
2022-11-18 21:44:34,688:INFO:SubProcess create_model() end ==================================
2022-11-18 21:44:34,690:INFO:Creating metrics dataframe
2022-11-18 21:44:34,714:INFO:Initializing Passive Aggressive Regressor
2022-11-18 21:44:34,715:INFO:Total runtime is 0.15558228095372517 minutes
2022-11-18 21:44:34,728:INFO:SubProcess create_model() called ==================================
2022-11-18 21:44:34,729:INFO:Initializing create_model()
2022-11-18 21:44:34,730:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085e30ad0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085be7350>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:44:34,730:INFO:Checking exceptions
2022-11-18 21:44:34,734:INFO:Importing libraries
2022-11-18 21:44:34,735:INFO:Copying training dataset
2022-11-18 21:44:34,742:INFO:Defining folds
2022-11-18 21:44:34,744:INFO:Declaring metric variables
2022-11-18 21:44:34,756:INFO:Importing untrained model
2022-11-18 21:44:34,770:INFO:Passive Aggressive Regressor Imported successfully
2022-11-18 21:44:34,790:INFO:Starting cross validation
2022-11-18 21:44:34,792:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:44:35,154:INFO:Calculating mean and std
2022-11-18 21:44:35,161:INFO:Creating metrics dataframe
2022-11-18 21:44:35,170:INFO:Uploading results into container
2022-11-18 21:44:35,171:INFO:Uploading model into container now
2022-11-18 21:44:35,172:INFO:master_model_container: 9
2022-11-18 21:44:35,172:INFO:display_container: 2
2022-11-18 21:44:35,173:INFO:PassiveAggressiveRegressor(random_state=123)
2022-11-18 21:44:35,173:INFO:create_model() successfully completed......................................
2022-11-18 21:44:35,367:INFO:SubProcess create_model() end ==================================
2022-11-18 21:44:35,367:INFO:Creating metrics dataframe
2022-11-18 21:44:35,390:INFO:Initializing Huber Regressor
2022-11-18 21:44:35,390:INFO:Total runtime is 0.16683331330617268 minutes
2022-11-18 21:44:35,402:INFO:SubProcess create_model() called ==================================
2022-11-18 21:44:35,403:INFO:Initializing create_model()
2022-11-18 21:44:35,403:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085e30ad0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085be7350>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:44:35,404:INFO:Checking exceptions
2022-11-18 21:44:35,407:INFO:Importing libraries
2022-11-18 21:44:35,407:INFO:Copying training dataset
2022-11-18 21:44:35,414:INFO:Defining folds
2022-11-18 21:44:35,416:INFO:Declaring metric variables
2022-11-18 21:44:35,431:INFO:Importing untrained model
2022-11-18 21:44:35,442:INFO:Huber Regressor Imported successfully
2022-11-18 21:44:35,464:INFO:Starting cross validation
2022-11-18 21:44:35,466:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:44:35,564:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:44:35,689:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:44:35,693:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:44:35,795:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:44:35,846:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:44:35,933:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:44:35,953:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:44:36,030:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:44:36,052:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:44:36,103:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:44:36,117:INFO:Calculating mean and std
2022-11-18 21:44:36,120:INFO:Creating metrics dataframe
2022-11-18 21:44:36,131:INFO:Uploading results into container
2022-11-18 21:44:36,133:INFO:Uploading model into container now
2022-11-18 21:44:36,134:INFO:master_model_container: 10
2022-11-18 21:44:36,134:INFO:display_container: 2
2022-11-18 21:44:36,135:INFO:HuberRegressor()
2022-11-18 21:44:36,135:INFO:create_model() successfully completed......................................
2022-11-18 21:44:36,341:INFO:SubProcess create_model() end ==================================
2022-11-18 21:44:36,342:INFO:Creating metrics dataframe
2022-11-18 21:44:36,370:INFO:Initializing K Neighbors Regressor
2022-11-18 21:44:36,370:INFO:Total runtime is 0.18316833972930907 minutes
2022-11-18 21:44:36,381:INFO:SubProcess create_model() called ==================================
2022-11-18 21:44:36,382:INFO:Initializing create_model()
2022-11-18 21:44:36,387:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085e30ad0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085be7350>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:44:36,388:INFO:Checking exceptions
2022-11-18 21:44:36,391:INFO:Importing libraries
2022-11-18 21:44:36,391:INFO:Copying training dataset
2022-11-18 21:44:36,399:INFO:Defining folds
2022-11-18 21:44:36,406:INFO:Declaring metric variables
2022-11-18 21:44:36,415:INFO:Importing untrained model
2022-11-18 21:44:36,428:INFO:K Neighbors Regressor Imported successfully
2022-11-18 21:44:36,450:INFO:Starting cross validation
2022-11-18 21:44:36,452:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:44:37,278:INFO:Calculating mean and std
2022-11-18 21:44:37,284:INFO:Creating metrics dataframe
2022-11-18 21:44:37,293:INFO:Uploading results into container
2022-11-18 21:44:37,297:INFO:Uploading model into container now
2022-11-18 21:44:37,298:INFO:master_model_container: 11
2022-11-18 21:44:37,298:INFO:display_container: 2
2022-11-18 21:44:37,299:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-18 21:44:37,299:INFO:create_model() successfully completed......................................
2022-11-18 21:44:37,489:INFO:SubProcess create_model() end ==================================
2022-11-18 21:44:37,489:INFO:Creating metrics dataframe
2022-11-18 21:44:37,514:INFO:Initializing Decision Tree Regressor
2022-11-18 21:44:37,515:INFO:Total runtime is 0.20225185950597127 minutes
2022-11-18 21:44:37,527:INFO:SubProcess create_model() called ==================================
2022-11-18 21:44:37,529:INFO:Initializing create_model()
2022-11-18 21:44:37,529:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085e30ad0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085be7350>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:44:37,529:INFO:Checking exceptions
2022-11-18 21:44:37,533:INFO:Importing libraries
2022-11-18 21:44:37,534:INFO:Copying training dataset
2022-11-18 21:44:37,542:INFO:Defining folds
2022-11-18 21:44:37,543:INFO:Declaring metric variables
2022-11-18 21:44:37,561:INFO:Importing untrained model
2022-11-18 21:44:37,578:INFO:Decision Tree Regressor Imported successfully
2022-11-18 21:44:37,599:INFO:Starting cross validation
2022-11-18 21:44:37,602:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:44:37,992:INFO:Calculating mean and std
2022-11-18 21:44:37,998:INFO:Creating metrics dataframe
2022-11-18 21:44:38,010:INFO:Uploading results into container
2022-11-18 21:44:38,011:INFO:Uploading model into container now
2022-11-18 21:44:38,012:INFO:master_model_container: 12
2022-11-18 21:44:38,012:INFO:display_container: 2
2022-11-18 21:44:38,013:INFO:DecisionTreeRegressor(random_state=123)
2022-11-18 21:44:38,013:INFO:create_model() successfully completed......................................
2022-11-18 21:44:38,205:INFO:SubProcess create_model() end ==================================
2022-11-18 21:44:38,206:INFO:Creating metrics dataframe
2022-11-18 21:44:38,236:INFO:Initializing Random Forest Regressor
2022-11-18 21:44:38,237:INFO:Total runtime is 0.21427639722824096 minutes
2022-11-18 21:44:38,247:INFO:SubProcess create_model() called ==================================
2022-11-18 21:44:38,248:INFO:Initializing create_model()
2022-11-18 21:44:38,249:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085e30ad0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085be7350>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:44:38,249:INFO:Checking exceptions
2022-11-18 21:44:38,252:INFO:Importing libraries
2022-11-18 21:44:38,252:INFO:Copying training dataset
2022-11-18 21:44:38,259:INFO:Defining folds
2022-11-18 21:44:38,259:INFO:Declaring metric variables
2022-11-18 21:44:38,275:INFO:Importing untrained model
2022-11-18 21:44:38,289:INFO:Random Forest Regressor Imported successfully
2022-11-18 21:44:38,310:INFO:Starting cross validation
2022-11-18 21:44:38,312:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:44:43,005:INFO:Calculating mean and std
2022-11-18 21:44:43,012:INFO:Creating metrics dataframe
2022-11-18 21:44:43,023:INFO:Uploading results into container
2022-11-18 21:44:43,025:INFO:Uploading model into container now
2022-11-18 21:44:43,026:INFO:master_model_container: 13
2022-11-18 21:44:43,027:INFO:display_container: 2
2022-11-18 21:44:43,027:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-18 21:44:43,027:INFO:create_model() successfully completed......................................
2022-11-18 21:44:43,216:INFO:SubProcess create_model() end ==================================
2022-11-18 21:44:43,216:INFO:Creating metrics dataframe
2022-11-18 21:44:43,240:INFO:Initializing Extra Trees Regressor
2022-11-18 21:44:43,241:INFO:Total runtime is 0.29767566521962485 minutes
2022-11-18 21:44:43,252:INFO:SubProcess create_model() called ==================================
2022-11-18 21:44:43,254:INFO:Initializing create_model()
2022-11-18 21:44:43,254:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085e30ad0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085be7350>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:44:43,254:INFO:Checking exceptions
2022-11-18 21:44:43,257:INFO:Importing libraries
2022-11-18 21:44:43,258:INFO:Copying training dataset
2022-11-18 21:44:43,266:INFO:Defining folds
2022-11-18 21:44:43,266:INFO:Declaring metric variables
2022-11-18 21:44:43,276:INFO:Importing untrained model
2022-11-18 21:44:43,288:INFO:Extra Trees Regressor Imported successfully
2022-11-18 21:44:43,303:INFO:Starting cross validation
2022-11-18 21:44:43,306:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:44:46,298:INFO:Calculating mean and std
2022-11-18 21:44:46,303:INFO:Creating metrics dataframe
2022-11-18 21:44:46,314:INFO:Uploading results into container
2022-11-18 21:44:46,316:INFO:Uploading model into container now
2022-11-18 21:44:46,317:INFO:master_model_container: 14
2022-11-18 21:44:46,317:INFO:display_container: 2
2022-11-18 21:44:46,318:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-18 21:44:46,318:INFO:create_model() successfully completed......................................
2022-11-18 21:44:46,507:INFO:SubProcess create_model() end ==================================
2022-11-18 21:44:46,508:INFO:Creating metrics dataframe
2022-11-18 21:44:46,537:INFO:Initializing AdaBoost Regressor
2022-11-18 21:44:46,538:INFO:Total runtime is 0.35263085762659707 minutes
2022-11-18 21:44:46,548:INFO:SubProcess create_model() called ==================================
2022-11-18 21:44:46,548:INFO:Initializing create_model()
2022-11-18 21:44:46,549:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085e30ad0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085be7350>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:44:46,549:INFO:Checking exceptions
2022-11-18 21:44:46,552:INFO:Importing libraries
2022-11-18 21:44:46,552:INFO:Copying training dataset
2022-11-18 21:44:46,562:INFO:Defining folds
2022-11-18 21:44:46,562:INFO:Declaring metric variables
2022-11-18 21:44:46,572:INFO:Importing untrained model
2022-11-18 21:44:46,582:INFO:AdaBoost Regressor Imported successfully
2022-11-18 21:44:46,599:INFO:Starting cross validation
2022-11-18 21:44:46,601:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:44:47,920:INFO:Calculating mean and std
2022-11-18 21:44:47,926:INFO:Creating metrics dataframe
2022-11-18 21:44:47,935:INFO:Uploading results into container
2022-11-18 21:44:47,936:INFO:Uploading model into container now
2022-11-18 21:44:47,937:INFO:master_model_container: 15
2022-11-18 21:44:47,937:INFO:display_container: 2
2022-11-18 21:44:47,937:INFO:AdaBoostRegressor(random_state=123)
2022-11-18 21:44:47,938:INFO:create_model() successfully completed......................................
2022-11-18 21:44:48,128:INFO:SubProcess create_model() end ==================================
2022-11-18 21:44:48,128:INFO:Creating metrics dataframe
2022-11-18 21:44:48,153:INFO:Initializing Gradient Boosting Regressor
2022-11-18 21:44:48,154:INFO:Total runtime is 0.37955392996470133 minutes
2022-11-18 21:44:48,163:INFO:SubProcess create_model() called ==================================
2022-11-18 21:44:48,165:INFO:Initializing create_model()
2022-11-18 21:44:48,165:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085e30ad0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085be7350>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:44:48,166:INFO:Checking exceptions
2022-11-18 21:44:48,169:INFO:Importing libraries
2022-11-18 21:44:48,169:INFO:Copying training dataset
2022-11-18 21:44:48,176:INFO:Defining folds
2022-11-18 21:44:48,176:INFO:Declaring metric variables
2022-11-18 21:44:48,187:INFO:Importing untrained model
2022-11-18 21:44:48,201:INFO:Gradient Boosting Regressor Imported successfully
2022-11-18 21:44:48,228:INFO:Starting cross validation
2022-11-18 21:44:48,230:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:44:50,144:INFO:Calculating mean and std
2022-11-18 21:44:50,147:INFO:Creating metrics dataframe
2022-11-18 21:44:50,154:INFO:Uploading results into container
2022-11-18 21:44:50,155:INFO:Uploading model into container now
2022-11-18 21:44:50,156:INFO:master_model_container: 16
2022-11-18 21:44:50,156:INFO:display_container: 2
2022-11-18 21:44:50,157:INFO:GradientBoostingRegressor(random_state=123)
2022-11-18 21:44:50,157:INFO:create_model() successfully completed......................................
2022-11-18 21:44:50,342:INFO:SubProcess create_model() end ==================================
2022-11-18 21:44:50,343:INFO:Creating metrics dataframe
2022-11-18 21:44:50,375:INFO:Initializing Light Gradient Boosting Machine
2022-11-18 21:44:50,375:INFO:Total runtime is 0.41658273537953694 minutes
2022-11-18 21:44:50,387:INFO:SubProcess create_model() called ==================================
2022-11-18 21:44:50,388:INFO:Initializing create_model()
2022-11-18 21:44:50,389:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085e30ad0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085be7350>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:44:50,389:INFO:Checking exceptions
2022-11-18 21:44:50,394:INFO:Importing libraries
2022-11-18 21:44:50,394:INFO:Copying training dataset
2022-11-18 21:44:50,402:INFO:Defining folds
2022-11-18 21:44:50,402:INFO:Declaring metric variables
2022-11-18 21:44:50,416:INFO:Importing untrained model
2022-11-18 21:44:50,426:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-18 21:44:50,448:INFO:Starting cross validation
2022-11-18 21:44:50,453:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:44:52,133:INFO:Calculating mean and std
2022-11-18 21:44:52,136:INFO:Creating metrics dataframe
2022-11-18 21:44:52,146:INFO:Uploading results into container
2022-11-18 21:44:52,147:INFO:Uploading model into container now
2022-11-18 21:44:52,148:INFO:master_model_container: 17
2022-11-18 21:44:52,148:INFO:display_container: 2
2022-11-18 21:44:52,149:INFO:LGBMRegressor(random_state=123)
2022-11-18 21:44:52,149:INFO:create_model() successfully completed......................................
2022-11-18 21:44:52,358:INFO:SubProcess create_model() end ==================================
2022-11-18 21:44:52,359:INFO:Creating metrics dataframe
2022-11-18 21:44:52,382:INFO:Initializing Dummy Regressor
2022-11-18 21:44:52,383:INFO:Total runtime is 0.4500455101331075 minutes
2022-11-18 21:44:52,395:INFO:SubProcess create_model() called ==================================
2022-11-18 21:44:52,396:INFO:Initializing create_model()
2022-11-18 21:44:52,397:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085e30ad0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085be7350>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:44:52,397:INFO:Checking exceptions
2022-11-18 21:44:52,401:INFO:Importing libraries
2022-11-18 21:44:52,401:INFO:Copying training dataset
2022-11-18 21:44:52,407:INFO:Defining folds
2022-11-18 21:44:52,408:INFO:Declaring metric variables
2022-11-18 21:44:52,424:INFO:Importing untrained model
2022-11-18 21:44:52,439:INFO:Dummy Regressor Imported successfully
2022-11-18 21:44:52,460:INFO:Starting cross validation
2022-11-18 21:44:52,465:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:44:52,778:INFO:Calculating mean and std
2022-11-18 21:44:52,784:INFO:Creating metrics dataframe
2022-11-18 21:44:52,798:INFO:Uploading results into container
2022-11-18 21:44:52,799:INFO:Uploading model into container now
2022-11-18 21:44:52,799:INFO:master_model_container: 18
2022-11-18 21:44:52,800:INFO:display_container: 2
2022-11-18 21:44:52,800:INFO:DummyRegressor()
2022-11-18 21:44:52,800:INFO:create_model() successfully completed......................................
2022-11-18 21:44:52,990:INFO:SubProcess create_model() end ==================================
2022-11-18 21:44:52,991:INFO:Creating metrics dataframe
2022-11-18 21:44:53,043:INFO:Initializing create_model()
2022-11-18 21:44:53,043:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085e30ad0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:44:53,044:INFO:Checking exceptions
2022-11-18 21:44:53,060:INFO:Importing libraries
2022-11-18 21:44:53,060:INFO:Copying training dataset
2022-11-18 21:44:53,066:INFO:Defining folds
2022-11-18 21:44:53,067:INFO:Declaring metric variables
2022-11-18 21:44:53,067:INFO:Importing untrained model
2022-11-18 21:44:53,068:INFO:Declaring custom model
2022-11-18 21:44:53,069:INFO:Random Forest Regressor Imported successfully
2022-11-18 21:44:53,071:INFO:Cross validation set to False
2022-11-18 21:44:53,072:INFO:Fitting Model
2022-11-18 21:44:53,628:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-18 21:44:53,629:INFO:create_model() successfully completed......................................
2022-11-18 21:44:53,943:INFO:master_model_container: 18
2022-11-18 21:44:53,944:INFO:display_container: 2
2022-11-18 21:44:53,945:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-18 21:44:53,945:INFO:compare_models() successfully completed......................................
2022-11-18 21:44:59,210:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  app.launch_new_instance()

2022-11-18 21:44:59,211:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:44:59,213:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:44:59,214:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:44:59,215:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:44:59,216:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:44:59,217:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:44:59,218:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:44:59,219:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:44:59,220:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:44:59,221:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:44:59,226:INFO:PyCaret RegressionExperiment
2022-11-18 21:44:59,226:INFO:Logging name: FullData
2022-11-18 21:44:59,227:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-18 21:44:59,227:INFO:version 3.0.0.rc4
2022-11-18 21:44:59,227:INFO:Initializing setup()
2022-11-18 21:44:59,227:INFO:self.USI: e830
2022-11-18 21:44:59,227:INFO:self.variable_keys: {'_available_plots', 'seed', 'log_plots_param', '_gpu_n_jobs_param', 'USI', 'pipeline', '_all_models_internal', 'fold_generator', 'variable_keys', 'gpu_param', 'exp_id', 'X_test', 'memory', '_ml_usecase', 'y', 'fold_groups_param', 'transform_target_method_param', 'display_container', 'logging_param', '_all_metrics', 'fold_shuffle_param', 'n_jobs_param', 'exp_name_log', 'data', 'y_test', 'html_param', 'target_param', 'transform_target_param', '_all_models', 'y_train', 'X_train', 'X', 'master_model_container', 'idx'}
2022-11-18 21:44:59,227:INFO:Checking environment
2022-11-18 21:44:59,228:INFO:python_version: 3.7.15
2022-11-18 21:44:59,228:INFO:python_build: ('default', 'Oct 12 2022 19:14:55')
2022-11-18 21:44:59,228:INFO:machine: x86_64
2022-11-18 21:44:59,228:INFO:platform: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-18 21:44:59,229:INFO:Memory: svmem(total=13616353280, available=11351080960, percent=16.6, used=2153705472, free=9022554112, active=982065152, inactive=3284832256, buffers=170323968, cached=2269769728, shared=1327104, slab=226439168)
2022-11-18 21:44:59,229:INFO:Physical Core: 1
2022-11-18 21:44:59,229:INFO:Logical Core: 2
2022-11-18 21:44:59,229:INFO:Checking libraries
2022-11-18 21:44:59,230:INFO:System:
2022-11-18 21:44:59,230:INFO:    python: 3.7.15 (default, Oct 12 2022, 19:14:55)  [GCC 7.5.0]
2022-11-18 21:44:59,230:INFO:executable: /usr/bin/python3
2022-11-18 21:44:59,230:INFO:   machine: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-18 21:44:59,230:INFO:PyCaret required dependencies:
2022-11-18 21:44:59,230:INFO:                 pip: 21.1.3
2022-11-18 21:44:59,231:INFO:          setuptools: 57.4.0
2022-11-18 21:44:59,231:INFO:             pycaret: 3.0.0rc4
2022-11-18 21:44:59,231:INFO:             IPython: 7.9.0
2022-11-18 21:44:59,231:INFO:          ipywidgets: 7.7.1
2022-11-18 21:44:59,231:INFO:                tqdm: 4.64.1
2022-11-18 21:44:59,231:INFO:               numpy: 1.21.6
2022-11-18 21:44:59,231:INFO:              pandas: 1.3.5
2022-11-18 21:44:59,232:INFO:              jinja2: 3.0.0
2022-11-18 21:44:59,232:INFO:               scipy: 1.7.3
2022-11-18 21:44:59,232:INFO:              joblib: 1.2.0
2022-11-18 21:44:59,232:INFO:             sklearn: 1.0.2
2022-11-18 21:44:59,232:INFO:                pyod: 1.0.6
2022-11-18 21:44:59,232:INFO:            imblearn: 0.8.1
2022-11-18 21:44:59,232:INFO:   category_encoders: 2.5.1.post0
2022-11-18 21:44:59,233:INFO:            lightgbm: 3.3.3
2022-11-18 21:44:59,233:INFO:               numba: 0.55.2
2022-11-18 21:44:59,233:INFO:            requests: 2.28.1
2022-11-18 21:44:59,233:INFO:          matplotlib: 3.5.3
2022-11-18 21:44:59,233:INFO:          scikitplot: 0.3.7
2022-11-18 21:44:59,233:INFO:         yellowbrick: 1.5
2022-11-18 21:44:59,233:INFO:              plotly: 5.5.0
2022-11-18 21:44:59,234:INFO:             kaleido: 0.2.1
2022-11-18 21:44:59,234:INFO:         statsmodels: 0.12.2
2022-11-18 21:44:59,234:INFO:              sktime: 0.13.4
2022-11-18 21:44:59,234:INFO:               tbats: 1.1.1
2022-11-18 21:44:59,234:INFO:            pmdarima: 1.8.5
2022-11-18 21:44:59,234:INFO:              psutil: 5.9.4
2022-11-18 21:44:59,234:INFO:PyCaret optional dependencies:
2022-11-18 21:44:59,235:INFO:                shap: Not installed
2022-11-18 21:44:59,235:INFO:           interpret: Not installed
2022-11-18 21:44:59,235:INFO:                umap: Not installed
2022-11-18 21:44:59,235:INFO:    pandas_profiling: 1.4.1
2022-11-18 21:44:59,235:INFO:  explainerdashboard: Not installed
2022-11-18 21:44:59,235:INFO:             autoviz: Not installed
2022-11-18 21:44:59,236:INFO:           fairlearn: Not installed
2022-11-18 21:44:59,236:INFO:             xgboost: 0.90
2022-11-18 21:44:59,236:INFO:            catboost: Not installed
2022-11-18 21:44:59,236:INFO:              kmodes: Not installed
2022-11-18 21:44:59,236:INFO:             mlxtend: 0.14.0
2022-11-18 21:44:59,236:INFO:       statsforecast: Not installed
2022-11-18 21:44:59,236:INFO:        tune_sklearn: Not installed
2022-11-18 21:44:59,237:INFO:                 ray: Not installed
2022-11-18 21:44:59,237:INFO:            hyperopt: 0.1.2
2022-11-18 21:44:59,237:INFO:              optuna: Not installed
2022-11-18 21:44:59,237:INFO:               skopt: Not installed
2022-11-18 21:44:59,237:INFO:              mlflow: Not installed
2022-11-18 21:44:59,237:INFO:              gradio: Not installed
2022-11-18 21:44:59,237:INFO:             fastapi: Not installed
2022-11-18 21:44:59,237:INFO:             uvicorn: Not installed
2022-11-18 21:44:59,238:INFO:              m2cgen: Not installed
2022-11-18 21:44:59,238:INFO:           evidently: Not installed
2022-11-18 21:44:59,238:INFO:                nltk: 3.7
2022-11-18 21:44:59,238:INFO:            pyLDAvis: Not installed
2022-11-18 21:44:59,238:INFO:              gensim: 3.6.0
2022-11-18 21:44:59,238:INFO:               spacy: 3.4.2
2022-11-18 21:44:59,238:INFO:           wordcloud: 1.8.2.2
2022-11-18 21:44:59,239:INFO:            textblob: 0.15.3
2022-11-18 21:44:59,239:INFO:               fugue: Not installed
2022-11-18 21:44:59,239:INFO:           streamlit: Not installed
2022-11-18 21:44:59,239:INFO:             prophet: 1.1.1
2022-11-18 21:44:59,239:INFO:None
2022-11-18 21:44:59,239:INFO:Set up data.
2022-11-18 21:44:59,247:INFO:Set up train/test split.
2022-11-18 21:44:59,251:INFO:Set up index.
2022-11-18 21:44:59,252:INFO:Set up folding strategy.
2022-11-18 21:44:59,252:INFO:Assigning column types.
2022-11-18 21:44:59,260:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-18 21:44:59,261:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-18 21:44:59,267:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:44:59,273:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:44:59,344:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:44:59,400:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:44:59,402:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:44:59,402:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:44:59,403:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:44:59,403:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-18 21:44:59,409:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:44:59,415:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:44:59,637:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:44:59,876:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:44:59,893:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:44:59,898:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:44:59,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:44:59,902:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-18 21:44:59,946:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:44:59,991:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:45:00,390:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:45:00,507:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:45:00,509:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:00,510:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:00,510:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:00,522:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:45:00,539:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:45:00,762:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:45:00,821:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:45:00,823:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:00,823:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:00,824:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:00,825:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-18 21:45:00,836:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:45:00,922:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:45:00,978:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:45:00,979:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:00,980:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:00,980:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:00,992:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:45:01,064:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:45:01,120:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:45:01,121:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:01,122:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:01,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:01,123:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-18 21:45:01,210:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:45:01,267:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:45:01,268:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:01,268:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:01,269:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:01,352:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:45:01,407:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:45:01,409:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:01,409:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:01,409:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:01,410:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-18 21:45:01,494:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:45:01,551:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:01,551:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:01,552:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:01,635:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:45:01,694:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:01,695:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:01,696:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:01,697:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-18 21:45:01,844:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:01,845:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:01,845:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:02,024:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:02,024:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:02,025:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:02,026:INFO:Preparing preprocessing pipeline...
2022-11-18 21:45:02,028:INFO:Set up simple imputation.
2022-11-18 21:45:02,028:INFO:Set up variance threshold.
2022-11-18 21:45:02,042:INFO:Finished creating preprocessing pipeline.
2022-11-18 21:45:02,048:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO',
                                             'Open_Line_ML_x'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-18 21:45:02,049:INFO:Creating final display dataframe.
2022-11-18 21:45:02,141:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 13)
4         Train data shape    (607, 13)
5          Test data shape    (261, 13)
6         Numeric features           12
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         e830
2022-11-18 21:45:02,306:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:02,307:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:02,308:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:02,451:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:02,452:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:02,453:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:02,460:INFO:setup() successfully completed in 3.24s...............
2022-11-18 21:45:02,461:INFO:Initializing compare_models()
2022-11-18 21:45:02,461:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825eedd0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fa0825eedd0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-18 21:45:02,461:INFO:Checking exceptions
2022-11-18 21:45:02,463:INFO:Preparing display monitor
2022-11-18 21:45:02,536:INFO:Initializing Linear Regression
2022-11-18 21:45:02,536:INFO:Total runtime is 9.1552734375e-06 minutes
2022-11-18 21:45:02,553:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:02,554:INFO:Initializing create_model()
2022-11-18 21:45:02,554:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825eedd0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085a00c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:02,555:INFO:Checking exceptions
2022-11-18 21:45:02,558:INFO:Importing libraries
2022-11-18 21:45:02,558:INFO:Copying training dataset
2022-11-18 21:45:02,564:INFO:Defining folds
2022-11-18 21:45:02,565:INFO:Declaring metric variables
2022-11-18 21:45:02,579:INFO:Importing untrained model
2022-11-18 21:45:02,592:INFO:Linear Regression Imported successfully
2022-11-18 21:45:02,615:INFO:Starting cross validation
2022-11-18 21:45:02,622:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:02,964:INFO:Calculating mean and std
2022-11-18 21:45:02,965:INFO:Creating metrics dataframe
2022-11-18 21:45:02,972:INFO:Uploading results into container
2022-11-18 21:45:02,972:INFO:Uploading model into container now
2022-11-18 21:45:02,973:INFO:master_model_container: 1
2022-11-18 21:45:02,973:INFO:display_container: 2
2022-11-18 21:45:02,974:INFO:LinearRegression(n_jobs=-1)
2022-11-18 21:45:02,974:INFO:create_model() successfully completed......................................
2022-11-18 21:45:03,170:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:03,170:INFO:Creating metrics dataframe
2022-11-18 21:45:03,189:INFO:Initializing Lasso Regression
2022-11-18 21:45:03,190:INFO:Total runtime is 0.010897382100423177 minutes
2022-11-18 21:45:03,200:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:03,201:INFO:Initializing create_model()
2022-11-18 21:45:03,201:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825eedd0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085a00c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:03,201:INFO:Checking exceptions
2022-11-18 21:45:03,204:INFO:Importing libraries
2022-11-18 21:45:03,204:INFO:Copying training dataset
2022-11-18 21:45:03,209:INFO:Defining folds
2022-11-18 21:45:03,209:INFO:Declaring metric variables
2022-11-18 21:45:03,215:INFO:Importing untrained model
2022-11-18 21:45:03,225:INFO:Lasso Regression Imported successfully
2022-11-18 21:45:03,245:INFO:Starting cross validation
2022-11-18 21:45:03,249:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:03,603:INFO:Calculating mean and std
2022-11-18 21:45:03,610:INFO:Creating metrics dataframe
2022-11-18 21:45:03,619:INFO:Uploading results into container
2022-11-18 21:45:03,622:INFO:Uploading model into container now
2022-11-18 21:45:03,623:INFO:master_model_container: 2
2022-11-18 21:45:03,623:INFO:display_container: 2
2022-11-18 21:45:03,624:INFO:Lasso(random_state=123)
2022-11-18 21:45:03,624:INFO:create_model() successfully completed......................................
2022-11-18 21:45:03,819:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:03,819:INFO:Creating metrics dataframe
2022-11-18 21:45:03,840:INFO:Initializing Ridge Regression
2022-11-18 21:45:03,841:INFO:Total runtime is 0.021746397018432617 minutes
2022-11-18 21:45:03,852:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:03,853:INFO:Initializing create_model()
2022-11-18 21:45:03,853:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825eedd0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085a00c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:03,853:INFO:Checking exceptions
2022-11-18 21:45:03,856:INFO:Importing libraries
2022-11-18 21:45:03,857:INFO:Copying training dataset
2022-11-18 21:45:03,863:INFO:Defining folds
2022-11-18 21:45:03,865:INFO:Declaring metric variables
2022-11-18 21:45:03,875:INFO:Importing untrained model
2022-11-18 21:45:03,888:INFO:Ridge Regression Imported successfully
2022-11-18 21:45:03,904:INFO:Starting cross validation
2022-11-18 21:45:03,907:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:03,956:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.19612e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:45:04,004:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1832e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:45:04,054:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.25596e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:45:04,094:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.27134e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:45:04,103:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1563e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:45:04,149:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.25177e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:45:04,189:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.30751e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:45:04,302:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1922e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:45:04,334:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.19532e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:45:04,455:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.20778e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:45:04,518:INFO:Calculating mean and std
2022-11-18 21:45:04,522:INFO:Creating metrics dataframe
2022-11-18 21:45:04,561:INFO:Uploading results into container
2022-11-18 21:45:04,563:INFO:Uploading model into container now
2022-11-18 21:45:04,572:INFO:master_model_container: 3
2022-11-18 21:45:04,576:INFO:display_container: 2
2022-11-18 21:45:04,577:INFO:Ridge(random_state=123)
2022-11-18 21:45:04,577:INFO:create_model() successfully completed......................................
2022-11-18 21:45:05,004:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:05,005:INFO:Creating metrics dataframe
2022-11-18 21:45:05,036:INFO:Initializing Elastic Net
2022-11-18 21:45:05,037:INFO:Total runtime is 0.04168720642725626 minutes
2022-11-18 21:45:05,047:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:05,048:INFO:Initializing create_model()
2022-11-18 21:45:05,048:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825eedd0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085a00c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:05,048:INFO:Checking exceptions
2022-11-18 21:45:05,051:INFO:Importing libraries
2022-11-18 21:45:05,055:INFO:Copying training dataset
2022-11-18 21:45:05,061:INFO:Defining folds
2022-11-18 21:45:05,062:INFO:Declaring metric variables
2022-11-18 21:45:05,081:INFO:Importing untrained model
2022-11-18 21:45:05,092:INFO:Elastic Net Imported successfully
2022-11-18 21:45:05,114:INFO:Starting cross validation
2022-11-18 21:45:05,116:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:05,455:INFO:Calculating mean and std
2022-11-18 21:45:05,459:INFO:Creating metrics dataframe
2022-11-18 21:45:05,468:INFO:Uploading results into container
2022-11-18 21:45:05,470:INFO:Uploading model into container now
2022-11-18 21:45:05,470:INFO:master_model_container: 4
2022-11-18 21:45:05,471:INFO:display_container: 2
2022-11-18 21:45:05,471:INFO:ElasticNet(random_state=123)
2022-11-18 21:45:05,472:INFO:create_model() successfully completed......................................
2022-11-18 21:45:05,667:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:05,668:INFO:Creating metrics dataframe
2022-11-18 21:45:05,697:INFO:Initializing Least Angle Regression
2022-11-18 21:45:05,698:INFO:Total runtime is 0.05269566774368286 minutes
2022-11-18 21:45:05,708:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:05,709:INFO:Initializing create_model()
2022-11-18 21:45:05,710:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825eedd0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085a00c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:05,711:INFO:Checking exceptions
2022-11-18 21:45:05,715:INFO:Importing libraries
2022-11-18 21:45:05,715:INFO:Copying training dataset
2022-11-18 21:45:05,720:INFO:Defining folds
2022-11-18 21:45:05,721:INFO:Declaring metric variables
2022-11-18 21:45:05,736:INFO:Importing untrained model
2022-11-18 21:45:05,752:INFO:Least Angle Regression Imported successfully
2022-11-18 21:45:05,777:INFO:Starting cross validation
2022-11-18 21:45:05,779:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:05,825:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:05,859:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:05,912:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:05,948:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:05,974:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:06,031:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:06,050:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:06,085:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:06,107:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:06,132:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:06,147:INFO:Calculating mean and std
2022-11-18 21:45:06,150:INFO:Creating metrics dataframe
2022-11-18 21:45:06,162:INFO:Uploading results into container
2022-11-18 21:45:06,163:INFO:Uploading model into container now
2022-11-18 21:45:06,164:INFO:master_model_container: 5
2022-11-18 21:45:06,164:INFO:display_container: 2
2022-11-18 21:45:06,165:INFO:Lars(random_state=123)
2022-11-18 21:45:06,165:INFO:create_model() successfully completed......................................
2022-11-18 21:45:06,356:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:06,356:INFO:Creating metrics dataframe
2022-11-18 21:45:06,377:INFO:Initializing Lasso Least Angle Regression
2022-11-18 21:45:06,377:INFO:Total runtime is 0.06402753591537476 minutes
2022-11-18 21:45:06,387:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:06,388:INFO:Initializing create_model()
2022-11-18 21:45:06,388:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825eedd0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085a00c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:06,388:INFO:Checking exceptions
2022-11-18 21:45:06,392:INFO:Importing libraries
2022-11-18 21:45:06,392:INFO:Copying training dataset
2022-11-18 21:45:06,400:INFO:Defining folds
2022-11-18 21:45:06,401:INFO:Declaring metric variables
2022-11-18 21:45:06,412:INFO:Importing untrained model
2022-11-18 21:45:06,423:INFO:Lasso Least Angle Regression Imported successfully
2022-11-18 21:45:06,444:INFO:Starting cross validation
2022-11-18 21:45:06,446:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:06,495:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:45:06,524:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:45:06,564:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:45:06,601:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:45:06,647:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:45:06,688:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:45:06,698:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:45:06,737:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:45:06,750:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:45:06,778:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:45:06,793:INFO:Calculating mean and std
2022-11-18 21:45:06,796:INFO:Creating metrics dataframe
2022-11-18 21:45:06,809:INFO:Uploading results into container
2022-11-18 21:45:06,810:INFO:Uploading model into container now
2022-11-18 21:45:06,811:INFO:master_model_container: 6
2022-11-18 21:45:06,812:INFO:display_container: 2
2022-11-18 21:45:06,813:INFO:LassoLars(random_state=123)
2022-11-18 21:45:06,813:INFO:create_model() successfully completed......................................
2022-11-18 21:45:07,008:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:07,009:INFO:Creating metrics dataframe
2022-11-18 21:45:07,031:INFO:Initializing Orthogonal Matching Pursuit
2022-11-18 21:45:07,034:INFO:Total runtime is 0.07496500412623087 minutes
2022-11-18 21:45:07,043:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:07,044:INFO:Initializing create_model()
2022-11-18 21:45:07,044:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825eedd0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085a00c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:07,044:INFO:Checking exceptions
2022-11-18 21:45:07,048:INFO:Importing libraries
2022-11-18 21:45:07,048:INFO:Copying training dataset
2022-11-18 21:45:07,057:INFO:Defining folds
2022-11-18 21:45:07,058:INFO:Declaring metric variables
2022-11-18 21:45:07,069:INFO:Importing untrained model
2022-11-18 21:45:07,081:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-18 21:45:07,099:INFO:Starting cross validation
2022-11-18 21:45:07,101:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:07,162:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:07,189:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:07,224:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:07,256:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:07,290:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:07,335:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:07,342:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:07,378:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:07,405:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:07,420:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:07,438:INFO:Calculating mean and std
2022-11-18 21:45:07,444:INFO:Creating metrics dataframe
2022-11-18 21:45:07,459:INFO:Uploading results into container
2022-11-18 21:45:07,460:INFO:Uploading model into container now
2022-11-18 21:45:07,461:INFO:master_model_container: 7
2022-11-18 21:45:07,461:INFO:display_container: 2
2022-11-18 21:45:07,461:INFO:OrthogonalMatchingPursuit()
2022-11-18 21:45:07,462:INFO:create_model() successfully completed......................................
2022-11-18 21:45:07,652:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:07,653:INFO:Creating metrics dataframe
2022-11-18 21:45:07,686:INFO:Initializing Bayesian Ridge
2022-11-18 21:45:07,687:INFO:Total runtime is 0.08584841092427571 minutes
2022-11-18 21:45:07,698:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:07,699:INFO:Initializing create_model()
2022-11-18 21:45:07,699:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825eedd0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085a00c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:07,699:INFO:Checking exceptions
2022-11-18 21:45:07,703:INFO:Importing libraries
2022-11-18 21:45:07,703:INFO:Copying training dataset
2022-11-18 21:45:07,710:INFO:Defining folds
2022-11-18 21:45:07,711:INFO:Declaring metric variables
2022-11-18 21:45:07,722:INFO:Importing untrained model
2022-11-18 21:45:07,734:INFO:Bayesian Ridge Imported successfully
2022-11-18 21:45:07,755:INFO:Starting cross validation
2022-11-18 21:45:07,757:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:08,105:INFO:Calculating mean and std
2022-11-18 21:45:08,108:INFO:Creating metrics dataframe
2022-11-18 21:45:08,115:INFO:Uploading results into container
2022-11-18 21:45:08,117:INFO:Uploading model into container now
2022-11-18 21:45:08,118:INFO:master_model_container: 8
2022-11-18 21:45:08,119:INFO:display_container: 2
2022-11-18 21:45:08,121:INFO:BayesianRidge()
2022-11-18 21:45:08,122:INFO:create_model() successfully completed......................................
2022-11-18 21:45:08,319:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:08,320:INFO:Creating metrics dataframe
2022-11-18 21:45:08,349:INFO:Initializing Passive Aggressive Regressor
2022-11-18 21:45:08,349:INFO:Total runtime is 0.09689081907272339 minutes
2022-11-18 21:45:08,361:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:08,362:INFO:Initializing create_model()
2022-11-18 21:45:08,367:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825eedd0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085a00c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:08,367:INFO:Checking exceptions
2022-11-18 21:45:08,370:INFO:Importing libraries
2022-11-18 21:45:08,370:INFO:Copying training dataset
2022-11-18 21:45:08,375:INFO:Defining folds
2022-11-18 21:45:08,379:INFO:Declaring metric variables
2022-11-18 21:45:08,391:INFO:Importing untrained model
2022-11-18 21:45:08,403:INFO:Passive Aggressive Regressor Imported successfully
2022-11-18 21:45:08,423:INFO:Starting cross validation
2022-11-18 21:45:08,425:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:08,778:INFO:Calculating mean and std
2022-11-18 21:45:08,781:INFO:Creating metrics dataframe
2022-11-18 21:45:08,787:INFO:Uploading results into container
2022-11-18 21:45:08,791:INFO:Uploading model into container now
2022-11-18 21:45:08,796:INFO:master_model_container: 9
2022-11-18 21:45:08,797:INFO:display_container: 2
2022-11-18 21:45:08,797:INFO:PassiveAggressiveRegressor(random_state=123)
2022-11-18 21:45:08,798:INFO:create_model() successfully completed......................................
2022-11-18 21:45:08,990:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:08,991:INFO:Creating metrics dataframe
2022-11-18 21:45:09,015:INFO:Initializing Huber Regressor
2022-11-18 21:45:09,016:INFO:Total runtime is 0.10799632867177328 minutes
2022-11-18 21:45:09,024:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:09,025:INFO:Initializing create_model()
2022-11-18 21:45:09,026:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825eedd0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085a00c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:09,026:INFO:Checking exceptions
2022-11-18 21:45:09,031:INFO:Importing libraries
2022-11-18 21:45:09,032:INFO:Copying training dataset
2022-11-18 21:45:09,039:INFO:Defining folds
2022-11-18 21:45:09,041:INFO:Declaring metric variables
2022-11-18 21:45:09,054:INFO:Importing untrained model
2022-11-18 21:45:09,064:INFO:Huber Regressor Imported successfully
2022-11-18 21:45:09,086:INFO:Starting cross validation
2022-11-18 21:45:09,088:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:09,221:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:45:09,262:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:45:09,344:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:45:09,413:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:45:09,498:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:45:09,537:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:45:09,614:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:45:09,639:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:45:09,714:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:45:09,740:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:45:09,755:INFO:Calculating mean and std
2022-11-18 21:45:09,761:INFO:Creating metrics dataframe
2022-11-18 21:45:09,772:INFO:Uploading results into container
2022-11-18 21:45:09,773:INFO:Uploading model into container now
2022-11-18 21:45:09,774:INFO:master_model_container: 10
2022-11-18 21:45:09,775:INFO:display_container: 2
2022-11-18 21:45:09,776:INFO:HuberRegressor()
2022-11-18 21:45:09,776:INFO:create_model() successfully completed......................................
2022-11-18 21:45:09,972:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:09,973:INFO:Creating metrics dataframe
2022-11-18 21:45:09,995:INFO:Initializing K Neighbors Regressor
2022-11-18 21:45:09,996:INFO:Total runtime is 0.12433277765909831 minutes
2022-11-18 21:45:10,005:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:10,006:INFO:Initializing create_model()
2022-11-18 21:45:10,006:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825eedd0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085a00c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:10,007:INFO:Checking exceptions
2022-11-18 21:45:10,010:INFO:Importing libraries
2022-11-18 21:45:10,010:INFO:Copying training dataset
2022-11-18 21:45:10,018:INFO:Defining folds
2022-11-18 21:45:10,019:INFO:Declaring metric variables
2022-11-18 21:45:10,029:INFO:Importing untrained model
2022-11-18 21:45:10,046:INFO:K Neighbors Regressor Imported successfully
2022-11-18 21:45:10,070:INFO:Starting cross validation
2022-11-18 21:45:10,072:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:10,845:INFO:Calculating mean and std
2022-11-18 21:45:10,848:INFO:Creating metrics dataframe
2022-11-18 21:45:10,866:INFO:Uploading results into container
2022-11-18 21:45:10,867:INFO:Uploading model into container now
2022-11-18 21:45:10,868:INFO:master_model_container: 11
2022-11-18 21:45:10,868:INFO:display_container: 2
2022-11-18 21:45:10,869:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-18 21:45:10,869:INFO:create_model() successfully completed......................................
2022-11-18 21:45:11,058:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:11,058:INFO:Creating metrics dataframe
2022-11-18 21:45:11,082:INFO:Initializing Decision Tree Regressor
2022-11-18 21:45:11,084:INFO:Total runtime is 0.14246803124745688 minutes
2022-11-18 21:45:11,093:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:11,094:INFO:Initializing create_model()
2022-11-18 21:45:11,095:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825eedd0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085a00c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:11,095:INFO:Checking exceptions
2022-11-18 21:45:11,100:INFO:Importing libraries
2022-11-18 21:45:11,100:INFO:Copying training dataset
2022-11-18 21:45:11,108:INFO:Defining folds
2022-11-18 21:45:11,109:INFO:Declaring metric variables
2022-11-18 21:45:11,120:INFO:Importing untrained model
2022-11-18 21:45:11,130:INFO:Decision Tree Regressor Imported successfully
2022-11-18 21:45:11,147:INFO:Starting cross validation
2022-11-18 21:45:11,149:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:11,542:INFO:Calculating mean and std
2022-11-18 21:45:11,547:INFO:Creating metrics dataframe
2022-11-18 21:45:11,556:INFO:Uploading results into container
2022-11-18 21:45:11,557:INFO:Uploading model into container now
2022-11-18 21:45:11,558:INFO:master_model_container: 12
2022-11-18 21:45:11,559:INFO:display_container: 2
2022-11-18 21:45:11,559:INFO:DecisionTreeRegressor(random_state=123)
2022-11-18 21:45:11,560:INFO:create_model() successfully completed......................................
2022-11-18 21:45:11,749:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:11,750:INFO:Creating metrics dataframe
2022-11-18 21:45:11,779:INFO:Initializing Random Forest Regressor
2022-11-18 21:45:11,780:INFO:Total runtime is 0.15406194925308228 minutes
2022-11-18 21:45:11,789:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:11,790:INFO:Initializing create_model()
2022-11-18 21:45:11,791:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825eedd0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085a00c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:11,791:INFO:Checking exceptions
2022-11-18 21:45:11,794:INFO:Importing libraries
2022-11-18 21:45:11,795:INFO:Copying training dataset
2022-11-18 21:45:11,802:INFO:Defining folds
2022-11-18 21:45:11,803:INFO:Declaring metric variables
2022-11-18 21:45:11,816:INFO:Importing untrained model
2022-11-18 21:45:11,833:INFO:Random Forest Regressor Imported successfully
2022-11-18 21:45:11,856:INFO:Starting cross validation
2022-11-18 21:45:11,858:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:16,536:INFO:Calculating mean and std
2022-11-18 21:45:16,538:INFO:Creating metrics dataframe
2022-11-18 21:45:16,545:INFO:Uploading results into container
2022-11-18 21:45:16,546:INFO:Uploading model into container now
2022-11-18 21:45:16,548:INFO:master_model_container: 13
2022-11-18 21:45:16,548:INFO:display_container: 2
2022-11-18 21:45:16,549:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-18 21:45:16,549:INFO:create_model() successfully completed......................................
2022-11-18 21:45:16,757:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:16,760:INFO:Creating metrics dataframe
2022-11-18 21:45:16,786:INFO:Initializing Extra Trees Regressor
2022-11-18 21:45:16,787:INFO:Total runtime is 0.23752482732137045 minutes
2022-11-18 21:45:16,797:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:16,798:INFO:Initializing create_model()
2022-11-18 21:45:16,802:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825eedd0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085a00c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:16,803:INFO:Checking exceptions
2022-11-18 21:45:16,806:INFO:Importing libraries
2022-11-18 21:45:16,806:INFO:Copying training dataset
2022-11-18 21:45:16,819:INFO:Defining folds
2022-11-18 21:45:16,821:INFO:Declaring metric variables
2022-11-18 21:45:16,832:INFO:Importing untrained model
2022-11-18 21:45:16,843:INFO:Extra Trees Regressor Imported successfully
2022-11-18 21:45:16,863:INFO:Starting cross validation
2022-11-18 21:45:16,866:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:19,719:INFO:Calculating mean and std
2022-11-18 21:45:19,724:INFO:Creating metrics dataframe
2022-11-18 21:45:19,738:INFO:Uploading results into container
2022-11-18 21:45:19,739:INFO:Uploading model into container now
2022-11-18 21:45:19,740:INFO:master_model_container: 14
2022-11-18 21:45:19,740:INFO:display_container: 2
2022-11-18 21:45:19,741:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-18 21:45:19,741:INFO:create_model() successfully completed......................................
2022-11-18 21:45:19,936:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:19,937:INFO:Creating metrics dataframe
2022-11-18 21:45:19,961:INFO:Initializing AdaBoost Regressor
2022-11-18 21:45:19,961:INFO:Total runtime is 0.29042586088180544 minutes
2022-11-18 21:45:19,972:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:19,973:INFO:Initializing create_model()
2022-11-18 21:45:19,973:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825eedd0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085a00c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:19,973:INFO:Checking exceptions
2022-11-18 21:45:19,977:INFO:Importing libraries
2022-11-18 21:45:19,977:INFO:Copying training dataset
2022-11-18 21:45:19,985:INFO:Defining folds
2022-11-18 21:45:19,985:INFO:Declaring metric variables
2022-11-18 21:45:19,997:INFO:Importing untrained model
2022-11-18 21:45:20,009:INFO:AdaBoost Regressor Imported successfully
2022-11-18 21:45:20,028:INFO:Starting cross validation
2022-11-18 21:45:20,030:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:21,377:INFO:Calculating mean and std
2022-11-18 21:45:21,384:INFO:Creating metrics dataframe
2022-11-18 21:45:21,400:INFO:Uploading results into container
2022-11-18 21:45:21,401:INFO:Uploading model into container now
2022-11-18 21:45:21,403:INFO:master_model_container: 15
2022-11-18 21:45:21,403:INFO:display_container: 2
2022-11-18 21:45:21,404:INFO:AdaBoostRegressor(random_state=123)
2022-11-18 21:45:21,404:INFO:create_model() successfully completed......................................
2022-11-18 21:45:21,598:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:21,599:INFO:Creating metrics dataframe
2022-11-18 21:45:21,628:INFO:Initializing Gradient Boosting Regressor
2022-11-18 21:45:21,636:INFO:Total runtime is 0.3183402299880982 minutes
2022-11-18 21:45:21,649:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:21,650:INFO:Initializing create_model()
2022-11-18 21:45:21,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825eedd0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085a00c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:21,651:INFO:Checking exceptions
2022-11-18 21:45:21,655:INFO:Importing libraries
2022-11-18 21:45:21,658:INFO:Copying training dataset
2022-11-18 21:45:21,665:INFO:Defining folds
2022-11-18 21:45:21,665:INFO:Declaring metric variables
2022-11-18 21:45:21,679:INFO:Importing untrained model
2022-11-18 21:45:21,696:INFO:Gradient Boosting Regressor Imported successfully
2022-11-18 21:45:21,716:INFO:Starting cross validation
2022-11-18 21:45:21,718:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:23,597:INFO:Calculating mean and std
2022-11-18 21:45:23,600:INFO:Creating metrics dataframe
2022-11-18 21:45:23,627:INFO:Uploading results into container
2022-11-18 21:45:23,628:INFO:Uploading model into container now
2022-11-18 21:45:23,629:INFO:master_model_container: 16
2022-11-18 21:45:23,629:INFO:display_container: 2
2022-11-18 21:45:23,630:INFO:GradientBoostingRegressor(random_state=123)
2022-11-18 21:45:23,631:INFO:create_model() successfully completed......................................
2022-11-18 21:45:23,828:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:23,829:INFO:Creating metrics dataframe
2022-11-18 21:45:23,855:INFO:Initializing Light Gradient Boosting Machine
2022-11-18 21:45:23,856:INFO:Total runtime is 0.3553304831186931 minutes
2022-11-18 21:45:23,871:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:23,873:INFO:Initializing create_model()
2022-11-18 21:45:23,875:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825eedd0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085a00c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:23,875:INFO:Checking exceptions
2022-11-18 21:45:23,878:INFO:Importing libraries
2022-11-18 21:45:23,879:INFO:Copying training dataset
2022-11-18 21:45:23,884:INFO:Defining folds
2022-11-18 21:45:23,885:INFO:Declaring metric variables
2022-11-18 21:45:23,896:INFO:Importing untrained model
2022-11-18 21:45:23,914:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-18 21:45:23,932:INFO:Starting cross validation
2022-11-18 21:45:23,934:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:24,842:INFO:Calculating mean and std
2022-11-18 21:45:24,848:INFO:Creating metrics dataframe
2022-11-18 21:45:24,860:INFO:Uploading results into container
2022-11-18 21:45:24,861:INFO:Uploading model into container now
2022-11-18 21:45:24,863:INFO:master_model_container: 17
2022-11-18 21:45:24,863:INFO:display_container: 2
2022-11-18 21:45:24,864:INFO:LGBMRegressor(random_state=123)
2022-11-18 21:45:24,865:INFO:create_model() successfully completed......................................
2022-11-18 21:45:25,051:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:25,052:INFO:Creating metrics dataframe
2022-11-18 21:45:25,078:INFO:Initializing Dummy Regressor
2022-11-18 21:45:25,079:INFO:Total runtime is 0.3757126053174337 minutes
2022-11-18 21:45:25,089:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:25,091:INFO:Initializing create_model()
2022-11-18 21:45:25,094:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825eedd0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa085a00c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:25,094:INFO:Checking exceptions
2022-11-18 21:45:25,097:INFO:Importing libraries
2022-11-18 21:45:25,098:INFO:Copying training dataset
2022-11-18 21:45:25,103:INFO:Defining folds
2022-11-18 21:45:25,103:INFO:Declaring metric variables
2022-11-18 21:45:25,116:INFO:Importing untrained model
2022-11-18 21:45:25,129:INFO:Dummy Regressor Imported successfully
2022-11-18 21:45:25,147:INFO:Starting cross validation
2022-11-18 21:45:25,149:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:25,444:INFO:Calculating mean and std
2022-11-18 21:45:25,447:INFO:Creating metrics dataframe
2022-11-18 21:45:25,456:INFO:Uploading results into container
2022-11-18 21:45:25,457:INFO:Uploading model into container now
2022-11-18 21:45:25,458:INFO:master_model_container: 18
2022-11-18 21:45:25,459:INFO:display_container: 2
2022-11-18 21:45:25,459:INFO:DummyRegressor()
2022-11-18 21:45:25,459:INFO:create_model() successfully completed......................................
2022-11-18 21:45:25,651:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:25,652:INFO:Creating metrics dataframe
2022-11-18 21:45:25,722:INFO:Initializing create_model()
2022-11-18 21:45:25,722:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825eedd0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:25,723:INFO:Checking exceptions
2022-11-18 21:45:25,740:INFO:Importing libraries
2022-11-18 21:45:25,740:INFO:Copying training dataset
2022-11-18 21:45:25,745:INFO:Defining folds
2022-11-18 21:45:25,745:INFO:Declaring metric variables
2022-11-18 21:45:25,746:INFO:Importing untrained model
2022-11-18 21:45:25,747:INFO:Declaring custom model
2022-11-18 21:45:25,749:INFO:Random Forest Regressor Imported successfully
2022-11-18 21:45:25,750:INFO:Cross validation set to False
2022-11-18 21:45:25,754:INFO:Fitting Model
2022-11-18 21:45:26,317:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-18 21:45:26,317:INFO:create_model() successfully completed......................................
2022-11-18 21:45:26,595:INFO:master_model_container: 18
2022-11-18 21:45:26,598:INFO:display_container: 2
2022-11-18 21:45:26,599:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-18 21:45:26,602:INFO:compare_models() successfully completed......................................
2022-11-18 21:45:33,891:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  app.launch_new_instance()

2022-11-18 21:45:33,893:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:45:33,895:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:45:33,897:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:45:33,898:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:45:33,900:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:45:33,901:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:45:33,902:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:45:33,904:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:45:33,905:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:45:33,911:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:45:33,918:INFO:PyCaret RegressionExperiment
2022-11-18 21:45:33,919:INFO:Logging name: FullData
2022-11-18 21:45:33,919:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-18 21:45:33,919:INFO:version 3.0.0.rc4
2022-11-18 21:45:33,919:INFO:Initializing setup()
2022-11-18 21:45:33,919:INFO:self.USI: e46b
2022-11-18 21:45:33,919:INFO:self.variable_keys: {'_available_plots', 'seed', 'log_plots_param', '_gpu_n_jobs_param', 'USI', 'pipeline', '_all_models_internal', 'fold_generator', 'variable_keys', 'gpu_param', 'exp_id', 'X_test', 'memory', '_ml_usecase', 'y', 'fold_groups_param', 'transform_target_method_param', 'display_container', 'logging_param', '_all_metrics', 'fold_shuffle_param', 'n_jobs_param', 'exp_name_log', 'data', 'y_test', 'html_param', 'target_param', 'transform_target_param', '_all_models', 'y_train', 'X_train', 'X', 'master_model_container', 'idx'}
2022-11-18 21:45:33,920:INFO:Checking environment
2022-11-18 21:45:33,920:INFO:python_version: 3.7.15
2022-11-18 21:45:33,920:INFO:python_build: ('default', 'Oct 12 2022 19:14:55')
2022-11-18 21:45:33,920:INFO:machine: x86_64
2022-11-18 21:45:33,920:INFO:platform: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-18 21:45:33,921:INFO:Memory: svmem(total=13616353280, available=11453190144, percent=15.9, used=2069127168, free=9102589952, active=982372352, inactive=3204894720, buffers=170508288, cached=2274127872, shared=1327104, slab=226598912)
2022-11-18 21:45:33,921:INFO:Physical Core: 1
2022-11-18 21:45:33,921:INFO:Logical Core: 2
2022-11-18 21:45:33,921:INFO:Checking libraries
2022-11-18 21:45:33,923:INFO:System:
2022-11-18 21:45:33,925:INFO:    python: 3.7.15 (default, Oct 12 2022, 19:14:55)  [GCC 7.5.0]
2022-11-18 21:45:33,925:INFO:executable: /usr/bin/python3
2022-11-18 21:45:33,925:INFO:   machine: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-18 21:45:33,925:INFO:PyCaret required dependencies:
2022-11-18 21:45:33,926:INFO:                 pip: 21.1.3
2022-11-18 21:45:33,926:INFO:          setuptools: 57.4.0
2022-11-18 21:45:33,926:INFO:             pycaret: 3.0.0rc4
2022-11-18 21:45:33,926:INFO:             IPython: 7.9.0
2022-11-18 21:45:33,926:INFO:          ipywidgets: 7.7.1
2022-11-18 21:45:33,926:INFO:                tqdm: 4.64.1
2022-11-18 21:45:33,926:INFO:               numpy: 1.21.6
2022-11-18 21:45:33,926:INFO:              pandas: 1.3.5
2022-11-18 21:45:33,926:INFO:              jinja2: 3.0.0
2022-11-18 21:45:33,926:INFO:               scipy: 1.7.3
2022-11-18 21:45:33,926:INFO:              joblib: 1.2.0
2022-11-18 21:45:33,927:INFO:             sklearn: 1.0.2
2022-11-18 21:45:33,927:INFO:                pyod: 1.0.6
2022-11-18 21:45:33,927:INFO:            imblearn: 0.8.1
2022-11-18 21:45:33,927:INFO:   category_encoders: 2.5.1.post0
2022-11-18 21:45:33,927:INFO:            lightgbm: 3.3.3
2022-11-18 21:45:33,927:INFO:               numba: 0.55.2
2022-11-18 21:45:33,927:INFO:            requests: 2.28.1
2022-11-18 21:45:33,927:INFO:          matplotlib: 3.5.3
2022-11-18 21:45:33,928:INFO:          scikitplot: 0.3.7
2022-11-18 21:45:33,928:INFO:         yellowbrick: 1.5
2022-11-18 21:45:33,928:INFO:              plotly: 5.5.0
2022-11-18 21:45:33,928:INFO:             kaleido: 0.2.1
2022-11-18 21:45:33,928:INFO:         statsmodels: 0.12.2
2022-11-18 21:45:33,928:INFO:              sktime: 0.13.4
2022-11-18 21:45:33,928:INFO:               tbats: 1.1.1
2022-11-18 21:45:33,929:INFO:            pmdarima: 1.8.5
2022-11-18 21:45:33,929:INFO:              psutil: 5.9.4
2022-11-18 21:45:33,929:INFO:PyCaret optional dependencies:
2022-11-18 21:45:33,929:INFO:                shap: Not installed
2022-11-18 21:45:33,929:INFO:           interpret: Not installed
2022-11-18 21:45:33,929:INFO:                umap: Not installed
2022-11-18 21:45:33,930:INFO:    pandas_profiling: 1.4.1
2022-11-18 21:45:33,930:INFO:  explainerdashboard: Not installed
2022-11-18 21:45:33,930:INFO:             autoviz: Not installed
2022-11-18 21:45:33,930:INFO:           fairlearn: Not installed
2022-11-18 21:45:33,930:INFO:             xgboost: 0.90
2022-11-18 21:45:33,930:INFO:            catboost: Not installed
2022-11-18 21:45:33,930:INFO:              kmodes: Not installed
2022-11-18 21:45:33,931:INFO:             mlxtend: 0.14.0
2022-11-18 21:45:33,931:INFO:       statsforecast: Not installed
2022-11-18 21:45:33,931:INFO:        tune_sklearn: Not installed
2022-11-18 21:45:33,931:INFO:                 ray: Not installed
2022-11-18 21:45:33,931:INFO:            hyperopt: 0.1.2
2022-11-18 21:45:33,931:INFO:              optuna: Not installed
2022-11-18 21:45:33,931:INFO:               skopt: Not installed
2022-11-18 21:45:33,931:INFO:              mlflow: Not installed
2022-11-18 21:45:33,932:INFO:              gradio: Not installed
2022-11-18 21:45:33,932:INFO:             fastapi: Not installed
2022-11-18 21:45:33,932:INFO:             uvicorn: Not installed
2022-11-18 21:45:33,932:INFO:              m2cgen: Not installed
2022-11-18 21:45:33,932:INFO:           evidently: Not installed
2022-11-18 21:45:33,932:INFO:                nltk: 3.7
2022-11-18 21:45:33,932:INFO:            pyLDAvis: Not installed
2022-11-18 21:45:33,933:INFO:              gensim: 3.6.0
2022-11-18 21:45:33,933:INFO:               spacy: 3.4.2
2022-11-18 21:45:33,933:INFO:           wordcloud: 1.8.2.2
2022-11-18 21:45:33,933:INFO:            textblob: 0.15.3
2022-11-18 21:45:33,933:INFO:               fugue: Not installed
2022-11-18 21:45:33,933:INFO:           streamlit: Not installed
2022-11-18 21:45:33,933:INFO:             prophet: 1.1.1
2022-11-18 21:45:33,934:INFO:None
2022-11-18 21:45:33,934:INFO:Set up data.
2022-11-18 21:45:33,942:INFO:Set up train/test split.
2022-11-18 21:45:33,946:INFO:Set up index.
2022-11-18 21:45:33,946:INFO:Set up folding strategy.
2022-11-18 21:45:33,947:INFO:Assigning column types.
2022-11-18 21:45:33,953:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-18 21:45:33,954:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-18 21:45:33,960:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:45:33,967:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:45:34,040:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:45:34,096:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:45:34,097:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:34,097:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:34,097:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:34,098:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-18 21:45:34,104:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:45:34,110:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:45:34,186:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:45:34,248:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:45:34,249:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:34,249:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:34,249:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:34,250:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-18 21:45:34,257:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:45:34,263:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:45:34,335:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:45:34,390:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:45:34,391:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:34,392:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:34,392:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:34,399:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:45:34,404:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:45:34,477:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:45:34,535:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:45:34,537:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:34,540:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:34,541:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:34,541:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-18 21:45:34,553:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:45:34,627:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:45:34,686:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:45:34,687:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:34,688:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:34,688:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:34,700:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:45:34,773:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:45:34,830:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:45:34,832:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:34,832:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:34,833:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:34,834:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-18 21:45:34,918:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:45:34,974:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:45:34,975:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:34,976:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:34,976:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:35,065:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:45:35,120:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:45:35,121:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:35,121:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:35,121:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:35,122:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-18 21:45:35,207:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:45:35,272:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:35,273:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:35,273:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:35,358:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:45:35,414:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:35,414:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:35,415:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:35,416:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-18 21:45:35,561:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:35,561:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:35,562:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:35,712:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:35,713:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:35,714:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:35,715:INFO:Preparing preprocessing pipeline...
2022-11-18 21:45:35,717:INFO:Set up simple imputation.
2022-11-18 21:45:35,717:INFO:Set up variance threshold.
2022-11-18 21:45:35,765:INFO:Finished creating preprocessing pipeline.
2022-11-18 21:45:35,771:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO',
                                             'Open_Line_ML_x'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-18 21:45:35,772:INFO:Creating final display dataframe.
2022-11-18 21:45:35,966:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 13)
4         Train data shape    (607, 13)
5          Test data shape    (261, 13)
6         Numeric features           12
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         e46b
2022-11-18 21:45:36,133:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:36,134:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:36,134:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:36,290:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:45:36,291:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:45:36,291:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:45:36,299:INFO:setup() successfully completed in 2.39s...............
2022-11-18 21:45:36,299:INFO:Initializing compare_models()
2022-11-18 21:45:36,299:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085bceed0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fa085bceed0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-18 21:45:36,299:INFO:Checking exceptions
2022-11-18 21:45:36,301:INFO:Preparing display monitor
2022-11-18 21:45:36,403:INFO:Initializing Linear Regression
2022-11-18 21:45:36,403:INFO:Total runtime is 8.31286112467448e-06 minutes
2022-11-18 21:45:36,414:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:36,414:INFO:Initializing create_model()
2022-11-18 21:45:36,415:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085bceed0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa082580c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:36,415:INFO:Checking exceptions
2022-11-18 21:45:36,419:INFO:Importing libraries
2022-11-18 21:45:36,419:INFO:Copying training dataset
2022-11-18 21:45:36,424:INFO:Defining folds
2022-11-18 21:45:36,424:INFO:Declaring metric variables
2022-11-18 21:45:36,434:INFO:Importing untrained model
2022-11-18 21:45:36,446:INFO:Linear Regression Imported successfully
2022-11-18 21:45:36,463:INFO:Starting cross validation
2022-11-18 21:45:36,468:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:38,223:INFO:Calculating mean and std
2022-11-18 21:45:38,227:INFO:Creating metrics dataframe
2022-11-18 21:45:38,244:INFO:Uploading results into container
2022-11-18 21:45:38,245:INFO:Uploading model into container now
2022-11-18 21:45:38,245:INFO:master_model_container: 1
2022-11-18 21:45:38,246:INFO:display_container: 2
2022-11-18 21:45:38,246:INFO:LinearRegression(n_jobs=-1)
2022-11-18 21:45:38,246:INFO:create_model() successfully completed......................................
2022-11-18 21:45:38,445:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:38,445:INFO:Creating metrics dataframe
2022-11-18 21:45:38,469:INFO:Initializing Lasso Regression
2022-11-18 21:45:38,469:INFO:Total runtime is 0.03444337050120036 minutes
2022-11-18 21:45:38,480:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:38,481:INFO:Initializing create_model()
2022-11-18 21:45:38,481:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085bceed0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa082580c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:38,481:INFO:Checking exceptions
2022-11-18 21:45:38,485:INFO:Importing libraries
2022-11-18 21:45:38,485:INFO:Copying training dataset
2022-11-18 21:45:38,494:INFO:Defining folds
2022-11-18 21:45:38,495:INFO:Declaring metric variables
2022-11-18 21:45:38,505:INFO:Importing untrained model
2022-11-18 21:45:38,515:INFO:Lasso Regression Imported successfully
2022-11-18 21:45:38,536:INFO:Starting cross validation
2022-11-18 21:45:38,538:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:38,879:INFO:Calculating mean and std
2022-11-18 21:45:38,883:INFO:Creating metrics dataframe
2022-11-18 21:45:38,904:INFO:Uploading results into container
2022-11-18 21:45:38,905:INFO:Uploading model into container now
2022-11-18 21:45:38,906:INFO:master_model_container: 2
2022-11-18 21:45:38,907:INFO:display_container: 2
2022-11-18 21:45:38,908:INFO:Lasso(random_state=123)
2022-11-18 21:45:38,908:INFO:create_model() successfully completed......................................
2022-11-18 21:45:39,098:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:39,098:INFO:Creating metrics dataframe
2022-11-18 21:45:39,120:INFO:Initializing Ridge Regression
2022-11-18 21:45:39,121:INFO:Total runtime is 0.04530313014984131 minutes
2022-11-18 21:45:39,130:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:39,131:INFO:Initializing create_model()
2022-11-18 21:45:39,132:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085bceed0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa082580c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:39,132:INFO:Checking exceptions
2022-11-18 21:45:39,135:INFO:Importing libraries
2022-11-18 21:45:39,135:INFO:Copying training dataset
2022-11-18 21:45:39,141:INFO:Defining folds
2022-11-18 21:45:39,142:INFO:Declaring metric variables
2022-11-18 21:45:39,154:INFO:Importing untrained model
2022-11-18 21:45:39,170:INFO:Ridge Regression Imported successfully
2022-11-18 21:45:39,190:INFO:Starting cross validation
2022-11-18 21:45:39,192:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:39,240:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.03719e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:45:39,267:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.05541e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:45:39,309:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.04032e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:45:39,346:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.0964e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:45:39,392:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.07071e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:45:39,431:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.02164e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:45:39,446:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.08942e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:45:39,478:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.05414e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:45:39,507:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.05338e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:45:39,519:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.04893e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-11-18 21:45:39,535:INFO:Calculating mean and std
2022-11-18 21:45:39,539:INFO:Creating metrics dataframe
2022-11-18 21:45:39,556:INFO:Uploading results into container
2022-11-18 21:45:39,558:INFO:Uploading model into container now
2022-11-18 21:45:39,558:INFO:master_model_container: 3
2022-11-18 21:45:39,558:INFO:display_container: 2
2022-11-18 21:45:39,559:INFO:Ridge(random_state=123)
2022-11-18 21:45:39,559:INFO:create_model() successfully completed......................................
2022-11-18 21:45:39,743:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:39,744:INFO:Creating metrics dataframe
2022-11-18 21:45:39,772:INFO:Initializing Elastic Net
2022-11-18 21:45:39,776:INFO:Total runtime is 0.056217281023661296 minutes
2022-11-18 21:45:39,785:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:39,786:INFO:Initializing create_model()
2022-11-18 21:45:39,787:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085bceed0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa082580c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:39,787:INFO:Checking exceptions
2022-11-18 21:45:39,790:INFO:Importing libraries
2022-11-18 21:45:39,790:INFO:Copying training dataset
2022-11-18 21:45:39,797:INFO:Defining folds
2022-11-18 21:45:39,797:INFO:Declaring metric variables
2022-11-18 21:45:39,814:INFO:Importing untrained model
2022-11-18 21:45:39,828:INFO:Elastic Net Imported successfully
2022-11-18 21:45:39,847:INFO:Starting cross validation
2022-11-18 21:45:39,853:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:40,176:INFO:Calculating mean and std
2022-11-18 21:45:40,179:INFO:Creating metrics dataframe
2022-11-18 21:45:40,185:INFO:Uploading results into container
2022-11-18 21:45:40,186:INFO:Uploading model into container now
2022-11-18 21:45:40,187:INFO:master_model_container: 4
2022-11-18 21:45:40,187:INFO:display_container: 2
2022-11-18 21:45:40,188:INFO:ElasticNet(random_state=123)
2022-11-18 21:45:40,188:INFO:create_model() successfully completed......................................
2022-11-18 21:45:40,372:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:40,373:INFO:Creating metrics dataframe
2022-11-18 21:45:40,412:INFO:Initializing Least Angle Regression
2022-11-18 21:45:40,413:INFO:Total runtime is 0.06683170398076375 minutes
2022-11-18 21:45:40,422:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:40,424:INFO:Initializing create_model()
2022-11-18 21:45:40,424:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085bceed0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa082580c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:40,425:INFO:Checking exceptions
2022-11-18 21:45:40,427:INFO:Importing libraries
2022-11-18 21:45:40,428:INFO:Copying training dataset
2022-11-18 21:45:40,433:INFO:Defining folds
2022-11-18 21:45:40,434:INFO:Declaring metric variables
2022-11-18 21:45:40,445:INFO:Importing untrained model
2022-11-18 21:45:40,458:INFO:Least Angle Regression Imported successfully
2022-11-18 21:45:40,476:INFO:Starting cross validation
2022-11-18 21:45:40,478:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:40,527:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:40,555:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:40,593:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:40,634:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:40,694:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:40,708:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:40,746:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:40,753:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:40,794:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:40,801:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:40,827:INFO:Calculating mean and std
2022-11-18 21:45:40,832:INFO:Creating metrics dataframe
2022-11-18 21:45:40,845:INFO:Uploading results into container
2022-11-18 21:45:40,846:INFO:Uploading model into container now
2022-11-18 21:45:40,848:INFO:master_model_container: 5
2022-11-18 21:45:40,848:INFO:display_container: 2
2022-11-18 21:45:40,849:INFO:Lars(random_state=123)
2022-11-18 21:45:40,849:INFO:create_model() successfully completed......................................
2022-11-18 21:45:41,036:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:41,037:INFO:Creating metrics dataframe
2022-11-18 21:45:41,059:INFO:Initializing Lasso Least Angle Regression
2022-11-18 21:45:41,061:INFO:Total runtime is 0.07764238516489665 minutes
2022-11-18 21:45:41,070:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:41,076:INFO:Initializing create_model()
2022-11-18 21:45:41,076:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085bceed0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa082580c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:41,076:INFO:Checking exceptions
2022-11-18 21:45:41,078:INFO:Importing libraries
2022-11-18 21:45:41,079:INFO:Copying training dataset
2022-11-18 21:45:41,085:INFO:Defining folds
2022-11-18 21:45:41,085:INFO:Declaring metric variables
2022-11-18 21:45:41,094:INFO:Importing untrained model
2022-11-18 21:45:41,104:INFO:Lasso Least Angle Regression Imported successfully
2022-11-18 21:45:41,122:INFO:Starting cross validation
2022-11-18 21:45:41,124:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:41,179:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:45:41,203:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:45:41,246:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:45:41,296:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:45:41,333:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:45:41,373:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:45:41,394:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:45:41,442:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:45:41,453:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:45:41,482:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:45:41,496:INFO:Calculating mean and std
2022-11-18 21:45:41,500:INFO:Creating metrics dataframe
2022-11-18 21:45:41,518:INFO:Uploading results into container
2022-11-18 21:45:41,520:INFO:Uploading model into container now
2022-11-18 21:45:41,520:INFO:master_model_container: 6
2022-11-18 21:45:41,521:INFO:display_container: 2
2022-11-18 21:45:41,521:INFO:LassoLars(random_state=123)
2022-11-18 21:45:41,521:INFO:create_model() successfully completed......................................
2022-11-18 21:45:41,710:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:41,710:INFO:Creating metrics dataframe
2022-11-18 21:45:41,736:INFO:Initializing Orthogonal Matching Pursuit
2022-11-18 21:45:41,743:INFO:Total runtime is 0.08900227944056192 minutes
2022-11-18 21:45:41,755:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:41,756:INFO:Initializing create_model()
2022-11-18 21:45:41,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085bceed0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa082580c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:41,756:INFO:Checking exceptions
2022-11-18 21:45:41,759:INFO:Importing libraries
2022-11-18 21:45:41,760:INFO:Copying training dataset
2022-11-18 21:45:41,767:INFO:Defining folds
2022-11-18 21:45:41,768:INFO:Declaring metric variables
2022-11-18 21:45:41,780:INFO:Importing untrained model
2022-11-18 21:45:41,795:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-18 21:45:41,820:INFO:Starting cross validation
2022-11-18 21:45:41,824:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:41,867:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:41,897:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:41,929:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:41,970:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:42,007:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:42,044:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:42,047:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:42,084:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:42,112:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:42,126:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:45:42,144:INFO:Calculating mean and std
2022-11-18 21:45:42,146:INFO:Creating metrics dataframe
2022-11-18 21:45:42,156:INFO:Uploading results into container
2022-11-18 21:45:42,159:INFO:Uploading model into container now
2022-11-18 21:45:42,159:INFO:master_model_container: 7
2022-11-18 21:45:42,160:INFO:display_container: 2
2022-11-18 21:45:42,162:INFO:OrthogonalMatchingPursuit()
2022-11-18 21:45:42,163:INFO:create_model() successfully completed......................................
2022-11-18 21:45:42,352:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:42,352:INFO:Creating metrics dataframe
2022-11-18 21:45:42,373:INFO:Initializing Bayesian Ridge
2022-11-18 21:45:42,373:INFO:Total runtime is 0.09951133728027343 minutes
2022-11-18 21:45:42,382:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:42,388:INFO:Initializing create_model()
2022-11-18 21:45:42,389:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085bceed0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa082580c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:42,389:INFO:Checking exceptions
2022-11-18 21:45:42,392:INFO:Importing libraries
2022-11-18 21:45:42,392:INFO:Copying training dataset
2022-11-18 21:45:42,398:INFO:Defining folds
2022-11-18 21:45:42,398:INFO:Declaring metric variables
2022-11-18 21:45:42,411:INFO:Importing untrained model
2022-11-18 21:45:42,423:INFO:Bayesian Ridge Imported successfully
2022-11-18 21:45:42,442:INFO:Starting cross validation
2022-11-18 21:45:42,445:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:42,799:INFO:Calculating mean and std
2022-11-18 21:45:42,803:INFO:Creating metrics dataframe
2022-11-18 21:45:42,818:INFO:Uploading results into container
2022-11-18 21:45:42,821:INFO:Uploading model into container now
2022-11-18 21:45:42,822:INFO:master_model_container: 8
2022-11-18 21:45:42,822:INFO:display_container: 2
2022-11-18 21:45:42,822:INFO:BayesianRidge()
2022-11-18 21:45:42,823:INFO:create_model() successfully completed......................................
2022-11-18 21:45:43,013:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:43,013:INFO:Creating metrics dataframe
2022-11-18 21:45:43,039:INFO:Initializing Passive Aggressive Regressor
2022-11-18 21:45:43,040:INFO:Total runtime is 0.11061472495396932 minutes
2022-11-18 21:45:43,052:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:43,052:INFO:Initializing create_model()
2022-11-18 21:45:43,053:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085bceed0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa082580c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:43,053:INFO:Checking exceptions
2022-11-18 21:45:43,059:INFO:Importing libraries
2022-11-18 21:45:43,060:INFO:Copying training dataset
2022-11-18 21:45:43,065:INFO:Defining folds
2022-11-18 21:45:43,066:INFO:Declaring metric variables
2022-11-18 21:45:43,090:INFO:Importing untrained model
2022-11-18 21:45:43,100:INFO:Passive Aggressive Regressor Imported successfully
2022-11-18 21:45:43,117:INFO:Starting cross validation
2022-11-18 21:45:43,120:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:43,446:INFO:Calculating mean and std
2022-11-18 21:45:43,451:INFO:Creating metrics dataframe
2022-11-18 21:45:43,462:INFO:Uploading results into container
2022-11-18 21:45:43,463:INFO:Uploading model into container now
2022-11-18 21:45:43,465:INFO:master_model_container: 9
2022-11-18 21:45:43,465:INFO:display_container: 2
2022-11-18 21:45:43,466:INFO:PassiveAggressiveRegressor(random_state=123)
2022-11-18 21:45:43,466:INFO:create_model() successfully completed......................................
2022-11-18 21:45:43,698:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:43,698:INFO:Creating metrics dataframe
2022-11-18 21:45:43,724:INFO:Initializing Huber Regressor
2022-11-18 21:45:43,725:INFO:Total runtime is 0.12203114032745362 minutes
2022-11-18 21:45:43,745:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:43,746:INFO:Initializing create_model()
2022-11-18 21:45:43,746:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085bceed0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa082580c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:43,746:INFO:Checking exceptions
2022-11-18 21:45:43,749:INFO:Importing libraries
2022-11-18 21:45:43,749:INFO:Copying training dataset
2022-11-18 21:45:43,756:INFO:Defining folds
2022-11-18 21:45:43,757:INFO:Declaring metric variables
2022-11-18 21:45:43,772:INFO:Importing untrained model
2022-11-18 21:45:43,786:INFO:Huber Regressor Imported successfully
2022-11-18 21:45:43,805:INFO:Starting cross validation
2022-11-18 21:45:43,807:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:43,932:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:45:43,957:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:45:44,049:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:45:44,087:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:45:44,186:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:45:44,199:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:45:44,279:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:45:44,295:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:45:44,375:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:45:44,390:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:45:44,406:INFO:Calculating mean and std
2022-11-18 21:45:44,409:INFO:Creating metrics dataframe
2022-11-18 21:45:44,415:INFO:Uploading results into container
2022-11-18 21:45:44,416:INFO:Uploading model into container now
2022-11-18 21:45:44,417:INFO:master_model_container: 10
2022-11-18 21:45:44,417:INFO:display_container: 2
2022-11-18 21:45:44,418:INFO:HuberRegressor()
2022-11-18 21:45:44,419:INFO:create_model() successfully completed......................................
2022-11-18 21:45:44,617:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:44,619:INFO:Creating metrics dataframe
2022-11-18 21:45:44,649:INFO:Initializing K Neighbors Regressor
2022-11-18 21:45:44,650:INFO:Total runtime is 0.13745613098144532 minutes
2022-11-18 21:45:44,668:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:44,670:INFO:Initializing create_model()
2022-11-18 21:45:44,670:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085bceed0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa082580c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:44,671:INFO:Checking exceptions
2022-11-18 21:45:44,675:INFO:Importing libraries
2022-11-18 21:45:44,675:INFO:Copying training dataset
2022-11-18 21:45:44,680:INFO:Defining folds
2022-11-18 21:45:44,684:INFO:Declaring metric variables
2022-11-18 21:45:44,698:INFO:Importing untrained model
2022-11-18 21:45:44,709:INFO:K Neighbors Regressor Imported successfully
2022-11-18 21:45:44,730:INFO:Starting cross validation
2022-11-18 21:45:44,733:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:45,494:INFO:Calculating mean and std
2022-11-18 21:45:45,497:INFO:Creating metrics dataframe
2022-11-18 21:45:45,503:INFO:Uploading results into container
2022-11-18 21:45:45,504:INFO:Uploading model into container now
2022-11-18 21:45:45,505:INFO:master_model_container: 11
2022-11-18 21:45:45,506:INFO:display_container: 2
2022-11-18 21:45:45,507:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-18 21:45:45,507:INFO:create_model() successfully completed......................................
2022-11-18 21:45:45,719:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:45,720:INFO:Creating metrics dataframe
2022-11-18 21:45:45,745:INFO:Initializing Decision Tree Regressor
2022-11-18 21:45:45,746:INFO:Total runtime is 0.1557225545247396 minutes
2022-11-18 21:45:45,756:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:45,757:INFO:Initializing create_model()
2022-11-18 21:45:45,757:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085bceed0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa082580c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:45,757:INFO:Checking exceptions
2022-11-18 21:45:45,762:INFO:Importing libraries
2022-11-18 21:45:45,762:INFO:Copying training dataset
2022-11-18 21:45:45,771:INFO:Defining folds
2022-11-18 21:45:45,772:INFO:Declaring metric variables
2022-11-18 21:45:45,784:INFO:Importing untrained model
2022-11-18 21:45:45,796:INFO:Decision Tree Regressor Imported successfully
2022-11-18 21:45:45,819:INFO:Starting cross validation
2022-11-18 21:45:45,827:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:46,211:INFO:Calculating mean and std
2022-11-18 21:45:46,214:INFO:Creating metrics dataframe
2022-11-18 21:45:46,232:INFO:Uploading results into container
2022-11-18 21:45:46,233:INFO:Uploading model into container now
2022-11-18 21:45:46,234:INFO:master_model_container: 12
2022-11-18 21:45:46,235:INFO:display_container: 2
2022-11-18 21:45:46,235:INFO:DecisionTreeRegressor(random_state=123)
2022-11-18 21:45:46,235:INFO:create_model() successfully completed......................................
2022-11-18 21:45:46,427:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:46,428:INFO:Creating metrics dataframe
2022-11-18 21:45:46,451:INFO:Initializing Random Forest Regressor
2022-11-18 21:45:46,451:INFO:Total runtime is 0.16747576395670574 minutes
2022-11-18 21:45:46,461:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:46,462:INFO:Initializing create_model()
2022-11-18 21:45:46,462:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085bceed0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa082580c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:46,462:INFO:Checking exceptions
2022-11-18 21:45:46,466:INFO:Importing libraries
2022-11-18 21:45:46,466:INFO:Copying training dataset
2022-11-18 21:45:46,475:INFO:Defining folds
2022-11-18 21:45:46,475:INFO:Declaring metric variables
2022-11-18 21:45:46,486:INFO:Importing untrained model
2022-11-18 21:45:46,498:INFO:Random Forest Regressor Imported successfully
2022-11-18 21:45:46,518:INFO:Starting cross validation
2022-11-18 21:45:46,520:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:51,731:INFO:Calculating mean and std
2022-11-18 21:45:51,738:INFO:Creating metrics dataframe
2022-11-18 21:45:51,752:INFO:Uploading results into container
2022-11-18 21:45:51,753:INFO:Uploading model into container now
2022-11-18 21:45:51,753:INFO:master_model_container: 13
2022-11-18 21:45:51,754:INFO:display_container: 2
2022-11-18 21:45:51,754:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-18 21:45:51,754:INFO:create_model() successfully completed......................................
2022-11-18 21:45:51,949:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:51,950:INFO:Creating metrics dataframe
2022-11-18 21:45:51,974:INFO:Initializing Extra Trees Regressor
2022-11-18 21:45:51,974:INFO:Total runtime is 0.2595291097958883 minutes
2022-11-18 21:45:51,994:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:51,995:INFO:Initializing create_model()
2022-11-18 21:45:51,996:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085bceed0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa082580c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:51,996:INFO:Checking exceptions
2022-11-18 21:45:51,999:INFO:Importing libraries
2022-11-18 21:45:51,999:INFO:Copying training dataset
2022-11-18 21:45:52,005:INFO:Defining folds
2022-11-18 21:45:52,007:INFO:Declaring metric variables
2022-11-18 21:45:52,018:INFO:Importing untrained model
2022-11-18 21:45:52,028:INFO:Extra Trees Regressor Imported successfully
2022-11-18 21:45:52,044:INFO:Starting cross validation
2022-11-18 21:45:52,046:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:55,134:INFO:Calculating mean and std
2022-11-18 21:45:55,139:INFO:Creating metrics dataframe
2022-11-18 21:45:55,153:INFO:Uploading results into container
2022-11-18 21:45:55,155:INFO:Uploading model into container now
2022-11-18 21:45:55,156:INFO:master_model_container: 14
2022-11-18 21:45:55,157:INFO:display_container: 2
2022-11-18 21:45:55,157:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-18 21:45:55,158:INFO:create_model() successfully completed......................................
2022-11-18 21:45:55,345:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:55,346:INFO:Creating metrics dataframe
2022-11-18 21:45:55,369:INFO:Initializing AdaBoost Regressor
2022-11-18 21:45:55,370:INFO:Total runtime is 0.316124693552653 minutes
2022-11-18 21:45:55,381:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:55,382:INFO:Initializing create_model()
2022-11-18 21:45:55,382:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085bceed0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa082580c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:55,382:INFO:Checking exceptions
2022-11-18 21:45:55,385:INFO:Importing libraries
2022-11-18 21:45:55,386:INFO:Copying training dataset
2022-11-18 21:45:55,394:INFO:Defining folds
2022-11-18 21:45:55,394:INFO:Declaring metric variables
2022-11-18 21:45:55,406:INFO:Importing untrained model
2022-11-18 21:45:55,417:INFO:AdaBoost Regressor Imported successfully
2022-11-18 21:45:55,436:INFO:Starting cross validation
2022-11-18 21:45:55,439:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:56,676:INFO:Calculating mean and std
2022-11-18 21:45:56,679:INFO:Creating metrics dataframe
2022-11-18 21:45:56,691:INFO:Uploading results into container
2022-11-18 21:45:56,692:INFO:Uploading model into container now
2022-11-18 21:45:56,693:INFO:master_model_container: 15
2022-11-18 21:45:56,693:INFO:display_container: 2
2022-11-18 21:45:56,694:INFO:AdaBoostRegressor(random_state=123)
2022-11-18 21:45:56,694:INFO:create_model() successfully completed......................................
2022-11-18 21:45:56,887:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:56,887:INFO:Creating metrics dataframe
2022-11-18 21:45:56,917:INFO:Initializing Gradient Boosting Regressor
2022-11-18 21:45:56,917:INFO:Total runtime is 0.34190849860509237 minutes
2022-11-18 21:45:56,925:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:56,927:INFO:Initializing create_model()
2022-11-18 21:45:56,932:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085bceed0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa082580c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:56,932:INFO:Checking exceptions
2022-11-18 21:45:56,936:INFO:Importing libraries
2022-11-18 21:45:56,938:INFO:Copying training dataset
2022-11-18 21:45:56,952:INFO:Defining folds
2022-11-18 21:45:56,952:INFO:Declaring metric variables
2022-11-18 21:45:56,967:INFO:Importing untrained model
2022-11-18 21:45:56,983:INFO:Gradient Boosting Regressor Imported successfully
2022-11-18 21:45:57,001:INFO:Starting cross validation
2022-11-18 21:45:57,003:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:45:58,957:INFO:Calculating mean and std
2022-11-18 21:45:58,963:INFO:Creating metrics dataframe
2022-11-18 21:45:58,976:INFO:Uploading results into container
2022-11-18 21:45:58,977:INFO:Uploading model into container now
2022-11-18 21:45:58,978:INFO:master_model_container: 16
2022-11-18 21:45:58,978:INFO:display_container: 2
2022-11-18 21:45:58,979:INFO:GradientBoostingRegressor(random_state=123)
2022-11-18 21:45:58,979:INFO:create_model() successfully completed......................................
2022-11-18 21:45:59,176:INFO:SubProcess create_model() end ==================================
2022-11-18 21:45:59,176:INFO:Creating metrics dataframe
2022-11-18 21:45:59,201:INFO:Initializing Light Gradient Boosting Machine
2022-11-18 21:45:59,201:INFO:Total runtime is 0.3799781322479248 minutes
2022-11-18 21:45:59,213:INFO:SubProcess create_model() called ==================================
2022-11-18 21:45:59,214:INFO:Initializing create_model()
2022-11-18 21:45:59,215:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085bceed0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa082580c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:45:59,215:INFO:Checking exceptions
2022-11-18 21:45:59,222:INFO:Importing libraries
2022-11-18 21:45:59,222:INFO:Copying training dataset
2022-11-18 21:45:59,231:INFO:Defining folds
2022-11-18 21:45:59,234:INFO:Declaring metric variables
2022-11-18 21:45:59,249:INFO:Importing untrained model
2022-11-18 21:45:59,261:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-18 21:45:59,283:INFO:Starting cross validation
2022-11-18 21:45:59,285:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:46:00,238:INFO:Calculating mean and std
2022-11-18 21:46:00,241:INFO:Creating metrics dataframe
2022-11-18 21:46:00,259:INFO:Uploading results into container
2022-11-18 21:46:00,261:INFO:Uploading model into container now
2022-11-18 21:46:00,262:INFO:master_model_container: 17
2022-11-18 21:46:00,262:INFO:display_container: 2
2022-11-18 21:46:00,263:INFO:LGBMRegressor(random_state=123)
2022-11-18 21:46:00,263:INFO:create_model() successfully completed......................................
2022-11-18 21:46:00,451:INFO:SubProcess create_model() end ==================================
2022-11-18 21:46:00,451:INFO:Creating metrics dataframe
2022-11-18 21:46:00,481:INFO:Initializing Dummy Regressor
2022-11-18 21:46:00,481:INFO:Total runtime is 0.40130950609842936 minutes
2022-11-18 21:46:00,492:INFO:SubProcess create_model() called ==================================
2022-11-18 21:46:00,496:INFO:Initializing create_model()
2022-11-18 21:46:00,496:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085bceed0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa082580c90>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:46:00,497:INFO:Checking exceptions
2022-11-18 21:46:00,501:INFO:Importing libraries
2022-11-18 21:46:00,501:INFO:Copying training dataset
2022-11-18 21:46:00,506:INFO:Defining folds
2022-11-18 21:46:00,507:INFO:Declaring metric variables
2022-11-18 21:46:00,521:INFO:Importing untrained model
2022-11-18 21:46:00,532:INFO:Dummy Regressor Imported successfully
2022-11-18 21:46:00,552:INFO:Starting cross validation
2022-11-18 21:46:00,555:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:46:00,858:INFO:Calculating mean and std
2022-11-18 21:46:00,869:INFO:Creating metrics dataframe
2022-11-18 21:46:00,879:INFO:Uploading results into container
2022-11-18 21:46:00,881:INFO:Uploading model into container now
2022-11-18 21:46:00,881:INFO:master_model_container: 18
2022-11-18 21:46:00,882:INFO:display_container: 2
2022-11-18 21:46:00,882:INFO:DummyRegressor()
2022-11-18 21:46:00,882:INFO:create_model() successfully completed......................................
2022-11-18 21:46:01,078:INFO:SubProcess create_model() end ==================================
2022-11-18 21:46:01,080:INFO:Creating metrics dataframe
2022-11-18 21:46:01,135:INFO:Initializing create_model()
2022-11-18 21:46:01,141:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa085bceed0>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:46:01,141:INFO:Checking exceptions
2022-11-18 21:46:01,148:INFO:Importing libraries
2022-11-18 21:46:01,149:INFO:Copying training dataset
2022-11-18 21:46:01,154:INFO:Defining folds
2022-11-18 21:46:01,155:INFO:Declaring metric variables
2022-11-18 21:46:01,156:INFO:Importing untrained model
2022-11-18 21:46:01,157:INFO:Declaring custom model
2022-11-18 21:46:01,158:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-18 21:46:01,160:INFO:Cross validation set to False
2022-11-18 21:46:01,160:INFO:Fitting Model
2022-11-18 21:46:01,198:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:46:01,202:INFO:OrthogonalMatchingPursuit()
2022-11-18 21:46:01,202:INFO:create_model() successfully completed......................................
2022-11-18 21:46:01,499:INFO:master_model_container: 18
2022-11-18 21:46:01,500:INFO:display_container: 2
2022-11-18 21:46:01,501:INFO:OrthogonalMatchingPursuit()
2022-11-18 21:46:01,501:INFO:compare_models() successfully completed......................................
2022-11-18 21:46:07,928:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  app.launch_new_instance()

2022-11-18 21:46:07,929:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:46:07,930:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:46:07,931:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:46:07,933:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:46:07,934:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:46:07,935:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:46:07,936:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:46:07,937:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:46:07,938:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:46:07,939:WARNING:/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy

2022-11-18 21:46:07,945:INFO:PyCaret RegressionExperiment
2022-11-18 21:46:07,945:INFO:Logging name: FullData
2022-11-18 21:46:07,945:INFO:ML Usecase: MLUsecase.REGRESSION
2022-11-18 21:46:07,946:INFO:version 3.0.0.rc4
2022-11-18 21:46:07,946:INFO:Initializing setup()
2022-11-18 21:46:07,946:INFO:self.USI: 50fc
2022-11-18 21:46:07,946:INFO:self.variable_keys: {'_available_plots', 'seed', 'log_plots_param', '_gpu_n_jobs_param', 'USI', 'pipeline', '_all_models_internal', 'fold_generator', 'variable_keys', 'gpu_param', 'exp_id', 'X_test', 'memory', '_ml_usecase', 'y', 'fold_groups_param', 'transform_target_method_param', 'display_container', 'logging_param', '_all_metrics', 'fold_shuffle_param', 'n_jobs_param', 'exp_name_log', 'data', 'y_test', 'html_param', 'target_param', 'transform_target_param', '_all_models', 'y_train', 'X_train', 'X', 'master_model_container', 'idx'}
2022-11-18 21:46:07,946:INFO:Checking environment
2022-11-18 21:46:07,946:INFO:python_version: 3.7.15
2022-11-18 21:46:07,947:INFO:python_build: ('default', 'Oct 12 2022 19:14:55')
2022-11-18 21:46:07,947:INFO:machine: x86_64
2022-11-18 21:46:07,947:INFO:platform: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-18 21:46:07,947:INFO:Memory: svmem(total=13616353280, available=11457261568, percent=15.9, used=2075930624, free=9084592128, active=984821760, inactive=3221917696, buffers=171196416, cached=2284634112, shared=1327104, slab=226332672)
2022-11-18 21:46:07,948:INFO:Physical Core: 1
2022-11-18 21:46:07,948:INFO:Logical Core: 2
2022-11-18 21:46:07,948:INFO:Checking libraries
2022-11-18 21:46:07,948:INFO:System:
2022-11-18 21:46:07,949:INFO:    python: 3.7.15 (default, Oct 12 2022, 19:14:55)  [GCC 7.5.0]
2022-11-18 21:46:07,949:INFO:executable: /usr/bin/python3
2022-11-18 21:46:07,949:INFO:   machine: Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic
2022-11-18 21:46:07,949:INFO:PyCaret required dependencies:
2022-11-18 21:46:07,949:INFO:                 pip: 21.1.3
2022-11-18 21:46:07,949:INFO:          setuptools: 57.4.0
2022-11-18 21:46:07,950:INFO:             pycaret: 3.0.0rc4
2022-11-18 21:46:07,950:INFO:             IPython: 7.9.0
2022-11-18 21:46:07,950:INFO:          ipywidgets: 7.7.1
2022-11-18 21:46:07,950:INFO:                tqdm: 4.64.1
2022-11-18 21:46:07,950:INFO:               numpy: 1.21.6
2022-11-18 21:46:07,950:INFO:              pandas: 1.3.5
2022-11-18 21:46:07,950:INFO:              jinja2: 3.0.0
2022-11-18 21:46:07,951:INFO:               scipy: 1.7.3
2022-11-18 21:46:07,951:INFO:              joblib: 1.2.0
2022-11-18 21:46:07,951:INFO:             sklearn: 1.0.2
2022-11-18 21:46:07,951:INFO:                pyod: 1.0.6
2022-11-18 21:46:07,951:INFO:            imblearn: 0.8.1
2022-11-18 21:46:07,951:INFO:   category_encoders: 2.5.1.post0
2022-11-18 21:46:07,951:INFO:            lightgbm: 3.3.3
2022-11-18 21:46:07,952:INFO:               numba: 0.55.2
2022-11-18 21:46:07,952:INFO:            requests: 2.28.1
2022-11-18 21:46:07,952:INFO:          matplotlib: 3.5.3
2022-11-18 21:46:07,952:INFO:          scikitplot: 0.3.7
2022-11-18 21:46:07,952:INFO:         yellowbrick: 1.5
2022-11-18 21:46:07,952:INFO:              plotly: 5.5.0
2022-11-18 21:46:07,952:INFO:             kaleido: 0.2.1
2022-11-18 21:46:07,952:INFO:         statsmodels: 0.12.2
2022-11-18 21:46:07,953:INFO:              sktime: 0.13.4
2022-11-18 21:46:07,953:INFO:               tbats: 1.1.1
2022-11-18 21:46:07,953:INFO:            pmdarima: 1.8.5
2022-11-18 21:46:07,953:INFO:              psutil: 5.9.4
2022-11-18 21:46:07,953:INFO:PyCaret optional dependencies:
2022-11-18 21:46:07,953:INFO:                shap: Not installed
2022-11-18 21:46:07,953:INFO:           interpret: Not installed
2022-11-18 21:46:07,954:INFO:                umap: Not installed
2022-11-18 21:46:07,954:INFO:    pandas_profiling: 1.4.1
2022-11-18 21:46:07,954:INFO:  explainerdashboard: Not installed
2022-11-18 21:46:07,954:INFO:             autoviz: Not installed
2022-11-18 21:46:07,954:INFO:           fairlearn: Not installed
2022-11-18 21:46:07,954:INFO:             xgboost: 0.90
2022-11-18 21:46:07,954:INFO:            catboost: Not installed
2022-11-18 21:46:07,955:INFO:              kmodes: Not installed
2022-11-18 21:46:07,955:INFO:             mlxtend: 0.14.0
2022-11-18 21:46:07,955:INFO:       statsforecast: Not installed
2022-11-18 21:46:07,955:INFO:        tune_sklearn: Not installed
2022-11-18 21:46:07,955:INFO:                 ray: Not installed
2022-11-18 21:46:07,955:INFO:            hyperopt: 0.1.2
2022-11-18 21:46:07,955:INFO:              optuna: Not installed
2022-11-18 21:46:07,956:INFO:               skopt: Not installed
2022-11-18 21:46:07,956:INFO:              mlflow: Not installed
2022-11-18 21:46:07,956:INFO:              gradio: Not installed
2022-11-18 21:46:07,956:INFO:             fastapi: Not installed
2022-11-18 21:46:07,956:INFO:             uvicorn: Not installed
2022-11-18 21:46:07,956:INFO:              m2cgen: Not installed
2022-11-18 21:46:07,956:INFO:           evidently: Not installed
2022-11-18 21:46:07,957:INFO:                nltk: 3.7
2022-11-18 21:46:07,957:INFO:            pyLDAvis: Not installed
2022-11-18 21:46:07,957:INFO:              gensim: 3.6.0
2022-11-18 21:46:07,957:INFO:               spacy: 3.4.2
2022-11-18 21:46:07,957:INFO:           wordcloud: 1.8.2.2
2022-11-18 21:46:07,957:INFO:            textblob: 0.15.3
2022-11-18 21:46:07,957:INFO:               fugue: Not installed
2022-11-18 21:46:07,957:INFO:           streamlit: Not installed
2022-11-18 21:46:07,958:INFO:             prophet: 1.1.1
2022-11-18 21:46:07,958:INFO:None
2022-11-18 21:46:07,958:INFO:Set up data.
2022-11-18 21:46:07,967:INFO:Set up train/test split.
2022-11-18 21:46:07,971:INFO:Set up index.
2022-11-18 21:46:07,971:INFO:Set up folding strategy.
2022-11-18 21:46:07,972:INFO:Assigning column types.
2022-11-18 21:46:07,978:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-11-18 21:46:07,979:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-18 21:46:07,984:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:46:07,991:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:46:08,063:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:46:08,127:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:46:08,128:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:46:08,128:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:46:08,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:46:08,130:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-11-18 21:46:08,135:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:46:08,141:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:46:08,215:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:46:08,282:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:46:08,283:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:46:08,284:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:46:08,284:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:46:08,284:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-11-18 21:46:08,290:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:46:08,296:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:46:08,368:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:46:08,423:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:46:08,425:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:46:08,425:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:46:08,426:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:46:08,432:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-11-18 21:46:08,438:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:46:08,516:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:46:08,573:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:46:08,575:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:46:08,575:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:46:08,576:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:46:08,576:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-11-18 21:46:08,588:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:46:08,661:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:46:08,717:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:46:08,718:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:46:08,719:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:46:08,719:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:46:08,731:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-11-18 21:46:08,806:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:46:08,863:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:46:08,868:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:46:08,869:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:46:08,869:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:46:08,870:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-11-18 21:46:08,976:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:46:09,033:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:46:09,034:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:46:09,035:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:46:09,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:46:09,120:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:46:09,177:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-11-18 21:46:09,178:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:46:09,178:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:46:09,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:46:09,179:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-11-18 21:46:09,268:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:46:09,335:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:46:09,336:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:46:09,336:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:46:09,419:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-11-18 21:46:09,476:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:46:09,476:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:46:09,477:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:46:09,477:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-11-18 21:46:09,620:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:46:09,620:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:46:09,621:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:46:09,767:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:46:09,768:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:46:09,769:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:46:09,771:INFO:Preparing preprocessing pipeline...
2022-11-18 21:46:09,773:INFO:Set up simple imputation.
2022-11-18 21:46:09,774:INFO:Set up variance threshold.
2022-11-18 21:46:09,825:INFO:Finished creating preprocessing pipeline.
2022-11-18 21:46:09,831:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO',
                                             'Open_Line_ML_x'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-11-18 21:46:09,832:INFO:Creating final display dataframe.
2022-11-18 21:46:10,038:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape   (1229, 13)
4         Train data shape    (860, 13)
5          Test data shape    (369, 13)
6         Numeric features           12
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         50fc
2022-11-18 21:46:10,207:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:46:10,208:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:46:10,209:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:46:10,365:INFO:Soft dependency imported: xgboost: 0.90
2022-11-18 21:46:10,366:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-11-18 21:46:10,366:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-11-18 21:46:10,375:INFO:setup() successfully completed in 2.43s...............
2022-11-18 21:46:10,375:INFO:Initializing compare_models()
2022-11-18 21:46:10,376:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825e9b10>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fa0825e9b10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-11-18 21:46:10,376:INFO:Checking exceptions
2022-11-18 21:46:10,378:INFO:Preparing display monitor
2022-11-18 21:46:10,480:INFO:Initializing Linear Regression
2022-11-18 21:46:10,480:INFO:Total runtime is 7.633368174235026e-06 minutes
2022-11-18 21:46:10,490:INFO:SubProcess create_model() called ==================================
2022-11-18 21:46:10,491:INFO:Initializing create_model()
2022-11-18 21:46:10,492:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825e9b10>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0825e2f50>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:46:10,492:INFO:Checking exceptions
2022-11-18 21:46:10,495:INFO:Importing libraries
2022-11-18 21:46:10,496:INFO:Copying training dataset
2022-11-18 21:46:10,501:INFO:Defining folds
2022-11-18 21:46:10,501:INFO:Declaring metric variables
2022-11-18 21:46:10,512:INFO:Importing untrained model
2022-11-18 21:46:10,522:INFO:Linear Regression Imported successfully
2022-11-18 21:46:10,549:INFO:Starting cross validation
2022-11-18 21:46:10,554:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:46:12,298:INFO:Calculating mean and std
2022-11-18 21:46:12,303:INFO:Creating metrics dataframe
2022-11-18 21:46:12,322:INFO:Uploading results into container
2022-11-18 21:46:12,323:INFO:Uploading model into container now
2022-11-18 21:46:12,324:INFO:master_model_container: 1
2022-11-18 21:46:12,325:INFO:display_container: 2
2022-11-18 21:46:12,325:INFO:LinearRegression(n_jobs=-1)
2022-11-18 21:46:12,325:INFO:create_model() successfully completed......................................
2022-11-18 21:46:12,530:INFO:SubProcess create_model() end ==================================
2022-11-18 21:46:12,531:INFO:Creating metrics dataframe
2022-11-18 21:46:12,554:INFO:Initializing Lasso Regression
2022-11-18 21:46:12,555:INFO:Total runtime is 0.034584081172943114 minutes
2022-11-18 21:46:12,575:INFO:SubProcess create_model() called ==================================
2022-11-18 21:46:12,584:INFO:Initializing create_model()
2022-11-18 21:46:12,585:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825e9b10>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0825e2f50>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:46:12,585:INFO:Checking exceptions
2022-11-18 21:46:12,588:INFO:Importing libraries
2022-11-18 21:46:12,589:INFO:Copying training dataset
2022-11-18 21:46:12,594:INFO:Defining folds
2022-11-18 21:46:12,596:INFO:Declaring metric variables
2022-11-18 21:46:12,609:INFO:Importing untrained model
2022-11-18 21:46:12,624:INFO:Lasso Regression Imported successfully
2022-11-18 21:46:12,643:INFO:Starting cross validation
2022-11-18 21:46:12,653:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:46:12,998:INFO:Calculating mean and std
2022-11-18 21:46:13,001:INFO:Creating metrics dataframe
2022-11-18 21:46:13,008:INFO:Uploading results into container
2022-11-18 21:46:13,012:INFO:Uploading model into container now
2022-11-18 21:46:13,015:INFO:master_model_container: 2
2022-11-18 21:46:13,019:INFO:display_container: 2
2022-11-18 21:46:13,020:INFO:Lasso(random_state=123)
2022-11-18 21:46:13,020:INFO:create_model() successfully completed......................................
2022-11-18 21:46:13,219:INFO:SubProcess create_model() end ==================================
2022-11-18 21:46:13,220:INFO:Creating metrics dataframe
2022-11-18 21:46:13,241:INFO:Initializing Ridge Regression
2022-11-18 21:46:13,242:INFO:Total runtime is 0.046031574408213295 minutes
2022-11-18 21:46:13,251:INFO:SubProcess create_model() called ==================================
2022-11-18 21:46:13,252:INFO:Initializing create_model()
2022-11-18 21:46:13,252:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825e9b10>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0825e2f50>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:46:13,252:INFO:Checking exceptions
2022-11-18 21:46:13,255:INFO:Importing libraries
2022-11-18 21:46:13,256:INFO:Copying training dataset
2022-11-18 21:46:13,262:INFO:Defining folds
2022-11-18 21:46:13,263:INFO:Declaring metric variables
2022-11-18 21:46:13,276:INFO:Importing untrained model
2022-11-18 21:46:13,288:INFO:Ridge Regression Imported successfully
2022-11-18 21:46:13,307:INFO:Starting cross validation
2022-11-18 21:46:13,309:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:46:13,671:INFO:Calculating mean and std
2022-11-18 21:46:13,674:INFO:Creating metrics dataframe
2022-11-18 21:46:13,697:INFO:Uploading results into container
2022-11-18 21:46:13,700:INFO:Uploading model into container now
2022-11-18 21:46:13,703:INFO:master_model_container: 3
2022-11-18 21:46:13,704:INFO:display_container: 2
2022-11-18 21:46:13,705:INFO:Ridge(random_state=123)
2022-11-18 21:46:13,705:INFO:create_model() successfully completed......................................
2022-11-18 21:46:13,913:INFO:SubProcess create_model() end ==================================
2022-11-18 21:46:13,914:INFO:Creating metrics dataframe
2022-11-18 21:46:13,941:INFO:Initializing Elastic Net
2022-11-18 21:46:13,942:INFO:Total runtime is 0.05770407120386759 minutes
2022-11-18 21:46:13,952:INFO:SubProcess create_model() called ==================================
2022-11-18 21:46:13,953:INFO:Initializing create_model()
2022-11-18 21:46:13,953:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825e9b10>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0825e2f50>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:46:13,954:INFO:Checking exceptions
2022-11-18 21:46:13,958:INFO:Importing libraries
2022-11-18 21:46:13,958:INFO:Copying training dataset
2022-11-18 21:46:13,967:INFO:Defining folds
2022-11-18 21:46:13,967:INFO:Declaring metric variables
2022-11-18 21:46:13,984:INFO:Importing untrained model
2022-11-18 21:46:14,043:INFO:Elastic Net Imported successfully
2022-11-18 21:46:14,120:INFO:Starting cross validation
2022-11-18 21:46:14,122:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:46:15,232:INFO:Calculating mean and std
2022-11-18 21:46:15,249:INFO:Creating metrics dataframe
2022-11-18 21:46:15,266:INFO:Uploading results into container
2022-11-18 21:46:15,274:INFO:Uploading model into container now
2022-11-18 21:46:15,275:INFO:master_model_container: 4
2022-11-18 21:46:15,276:INFO:display_container: 2
2022-11-18 21:46:15,277:INFO:ElasticNet(random_state=123)
2022-11-18 21:46:15,281:INFO:create_model() successfully completed......................................
2022-11-18 21:46:15,590:INFO:SubProcess create_model() end ==================================
2022-11-18 21:46:15,590:INFO:Creating metrics dataframe
2022-11-18 21:46:15,616:INFO:Initializing Least Angle Regression
2022-11-18 21:46:15,625:INFO:Total runtime is 0.08574667374293009 minutes
2022-11-18 21:46:15,636:INFO:SubProcess create_model() called ==================================
2022-11-18 21:46:15,637:INFO:Initializing create_model()
2022-11-18 21:46:15,637:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825e9b10>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0825e2f50>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:46:15,637:INFO:Checking exceptions
2022-11-18 21:46:15,641:INFO:Importing libraries
2022-11-18 21:46:15,641:INFO:Copying training dataset
2022-11-18 21:46:15,648:INFO:Defining folds
2022-11-18 21:46:15,649:INFO:Declaring metric variables
2022-11-18 21:46:15,663:INFO:Importing untrained model
2022-11-18 21:46:15,677:INFO:Least Angle Regression Imported successfully
2022-11-18 21:46:15,697:INFO:Starting cross validation
2022-11-18 21:46:15,702:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:46:15,758:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:46:15,787:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:46:15,835:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:46:15,891:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:46:16,023:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:46:16,055:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:46:16,178:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:46:16,263:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:46:16,345:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:46:16,443:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:46:16,541:INFO:Calculating mean and std
2022-11-18 21:46:16,548:INFO:Creating metrics dataframe
2022-11-18 21:46:16,596:INFO:Uploading results into container
2022-11-18 21:46:16,601:INFO:Uploading model into container now
2022-11-18 21:46:16,612:INFO:master_model_container: 5
2022-11-18 21:46:16,612:INFO:display_container: 2
2022-11-18 21:46:16,613:INFO:Lars(random_state=123)
2022-11-18 21:46:16,616:INFO:create_model() successfully completed......................................
2022-11-18 21:46:17,185:INFO:SubProcess create_model() end ==================================
2022-11-18 21:46:17,185:INFO:Creating metrics dataframe
2022-11-18 21:46:17,206:INFO:Initializing Lasso Least Angle Regression
2022-11-18 21:46:17,207:INFO:Total runtime is 0.11211950778961181 minutes
2022-11-18 21:46:17,219:INFO:SubProcess create_model() called ==================================
2022-11-18 21:46:17,220:INFO:Initializing create_model()
2022-11-18 21:46:17,221:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825e9b10>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0825e2f50>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:46:17,221:INFO:Checking exceptions
2022-11-18 21:46:17,225:INFO:Importing libraries
2022-11-18 21:46:17,225:INFO:Copying training dataset
2022-11-18 21:46:17,231:INFO:Defining folds
2022-11-18 21:46:17,233:INFO:Declaring metric variables
2022-11-18 21:46:17,244:INFO:Importing untrained model
2022-11-18 21:46:17,256:INFO:Lasso Least Angle Regression Imported successfully
2022-11-18 21:46:17,277:INFO:Starting cross validation
2022-11-18 21:46:17,279:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:46:17,335:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:46:17,368:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:46:17,407:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:46:17,438:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:46:17,474:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:46:17,515:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:46:17,527:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:46:17,586:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:46:17,600:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:46:17,627:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:46:17,641:INFO:Calculating mean and std
2022-11-18 21:46:17,645:INFO:Creating metrics dataframe
2022-11-18 21:46:17,660:INFO:Uploading results into container
2022-11-18 21:46:17,663:INFO:Uploading model into container now
2022-11-18 21:46:17,663:INFO:master_model_container: 6
2022-11-18 21:46:17,664:INFO:display_container: 2
2022-11-18 21:46:17,664:INFO:LassoLars(random_state=123)
2022-11-18 21:46:17,665:INFO:create_model() successfully completed......................................
2022-11-18 21:46:17,850:INFO:SubProcess create_model() end ==================================
2022-11-18 21:46:17,851:INFO:Creating metrics dataframe
2022-11-18 21:46:17,878:INFO:Initializing Orthogonal Matching Pursuit
2022-11-18 21:46:17,878:INFO:Total runtime is 0.12330923080444335 minutes
2022-11-18 21:46:17,891:INFO:SubProcess create_model() called ==================================
2022-11-18 21:46:17,892:INFO:Initializing create_model()
2022-11-18 21:46:17,893:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825e9b10>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0825e2f50>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:46:17,893:INFO:Checking exceptions
2022-11-18 21:46:17,896:INFO:Importing libraries
2022-11-18 21:46:17,897:INFO:Copying training dataset
2022-11-18 21:46:17,903:INFO:Defining folds
2022-11-18 21:46:17,906:INFO:Declaring metric variables
2022-11-18 21:46:17,925:INFO:Importing untrained model
2022-11-18 21:46:17,940:INFO:Orthogonal Matching Pursuit Imported successfully
2022-11-18 21:46:17,960:INFO:Starting cross validation
2022-11-18 21:46:17,962:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:46:18,008:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:46:18,038:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:46:18,081:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:46:18,118:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:46:18,157:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:46:18,205:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:46:18,208:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:46:18,251:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:46:18,272:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:46:18,297:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  FutureWarning,

2022-11-18 21:46:18,312:INFO:Calculating mean and std
2022-11-18 21:46:18,318:INFO:Creating metrics dataframe
2022-11-18 21:46:18,330:INFO:Uploading results into container
2022-11-18 21:46:18,331:INFO:Uploading model into container now
2022-11-18 21:46:18,333:INFO:master_model_container: 7
2022-11-18 21:46:18,333:INFO:display_container: 2
2022-11-18 21:46:18,333:INFO:OrthogonalMatchingPursuit()
2022-11-18 21:46:18,334:INFO:create_model() successfully completed......................................
2022-11-18 21:46:18,522:INFO:SubProcess create_model() end ==================================
2022-11-18 21:46:18,523:INFO:Creating metrics dataframe
2022-11-18 21:46:18,549:INFO:Initializing Bayesian Ridge
2022-11-18 21:46:18,550:INFO:Total runtime is 0.13450329303741454 minutes
2022-11-18 21:46:18,561:INFO:SubProcess create_model() called ==================================
2022-11-18 21:46:18,562:INFO:Initializing create_model()
2022-11-18 21:46:18,562:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825e9b10>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0825e2f50>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:46:18,562:INFO:Checking exceptions
2022-11-18 21:46:18,568:INFO:Importing libraries
2022-11-18 21:46:18,568:INFO:Copying training dataset
2022-11-18 21:46:18,585:INFO:Defining folds
2022-11-18 21:46:18,586:INFO:Declaring metric variables
2022-11-18 21:46:18,600:INFO:Importing untrained model
2022-11-18 21:46:18,612:INFO:Bayesian Ridge Imported successfully
2022-11-18 21:46:18,633:INFO:Starting cross validation
2022-11-18 21:46:18,636:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:46:18,982:INFO:Calculating mean and std
2022-11-18 21:46:18,989:INFO:Creating metrics dataframe
2022-11-18 21:46:19,001:INFO:Uploading results into container
2022-11-18 21:46:19,002:INFO:Uploading model into container now
2022-11-18 21:46:19,003:INFO:master_model_container: 8
2022-11-18 21:46:19,003:INFO:display_container: 2
2022-11-18 21:46:19,005:INFO:BayesianRidge()
2022-11-18 21:46:19,005:INFO:create_model() successfully completed......................................
2022-11-18 21:46:19,190:INFO:SubProcess create_model() end ==================================
2022-11-18 21:46:19,191:INFO:Creating metrics dataframe
2022-11-18 21:46:19,213:INFO:Initializing Passive Aggressive Regressor
2022-11-18 21:46:19,213:INFO:Total runtime is 0.14555895328521729 minutes
2022-11-18 21:46:19,224:INFO:SubProcess create_model() called ==================================
2022-11-18 21:46:19,225:INFO:Initializing create_model()
2022-11-18 21:46:19,225:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825e9b10>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0825e2f50>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:46:19,225:INFO:Checking exceptions
2022-11-18 21:46:19,230:INFO:Importing libraries
2022-11-18 21:46:19,230:INFO:Copying training dataset
2022-11-18 21:46:19,237:INFO:Defining folds
2022-11-18 21:46:19,238:INFO:Declaring metric variables
2022-11-18 21:46:19,249:INFO:Importing untrained model
2022-11-18 21:46:19,261:INFO:Passive Aggressive Regressor Imported successfully
2022-11-18 21:46:19,283:INFO:Starting cross validation
2022-11-18 21:46:19,285:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:46:19,650:INFO:Calculating mean and std
2022-11-18 21:46:19,652:INFO:Creating metrics dataframe
2022-11-18 21:46:19,667:INFO:Uploading results into container
2022-11-18 21:46:19,669:INFO:Uploading model into container now
2022-11-18 21:46:19,670:INFO:master_model_container: 9
2022-11-18 21:46:19,670:INFO:display_container: 2
2022-11-18 21:46:19,671:INFO:PassiveAggressiveRegressor(random_state=123)
2022-11-18 21:46:19,671:INFO:create_model() successfully completed......................................
2022-11-18 21:46:19,865:INFO:SubProcess create_model() end ==================================
2022-11-18 21:46:19,866:INFO:Creating metrics dataframe
2022-11-18 21:46:19,888:INFO:Initializing Huber Regressor
2022-11-18 21:46:19,889:INFO:Total runtime is 0.15682258208592734 minutes
2022-11-18 21:46:19,902:INFO:SubProcess create_model() called ==================================
2022-11-18 21:46:19,903:INFO:Initializing create_model()
2022-11-18 21:46:19,904:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825e9b10>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0825e2f50>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:46:19,905:INFO:Checking exceptions
2022-11-18 21:46:19,908:INFO:Importing libraries
2022-11-18 21:46:19,913:INFO:Copying training dataset
2022-11-18 21:46:19,921:INFO:Defining folds
2022-11-18 21:46:19,922:INFO:Declaring metric variables
2022-11-18 21:46:19,932:INFO:Importing untrained model
2022-11-18 21:46:19,945:INFO:Huber Regressor Imported successfully
2022-11-18 21:46:19,963:INFO:Starting cross validation
2022-11-18 21:46:19,965:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:46:20,082:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:46:20,157:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:46:20,200:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:46:20,276:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:46:20,327:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:46:20,400:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:46:20,452:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:46:20,502:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:46:20,558:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:46:20,593:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-11-18 21:46:20,606:INFO:Calculating mean and std
2022-11-18 21:46:20,612:INFO:Creating metrics dataframe
2022-11-18 21:46:20,625:INFO:Uploading results into container
2022-11-18 21:46:20,626:INFO:Uploading model into container now
2022-11-18 21:46:20,627:INFO:master_model_container: 10
2022-11-18 21:46:20,627:INFO:display_container: 2
2022-11-18 21:46:20,628:INFO:HuberRegressor()
2022-11-18 21:46:20,628:INFO:create_model() successfully completed......................................
2022-11-18 21:46:20,822:INFO:SubProcess create_model() end ==================================
2022-11-18 21:46:20,823:INFO:Creating metrics dataframe
2022-11-18 21:46:20,845:INFO:Initializing K Neighbors Regressor
2022-11-18 21:46:20,845:INFO:Total runtime is 0.17275612354278566 minutes
2022-11-18 21:46:20,858:INFO:SubProcess create_model() called ==================================
2022-11-18 21:46:20,860:INFO:Initializing create_model()
2022-11-18 21:46:20,862:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825e9b10>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0825e2f50>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:46:20,864:INFO:Checking exceptions
2022-11-18 21:46:20,867:INFO:Importing libraries
2022-11-18 21:46:20,868:INFO:Copying training dataset
2022-11-18 21:46:20,875:INFO:Defining folds
2022-11-18 21:46:20,875:INFO:Declaring metric variables
2022-11-18 21:46:20,885:INFO:Importing untrained model
2022-11-18 21:46:20,895:INFO:K Neighbors Regressor Imported successfully
2022-11-18 21:46:20,918:INFO:Starting cross validation
2022-11-18 21:46:20,921:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:46:21,698:INFO:Calculating mean and std
2022-11-18 21:46:21,702:INFO:Creating metrics dataframe
2022-11-18 21:46:21,715:INFO:Uploading results into container
2022-11-18 21:46:21,717:INFO:Uploading model into container now
2022-11-18 21:46:21,718:INFO:master_model_container: 11
2022-11-18 21:46:21,718:INFO:display_container: 2
2022-11-18 21:46:21,719:INFO:KNeighborsRegressor(n_jobs=-1)
2022-11-18 21:46:21,719:INFO:create_model() successfully completed......................................
2022-11-18 21:46:21,906:INFO:SubProcess create_model() end ==================================
2022-11-18 21:46:21,906:INFO:Creating metrics dataframe
2022-11-18 21:46:21,935:INFO:Initializing Decision Tree Regressor
2022-11-18 21:46:21,937:INFO:Total runtime is 0.19095083077748617 minutes
2022-11-18 21:46:21,946:INFO:SubProcess create_model() called ==================================
2022-11-18 21:46:21,947:INFO:Initializing create_model()
2022-11-18 21:46:21,947:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825e9b10>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0825e2f50>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:46:21,947:INFO:Checking exceptions
2022-11-18 21:46:21,950:INFO:Importing libraries
2022-11-18 21:46:21,950:INFO:Copying training dataset
2022-11-18 21:46:21,959:INFO:Defining folds
2022-11-18 21:46:21,959:INFO:Declaring metric variables
2022-11-18 21:46:21,969:INFO:Importing untrained model
2022-11-18 21:46:21,979:INFO:Decision Tree Regressor Imported successfully
2022-11-18 21:46:21,998:INFO:Starting cross validation
2022-11-18 21:46:22,000:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:46:22,436:INFO:Calculating mean and std
2022-11-18 21:46:22,440:INFO:Creating metrics dataframe
2022-11-18 21:46:22,453:INFO:Uploading results into container
2022-11-18 21:46:22,455:INFO:Uploading model into container now
2022-11-18 21:46:22,456:INFO:master_model_container: 12
2022-11-18 21:46:22,457:INFO:display_container: 2
2022-11-18 21:46:22,457:INFO:DecisionTreeRegressor(random_state=123)
2022-11-18 21:46:22,457:INFO:create_model() successfully completed......................................
2022-11-18 21:46:22,647:INFO:SubProcess create_model() end ==================================
2022-11-18 21:46:22,648:INFO:Creating metrics dataframe
2022-11-18 21:46:22,677:INFO:Initializing Random Forest Regressor
2022-11-18 21:46:22,678:INFO:Total runtime is 0.20329253673553468 minutes
2022-11-18 21:46:22,691:INFO:SubProcess create_model() called ==================================
2022-11-18 21:46:22,693:INFO:Initializing create_model()
2022-11-18 21:46:22,693:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825e9b10>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0825e2f50>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:46:22,694:INFO:Checking exceptions
2022-11-18 21:46:22,697:INFO:Importing libraries
2022-11-18 21:46:22,698:INFO:Copying training dataset
2022-11-18 21:46:22,709:INFO:Defining folds
2022-11-18 21:46:22,709:INFO:Declaring metric variables
2022-11-18 21:46:22,720:INFO:Importing untrained model
2022-11-18 21:46:22,735:INFO:Random Forest Regressor Imported successfully
2022-11-18 21:46:22,763:INFO:Starting cross validation
2022-11-18 21:46:22,766:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:46:29,445:INFO:Calculating mean and std
2022-11-18 21:46:29,451:INFO:Creating metrics dataframe
2022-11-18 21:46:29,468:INFO:Uploading results into container
2022-11-18 21:46:29,469:INFO:Uploading model into container now
2022-11-18 21:46:29,470:INFO:master_model_container: 13
2022-11-18 21:46:29,470:INFO:display_container: 2
2022-11-18 21:46:29,471:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-11-18 21:46:29,471:INFO:create_model() successfully completed......................................
2022-11-18 21:46:29,659:INFO:SubProcess create_model() end ==================================
2022-11-18 21:46:29,659:INFO:Creating metrics dataframe
2022-11-18 21:46:29,685:INFO:Initializing Extra Trees Regressor
2022-11-18 21:46:29,688:INFO:Total runtime is 0.32013794978459675 minutes
2022-11-18 21:46:29,700:INFO:SubProcess create_model() called ==================================
2022-11-18 21:46:29,701:INFO:Initializing create_model()
2022-11-18 21:46:29,704:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825e9b10>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0825e2f50>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:46:29,704:INFO:Checking exceptions
2022-11-18 21:46:29,708:INFO:Importing libraries
2022-11-18 21:46:29,711:INFO:Copying training dataset
2022-11-18 21:46:29,718:INFO:Defining folds
2022-11-18 21:46:29,719:INFO:Declaring metric variables
2022-11-18 21:46:29,728:INFO:Importing untrained model
2022-11-18 21:46:29,737:INFO:Extra Trees Regressor Imported successfully
2022-11-18 21:46:29,758:INFO:Starting cross validation
2022-11-18 21:46:29,760:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:46:33,398:INFO:Calculating mean and std
2022-11-18 21:46:33,405:INFO:Creating metrics dataframe
2022-11-18 21:46:33,419:INFO:Uploading results into container
2022-11-18 21:46:33,424:INFO:Uploading model into container now
2022-11-18 21:46:33,425:INFO:master_model_container: 14
2022-11-18 21:46:33,426:INFO:display_container: 2
2022-11-18 21:46:33,426:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-11-18 21:46:33,427:INFO:create_model() successfully completed......................................
2022-11-18 21:46:33,620:INFO:SubProcess create_model() end ==================================
2022-11-18 21:46:33,620:INFO:Creating metrics dataframe
2022-11-18 21:46:33,649:INFO:Initializing AdaBoost Regressor
2022-11-18 21:46:33,649:INFO:Total runtime is 0.3861607233683268 minutes
2022-11-18 21:46:33,671:INFO:SubProcess create_model() called ==================================
2022-11-18 21:46:33,673:INFO:Initializing create_model()
2022-11-18 21:46:33,673:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825e9b10>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0825e2f50>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:46:33,674:INFO:Checking exceptions
2022-11-18 21:46:33,677:INFO:Importing libraries
2022-11-18 21:46:33,680:INFO:Copying training dataset
2022-11-18 21:46:33,688:INFO:Defining folds
2022-11-18 21:46:33,689:INFO:Declaring metric variables
2022-11-18 21:46:33,710:INFO:Importing untrained model
2022-11-18 21:46:33,720:INFO:AdaBoost Regressor Imported successfully
2022-11-18 21:46:33,741:INFO:Starting cross validation
2022-11-18 21:46:33,747:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:46:34,821:INFO:Calculating mean and std
2022-11-18 21:46:34,824:INFO:Creating metrics dataframe
2022-11-18 21:46:34,834:INFO:Uploading results into container
2022-11-18 21:46:34,836:INFO:Uploading model into container now
2022-11-18 21:46:34,837:INFO:master_model_container: 15
2022-11-18 21:46:34,837:INFO:display_container: 2
2022-11-18 21:46:34,837:INFO:AdaBoostRegressor(random_state=123)
2022-11-18 21:46:34,838:INFO:create_model() successfully completed......................................
2022-11-18 21:46:35,028:INFO:SubProcess create_model() end ==================================
2022-11-18 21:46:35,029:INFO:Creating metrics dataframe
2022-11-18 21:46:35,052:INFO:Initializing Gradient Boosting Regressor
2022-11-18 21:46:35,053:INFO:Total runtime is 0.40955054362614945 minutes
2022-11-18 21:46:35,062:INFO:SubProcess create_model() called ==================================
2022-11-18 21:46:35,069:INFO:Initializing create_model()
2022-11-18 21:46:35,072:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825e9b10>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0825e2f50>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:46:35,072:INFO:Checking exceptions
2022-11-18 21:46:35,076:INFO:Importing libraries
2022-11-18 21:46:35,079:INFO:Copying training dataset
2022-11-18 21:46:35,089:INFO:Defining folds
2022-11-18 21:46:35,090:INFO:Declaring metric variables
2022-11-18 21:46:35,101:INFO:Importing untrained model
2022-11-18 21:46:35,114:INFO:Gradient Boosting Regressor Imported successfully
2022-11-18 21:46:35,134:INFO:Starting cross validation
2022-11-18 21:46:35,136:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:46:37,735:INFO:Calculating mean and std
2022-11-18 21:46:37,740:INFO:Creating metrics dataframe
2022-11-18 21:46:37,750:INFO:Uploading results into container
2022-11-18 21:46:37,752:INFO:Uploading model into container now
2022-11-18 21:46:37,753:INFO:master_model_container: 16
2022-11-18 21:46:37,753:INFO:display_container: 2
2022-11-18 21:46:37,755:INFO:GradientBoostingRegressor(random_state=123)
2022-11-18 21:46:37,756:INFO:create_model() successfully completed......................................
2022-11-18 21:46:37,946:INFO:SubProcess create_model() end ==================================
2022-11-18 21:46:37,947:INFO:Creating metrics dataframe
2022-11-18 21:46:37,972:INFO:Initializing Light Gradient Boosting Machine
2022-11-18 21:46:37,973:INFO:Total runtime is 0.4582234144210815 minutes
2022-11-18 21:46:37,984:INFO:SubProcess create_model() called ==================================
2022-11-18 21:46:37,985:INFO:Initializing create_model()
2022-11-18 21:46:37,986:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825e9b10>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0825e2f50>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:46:37,986:INFO:Checking exceptions
2022-11-18 21:46:37,989:INFO:Importing libraries
2022-11-18 21:46:37,989:INFO:Copying training dataset
2022-11-18 21:46:37,995:INFO:Defining folds
2022-11-18 21:46:37,996:INFO:Declaring metric variables
2022-11-18 21:46:38,010:INFO:Importing untrained model
2022-11-18 21:46:38,026:INFO:Light Gradient Boosting Machine Imported successfully
2022-11-18 21:46:38,047:INFO:Starting cross validation
2022-11-18 21:46:38,052:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:46:39,407:INFO:Calculating mean and std
2022-11-18 21:46:39,413:INFO:Creating metrics dataframe
2022-11-18 21:46:39,423:INFO:Uploading results into container
2022-11-18 21:46:39,424:INFO:Uploading model into container now
2022-11-18 21:46:39,425:INFO:master_model_container: 17
2022-11-18 21:46:39,426:INFO:display_container: 2
2022-11-18 21:46:39,427:INFO:LGBMRegressor(random_state=123)
2022-11-18 21:46:39,427:INFO:create_model() successfully completed......................................
2022-11-18 21:46:39,623:INFO:SubProcess create_model() end ==================================
2022-11-18 21:46:39,624:INFO:Creating metrics dataframe
2022-11-18 21:46:39,654:INFO:Initializing Dummy Regressor
2022-11-18 21:46:39,659:INFO:Total runtime is 0.4863147775332132 minutes
2022-11-18 21:46:39,674:INFO:SubProcess create_model() called ==================================
2022-11-18 21:46:39,677:INFO:Initializing create_model()
2022-11-18 21:46:39,678:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825e9b10>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fa0825e2f50>, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:46:39,678:INFO:Checking exceptions
2022-11-18 21:46:39,681:INFO:Importing libraries
2022-11-18 21:46:39,681:INFO:Copying training dataset
2022-11-18 21:46:39,689:INFO:Defining folds
2022-11-18 21:46:39,689:INFO:Declaring metric variables
2022-11-18 21:46:39,708:INFO:Importing untrained model
2022-11-18 21:46:39,721:INFO:Dummy Regressor Imported successfully
2022-11-18 21:46:39,741:INFO:Starting cross validation
2022-11-18 21:46:39,743:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-11-18 21:46:40,076:INFO:Calculating mean and std
2022-11-18 21:46:40,082:INFO:Creating metrics dataframe
2022-11-18 21:46:40,097:INFO:Uploading results into container
2022-11-18 21:46:40,098:INFO:Uploading model into container now
2022-11-18 21:46:40,099:INFO:master_model_container: 18
2022-11-18 21:46:40,099:INFO:display_container: 2
2022-11-18 21:46:40,099:INFO:DummyRegressor()
2022-11-18 21:46:40,099:INFO:create_model() successfully completed......................................
2022-11-18 21:46:40,296:INFO:SubProcess create_model() end ==================================
2022-11-18 21:46:40,296:INFO:Creating metrics dataframe
2022-11-18 21:46:40,361:INFO:Initializing create_model()
2022-11-18 21:46:40,362:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fa0825e9b10>, estimator=LassoLars(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-11-18 21:46:40,362:INFO:Checking exceptions
2022-11-18 21:46:40,370:INFO:Importing libraries
2022-11-18 21:46:40,371:INFO:Copying training dataset
2022-11-18 21:46:40,376:INFO:Defining folds
2022-11-18 21:46:40,376:INFO:Declaring metric variables
2022-11-18 21:46:40,377:INFO:Importing untrained model
2022-11-18 21:46:40,378:INFO:Declaring custom model
2022-11-18 21:46:40,380:INFO:Least Angle Regression Imported successfully
2022-11-18 21:46:40,384:INFO:Cross validation set to False
2022-11-18 21:46:40,384:INFO:Fitting Model
2022-11-18 21:46:40,430:WARNING:/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  FutureWarning,

2022-11-18 21:46:40,432:INFO:LassoLars(random_state=123)
2022-11-18 21:46:40,433:INFO:create_model() successfully completed......................................
2022-11-18 21:46:40,769:INFO:master_model_container: 18
2022-11-18 21:46:40,771:INFO:display_container: 2
2022-11-18 21:46:40,774:INFO:LassoLars(random_state=123)
2022-11-18 21:46:40,775:INFO:compare_models() successfully completed......................................
2022-12-01 02:32:03,571:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-12-01 02:32:03,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-12-01 02:32:03,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-12-01 02:32:03,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2022-12-01 02:32:05,221:INFO:Soft dependency imported: prophet: 1.1.1
2022-12-01 02:32:05,739:INFO:PyCaret RegressionExperiment
2022-12-01 02:32:05,740:INFO:Logging name: FullData
2022-12-01 02:32:05,740:INFO:ML Usecase: MLUsecase.REGRESSION
2022-12-01 02:32:05,740:INFO:version 3.0.0.rc4
2022-12-01 02:32:05,740:INFO:Initializing setup()
2022-12-01 02:32:05,740:INFO:self.USI: d734
2022-12-01 02:32:05,740:INFO:self.variable_keys: {'fold_shuffle_param', 'y_test', 'pipeline', 'data', 'X', 'exp_id', 'master_model_container', '_available_plots', '_all_metrics', '_ml_usecase', 'log_plots_param', '_all_models', 'logging_param', 'idx', 'html_param', 'display_container', 'USI', 'target_param', 'fold_generator', '_gpu_n_jobs_param', 'n_jobs_param', 'transform_target_method_param', 'exp_name_log', 'X_test', 'variable_keys', 'gpu_param', 'memory', 'y_train', 'transform_target_param', 'y', 'X_train', '_all_models_internal', 'fold_groups_param', 'seed'}
2022-12-01 02:32:05,740:INFO:Checking environment
2022-12-01 02:32:05,741:INFO:python_version: 3.8.15
2022-12-01 02:32:05,741:INFO:python_build: ('default', 'Oct 12 2022 19:14:39')
2022-12-01 02:32:05,741:INFO:machine: x86_64
2022-12-01 02:32:05,741:INFO:platform: Linux-5.10.133+-x86_64-with-glibc2.27
2022-12-01 02:32:05,741:INFO:Memory: svmem(total=13616361472, available=12122456064, percent=11.0, used=1274277888, free=5301329920, active=788713472, inactive=7124803584, buffers=421797888, cached=6618955776, shared=1208320, slab=308142080)
2022-12-01 02:32:05,743:INFO:Physical Core: 1
2022-12-01 02:32:05,743:INFO:Logical Core: 2
2022-12-01 02:32:05,743:INFO:Checking libraries
2022-12-01 02:32:05,743:INFO:System:
2022-12-01 02:32:05,743:INFO:    python: 3.8.15 (default, Oct 12 2022, 19:14:39)  [GCC 7.5.0]
2022-12-01 02:32:05,744:INFO:executable: /usr/bin/python3
2022-12-01 02:32:05,744:INFO:   machine: Linux-5.10.133+-x86_64-with-glibc2.27
2022-12-01 02:32:05,744:INFO:PyCaret required dependencies:
2022-12-01 02:32:05,744:INFO:                 pip: 21.1.3
2022-12-01 02:32:05,744:INFO:          setuptools: 57.4.0
2022-12-01 02:32:05,745:INFO:             pycaret: 3.0.0rc4
2022-12-01 02:32:05,745:INFO:             IPython: 7.9.0
2022-12-01 02:32:05,745:INFO:          ipywidgets: 7.7.1
2022-12-01 02:32:05,745:INFO:                tqdm: 4.64.1
2022-12-01 02:32:05,746:INFO:               numpy: 1.21.6
2022-12-01 02:32:05,746:INFO:              pandas: 1.3.5
2022-12-01 02:32:05,746:INFO:              jinja2: 3.0.0
2022-12-01 02:32:05,746:INFO:               scipy: 1.7.3
2022-12-01 02:32:05,746:INFO:              joblib: 1.2.0
2022-12-01 02:32:05,746:INFO:             sklearn: 1.0.2
2022-12-01 02:32:05,747:INFO:                pyod: 1.0.6
2022-12-01 02:32:05,747:INFO:            imblearn: 0.8.1
2022-12-01 02:32:05,747:INFO:   category_encoders: 2.5.1.post0
2022-12-01 02:32:05,747:INFO:            lightgbm: 3.3.3
2022-12-01 02:32:05,747:INFO:               numba: 0.55.2
2022-12-01 02:32:05,747:INFO:            requests: 2.28.1
2022-12-01 02:32:05,747:INFO:          matplotlib: 3.6.2
2022-12-01 02:32:05,748:INFO:          scikitplot: 0.3.7
2022-12-01 02:32:05,748:INFO:         yellowbrick: 1.5
2022-12-01 02:32:05,748:INFO:              plotly: 5.5.0
2022-12-01 02:32:05,748:INFO:             kaleido: 0.2.1
2022-12-01 02:32:05,748:INFO:         statsmodels: 0.12.2
2022-12-01 02:32:05,748:INFO:              sktime: 0.13.4
2022-12-01 02:32:05,748:INFO:               tbats: 1.1.1
2022-12-01 02:32:05,748:INFO:            pmdarima: 1.8.5
2022-12-01 02:32:05,749:INFO:              psutil: 5.9.4
2022-12-01 02:32:05,751:INFO:PyCaret optional dependencies:
2022-12-01 02:32:05,758:INFO:                shap: Not installed
2022-12-01 02:32:05,758:INFO:           interpret: Not installed
2022-12-01 02:32:05,759:INFO:                umap: Not installed
2022-12-01 02:32:05,759:INFO:    pandas_profiling: 1.4.1
2022-12-01 02:32:05,759:INFO:  explainerdashboard: Not installed
2022-12-01 02:32:05,759:INFO:             autoviz: Not installed
2022-12-01 02:32:05,759:INFO:           fairlearn: Not installed
2022-12-01 02:32:05,760:INFO:             xgboost: 0.90
2022-12-01 02:32:05,760:INFO:            catboost: Not installed
2022-12-01 02:32:05,760:INFO:              kmodes: Not installed
2022-12-01 02:32:05,760:INFO:             mlxtend: 0.14.0
2022-12-01 02:32:05,760:INFO:       statsforecast: Not installed
2022-12-01 02:32:05,760:INFO:        tune_sklearn: Not installed
2022-12-01 02:32:05,760:INFO:                 ray: Not installed
2022-12-01 02:32:05,761:INFO:            hyperopt: 0.1.2
2022-12-01 02:32:05,761:INFO:              optuna: Not installed
2022-12-01 02:32:05,761:INFO:               skopt: Not installed
2022-12-01 02:32:05,761:INFO:              mlflow: Not installed
2022-12-01 02:32:05,761:INFO:              gradio: Not installed
2022-12-01 02:32:05,761:INFO:             fastapi: Not installed
2022-12-01 02:32:05,762:INFO:             uvicorn: Not installed
2022-12-01 02:32:05,762:INFO:              m2cgen: Not installed
2022-12-01 02:32:05,762:INFO:           evidently: Not installed
2022-12-01 02:32:05,762:INFO:                nltk: 3.7
2022-12-01 02:32:05,762:INFO:            pyLDAvis: Not installed
2022-12-01 02:32:05,762:INFO:              gensim: 3.6.0
2022-12-01 02:32:05,763:INFO:               spacy: 3.4.3
2022-12-01 02:32:05,763:INFO:           wordcloud: 1.8.2.2
2022-12-01 02:32:05,763:INFO:            textblob: 0.15.3
2022-12-01 02:32:05,763:INFO:               fugue: Not installed
2022-12-01 02:32:05,763:INFO:           streamlit: Not installed
2022-12-01 02:32:05,763:INFO:             prophet: 1.1.1
2022-12-01 02:32:05,764:INFO:None
2022-12-01 02:32:05,764:INFO:Set up data.
2022-12-01 02:32:05,771:INFO:Set up train/test split.
2022-12-01 02:32:05,775:INFO:Set up index.
2022-12-01 02:32:05,775:INFO:Set up folding strategy.
2022-12-01 02:32:05,776:INFO:Assigning column types.
2022-12-01 02:32:05,782:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-12-01 02:32:05,782:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-01 02:32:05,787:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:32:05,793:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:32:05,858:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:32:05,911:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:32:05,912:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:32:05,912:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:32:06,039:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:32:06,039:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-01 02:32:06,045:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:32:06,050:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:32:06,117:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:32:06,167:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:32:06,168:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:32:06,169:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:32:06,169:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:32:06,170:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-12-01 02:32:06,175:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:32:06,180:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:32:06,246:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:32:06,296:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:32:06,297:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:32:06,298:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:32:06,298:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:32:06,304:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:32:06,309:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:32:06,377:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:32:06,427:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:32:06,429:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:32:06,429:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:32:06,429:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:32:06,429:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-12-01 02:32:06,440:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:32:06,505:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:32:06,565:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:32:06,569:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:32:06,569:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:32:06,569:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:32:06,580:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:32:06,643:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:32:06,693:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:32:06,694:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:32:06,694:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:32:06,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:32:06,695:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-12-01 02:32:06,770:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:32:06,821:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:32:06,821:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:32:06,822:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:32:06,822:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:32:06,897:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:32:06,947:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:32:06,948:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:32:06,948:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:32:06,949:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:32:06,949:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-12-01 02:32:07,056:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:32:07,104:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:32:07,104:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:32:07,105:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:32:07,175:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:32:07,223:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:32:07,223:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:32:07,223:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:32:07,224:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-12-01 02:32:07,344:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:32:07,345:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:32:07,345:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:32:07,464:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:32:07,464:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:32:07,465:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:32:07,466:INFO:Preparing preprocessing pipeline...
2022-12-01 02:32:07,467:INFO:Set up simple imputation.
2022-12-01 02:32:07,467:INFO:Set up variance threshold.
2022-12-01 02:32:07,509:INFO:Finished creating preprocessing pipeline.
2022-12-01 02:32:07,515:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO',
                                             'Open_Line_ML_x'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-12-01 02:32:07,516:INFO:Creating final display dataframe.
2022-12-01 02:32:07,680:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 13)
4         Train data shape    (607, 13)
5          Test data shape    (261, 13)
6         Numeric features           12
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         d734
2022-12-01 02:32:07,814:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:32:07,815:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:32:07,816:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:32:07,940:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:32:07,941:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:32:07,942:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:32:07,952:INFO:setup() successfully completed in 2.22s...............
2022-12-01 02:32:07,952:INFO:Initializing compare_models()
2022-12-01 02:32:07,952:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f499e9bd3d0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f499e9bd3d0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-12-01 02:32:07,952:INFO:Checking exceptions
2022-12-01 02:32:07,954:INFO:Preparing display monitor
2022-12-01 02:32:08,038:INFO:Initializing Linear Regression
2022-12-01 02:32:08,039:INFO:Total runtime is 3.165006637573242e-05 minutes
2022-12-01 02:32:08,046:INFO:SubProcess create_model() called ==================================
2022-12-01 02:32:08,047:INFO:Initializing create_model()
2022-12-01 02:32:08,047:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f499e9bd3d0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961904dc0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:32:08,049:INFO:Checking exceptions
2022-12-01 02:32:08,052:INFO:Importing libraries
2022-12-01 02:32:08,052:INFO:Copying training dataset
2022-12-01 02:32:08,055:INFO:Defining folds
2022-12-01 02:32:08,055:INFO:Declaring metric variables
2022-12-01 02:32:08,060:INFO:Importing untrained model
2022-12-01 02:32:08,068:INFO:Linear Regression Imported successfully
2022-12-01 02:32:08,079:INFO:Starting cross validation
2022-12-01 02:32:08,090:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:32:12,765:INFO:Calculating mean and std
2022-12-01 02:32:12,770:INFO:Creating metrics dataframe
2022-12-01 02:32:12,781:INFO:Uploading results into container
2022-12-01 02:32:12,782:INFO:Uploading model into container now
2022-12-01 02:32:12,783:INFO:master_model_container: 1
2022-12-01 02:32:12,783:INFO:display_container: 2
2022-12-01 02:32:12,783:INFO:LinearRegression(n_jobs=-1)
2022-12-01 02:32:12,784:INFO:create_model() successfully completed......................................
2022-12-01 02:32:12,928:INFO:SubProcess create_model() end ==================================
2022-12-01 02:32:12,929:INFO:Creating metrics dataframe
2022-12-01 02:32:12,952:INFO:Initializing Lasso Regression
2022-12-01 02:32:12,952:INFO:Total runtime is 0.081913956006368 minutes
2022-12-01 02:32:12,958:INFO:SubProcess create_model() called ==================================
2022-12-01 02:32:12,959:INFO:Initializing create_model()
2022-12-01 02:32:12,959:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f499e9bd3d0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961904dc0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:32:12,959:INFO:Checking exceptions
2022-12-01 02:32:12,961:INFO:Importing libraries
2022-12-01 02:32:12,962:INFO:Copying training dataset
2022-12-01 02:32:12,966:INFO:Defining folds
2022-12-01 02:32:12,967:INFO:Declaring metric variables
2022-12-01 02:32:12,976:INFO:Importing untrained model
2022-12-01 02:32:12,985:INFO:Lasso Regression Imported successfully
2022-12-01 02:32:13,003:INFO:Starting cross validation
2022-12-01 02:32:13,004:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:32:13,271:INFO:Calculating mean and std
2022-12-01 02:32:13,273:INFO:Creating metrics dataframe
2022-12-01 02:32:13,283:INFO:Uploading results into container
2022-12-01 02:32:13,284:INFO:Uploading model into container now
2022-12-01 02:32:13,285:INFO:master_model_container: 2
2022-12-01 02:32:13,285:INFO:display_container: 2
2022-12-01 02:32:13,285:INFO:Lasso(random_state=123)
2022-12-01 02:32:13,286:INFO:create_model() successfully completed......................................
2022-12-01 02:32:13,412:INFO:SubProcess create_model() end ==================================
2022-12-01 02:32:13,412:INFO:Creating metrics dataframe
2022-12-01 02:32:13,429:INFO:Initializing Ridge Regression
2022-12-01 02:32:13,430:INFO:Total runtime is 0.08986883958180746 minutes
2022-12-01 02:32:13,437:INFO:SubProcess create_model() called ==================================
2022-12-01 02:32:13,437:INFO:Initializing create_model()
2022-12-01 02:32:13,438:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f499e9bd3d0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961904dc0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:32:13,438:INFO:Checking exceptions
2022-12-01 02:32:13,442:INFO:Importing libraries
2022-12-01 02:32:13,442:INFO:Copying training dataset
2022-12-01 02:32:13,446:INFO:Defining folds
2022-12-01 02:32:13,447:INFO:Declaring metric variables
2022-12-01 02:32:13,456:INFO:Importing untrained model
2022-12-01 02:32:13,464:INFO:Ridge Regression Imported successfully
2022-12-01 02:32:13,482:INFO:Starting cross validation
2022-12-01 02:32:13,485:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:32:13,537:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.19612e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:32:13,540:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1832e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:32:13,578:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.25596e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:32:13,606:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.27134e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:32:13,631:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1563e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:32:13,665:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.30751e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:32:13,668:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.25177e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:32:13,703:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.19532e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:32:13,708:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1922e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:32:13,740:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.20778e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:32:13,753:INFO:Calculating mean and std
2022-12-01 02:32:13,755:INFO:Creating metrics dataframe
2022-12-01 02:32:13,769:INFO:Uploading results into container
2022-12-01 02:32:13,770:INFO:Uploading model into container now
2022-12-01 02:32:13,771:INFO:master_model_container: 3
2022-12-01 02:32:13,771:INFO:display_container: 2
2022-12-01 02:32:13,771:INFO:Ridge(random_state=123)
2022-12-01 02:32:13,771:INFO:create_model() successfully completed......................................
2022-12-01 02:32:13,897:INFO:SubProcess create_model() end ==================================
2022-12-01 02:32:13,899:INFO:Creating metrics dataframe
2022-12-01 02:32:13,917:INFO:Initializing Elastic Net
2022-12-01 02:32:13,918:INFO:Total runtime is 0.09800784190495809 minutes
2022-12-01 02:32:13,926:INFO:SubProcess create_model() called ==================================
2022-12-01 02:32:13,927:INFO:Initializing create_model()
2022-12-01 02:32:13,927:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f499e9bd3d0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961904dc0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:32:13,927:INFO:Checking exceptions
2022-12-01 02:32:13,930:INFO:Importing libraries
2022-12-01 02:32:13,930:INFO:Copying training dataset
2022-12-01 02:32:13,935:INFO:Defining folds
2022-12-01 02:32:13,936:INFO:Declaring metric variables
2022-12-01 02:32:13,946:INFO:Importing untrained model
2022-12-01 02:32:13,954:INFO:Elastic Net Imported successfully
2022-12-01 02:32:13,969:INFO:Starting cross validation
2022-12-01 02:32:13,976:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:32:14,227:INFO:Calculating mean and std
2022-12-01 02:32:14,230:INFO:Creating metrics dataframe
2022-12-01 02:32:14,244:INFO:Uploading results into container
2022-12-01 02:32:14,246:INFO:Uploading model into container now
2022-12-01 02:32:14,247:INFO:master_model_container: 4
2022-12-01 02:32:14,247:INFO:display_container: 2
2022-12-01 02:32:14,248:INFO:ElasticNet(random_state=123)
2022-12-01 02:32:14,248:INFO:create_model() successfully completed......................................
2022-12-01 02:32:14,372:INFO:SubProcess create_model() end ==================================
2022-12-01 02:32:14,372:INFO:Creating metrics dataframe
2022-12-01 02:32:14,390:INFO:Initializing Least Angle Regression
2022-12-01 02:32:14,390:INFO:Total runtime is 0.1058773676554362 minutes
2022-12-01 02:32:14,398:INFO:SubProcess create_model() called ==================================
2022-12-01 02:32:14,399:INFO:Initializing create_model()
2022-12-01 02:32:14,399:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f499e9bd3d0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961904dc0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:32:14,399:INFO:Checking exceptions
2022-12-01 02:32:14,402:INFO:Importing libraries
2022-12-01 02:32:14,403:INFO:Copying training dataset
2022-12-01 02:32:14,408:INFO:Defining folds
2022-12-01 02:32:14,411:INFO:Declaring metric variables
2022-12-01 02:32:14,419:INFO:Importing untrained model
2022-12-01 02:32:14,427:INFO:Least Angle Regression Imported successfully
2022-12-01 02:32:14,441:INFO:Starting cross validation
2022-12-01 02:32:14,443:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:32:14,483:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:32:14,511:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:32:14,536:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:32:14,587:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:32:14,597:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:32:14,630:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:32:14,651:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:32:14,671:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:32:14,690:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:32:14,711:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:32:14,724:INFO:Calculating mean and std
2022-12-01 02:32:14,726:INFO:Creating metrics dataframe
2022-12-01 02:32:14,734:INFO:Uploading results into container
2022-12-01 02:32:14,735:INFO:Uploading model into container now
2022-12-01 02:32:14,736:INFO:master_model_container: 5
2022-12-01 02:32:14,736:INFO:display_container: 2
2022-12-01 02:32:14,737:INFO:Lars(random_state=123)
2022-12-01 02:32:14,737:INFO:create_model() successfully completed......................................
2022-12-01 02:32:14,876:INFO:SubProcess create_model() end ==================================
2022-12-01 02:32:14,877:INFO:Creating metrics dataframe
2022-12-01 02:32:14,894:INFO:Initializing Lasso Least Angle Regression
2022-12-01 02:32:14,895:INFO:Total runtime is 0.11429396073023479 minutes
2022-12-01 02:32:14,902:INFO:SubProcess create_model() called ==================================
2022-12-01 02:32:14,903:INFO:Initializing create_model()
2022-12-01 02:32:14,903:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f499e9bd3d0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961904dc0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:32:14,903:INFO:Checking exceptions
2022-12-01 02:32:14,906:INFO:Importing libraries
2022-12-01 02:32:14,906:INFO:Copying training dataset
2022-12-01 02:32:14,911:INFO:Defining folds
2022-12-01 02:32:14,912:INFO:Declaring metric variables
2022-12-01 02:32:14,925:INFO:Importing untrained model
2022-12-01 02:32:14,934:INFO:Lasso Least Angle Regression Imported successfully
2022-12-01 02:32:14,948:INFO:Starting cross validation
2022-12-01 02:32:14,949:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:32:14,999:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:32:15,015:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:32:15,037:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:32:15,076:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:32:15,093:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:32:15,135:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:32:15,148:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:32:15,175:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:32:15,186:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:32:15,211:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:32:15,222:INFO:Calculating mean and std
2022-12-01 02:32:15,224:INFO:Creating metrics dataframe
2022-12-01 02:32:15,234:INFO:Uploading results into container
2022-12-01 02:32:15,235:INFO:Uploading model into container now
2022-12-01 02:32:15,236:INFO:master_model_container: 6
2022-12-01 02:32:15,236:INFO:display_container: 2
2022-12-01 02:32:15,236:INFO:LassoLars(random_state=123)
2022-12-01 02:32:15,237:INFO:create_model() successfully completed......................................
2022-12-01 02:32:15,367:INFO:SubProcess create_model() end ==================================
2022-12-01 02:32:15,367:INFO:Creating metrics dataframe
2022-12-01 02:32:15,386:INFO:Initializing Orthogonal Matching Pursuit
2022-12-01 02:32:15,387:INFO:Total runtime is 0.12249150276184083 minutes
2022-12-01 02:32:15,394:INFO:SubProcess create_model() called ==================================
2022-12-01 02:32:15,396:INFO:Initializing create_model()
2022-12-01 02:32:15,396:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f499e9bd3d0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961904dc0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:32:15,396:INFO:Checking exceptions
2022-12-01 02:32:15,399:INFO:Importing libraries
2022-12-01 02:32:15,399:INFO:Copying training dataset
2022-12-01 02:32:15,403:INFO:Defining folds
2022-12-01 02:32:15,404:INFO:Declaring metric variables
2022-12-01 02:32:15,413:INFO:Importing untrained model
2022-12-01 02:32:15,421:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-01 02:32:15,437:INFO:Starting cross validation
2022-12-01 02:32:15,441:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:32:15,472:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:32:15,508:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:32:15,515:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:32:15,560:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:32:15,597:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:32:15,604:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:32:15,634:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:32:15,644:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:32:15,673:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:32:15,681:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:32:15,698:INFO:Calculating mean and std
2022-12-01 02:32:15,700:INFO:Creating metrics dataframe
2022-12-01 02:32:15,708:INFO:Uploading results into container
2022-12-01 02:32:15,708:INFO:Uploading model into container now
2022-12-01 02:32:15,709:INFO:master_model_container: 7
2022-12-01 02:32:15,710:INFO:display_container: 2
2022-12-01 02:32:15,710:INFO:OrthogonalMatchingPursuit()
2022-12-01 02:32:15,712:INFO:create_model() successfully completed......................................
2022-12-01 02:32:15,850:INFO:SubProcess create_model() end ==================================
2022-12-01 02:32:15,850:INFO:Creating metrics dataframe
2022-12-01 02:32:15,869:INFO:Initializing Bayesian Ridge
2022-12-01 02:32:15,869:INFO:Total runtime is 0.13052587509155275 minutes
2022-12-01 02:32:15,879:INFO:SubProcess create_model() called ==================================
2022-12-01 02:32:15,882:INFO:Initializing create_model()
2022-12-01 02:32:15,882:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f499e9bd3d0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961904dc0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:32:15,882:INFO:Checking exceptions
2022-12-01 02:32:15,885:INFO:Importing libraries
2022-12-01 02:32:15,885:INFO:Copying training dataset
2022-12-01 02:32:15,891:INFO:Defining folds
2022-12-01 02:32:15,891:INFO:Declaring metric variables
2022-12-01 02:32:15,901:INFO:Importing untrained model
2022-12-01 02:32:15,909:INFO:Bayesian Ridge Imported successfully
2022-12-01 02:32:15,929:INFO:Starting cross validation
2022-12-01 02:32:15,931:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:32:16,179:INFO:Calculating mean and std
2022-12-01 02:32:16,181:INFO:Creating metrics dataframe
2022-12-01 02:32:16,188:INFO:Uploading results into container
2022-12-01 02:32:16,189:INFO:Uploading model into container now
2022-12-01 02:32:16,190:INFO:master_model_container: 8
2022-12-01 02:32:16,190:INFO:display_container: 2
2022-12-01 02:32:16,190:INFO:BayesianRidge()
2022-12-01 02:32:16,191:INFO:create_model() successfully completed......................................
2022-12-01 02:32:16,320:INFO:SubProcess create_model() end ==================================
2022-12-01 02:32:16,320:INFO:Creating metrics dataframe
2022-12-01 02:32:16,338:INFO:Initializing Passive Aggressive Regressor
2022-12-01 02:32:16,339:INFO:Total runtime is 0.13835224707921348 minutes
2022-12-01 02:32:16,346:INFO:SubProcess create_model() called ==================================
2022-12-01 02:32:16,347:INFO:Initializing create_model()
2022-12-01 02:32:16,347:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f499e9bd3d0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961904dc0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:32:16,347:INFO:Checking exceptions
2022-12-01 02:32:16,349:INFO:Importing libraries
2022-12-01 02:32:16,350:INFO:Copying training dataset
2022-12-01 02:32:16,355:INFO:Defining folds
2022-12-01 02:32:16,360:INFO:Declaring metric variables
2022-12-01 02:32:16,368:INFO:Importing untrained model
2022-12-01 02:32:16,375:INFO:Passive Aggressive Regressor Imported successfully
2022-12-01 02:32:16,388:INFO:Starting cross validation
2022-12-01 02:32:16,390:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:32:16,652:INFO:Calculating mean and std
2022-12-01 02:32:16,654:INFO:Creating metrics dataframe
2022-12-01 02:32:16,662:INFO:Uploading results into container
2022-12-01 02:32:16,663:INFO:Uploading model into container now
2022-12-01 02:32:16,664:INFO:master_model_container: 9
2022-12-01 02:32:16,664:INFO:display_container: 2
2022-12-01 02:32:16,665:INFO:PassiveAggressiveRegressor(random_state=123)
2022-12-01 02:32:16,665:INFO:create_model() successfully completed......................................
2022-12-01 02:32:16,795:INFO:SubProcess create_model() end ==================================
2022-12-01 02:32:16,795:INFO:Creating metrics dataframe
2022-12-01 02:32:16,819:INFO:Initializing Huber Regressor
2022-12-01 02:32:16,821:INFO:Total runtime is 0.14639775753021242 minutes
2022-12-01 02:32:16,828:INFO:SubProcess create_model() called ==================================
2022-12-01 02:32:16,829:INFO:Initializing create_model()
2022-12-01 02:32:16,829:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f499e9bd3d0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961904dc0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:32:16,829:INFO:Checking exceptions
2022-12-01 02:32:16,832:INFO:Importing libraries
2022-12-01 02:32:16,832:INFO:Copying training dataset
2022-12-01 02:32:16,837:INFO:Defining folds
2022-12-01 02:32:16,837:INFO:Declaring metric variables
2022-12-01 02:32:16,847:INFO:Importing untrained model
2022-12-01 02:32:16,856:INFO:Huber Regressor Imported successfully
2022-12-01 02:32:16,869:INFO:Starting cross validation
2022-12-01 02:32:16,871:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:32:16,959:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:32:17,007:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:32:17,070:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:32:17,112:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:32:17,200:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:32:17,245:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:32:17,299:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:32:17,332:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:32:17,385:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:32:17,414:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:32:17,425:INFO:Calculating mean and std
2022-12-01 02:32:17,427:INFO:Creating metrics dataframe
2022-12-01 02:32:17,437:INFO:Uploading results into container
2022-12-01 02:32:17,438:INFO:Uploading model into container now
2022-12-01 02:32:17,439:INFO:master_model_container: 10
2022-12-01 02:32:17,439:INFO:display_container: 2
2022-12-01 02:32:17,441:INFO:HuberRegressor()
2022-12-01 02:32:17,441:INFO:create_model() successfully completed......................................
2022-12-01 02:32:17,570:INFO:SubProcess create_model() end ==================================
2022-12-01 02:32:17,570:INFO:Creating metrics dataframe
2022-12-01 02:32:17,590:INFO:Initializing K Neighbors Regressor
2022-12-01 02:32:17,591:INFO:Total runtime is 0.1592181483904521 minutes
2022-12-01 02:32:17,600:INFO:SubProcess create_model() called ==================================
2022-12-01 02:32:17,600:INFO:Initializing create_model()
2022-12-01 02:32:17,601:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f499e9bd3d0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961904dc0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:32:17,601:INFO:Checking exceptions
2022-12-01 02:32:17,605:INFO:Importing libraries
2022-12-01 02:32:17,605:INFO:Copying training dataset
2022-12-01 02:32:17,611:INFO:Defining folds
2022-12-01 02:32:17,612:INFO:Declaring metric variables
2022-12-01 02:32:17,622:INFO:Importing untrained model
2022-12-01 02:32:17,629:INFO:K Neighbors Regressor Imported successfully
2022-12-01 02:32:17,644:INFO:Starting cross validation
2022-12-01 02:32:17,647:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:32:17,938:INFO:Calculating mean and std
2022-12-01 02:32:17,940:INFO:Creating metrics dataframe
2022-12-01 02:32:17,948:INFO:Uploading results into container
2022-12-01 02:32:17,948:INFO:Uploading model into container now
2022-12-01 02:32:17,949:INFO:master_model_container: 11
2022-12-01 02:32:17,949:INFO:display_container: 2
2022-12-01 02:32:17,950:INFO:KNeighborsRegressor(n_jobs=-1)
2022-12-01 02:32:17,950:INFO:create_model() successfully completed......................................
2022-12-01 02:32:18,078:INFO:SubProcess create_model() end ==================================
2022-12-01 02:32:18,079:INFO:Creating metrics dataframe
2022-12-01 02:32:18,105:INFO:Initializing Decision Tree Regressor
2022-12-01 02:32:18,106:INFO:Total runtime is 0.16780766646067305 minutes
2022-12-01 02:32:18,115:INFO:SubProcess create_model() called ==================================
2022-12-01 02:32:18,115:INFO:Initializing create_model()
2022-12-01 02:32:18,116:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f499e9bd3d0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961904dc0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:32:18,116:INFO:Checking exceptions
2022-12-01 02:32:18,119:INFO:Importing libraries
2022-12-01 02:32:18,119:INFO:Copying training dataset
2022-12-01 02:32:18,124:INFO:Defining folds
2022-12-01 02:32:18,124:INFO:Declaring metric variables
2022-12-01 02:32:18,134:INFO:Importing untrained model
2022-12-01 02:32:18,142:INFO:Decision Tree Regressor Imported successfully
2022-12-01 02:32:18,159:INFO:Starting cross validation
2022-12-01 02:32:18,161:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:32:18,460:INFO:Calculating mean and std
2022-12-01 02:32:18,463:INFO:Creating metrics dataframe
2022-12-01 02:32:18,473:INFO:Uploading results into container
2022-12-01 02:32:18,474:INFO:Uploading model into container now
2022-12-01 02:32:18,475:INFO:master_model_container: 12
2022-12-01 02:32:18,475:INFO:display_container: 2
2022-12-01 02:32:18,475:INFO:DecisionTreeRegressor(random_state=123)
2022-12-01 02:32:18,475:INFO:create_model() successfully completed......................................
2022-12-01 02:32:18,605:INFO:SubProcess create_model() end ==================================
2022-12-01 02:32:18,606:INFO:Creating metrics dataframe
2022-12-01 02:32:18,626:INFO:Initializing Random Forest Regressor
2022-12-01 02:32:18,629:INFO:Total runtime is 0.17653150161107384 minutes
2022-12-01 02:32:18,637:INFO:SubProcess create_model() called ==================================
2022-12-01 02:32:18,638:INFO:Initializing create_model()
2022-12-01 02:32:18,638:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f499e9bd3d0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961904dc0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:32:18,638:INFO:Checking exceptions
2022-12-01 02:32:18,641:INFO:Importing libraries
2022-12-01 02:32:18,641:INFO:Copying training dataset
2022-12-01 02:32:18,648:INFO:Defining folds
2022-12-01 02:32:18,648:INFO:Declaring metric variables
2022-12-01 02:32:18,658:INFO:Importing untrained model
2022-12-01 02:32:18,665:INFO:Random Forest Regressor Imported successfully
2022-12-01 02:32:18,679:INFO:Starting cross validation
2022-12-01 02:32:18,683:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:32:22,598:INFO:Calculating mean and std
2022-12-01 02:32:22,600:INFO:Creating metrics dataframe
2022-12-01 02:32:22,617:INFO:Uploading results into container
2022-12-01 02:32:22,620:INFO:Uploading model into container now
2022-12-01 02:32:22,621:INFO:master_model_container: 13
2022-12-01 02:32:22,621:INFO:display_container: 2
2022-12-01 02:32:22,621:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-12-01 02:32:22,622:INFO:create_model() successfully completed......................................
2022-12-01 02:32:22,750:INFO:SubProcess create_model() end ==================================
2022-12-01 02:32:22,750:INFO:Creating metrics dataframe
2022-12-01 02:32:22,774:INFO:Initializing Extra Trees Regressor
2022-12-01 02:32:22,774:INFO:Total runtime is 0.24561119476954146 minutes
2022-12-01 02:32:22,782:INFO:SubProcess create_model() called ==================================
2022-12-01 02:32:22,783:INFO:Initializing create_model()
2022-12-01 02:32:22,783:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f499e9bd3d0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961904dc0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:32:22,783:INFO:Checking exceptions
2022-12-01 02:32:22,786:INFO:Importing libraries
2022-12-01 02:32:22,787:INFO:Copying training dataset
2022-12-01 02:32:22,795:INFO:Defining folds
2022-12-01 02:32:22,796:INFO:Declaring metric variables
2022-12-01 02:32:22,804:INFO:Importing untrained model
2022-12-01 02:32:22,813:INFO:Extra Trees Regressor Imported successfully
2022-12-01 02:32:22,829:INFO:Starting cross validation
2022-12-01 02:32:22,831:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:32:24,854:INFO:Calculating mean and std
2022-12-01 02:32:24,857:INFO:Creating metrics dataframe
2022-12-01 02:32:24,870:INFO:Uploading results into container
2022-12-01 02:32:24,871:INFO:Uploading model into container now
2022-12-01 02:32:24,871:INFO:master_model_container: 14
2022-12-01 02:32:24,871:INFO:display_container: 2
2022-12-01 02:32:24,872:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-12-01 02:32:24,872:INFO:create_model() successfully completed......................................
2022-12-01 02:32:24,995:INFO:SubProcess create_model() end ==================================
2022-12-01 02:32:24,995:INFO:Creating metrics dataframe
2022-12-01 02:32:25,013:INFO:Initializing AdaBoost Regressor
2022-12-01 02:32:25,014:INFO:Total runtime is 0.28293722073237104 minutes
2022-12-01 02:32:25,022:INFO:SubProcess create_model() called ==================================
2022-12-01 02:32:25,023:INFO:Initializing create_model()
2022-12-01 02:32:25,024:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f499e9bd3d0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961904dc0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:32:25,024:INFO:Checking exceptions
2022-12-01 02:32:25,027:INFO:Importing libraries
2022-12-01 02:32:25,027:INFO:Copying training dataset
2022-12-01 02:32:25,036:INFO:Defining folds
2022-12-01 02:32:25,039:INFO:Declaring metric variables
2022-12-01 02:32:25,049:INFO:Importing untrained model
2022-12-01 02:32:25,057:INFO:AdaBoost Regressor Imported successfully
2022-12-01 02:32:25,073:INFO:Starting cross validation
2022-12-01 02:32:25,082:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:32:26,220:INFO:Calculating mean and std
2022-12-01 02:32:26,222:INFO:Creating metrics dataframe
2022-12-01 02:32:26,233:INFO:Uploading results into container
2022-12-01 02:32:26,235:INFO:Uploading model into container now
2022-12-01 02:32:26,237:INFO:master_model_container: 15
2022-12-01 02:32:26,239:INFO:display_container: 2
2022-12-01 02:32:26,239:INFO:AdaBoostRegressor(random_state=123)
2022-12-01 02:32:26,240:INFO:create_model() successfully completed......................................
2022-12-01 02:32:26,368:INFO:SubProcess create_model() end ==================================
2022-12-01 02:32:26,368:INFO:Creating metrics dataframe
2022-12-01 02:32:26,388:INFO:Initializing Gradient Boosting Regressor
2022-12-01 02:32:26,389:INFO:Total runtime is 0.30585590203603114 minutes
2022-12-01 02:32:26,399:INFO:SubProcess create_model() called ==================================
2022-12-01 02:32:26,399:INFO:Initializing create_model()
2022-12-01 02:32:26,400:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f499e9bd3d0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961904dc0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:32:26,400:INFO:Checking exceptions
2022-12-01 02:32:26,402:INFO:Importing libraries
2022-12-01 02:32:26,402:INFO:Copying training dataset
2022-12-01 02:32:26,414:INFO:Defining folds
2022-12-01 02:32:26,415:INFO:Declaring metric variables
2022-12-01 02:32:26,423:INFO:Importing untrained model
2022-12-01 02:32:26,433:INFO:Gradient Boosting Regressor Imported successfully
2022-12-01 02:32:26,446:INFO:Starting cross validation
2022-12-01 02:32:26,448:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:32:28,136:INFO:Calculating mean and std
2022-12-01 02:32:28,138:INFO:Creating metrics dataframe
2022-12-01 02:32:28,145:INFO:Uploading results into container
2022-12-01 02:32:28,146:INFO:Uploading model into container now
2022-12-01 02:32:28,146:INFO:master_model_container: 16
2022-12-01 02:32:28,147:INFO:display_container: 2
2022-12-01 02:32:28,147:INFO:GradientBoostingRegressor(random_state=123)
2022-12-01 02:32:28,147:INFO:create_model() successfully completed......................................
2022-12-01 02:32:28,279:INFO:SubProcess create_model() end ==================================
2022-12-01 02:32:28,281:INFO:Creating metrics dataframe
2022-12-01 02:32:28,303:INFO:Initializing Light Gradient Boosting Machine
2022-12-01 02:32:28,307:INFO:Total runtime is 0.3378160357475281 minutes
2022-12-01 02:32:28,314:INFO:SubProcess create_model() called ==================================
2022-12-01 02:32:28,315:INFO:Initializing create_model()
2022-12-01 02:32:28,315:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f499e9bd3d0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961904dc0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:32:28,315:INFO:Checking exceptions
2022-12-01 02:32:28,318:INFO:Importing libraries
2022-12-01 02:32:28,318:INFO:Copying training dataset
2022-12-01 02:32:28,323:INFO:Defining folds
2022-12-01 02:32:28,323:INFO:Declaring metric variables
2022-12-01 02:32:28,330:INFO:Importing untrained model
2022-12-01 02:32:28,338:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-01 02:32:28,351:INFO:Starting cross validation
2022-12-01 02:32:28,353:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:32:29,728:INFO:Calculating mean and std
2022-12-01 02:32:29,730:INFO:Creating metrics dataframe
2022-12-01 02:32:29,739:INFO:Uploading results into container
2022-12-01 02:32:29,740:INFO:Uploading model into container now
2022-12-01 02:32:29,741:INFO:master_model_container: 17
2022-12-01 02:32:29,741:INFO:display_container: 2
2022-12-01 02:32:29,742:INFO:LGBMRegressor(random_state=123)
2022-12-01 02:32:29,742:INFO:create_model() successfully completed......................................
2022-12-01 02:32:29,869:INFO:SubProcess create_model() end ==================================
2022-12-01 02:32:29,870:INFO:Creating metrics dataframe
2022-12-01 02:32:29,891:INFO:Initializing Dummy Regressor
2022-12-01 02:32:29,891:INFO:Total runtime is 0.36422597964604697 minutes
2022-12-01 02:32:29,901:INFO:SubProcess create_model() called ==================================
2022-12-01 02:32:29,902:INFO:Initializing create_model()
2022-12-01 02:32:29,902:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f499e9bd3d0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961904dc0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:32:29,902:INFO:Checking exceptions
2022-12-01 02:32:29,905:INFO:Importing libraries
2022-12-01 02:32:29,905:INFO:Copying training dataset
2022-12-01 02:32:29,911:INFO:Defining folds
2022-12-01 02:32:29,912:INFO:Declaring metric variables
2022-12-01 02:32:29,923:INFO:Importing untrained model
2022-12-01 02:32:29,931:INFO:Dummy Regressor Imported successfully
2022-12-01 02:32:29,946:INFO:Starting cross validation
2022-12-01 02:32:29,948:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:32:30,177:INFO:Calculating mean and std
2022-12-01 02:32:30,179:INFO:Creating metrics dataframe
2022-12-01 02:32:30,191:INFO:Uploading results into container
2022-12-01 02:32:30,192:INFO:Uploading model into container now
2022-12-01 02:32:30,192:INFO:master_model_container: 18
2022-12-01 02:32:30,192:INFO:display_container: 2
2022-12-01 02:32:30,193:INFO:DummyRegressor()
2022-12-01 02:32:30,193:INFO:create_model() successfully completed......................................
2022-12-01 02:32:30,333:INFO:SubProcess create_model() end ==================================
2022-12-01 02:32:30,333:INFO:Creating metrics dataframe
2022-12-01 02:32:30,385:INFO:Initializing create_model()
2022-12-01 02:32:30,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f499e9bd3d0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:32:30,386:INFO:Checking exceptions
2022-12-01 02:32:30,391:INFO:Importing libraries
2022-12-01 02:32:30,391:INFO:Copying training dataset
2022-12-01 02:32:30,393:INFO:Defining folds
2022-12-01 02:32:30,393:INFO:Declaring metric variables
2022-12-01 02:32:30,394:INFO:Importing untrained model
2022-12-01 02:32:30,394:INFO:Declaring custom model
2022-12-01 02:32:30,395:INFO:Random Forest Regressor Imported successfully
2022-12-01 02:32:30,396:INFO:Cross validation set to False
2022-12-01 02:32:30,396:INFO:Fitting Model
2022-12-01 02:32:30,855:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-12-01 02:32:30,855:INFO:create_model() successfully completed......................................
2022-12-01 02:32:31,059:INFO:master_model_container: 18
2022-12-01 02:32:31,060:INFO:display_container: 2
2022-12-01 02:32:31,060:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-12-01 02:32:31,061:INFO:compare_models() successfully completed......................................
2022-12-01 02:34:14,276:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1599: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)

2022-12-01 02:34:16,052:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.
  warnings.warn(

2022-12-01 02:34:33,150:WARNING:<ipython-input-18-387158f279ba>:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q1'] = abs(data['PTS_QTR1_x'] - data['PTS_QTR1_y'])

2022-12-01 02:34:33,155:WARNING:<ipython-input-18-387158f279ba>:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q2'] = abs(data['PTS_QTR2_x'] - data['PTS_QTR2_y'])

2022-12-01 02:34:33,158:WARNING:<ipython-input-18-387158f279ba>:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q3'] = abs(data['PTS_QTR3_x'] - data['PTS_QTR3_y'])

2022-12-01 02:34:33,166:WARNING:<ipython-input-18-387158f279ba>:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q4'] = abs(data['PTS_QTR4_x'] - data['PTS_QTR4_y'])

2022-12-01 02:34:33,168:WARNING:<ipython-input-18-387158f279ba>:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['PTS'] = abs(data['PTS_x'] - data['PTS_y'])

2022-12-01 02:34:33,169:WARNING:<ipython-input-18-387158f279ba>:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FG_PCT'] = abs(data['FG_PCT_x'] - data['FG_PCT_y'])

2022-12-01 02:34:33,171:WARNING:<ipython-input-18-387158f279ba>:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT'] = abs(data['FT_PCT_x'] - data['FT_PCT_y'])

2022-12-01 02:34:33,172:WARNING:<ipython-input-18-387158f279ba>:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT3'] = abs(data['FG3_PCT_x'] - data['FG3_PCT_y'])

2022-12-01 02:34:33,174:WARNING:<ipython-input-18-387158f279ba>:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['AST'] = abs(data['AST_x'] - data['AST_y'])

2022-12-01 02:34:33,175:WARNING:<ipython-input-18-387158f279ba>:26: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['REB'] = abs(data['REB_x'] - data['REB_y'])

2022-12-01 02:34:33,176:WARNING:<ipython-input-18-387158f279ba>:27: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['TO'] = abs(data['TOV_x'] - data['TOV_y'])

2022-12-01 02:34:33,183:INFO:PyCaret RegressionExperiment
2022-12-01 02:34:33,183:INFO:Logging name: FullData
2022-12-01 02:34:33,183:INFO:ML Usecase: MLUsecase.REGRESSION
2022-12-01 02:34:33,183:INFO:version 3.0.0.rc4
2022-12-01 02:34:33,183:INFO:Initializing setup()
2022-12-01 02:34:33,184:INFO:self.USI: 778b
2022-12-01 02:34:33,184:INFO:self.variable_keys: {'fold_shuffle_param', 'y_test', 'pipeline', 'data', 'X', 'exp_id', 'master_model_container', '_available_plots', '_all_metrics', '_ml_usecase', 'log_plots_param', '_all_models', 'logging_param', 'idx', 'html_param', 'display_container', 'USI', 'target_param', 'fold_generator', '_gpu_n_jobs_param', 'n_jobs_param', 'transform_target_method_param', 'exp_name_log', 'X_test', 'variable_keys', 'gpu_param', 'memory', 'y_train', 'transform_target_param', 'y', 'X_train', '_all_models_internal', 'fold_groups_param', 'seed'}
2022-12-01 02:34:33,184:INFO:Checking environment
2022-12-01 02:34:33,184:INFO:python_version: 3.8.15
2022-12-01 02:34:33,184:INFO:python_build: ('default', 'Oct 12 2022 19:14:39')
2022-12-01 02:34:33,184:INFO:machine: x86_64
2022-12-01 02:34:33,184:INFO:platform: Linux-5.10.133+-x86_64-with-glibc2.27
2022-12-01 02:34:33,185:INFO:Memory: svmem(total=13616361472, available=11768246272, percent=13.6, used=1697546240, free=4844920832, active=840560640, inactive=7533121536, buffers=422817792, cached=6651076608, shared=1245184, slab=311873536)
2022-12-01 02:34:33,185:INFO:Physical Core: 1
2022-12-01 02:34:33,185:INFO:Logical Core: 2
2022-12-01 02:34:33,186:INFO:Checking libraries
2022-12-01 02:34:33,186:INFO:System:
2022-12-01 02:34:33,186:INFO:    python: 3.8.15 (default, Oct 12 2022, 19:14:39)  [GCC 7.5.0]
2022-12-01 02:34:33,186:INFO:executable: /usr/bin/python3
2022-12-01 02:34:33,186:INFO:   machine: Linux-5.10.133+-x86_64-with-glibc2.27
2022-12-01 02:34:33,186:INFO:PyCaret required dependencies:
2022-12-01 02:34:33,187:INFO:                 pip: 21.1.3
2022-12-01 02:34:33,187:INFO:          setuptools: 57.4.0
2022-12-01 02:34:33,187:INFO:             pycaret: 3.0.0rc4
2022-12-01 02:34:33,187:INFO:             IPython: 7.9.0
2022-12-01 02:34:33,187:INFO:          ipywidgets: 7.7.1
2022-12-01 02:34:33,187:INFO:                tqdm: 4.64.1
2022-12-01 02:34:33,188:INFO:               numpy: 1.21.6
2022-12-01 02:34:33,188:INFO:              pandas: 1.3.5
2022-12-01 02:34:33,188:INFO:              jinja2: 3.0.0
2022-12-01 02:34:33,188:INFO:               scipy: 1.7.3
2022-12-01 02:34:33,188:INFO:              joblib: 1.2.0
2022-12-01 02:34:33,188:INFO:             sklearn: 1.0.2
2022-12-01 02:34:33,188:INFO:                pyod: 1.0.6
2022-12-01 02:34:33,189:INFO:            imblearn: 0.8.1
2022-12-01 02:34:33,189:INFO:   category_encoders: 2.5.1.post0
2022-12-01 02:34:33,189:INFO:            lightgbm: 3.3.3
2022-12-01 02:34:33,189:INFO:               numba: 0.55.2
2022-12-01 02:34:33,189:INFO:            requests: 2.28.1
2022-12-01 02:34:33,189:INFO:          matplotlib: 3.6.2
2022-12-01 02:34:33,189:INFO:          scikitplot: 0.3.7
2022-12-01 02:34:33,190:INFO:         yellowbrick: 1.5
2022-12-01 02:34:33,190:INFO:              plotly: 5.5.0
2022-12-01 02:34:33,190:INFO:             kaleido: 0.2.1
2022-12-01 02:34:33,190:INFO:         statsmodels: 0.12.2
2022-12-01 02:34:33,190:INFO:              sktime: 0.13.4
2022-12-01 02:34:33,190:INFO:               tbats: 1.1.1
2022-12-01 02:34:33,190:INFO:            pmdarima: 1.8.5
2022-12-01 02:34:33,191:INFO:              psutil: 5.9.4
2022-12-01 02:34:33,191:INFO:PyCaret optional dependencies:
2022-12-01 02:34:33,191:INFO:                shap: Not installed
2022-12-01 02:34:33,191:INFO:           interpret: Not installed
2022-12-01 02:34:33,191:INFO:                umap: Not installed
2022-12-01 02:34:33,191:INFO:    pandas_profiling: 1.4.1
2022-12-01 02:34:33,192:INFO:  explainerdashboard: Not installed
2022-12-01 02:34:33,192:INFO:             autoviz: Not installed
2022-12-01 02:34:33,192:INFO:           fairlearn: Not installed
2022-12-01 02:34:33,192:INFO:             xgboost: 0.90
2022-12-01 02:34:33,192:INFO:            catboost: Not installed
2022-12-01 02:34:33,192:INFO:              kmodes: Not installed
2022-12-01 02:34:33,192:INFO:             mlxtend: 0.14.0
2022-12-01 02:34:33,192:INFO:       statsforecast: Not installed
2022-12-01 02:34:33,193:INFO:        tune_sklearn: Not installed
2022-12-01 02:34:33,193:INFO:                 ray: Not installed
2022-12-01 02:34:33,193:INFO:            hyperopt: 0.1.2
2022-12-01 02:34:33,193:INFO:              optuna: Not installed
2022-12-01 02:34:33,193:INFO:               skopt: Not installed
2022-12-01 02:34:33,193:INFO:              mlflow: Not installed
2022-12-01 02:34:33,193:INFO:              gradio: Not installed
2022-12-01 02:34:33,193:INFO:             fastapi: Not installed
2022-12-01 02:34:33,194:INFO:             uvicorn: Not installed
2022-12-01 02:34:33,194:INFO:              m2cgen: Not installed
2022-12-01 02:34:33,194:INFO:           evidently: Not installed
2022-12-01 02:34:33,194:INFO:                nltk: 3.7
2022-12-01 02:34:33,194:INFO:            pyLDAvis: Not installed
2022-12-01 02:34:33,194:INFO:              gensim: 3.6.0
2022-12-01 02:34:33,194:INFO:               spacy: 3.4.3
2022-12-01 02:34:33,194:INFO:           wordcloud: 1.8.2.2
2022-12-01 02:34:33,195:INFO:            textblob: 0.15.3
2022-12-01 02:34:33,195:INFO:               fugue: Not installed
2022-12-01 02:34:33,195:INFO:           streamlit: Not installed
2022-12-01 02:34:33,195:INFO:             prophet: 1.1.1
2022-12-01 02:34:33,195:INFO:None
2022-12-01 02:34:33,195:INFO:Set up data.
2022-12-01 02:34:33,207:INFO:Set up train/test split.
2022-12-01 02:34:33,212:INFO:Set up index.
2022-12-01 02:34:33,213:INFO:Set up folding strategy.
2022-12-01 02:34:33,213:INFO:Assigning column types.
2022-12-01 02:34:33,222:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-12-01 02:34:33,223:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-01 02:34:33,232:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:34:33,245:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:34:33,361:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:34:33,475:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:34:33,476:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:34:33,477:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:34:33,477:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:34:33,478:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-01 02:34:33,487:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:34:33,497:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:34:33,656:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:34:33,824:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:34:33,825:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:34:33,832:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:34:33,833:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:34:33,833:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-12-01 02:34:33,843:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:34:33,852:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:34:34,001:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:34:34,158:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:34:34,166:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:34:34,171:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:34:34,172:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:34:34,188:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:34:34,210:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:34:34,360:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:34:34,513:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:34:34,517:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:34:34,518:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:34:34,523:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:34:34,523:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-12-01 02:34:34,550:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:34:34,738:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:34:34,867:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:34:34,880:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:34:34,882:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:34:34,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:34:34,905:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:34:35,028:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:34:35,128:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:34:35,131:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:34:35,131:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:34:35,132:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:34:35,132:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-12-01 02:34:35,450:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:34:35,557:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:34:35,558:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:34:35,559:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:34:35,560:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:34:35,710:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:34:35,849:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:34:35,850:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:34:35,851:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:34:35,851:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:34:35,852:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-12-01 02:34:36,053:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:34:36,174:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:34:36,175:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:34:36,175:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:34:36,431:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:34:36,639:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:34:36,639:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:34:36,640:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:34:36,647:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-12-01 02:34:36,998:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:34:37,003:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:34:37,004:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:34:37,328:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:34:37,328:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:34:37,329:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:34:37,335:INFO:Preparing preprocessing pipeline...
2022-12-01 02:34:37,342:INFO:Set up simple imputation.
2022-12-01 02:34:37,342:INFO:Set up variance threshold.
2022-12-01 02:34:37,375:INFO:Finished creating preprocessing pipeline.
2022-12-01 02:34:37,399:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO',
                                             'Open_Line_ML_x'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-12-01 02:34:37,399:INFO:Creating final display dataframe.
2022-12-01 02:34:37,578:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 13)
4         Train data shape    (607, 13)
5          Test data shape    (261, 13)
6         Numeric features           12
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         778b
2022-12-01 02:34:38,016:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:34:38,039:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:34:38,040:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:34:38,408:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:34:38,409:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:34:38,409:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:34:38,419:INFO:setup() successfully completed in 5.24s...............
2022-12-01 02:34:38,420:INFO:Initializing compare_models()
2022-12-01 02:34:38,420:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b57c0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f49619b57c0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-12-01 02:34:38,420:INFO:Checking exceptions
2022-12-01 02:34:38,422:INFO:Preparing display monitor
2022-12-01 02:34:38,543:INFO:Initializing Linear Regression
2022-12-01 02:34:38,547:INFO:Total runtime is 6.482601165771484e-05 minutes
2022-12-01 02:34:38,554:INFO:SubProcess create_model() called ==================================
2022-12-01 02:34:38,556:INFO:Initializing create_model()
2022-12-01 02:34:38,556:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b57c0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e3d460>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:34:38,557:INFO:Checking exceptions
2022-12-01 02:34:38,560:INFO:Importing libraries
2022-12-01 02:34:38,561:INFO:Copying training dataset
2022-12-01 02:34:38,563:INFO:Defining folds
2022-12-01 02:34:38,563:INFO:Declaring metric variables
2022-12-01 02:34:38,569:INFO:Importing untrained model
2022-12-01 02:34:38,576:INFO:Linear Regression Imported successfully
2022-12-01 02:34:38,591:INFO:Starting cross validation
2022-12-01 02:34:38,596:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:34:38,854:INFO:Calculating mean and std
2022-12-01 02:34:38,854:INFO:Creating metrics dataframe
2022-12-01 02:34:38,859:INFO:Uploading results into container
2022-12-01 02:34:38,860:INFO:Uploading model into container now
2022-12-01 02:34:38,860:INFO:master_model_container: 1
2022-12-01 02:34:38,860:INFO:display_container: 2
2022-12-01 02:34:38,860:INFO:LinearRegression(n_jobs=-1)
2022-12-01 02:34:38,861:INFO:create_model() successfully completed......................................
2022-12-01 02:34:38,999:INFO:SubProcess create_model() end ==================================
2022-12-01 02:34:38,999:INFO:Creating metrics dataframe
2022-12-01 02:34:39,025:INFO:Initializing Lasso Regression
2022-12-01 02:34:39,025:INFO:Total runtime is 0.008038536707560221 minutes
2022-12-01 02:34:39,031:INFO:SubProcess create_model() called ==================================
2022-12-01 02:34:39,033:INFO:Initializing create_model()
2022-12-01 02:34:39,033:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b57c0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e3d460>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:34:39,033:INFO:Checking exceptions
2022-12-01 02:34:39,037:INFO:Importing libraries
2022-12-01 02:34:39,037:INFO:Copying training dataset
2022-12-01 02:34:39,040:INFO:Defining folds
2022-12-01 02:34:39,040:INFO:Declaring metric variables
2022-12-01 02:34:39,045:INFO:Importing untrained model
2022-12-01 02:34:39,054:INFO:Lasso Regression Imported successfully
2022-12-01 02:34:39,075:INFO:Starting cross validation
2022-12-01 02:34:39,077:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:34:39,343:INFO:Calculating mean and std
2022-12-01 02:34:39,344:INFO:Creating metrics dataframe
2022-12-01 02:34:39,351:INFO:Uploading results into container
2022-12-01 02:34:39,352:INFO:Uploading model into container now
2022-12-01 02:34:39,353:INFO:master_model_container: 2
2022-12-01 02:34:39,353:INFO:display_container: 2
2022-12-01 02:34:39,354:INFO:Lasso(random_state=123)
2022-12-01 02:34:39,354:INFO:create_model() successfully completed......................................
2022-12-01 02:34:39,483:INFO:SubProcess create_model() end ==================================
2022-12-01 02:34:39,484:INFO:Creating metrics dataframe
2022-12-01 02:34:39,501:INFO:Initializing Ridge Regression
2022-12-01 02:34:39,501:INFO:Total runtime is 0.015974911053975423 minutes
2022-12-01 02:34:39,511:INFO:SubProcess create_model() called ==================================
2022-12-01 02:34:39,511:INFO:Initializing create_model()
2022-12-01 02:34:39,512:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b57c0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e3d460>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:34:39,512:INFO:Checking exceptions
2022-12-01 02:34:39,514:INFO:Importing libraries
2022-12-01 02:34:39,515:INFO:Copying training dataset
2022-12-01 02:34:39,519:INFO:Defining folds
2022-12-01 02:34:39,520:INFO:Declaring metric variables
2022-12-01 02:34:39,531:INFO:Importing untrained model
2022-12-01 02:34:39,541:INFO:Ridge Regression Imported successfully
2022-12-01 02:34:39,559:INFO:Starting cross validation
2022-12-01 02:34:39,561:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:34:39,598:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.19612e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:34:39,630:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1832e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:34:39,648:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.25596e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:34:39,696:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1563e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:34:39,704:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.27134e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:34:39,736:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.30751e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:34:39,754:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.25177e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:34:39,773:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.19532e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:34:39,791:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1922e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:34:39,812:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.20778e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:34:39,822:INFO:Calculating mean and std
2022-12-01 02:34:39,824:INFO:Creating metrics dataframe
2022-12-01 02:34:39,837:INFO:Uploading results into container
2022-12-01 02:34:39,838:INFO:Uploading model into container now
2022-12-01 02:34:39,839:INFO:master_model_container: 3
2022-12-01 02:34:39,839:INFO:display_container: 2
2022-12-01 02:34:39,839:INFO:Ridge(random_state=123)
2022-12-01 02:34:39,839:INFO:create_model() successfully completed......................................
2022-12-01 02:34:39,973:INFO:SubProcess create_model() end ==================================
2022-12-01 02:34:39,975:INFO:Creating metrics dataframe
2022-12-01 02:34:39,994:INFO:Initializing Elastic Net
2022-12-01 02:34:39,995:INFO:Total runtime is 0.02419336239496867 minutes
2022-12-01 02:34:40,003:INFO:SubProcess create_model() called ==================================
2022-12-01 02:34:40,004:INFO:Initializing create_model()
2022-12-01 02:34:40,004:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b57c0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e3d460>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:34:40,004:INFO:Checking exceptions
2022-12-01 02:34:40,008:INFO:Importing libraries
2022-12-01 02:34:40,009:INFO:Copying training dataset
2022-12-01 02:34:40,013:INFO:Defining folds
2022-12-01 02:34:40,013:INFO:Declaring metric variables
2022-12-01 02:34:40,023:INFO:Importing untrained model
2022-12-01 02:34:40,034:INFO:Elastic Net Imported successfully
2022-12-01 02:34:40,052:INFO:Starting cross validation
2022-12-01 02:34:40,053:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:34:40,313:INFO:Calculating mean and std
2022-12-01 02:34:40,315:INFO:Creating metrics dataframe
2022-12-01 02:34:40,327:INFO:Uploading results into container
2022-12-01 02:34:40,328:INFO:Uploading model into container now
2022-12-01 02:34:40,328:INFO:master_model_container: 4
2022-12-01 02:34:40,328:INFO:display_container: 2
2022-12-01 02:34:40,329:INFO:ElasticNet(random_state=123)
2022-12-01 02:34:40,329:INFO:create_model() successfully completed......................................
2022-12-01 02:34:40,465:INFO:SubProcess create_model() end ==================================
2022-12-01 02:34:40,466:INFO:Creating metrics dataframe
2022-12-01 02:34:40,483:INFO:Initializing Least Angle Regression
2022-12-01 02:34:40,484:INFO:Total runtime is 0.032346689701080324 minutes
2022-12-01 02:34:40,492:INFO:SubProcess create_model() called ==================================
2022-12-01 02:34:40,493:INFO:Initializing create_model()
2022-12-01 02:34:40,495:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b57c0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e3d460>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:34:40,495:INFO:Checking exceptions
2022-12-01 02:34:40,498:INFO:Importing libraries
2022-12-01 02:34:40,498:INFO:Copying training dataset
2022-12-01 02:34:40,502:INFO:Defining folds
2022-12-01 02:34:40,502:INFO:Declaring metric variables
2022-12-01 02:34:40,514:INFO:Importing untrained model
2022-12-01 02:34:40,522:INFO:Least Angle Regression Imported successfully
2022-12-01 02:34:40,535:INFO:Starting cross validation
2022-12-01 02:34:40,536:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:34:40,582:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:34:40,598:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:34:40,633:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:34:40,677:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:34:40,679:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:34:40,714:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:34:40,728:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:34:40,761:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:34:40,768:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:34:40,800:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:34:40,815:INFO:Calculating mean and std
2022-12-01 02:34:40,817:INFO:Creating metrics dataframe
2022-12-01 02:34:40,822:INFO:Uploading results into container
2022-12-01 02:34:40,823:INFO:Uploading model into container now
2022-12-01 02:34:40,824:INFO:master_model_container: 5
2022-12-01 02:34:40,824:INFO:display_container: 2
2022-12-01 02:34:40,825:INFO:Lars(random_state=123)
2022-12-01 02:34:40,826:INFO:create_model() successfully completed......................................
2022-12-01 02:34:40,974:INFO:SubProcess create_model() end ==================================
2022-12-01 02:34:40,977:INFO:Creating metrics dataframe
2022-12-01 02:34:40,996:INFO:Initializing Lasso Least Angle Regression
2022-12-01 02:34:40,997:INFO:Total runtime is 0.040901672840118405 minutes
2022-12-01 02:34:41,004:INFO:SubProcess create_model() called ==================================
2022-12-01 02:34:41,007:INFO:Initializing create_model()
2022-12-01 02:34:41,007:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b57c0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e3d460>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:34:41,007:INFO:Checking exceptions
2022-12-01 02:34:41,010:INFO:Importing libraries
2022-12-01 02:34:41,010:INFO:Copying training dataset
2022-12-01 02:34:41,015:INFO:Defining folds
2022-12-01 02:34:41,016:INFO:Declaring metric variables
2022-12-01 02:34:41,026:INFO:Importing untrained model
2022-12-01 02:34:41,034:INFO:Lasso Least Angle Regression Imported successfully
2022-12-01 02:34:41,049:INFO:Starting cross validation
2022-12-01 02:34:41,050:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:34:41,085:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:34:41,114:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:34:41,131:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:34:41,167:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:34:41,188:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:34:41,221:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:34:41,224:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:34:41,259:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:34:41,269:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:34:41,291:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:34:41,303:INFO:Calculating mean and std
2022-12-01 02:34:41,305:INFO:Creating metrics dataframe
2022-12-01 02:34:41,317:INFO:Uploading results into container
2022-12-01 02:34:41,317:INFO:Uploading model into container now
2022-12-01 02:34:41,318:INFO:master_model_container: 6
2022-12-01 02:34:41,318:INFO:display_container: 2
2022-12-01 02:34:41,318:INFO:LassoLars(random_state=123)
2022-12-01 02:34:41,318:INFO:create_model() successfully completed......................................
2022-12-01 02:34:41,453:INFO:SubProcess create_model() end ==================================
2022-12-01 02:34:41,453:INFO:Creating metrics dataframe
2022-12-01 02:34:41,470:INFO:Initializing Orthogonal Matching Pursuit
2022-12-01 02:34:41,471:INFO:Total runtime is 0.0488017201423645 minutes
2022-12-01 02:34:41,479:INFO:SubProcess create_model() called ==================================
2022-12-01 02:34:41,481:INFO:Initializing create_model()
2022-12-01 02:34:41,482:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b57c0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e3d460>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:34:41,482:INFO:Checking exceptions
2022-12-01 02:34:41,485:INFO:Importing libraries
2022-12-01 02:34:41,485:INFO:Copying training dataset
2022-12-01 02:34:41,488:INFO:Defining folds
2022-12-01 02:34:41,490:INFO:Declaring metric variables
2022-12-01 02:34:41,501:INFO:Importing untrained model
2022-12-01 02:34:41,508:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-01 02:34:41,521:INFO:Starting cross validation
2022-12-01 02:34:41,523:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:34:41,553:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:34:41,576:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:34:41,591:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:34:41,634:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:34:41,657:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:34:41,687:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:34:41,689:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:34:41,723:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:34:41,725:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:34:41,754:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:34:41,765:INFO:Calculating mean and std
2022-12-01 02:34:41,767:INFO:Creating metrics dataframe
2022-12-01 02:34:41,776:INFO:Uploading results into container
2022-12-01 02:34:41,776:INFO:Uploading model into container now
2022-12-01 02:34:41,777:INFO:master_model_container: 7
2022-12-01 02:34:41,777:INFO:display_container: 2
2022-12-01 02:34:41,778:INFO:OrthogonalMatchingPursuit()
2022-12-01 02:34:41,778:INFO:create_model() successfully completed......................................
2022-12-01 02:34:41,906:INFO:SubProcess create_model() end ==================================
2022-12-01 02:34:41,907:INFO:Creating metrics dataframe
2022-12-01 02:34:41,930:INFO:Initializing Bayesian Ridge
2022-12-01 02:34:41,932:INFO:Total runtime is 0.05647832155227661 minutes
2022-12-01 02:34:41,940:INFO:SubProcess create_model() called ==================================
2022-12-01 02:34:41,941:INFO:Initializing create_model()
2022-12-01 02:34:41,945:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b57c0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e3d460>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:34:41,946:INFO:Checking exceptions
2022-12-01 02:34:41,947:INFO:Importing libraries
2022-12-01 02:34:41,948:INFO:Copying training dataset
2022-12-01 02:34:41,954:INFO:Defining folds
2022-12-01 02:34:41,955:INFO:Declaring metric variables
2022-12-01 02:34:41,965:INFO:Importing untrained model
2022-12-01 02:34:41,977:INFO:Bayesian Ridge Imported successfully
2022-12-01 02:34:41,989:INFO:Starting cross validation
2022-12-01 02:34:41,991:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:34:42,248:INFO:Calculating mean and std
2022-12-01 02:34:42,250:INFO:Creating metrics dataframe
2022-12-01 02:34:42,262:INFO:Uploading results into container
2022-12-01 02:34:42,263:INFO:Uploading model into container now
2022-12-01 02:34:42,264:INFO:master_model_container: 8
2022-12-01 02:34:42,264:INFO:display_container: 2
2022-12-01 02:34:42,264:INFO:BayesianRidge()
2022-12-01 02:34:42,264:INFO:create_model() successfully completed......................................
2022-12-01 02:34:42,392:INFO:SubProcess create_model() end ==================================
2022-12-01 02:34:42,393:INFO:Creating metrics dataframe
2022-12-01 02:34:42,414:INFO:Initializing Passive Aggressive Regressor
2022-12-01 02:34:42,418:INFO:Total runtime is 0.06458698113759359 minutes
2022-12-01 02:34:42,428:INFO:SubProcess create_model() called ==================================
2022-12-01 02:34:42,430:INFO:Initializing create_model()
2022-12-01 02:34:42,430:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b57c0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e3d460>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:34:42,430:INFO:Checking exceptions
2022-12-01 02:34:42,433:INFO:Importing libraries
2022-12-01 02:34:42,433:INFO:Copying training dataset
2022-12-01 02:34:42,440:INFO:Defining folds
2022-12-01 02:34:42,441:INFO:Declaring metric variables
2022-12-01 02:34:42,453:INFO:Importing untrained model
2022-12-01 02:34:42,461:INFO:Passive Aggressive Regressor Imported successfully
2022-12-01 02:34:42,476:INFO:Starting cross validation
2022-12-01 02:34:42,479:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:34:42,741:INFO:Calculating mean and std
2022-12-01 02:34:42,747:INFO:Creating metrics dataframe
2022-12-01 02:34:42,754:INFO:Uploading results into container
2022-12-01 02:34:42,755:INFO:Uploading model into container now
2022-12-01 02:34:42,755:INFO:master_model_container: 9
2022-12-01 02:34:42,755:INFO:display_container: 2
2022-12-01 02:34:42,756:INFO:PassiveAggressiveRegressor(random_state=123)
2022-12-01 02:34:42,756:INFO:create_model() successfully completed......................................
2022-12-01 02:34:42,887:INFO:SubProcess create_model() end ==================================
2022-12-01 02:34:42,888:INFO:Creating metrics dataframe
2022-12-01 02:34:42,913:INFO:Initializing Huber Regressor
2022-12-01 02:34:42,915:INFO:Total runtime is 0.07286704381306966 minutes
2022-12-01 02:34:42,922:INFO:SubProcess create_model() called ==================================
2022-12-01 02:34:42,924:INFO:Initializing create_model()
2022-12-01 02:34:42,924:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b57c0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e3d460>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:34:42,924:INFO:Checking exceptions
2022-12-01 02:34:42,927:INFO:Importing libraries
2022-12-01 02:34:42,927:INFO:Copying training dataset
2022-12-01 02:34:42,934:INFO:Defining folds
2022-12-01 02:34:42,934:INFO:Declaring metric variables
2022-12-01 02:34:42,942:INFO:Importing untrained model
2022-12-01 02:34:42,950:INFO:Huber Regressor Imported successfully
2022-12-01 02:34:42,963:INFO:Starting cross validation
2022-12-01 02:34:42,965:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:34:43,061:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:34:43,087:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:34:43,178:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:34:43,189:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:34:43,280:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:34:43,290:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:34:43,370:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:34:43,373:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:34:43,458:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:34:43,476:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:34:43,488:INFO:Calculating mean and std
2022-12-01 02:34:43,490:INFO:Creating metrics dataframe
2022-12-01 02:34:43,499:INFO:Uploading results into container
2022-12-01 02:34:43,499:INFO:Uploading model into container now
2022-12-01 02:34:43,500:INFO:master_model_container: 10
2022-12-01 02:34:43,500:INFO:display_container: 2
2022-12-01 02:34:43,501:INFO:HuberRegressor()
2022-12-01 02:34:43,501:INFO:create_model() successfully completed......................................
2022-12-01 02:34:43,628:INFO:SubProcess create_model() end ==================================
2022-12-01 02:34:43,629:INFO:Creating metrics dataframe
2022-12-01 02:34:43,646:INFO:Initializing K Neighbors Regressor
2022-12-01 02:34:43,647:INFO:Total runtime is 0.0850632111231486 minutes
2022-12-01 02:34:43,654:INFO:SubProcess create_model() called ==================================
2022-12-01 02:34:43,655:INFO:Initializing create_model()
2022-12-01 02:34:43,655:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b57c0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e3d460>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:34:43,655:INFO:Checking exceptions
2022-12-01 02:34:43,657:INFO:Importing libraries
2022-12-01 02:34:43,658:INFO:Copying training dataset
2022-12-01 02:34:43,662:INFO:Defining folds
2022-12-01 02:34:43,663:INFO:Declaring metric variables
2022-12-01 02:34:43,671:INFO:Importing untrained model
2022-12-01 02:34:43,680:INFO:K Neighbors Regressor Imported successfully
2022-12-01 02:34:43,695:INFO:Starting cross validation
2022-12-01 02:34:43,700:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:34:43,982:INFO:Calculating mean and std
2022-12-01 02:34:43,984:INFO:Creating metrics dataframe
2022-12-01 02:34:43,995:INFO:Uploading results into container
2022-12-01 02:34:43,996:INFO:Uploading model into container now
2022-12-01 02:34:43,997:INFO:master_model_container: 11
2022-12-01 02:34:43,998:INFO:display_container: 2
2022-12-01 02:34:43,998:INFO:KNeighborsRegressor(n_jobs=-1)
2022-12-01 02:34:43,998:INFO:create_model() successfully completed......................................
2022-12-01 02:34:44,127:INFO:SubProcess create_model() end ==================================
2022-12-01 02:34:44,127:INFO:Creating metrics dataframe
2022-12-01 02:34:44,146:INFO:Initializing Decision Tree Regressor
2022-12-01 02:34:44,147:INFO:Total runtime is 0.09340153137842815 minutes
2022-12-01 02:34:44,156:INFO:SubProcess create_model() called ==================================
2022-12-01 02:34:44,156:INFO:Initializing create_model()
2022-12-01 02:34:44,157:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b57c0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e3d460>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:34:44,157:INFO:Checking exceptions
2022-12-01 02:34:44,160:INFO:Importing libraries
2022-12-01 02:34:44,161:INFO:Copying training dataset
2022-12-01 02:34:44,167:INFO:Defining folds
2022-12-01 02:34:44,168:INFO:Declaring metric variables
2022-12-01 02:34:44,177:INFO:Importing untrained model
2022-12-01 02:34:44,189:INFO:Decision Tree Regressor Imported successfully
2022-12-01 02:34:44,204:INFO:Starting cross validation
2022-12-01 02:34:44,206:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:34:44,508:INFO:Calculating mean and std
2022-12-01 02:34:44,511:INFO:Creating metrics dataframe
2022-12-01 02:34:44,521:INFO:Uploading results into container
2022-12-01 02:34:44,522:INFO:Uploading model into container now
2022-12-01 02:34:44,523:INFO:master_model_container: 12
2022-12-01 02:34:44,523:INFO:display_container: 2
2022-12-01 02:34:44,524:INFO:DecisionTreeRegressor(random_state=123)
2022-12-01 02:34:44,524:INFO:create_model() successfully completed......................................
2022-12-01 02:34:44,653:INFO:SubProcess create_model() end ==================================
2022-12-01 02:34:44,653:INFO:Creating metrics dataframe
2022-12-01 02:34:44,678:INFO:Initializing Random Forest Regressor
2022-12-01 02:34:44,678:INFO:Total runtime is 0.10225606759389241 minutes
2022-12-01 02:34:44,686:INFO:SubProcess create_model() called ==================================
2022-12-01 02:34:44,690:INFO:Initializing create_model()
2022-12-01 02:34:44,690:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b57c0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e3d460>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:34:44,690:INFO:Checking exceptions
2022-12-01 02:34:44,692:INFO:Importing libraries
2022-12-01 02:34:44,692:INFO:Copying training dataset
2022-12-01 02:34:44,697:INFO:Defining folds
2022-12-01 02:34:44,698:INFO:Declaring metric variables
2022-12-01 02:34:44,708:INFO:Importing untrained model
2022-12-01 02:34:44,715:INFO:Random Forest Regressor Imported successfully
2022-12-01 02:34:44,731:INFO:Starting cross validation
2022-12-01 02:34:44,733:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:34:48,603:INFO:Calculating mean and std
2022-12-01 02:34:48,608:INFO:Creating metrics dataframe
2022-12-01 02:34:48,619:INFO:Uploading results into container
2022-12-01 02:34:48,620:INFO:Uploading model into container now
2022-12-01 02:34:48,621:INFO:master_model_container: 13
2022-12-01 02:34:48,621:INFO:display_container: 2
2022-12-01 02:34:48,622:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-12-01 02:34:48,622:INFO:create_model() successfully completed......................................
2022-12-01 02:34:48,747:INFO:SubProcess create_model() end ==================================
2022-12-01 02:34:48,748:INFO:Creating metrics dataframe
2022-12-01 02:34:48,766:INFO:Initializing Extra Trees Regressor
2022-12-01 02:34:48,766:INFO:Total runtime is 0.17039008537928263 minutes
2022-12-01 02:34:48,775:INFO:SubProcess create_model() called ==================================
2022-12-01 02:34:48,778:INFO:Initializing create_model()
2022-12-01 02:34:48,778:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b57c0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e3d460>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:34:48,778:INFO:Checking exceptions
2022-12-01 02:34:48,780:INFO:Importing libraries
2022-12-01 02:34:48,781:INFO:Copying training dataset
2022-12-01 02:34:48,784:INFO:Defining folds
2022-12-01 02:34:48,786:INFO:Declaring metric variables
2022-12-01 02:34:48,794:INFO:Importing untrained model
2022-12-01 02:34:48,802:INFO:Extra Trees Regressor Imported successfully
2022-12-01 02:34:48,817:INFO:Starting cross validation
2022-12-01 02:34:48,820:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:34:50,918:INFO:Calculating mean and std
2022-12-01 02:34:50,922:INFO:Creating metrics dataframe
2022-12-01 02:34:50,929:INFO:Uploading results into container
2022-12-01 02:34:50,930:INFO:Uploading model into container now
2022-12-01 02:34:50,931:INFO:master_model_container: 14
2022-12-01 02:34:50,931:INFO:display_container: 2
2022-12-01 02:34:50,932:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-12-01 02:34:50,932:INFO:create_model() successfully completed......................................
2022-12-01 02:34:51,065:INFO:SubProcess create_model() end ==================================
2022-12-01 02:34:51,065:INFO:Creating metrics dataframe
2022-12-01 02:34:51,097:INFO:Initializing AdaBoost Regressor
2022-12-01 02:34:51,098:INFO:Total runtime is 0.20924739042917886 minutes
2022-12-01 02:34:51,105:INFO:SubProcess create_model() called ==================================
2022-12-01 02:34:51,106:INFO:Initializing create_model()
2022-12-01 02:34:51,106:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b57c0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e3d460>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:34:51,106:INFO:Checking exceptions
2022-12-01 02:34:51,109:INFO:Importing libraries
2022-12-01 02:34:51,109:INFO:Copying training dataset
2022-12-01 02:34:51,116:INFO:Defining folds
2022-12-01 02:34:51,116:INFO:Declaring metric variables
2022-12-01 02:34:51,124:INFO:Importing untrained model
2022-12-01 02:34:51,131:INFO:AdaBoost Regressor Imported successfully
2022-12-01 02:34:51,146:INFO:Starting cross validation
2022-12-01 02:34:51,147:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:34:52,275:INFO:Calculating mean and std
2022-12-01 02:34:52,278:INFO:Creating metrics dataframe
2022-12-01 02:34:52,285:INFO:Uploading results into container
2022-12-01 02:34:52,286:INFO:Uploading model into container now
2022-12-01 02:34:52,287:INFO:master_model_container: 15
2022-12-01 02:34:52,287:INFO:display_container: 2
2022-12-01 02:34:52,287:INFO:AdaBoostRegressor(random_state=123)
2022-12-01 02:34:52,288:INFO:create_model() successfully completed......................................
2022-12-01 02:34:52,416:INFO:SubProcess create_model() end ==================================
2022-12-01 02:34:52,417:INFO:Creating metrics dataframe
2022-12-01 02:34:52,437:INFO:Initializing Gradient Boosting Regressor
2022-12-01 02:34:52,437:INFO:Total runtime is 0.23157395124435423 minutes
2022-12-01 02:34:52,445:INFO:SubProcess create_model() called ==================================
2022-12-01 02:34:52,445:INFO:Initializing create_model()
2022-12-01 02:34:52,446:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b57c0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e3d460>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:34:52,446:INFO:Checking exceptions
2022-12-01 02:34:52,448:INFO:Importing libraries
2022-12-01 02:34:52,448:INFO:Copying training dataset
2022-12-01 02:34:52,454:INFO:Defining folds
2022-12-01 02:34:52,456:INFO:Declaring metric variables
2022-12-01 02:34:52,466:INFO:Importing untrained model
2022-12-01 02:34:52,475:INFO:Gradient Boosting Regressor Imported successfully
2022-12-01 02:34:52,491:INFO:Starting cross validation
2022-12-01 02:34:52,493:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:34:54,190:INFO:Calculating mean and std
2022-12-01 02:34:54,192:INFO:Creating metrics dataframe
2022-12-01 02:34:54,203:INFO:Uploading results into container
2022-12-01 02:34:54,207:INFO:Uploading model into container now
2022-12-01 02:34:54,208:INFO:master_model_container: 16
2022-12-01 02:34:54,208:INFO:display_container: 2
2022-12-01 02:34:54,208:INFO:GradientBoostingRegressor(random_state=123)
2022-12-01 02:34:54,208:INFO:create_model() successfully completed......................................
2022-12-01 02:34:54,339:INFO:SubProcess create_model() end ==================================
2022-12-01 02:34:54,340:INFO:Creating metrics dataframe
2022-12-01 02:34:54,362:INFO:Initializing Light Gradient Boosting Machine
2022-12-01 02:34:54,363:INFO:Total runtime is 0.26366251707077026 minutes
2022-12-01 02:34:54,371:INFO:SubProcess create_model() called ==================================
2022-12-01 02:34:54,372:INFO:Initializing create_model()
2022-12-01 02:34:54,372:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b57c0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e3d460>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:34:54,373:INFO:Checking exceptions
2022-12-01 02:34:54,375:INFO:Importing libraries
2022-12-01 02:34:54,375:INFO:Copying training dataset
2022-12-01 02:34:54,380:INFO:Defining folds
2022-12-01 02:34:54,380:INFO:Declaring metric variables
2022-12-01 02:34:54,391:INFO:Importing untrained model
2022-12-01 02:34:54,401:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-01 02:34:54,415:INFO:Starting cross validation
2022-12-01 02:34:54,418:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:34:55,230:INFO:Calculating mean and std
2022-12-01 02:34:55,232:INFO:Creating metrics dataframe
2022-12-01 02:34:55,244:INFO:Uploading results into container
2022-12-01 02:34:55,245:INFO:Uploading model into container now
2022-12-01 02:34:55,245:INFO:master_model_container: 17
2022-12-01 02:34:55,246:INFO:display_container: 2
2022-12-01 02:34:55,246:INFO:LGBMRegressor(random_state=123)
2022-12-01 02:34:55,247:INFO:create_model() successfully completed......................................
2022-12-01 02:34:55,377:INFO:SubProcess create_model() end ==================================
2022-12-01 02:34:55,378:INFO:Creating metrics dataframe
2022-12-01 02:34:55,402:INFO:Initializing Dummy Regressor
2022-12-01 02:34:55,403:INFO:Total runtime is 0.28100337187449137 minutes
2022-12-01 02:34:55,412:INFO:SubProcess create_model() called ==================================
2022-12-01 02:34:55,412:INFO:Initializing create_model()
2022-12-01 02:34:55,413:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b57c0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e3d460>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:34:55,413:INFO:Checking exceptions
2022-12-01 02:34:55,416:INFO:Importing libraries
2022-12-01 02:34:55,417:INFO:Copying training dataset
2022-12-01 02:34:55,425:INFO:Defining folds
2022-12-01 02:34:55,426:INFO:Declaring metric variables
2022-12-01 02:34:55,435:INFO:Importing untrained model
2022-12-01 02:34:55,443:INFO:Dummy Regressor Imported successfully
2022-12-01 02:34:55,458:INFO:Starting cross validation
2022-12-01 02:34:55,460:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:34:55,696:INFO:Calculating mean and std
2022-12-01 02:34:55,698:INFO:Creating metrics dataframe
2022-12-01 02:34:55,713:INFO:Uploading results into container
2022-12-01 02:34:55,713:INFO:Uploading model into container now
2022-12-01 02:34:55,714:INFO:master_model_container: 18
2022-12-01 02:34:55,714:INFO:display_container: 2
2022-12-01 02:34:55,714:INFO:DummyRegressor()
2022-12-01 02:34:55,714:INFO:create_model() successfully completed......................................
2022-12-01 02:34:55,853:INFO:SubProcess create_model() end ==================================
2022-12-01 02:34:55,854:INFO:Creating metrics dataframe
2022-12-01 02:34:55,902:INFO:Initializing create_model()
2022-12-01 02:34:55,903:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b57c0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:34:55,903:INFO:Checking exceptions
2022-12-01 02:34:55,908:INFO:Importing libraries
2022-12-01 02:34:55,908:INFO:Copying training dataset
2022-12-01 02:34:55,910:INFO:Defining folds
2022-12-01 02:34:55,910:INFO:Declaring metric variables
2022-12-01 02:34:55,911:INFO:Importing untrained model
2022-12-01 02:34:55,911:INFO:Declaring custom model
2022-12-01 02:34:55,912:INFO:Random Forest Regressor Imported successfully
2022-12-01 02:34:55,913:INFO:Cross validation set to False
2022-12-01 02:34:55,913:INFO:Fitting Model
2022-12-01 02:34:56,353:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-12-01 02:34:56,353:INFO:create_model() successfully completed......................................
2022-12-01 02:34:56,550:INFO:master_model_container: 18
2022-12-01 02:34:56,550:INFO:display_container: 2
2022-12-01 02:34:56,551:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-12-01 02:34:56,551:INFO:compare_models() successfully completed......................................
2022-12-01 02:35:00,824:WARNING:<ipython-input-18-387158f279ba>:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q1'] = abs(data['PTS_QTR1_x'] - data['PTS_QTR1_y'])

2022-12-01 02:35:00,825:WARNING:<ipython-input-18-387158f279ba>:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q2'] = abs(data['PTS_QTR2_x'] - data['PTS_QTR2_y'])

2022-12-01 02:35:00,826:WARNING:<ipython-input-18-387158f279ba>:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q3'] = abs(data['PTS_QTR3_x'] - data['PTS_QTR3_y'])

2022-12-01 02:35:00,827:WARNING:<ipython-input-18-387158f279ba>:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q4'] = abs(data['PTS_QTR4_x'] - data['PTS_QTR4_y'])

2022-12-01 02:35:00,828:WARNING:<ipython-input-18-387158f279ba>:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['PTS'] = abs(data['PTS_x'] - data['PTS_y'])

2022-12-01 02:35:00,829:WARNING:<ipython-input-18-387158f279ba>:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FG_PCT'] = abs(data['FG_PCT_x'] - data['FG_PCT_y'])

2022-12-01 02:35:00,829:WARNING:<ipython-input-18-387158f279ba>:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT'] = abs(data['FT_PCT_x'] - data['FT_PCT_y'])

2022-12-01 02:35:00,830:WARNING:<ipython-input-18-387158f279ba>:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT3'] = abs(data['FG3_PCT_x'] - data['FG3_PCT_y'])

2022-12-01 02:35:00,831:WARNING:<ipython-input-18-387158f279ba>:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['AST'] = abs(data['AST_x'] - data['AST_y'])

2022-12-01 02:35:00,832:WARNING:<ipython-input-18-387158f279ba>:26: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['REB'] = abs(data['REB_x'] - data['REB_y'])

2022-12-01 02:35:00,833:WARNING:<ipython-input-18-387158f279ba>:27: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['TO'] = abs(data['TOV_x'] - data['TOV_y'])

2022-12-01 02:35:00,838:INFO:PyCaret RegressionExperiment
2022-12-01 02:35:00,838:INFO:Logging name: FullData
2022-12-01 02:35:00,838:INFO:ML Usecase: MLUsecase.REGRESSION
2022-12-01 02:35:00,838:INFO:version 3.0.0.rc4
2022-12-01 02:35:00,839:INFO:Initializing setup()
2022-12-01 02:35:00,839:INFO:self.USI: fcdb
2022-12-01 02:35:00,839:INFO:self.variable_keys: {'fold_shuffle_param', 'y_test', 'pipeline', 'data', 'X', 'exp_id', 'master_model_container', '_available_plots', '_all_metrics', '_ml_usecase', 'log_plots_param', '_all_models', 'logging_param', 'idx', 'html_param', 'display_container', 'USI', 'target_param', 'fold_generator', '_gpu_n_jobs_param', 'n_jobs_param', 'transform_target_method_param', 'exp_name_log', 'X_test', 'variable_keys', 'gpu_param', 'memory', 'y_train', 'transform_target_param', 'y', 'X_train', '_all_models_internal', 'fold_groups_param', 'seed'}
2022-12-01 02:35:00,839:INFO:Checking environment
2022-12-01 02:35:00,839:INFO:python_version: 3.8.15
2022-12-01 02:35:00,839:INFO:python_build: ('default', 'Oct 12 2022 19:14:39')
2022-12-01 02:35:00,839:INFO:machine: x86_64
2022-12-01 02:35:00,840:INFO:platform: Linux-5.10.133+-x86_64-with-glibc2.27
2022-12-01 02:35:00,840:INFO:Memory: svmem(total=13616361472, available=11729637376, percent=13.9, used=1765613568, free=4773851136, active=840994816, inactive=7603630080, buffers=422969344, cached=6653927424, shared=1245184, slab=312135680)
2022-12-01 02:35:00,840:INFO:Physical Core: 1
2022-12-01 02:35:00,840:INFO:Logical Core: 2
2022-12-01 02:35:00,841:INFO:Checking libraries
2022-12-01 02:35:00,841:INFO:System:
2022-12-01 02:35:00,841:INFO:    python: 3.8.15 (default, Oct 12 2022, 19:14:39)  [GCC 7.5.0]
2022-12-01 02:35:00,841:INFO:executable: /usr/bin/python3
2022-12-01 02:35:00,841:INFO:   machine: Linux-5.10.133+-x86_64-with-glibc2.27
2022-12-01 02:35:00,841:INFO:PyCaret required dependencies:
2022-12-01 02:35:00,842:INFO:                 pip: 21.1.3
2022-12-01 02:35:00,842:INFO:          setuptools: 57.4.0
2022-12-01 02:35:00,842:INFO:             pycaret: 3.0.0rc4
2022-12-01 02:35:00,842:INFO:             IPython: 7.9.0
2022-12-01 02:35:00,842:INFO:          ipywidgets: 7.7.1
2022-12-01 02:35:00,842:INFO:                tqdm: 4.64.1
2022-12-01 02:35:00,842:INFO:               numpy: 1.21.6
2022-12-01 02:35:00,843:INFO:              pandas: 1.3.5
2022-12-01 02:35:00,843:INFO:              jinja2: 3.0.0
2022-12-01 02:35:00,843:INFO:               scipy: 1.7.3
2022-12-01 02:35:00,843:INFO:              joblib: 1.2.0
2022-12-01 02:35:00,843:INFO:             sklearn: 1.0.2
2022-12-01 02:35:00,843:INFO:                pyod: 1.0.6
2022-12-01 02:35:00,843:INFO:            imblearn: 0.8.1
2022-12-01 02:35:00,843:INFO:   category_encoders: 2.5.1.post0
2022-12-01 02:35:00,844:INFO:            lightgbm: 3.3.3
2022-12-01 02:35:00,844:INFO:               numba: 0.55.2
2022-12-01 02:35:00,844:INFO:            requests: 2.28.1
2022-12-01 02:35:00,844:INFO:          matplotlib: 3.6.2
2022-12-01 02:35:00,844:INFO:          scikitplot: 0.3.7
2022-12-01 02:35:00,844:INFO:         yellowbrick: 1.5
2022-12-01 02:35:00,844:INFO:              plotly: 5.5.0
2022-12-01 02:35:00,844:INFO:             kaleido: 0.2.1
2022-12-01 02:35:00,845:INFO:         statsmodels: 0.12.2
2022-12-01 02:35:00,845:INFO:              sktime: 0.13.4
2022-12-01 02:35:00,845:INFO:               tbats: 1.1.1
2022-12-01 02:35:00,845:INFO:            pmdarima: 1.8.5
2022-12-01 02:35:00,845:INFO:              psutil: 5.9.4
2022-12-01 02:35:00,845:INFO:PyCaret optional dependencies:
2022-12-01 02:35:00,845:INFO:                shap: Not installed
2022-12-01 02:35:00,845:INFO:           interpret: Not installed
2022-12-01 02:35:00,846:INFO:                umap: Not installed
2022-12-01 02:35:00,846:INFO:    pandas_profiling: 1.4.1
2022-12-01 02:35:00,846:INFO:  explainerdashboard: Not installed
2022-12-01 02:35:00,846:INFO:             autoviz: Not installed
2022-12-01 02:35:00,846:INFO:           fairlearn: Not installed
2022-12-01 02:35:00,846:INFO:             xgboost: 0.90
2022-12-01 02:35:00,847:INFO:            catboost: Not installed
2022-12-01 02:35:00,847:INFO:              kmodes: Not installed
2022-12-01 02:35:00,847:INFO:             mlxtend: 0.14.0
2022-12-01 02:35:00,847:INFO:       statsforecast: Not installed
2022-12-01 02:35:00,847:INFO:        tune_sklearn: Not installed
2022-12-01 02:35:00,847:INFO:                 ray: Not installed
2022-12-01 02:35:00,847:INFO:            hyperopt: 0.1.2
2022-12-01 02:35:00,848:INFO:              optuna: Not installed
2022-12-01 02:35:00,848:INFO:               skopt: Not installed
2022-12-01 02:35:00,848:INFO:              mlflow: Not installed
2022-12-01 02:35:00,848:INFO:              gradio: Not installed
2022-12-01 02:35:00,848:INFO:             fastapi: Not installed
2022-12-01 02:35:00,848:INFO:             uvicorn: Not installed
2022-12-01 02:35:00,848:INFO:              m2cgen: Not installed
2022-12-01 02:35:00,848:INFO:           evidently: Not installed
2022-12-01 02:35:00,849:INFO:                nltk: 3.7
2022-12-01 02:35:00,849:INFO:            pyLDAvis: Not installed
2022-12-01 02:35:00,849:INFO:              gensim: 3.6.0
2022-12-01 02:35:00,849:INFO:               spacy: 3.4.3
2022-12-01 02:35:00,849:INFO:           wordcloud: 1.8.2.2
2022-12-01 02:35:00,849:INFO:            textblob: 0.15.3
2022-12-01 02:35:00,849:INFO:               fugue: Not installed
2022-12-01 02:35:00,849:INFO:           streamlit: Not installed
2022-12-01 02:35:00,852:INFO:             prophet: 1.1.1
2022-12-01 02:35:00,855:INFO:None
2022-12-01 02:35:00,856:INFO:Set up data.
2022-12-01 02:35:00,863:INFO:Set up train/test split.
2022-12-01 02:35:00,867:INFO:Set up index.
2022-12-01 02:35:00,867:INFO:Set up folding strategy.
2022-12-01 02:35:00,867:INFO:Assigning column types.
2022-12-01 02:35:00,873:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-12-01 02:35:00,873:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-01 02:35:00,879:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:35:00,884:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:35:00,961:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,015:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,016:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:01,017:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:01,017:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:01,017:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,023:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,028:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,092:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,143:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,144:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:01,145:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:01,145:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:01,146:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-12-01 02:35:01,151:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,156:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,223:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,291:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,292:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:01,292:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:01,292:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:01,298:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,304:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,369:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,420:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,421:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:01,421:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:01,422:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:01,422:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-12-01 02:35:01,433:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,497:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,547:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,548:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:01,548:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:01,549:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:01,560:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,626:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,676:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,677:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:01,677:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:01,678:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:01,678:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-12-01 02:35:01,752:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,807:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,808:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:01,809:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:01,809:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:01,888:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,944:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:35:01,946:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:01,946:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:01,947:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:01,947:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-12-01 02:35:02,024:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:02,076:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:02,076:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:02,077:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:02,146:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:02,193:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:02,193:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:02,194:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:02,195:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-12-01 02:35:02,312:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:02,312:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:02,312:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:02,429:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:02,429:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:02,430:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:02,430:INFO:Preparing preprocessing pipeline...
2022-12-01 02:35:02,432:INFO:Set up simple imputation.
2022-12-01 02:35:02,433:INFO:Set up variance threshold.
2022-12-01 02:35:02,444:INFO:Finished creating preprocessing pipeline.
2022-12-01 02:35:02,449:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO',
                                             'Open_Line_ML_x'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-12-01 02:35:02,449:INFO:Creating final display dataframe.
2022-12-01 02:35:02,517:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 13)
4         Train data shape    (607, 13)
5          Test data shape    (261, 13)
6         Numeric features           12
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         fcdb
2022-12-01 02:35:02,656:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:02,657:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:02,657:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:02,771:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:02,771:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:02,772:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:02,778:INFO:setup() successfully completed in 1.94s...............
2022-12-01 02:35:02,778:INFO:Initializing compare_models()
2022-12-01 02:35:02,778:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49618f52e0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f49618f52e0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-12-01 02:35:02,778:INFO:Checking exceptions
2022-12-01 02:35:02,779:INFO:Preparing display monitor
2022-12-01 02:35:02,847:INFO:Initializing Linear Regression
2022-12-01 02:35:02,847:INFO:Total runtime is 6.3141187032063804e-06 minutes
2022-12-01 02:35:02,856:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:02,857:INFO:Initializing create_model()
2022-12-01 02:35:02,862:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49618f52e0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e61fd0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:02,863:INFO:Checking exceptions
2022-12-01 02:35:02,865:INFO:Importing libraries
2022-12-01 02:35:02,867:INFO:Copying training dataset
2022-12-01 02:35:02,871:INFO:Defining folds
2022-12-01 02:35:02,871:INFO:Declaring metric variables
2022-12-01 02:35:02,880:INFO:Importing untrained model
2022-12-01 02:35:02,886:INFO:Linear Regression Imported successfully
2022-12-01 02:35:02,897:INFO:Starting cross validation
2022-12-01 02:35:02,902:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:03,167:INFO:Calculating mean and std
2022-12-01 02:35:03,167:INFO:Creating metrics dataframe
2022-12-01 02:35:03,172:INFO:Uploading results into container
2022-12-01 02:35:03,172:INFO:Uploading model into container now
2022-12-01 02:35:03,173:INFO:master_model_container: 1
2022-12-01 02:35:03,173:INFO:display_container: 2
2022-12-01 02:35:03,174:INFO:LinearRegression(n_jobs=-1)
2022-12-01 02:35:03,174:INFO:create_model() successfully completed......................................
2022-12-01 02:35:03,311:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:03,311:INFO:Creating metrics dataframe
2022-12-01 02:35:03,327:INFO:Initializing Lasso Regression
2022-12-01 02:35:03,332:INFO:Total runtime is 0.00808422565460205 minutes
2022-12-01 02:35:03,338:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:03,338:INFO:Initializing create_model()
2022-12-01 02:35:03,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49618f52e0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e61fd0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:03,339:INFO:Checking exceptions
2022-12-01 02:35:03,341:INFO:Importing libraries
2022-12-01 02:35:03,341:INFO:Copying training dataset
2022-12-01 02:35:03,345:INFO:Defining folds
2022-12-01 02:35:03,345:INFO:Declaring metric variables
2022-12-01 02:35:03,351:INFO:Importing untrained model
2022-12-01 02:35:03,358:INFO:Lasso Regression Imported successfully
2022-12-01 02:35:03,373:INFO:Starting cross validation
2022-12-01 02:35:03,375:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:03,636:INFO:Calculating mean and std
2022-12-01 02:35:03,636:INFO:Creating metrics dataframe
2022-12-01 02:35:03,641:INFO:Uploading results into container
2022-12-01 02:35:03,641:INFO:Uploading model into container now
2022-12-01 02:35:03,642:INFO:master_model_container: 2
2022-12-01 02:35:03,642:INFO:display_container: 2
2022-12-01 02:35:03,642:INFO:Lasso(random_state=123)
2022-12-01 02:35:03,642:INFO:create_model() successfully completed......................................
2022-12-01 02:35:03,768:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:03,769:INFO:Creating metrics dataframe
2022-12-01 02:35:03,786:INFO:Initializing Ridge Regression
2022-12-01 02:35:03,786:INFO:Total runtime is 0.01566284497578939 minutes
2022-12-01 02:35:03,795:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:03,796:INFO:Initializing create_model()
2022-12-01 02:35:03,797:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49618f52e0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e61fd0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:03,797:INFO:Checking exceptions
2022-12-01 02:35:03,800:INFO:Importing libraries
2022-12-01 02:35:03,800:INFO:Copying training dataset
2022-12-01 02:35:03,806:INFO:Defining folds
2022-12-01 02:35:03,806:INFO:Declaring metric variables
2022-12-01 02:35:03,817:INFO:Importing untrained model
2022-12-01 02:35:03,830:INFO:Ridge Regression Imported successfully
2022-12-01 02:35:03,845:INFO:Starting cross validation
2022-12-01 02:35:03,846:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:03,894:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.19612e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:35:03,896:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1832e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:35:03,931:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.25596e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:35:03,965:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.27134e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:35:03,992:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1563e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:35:04,034:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.25177e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:35:04,046:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.30751e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:35:04,078:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1922e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:35:04,085:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.19532e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:35:04,112:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.20778e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:35:04,123:INFO:Calculating mean and std
2022-12-01 02:35:04,125:INFO:Creating metrics dataframe
2022-12-01 02:35:04,133:INFO:Uploading results into container
2022-12-01 02:35:04,134:INFO:Uploading model into container now
2022-12-01 02:35:04,135:INFO:master_model_container: 3
2022-12-01 02:35:04,135:INFO:display_container: 2
2022-12-01 02:35:04,135:INFO:Ridge(random_state=123)
2022-12-01 02:35:04,136:INFO:create_model() successfully completed......................................
2022-12-01 02:35:04,266:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:04,269:INFO:Creating metrics dataframe
2022-12-01 02:35:04,288:INFO:Initializing Elastic Net
2022-12-01 02:35:04,292:INFO:Total runtime is 0.024081969261169435 minutes
2022-12-01 02:35:04,298:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:04,299:INFO:Initializing create_model()
2022-12-01 02:35:04,299:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49618f52e0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e61fd0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:04,299:INFO:Checking exceptions
2022-12-01 02:35:04,301:INFO:Importing libraries
2022-12-01 02:35:04,301:INFO:Copying training dataset
2022-12-01 02:35:04,306:INFO:Defining folds
2022-12-01 02:35:04,307:INFO:Declaring metric variables
2022-12-01 02:35:04,318:INFO:Importing untrained model
2022-12-01 02:35:04,327:INFO:Elastic Net Imported successfully
2022-12-01 02:35:04,348:INFO:Starting cross validation
2022-12-01 02:35:04,349:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:04,603:INFO:Calculating mean and std
2022-12-01 02:35:04,605:INFO:Creating metrics dataframe
2022-12-01 02:35:04,617:INFO:Uploading results into container
2022-12-01 02:35:04,620:INFO:Uploading model into container now
2022-12-01 02:35:04,621:INFO:master_model_container: 4
2022-12-01 02:35:04,622:INFO:display_container: 2
2022-12-01 02:35:04,623:INFO:ElasticNet(random_state=123)
2022-12-01 02:35:04,623:INFO:create_model() successfully completed......................................
2022-12-01 02:35:04,751:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:04,751:INFO:Creating metrics dataframe
2022-12-01 02:35:04,769:INFO:Initializing Least Angle Regression
2022-12-01 02:35:04,775:INFO:Total runtime is 0.032132033507029215 minutes
2022-12-01 02:35:04,780:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:04,781:INFO:Initializing create_model()
2022-12-01 02:35:04,781:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49618f52e0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e61fd0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:04,781:INFO:Checking exceptions
2022-12-01 02:35:04,784:INFO:Importing libraries
2022-12-01 02:35:04,784:INFO:Copying training dataset
2022-12-01 02:35:04,790:INFO:Defining folds
2022-12-01 02:35:04,791:INFO:Declaring metric variables
2022-12-01 02:35:04,799:INFO:Importing untrained model
2022-12-01 02:35:04,808:INFO:Least Angle Regression Imported successfully
2022-12-01 02:35:04,821:INFO:Starting cross validation
2022-12-01 02:35:04,823:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:04,859:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:04,882:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:04,918:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:04,943:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:04,964:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:05,017:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:05,019:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:05,068:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:05,073:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:05,108:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:05,122:INFO:Calculating mean and std
2022-12-01 02:35:05,124:INFO:Creating metrics dataframe
2022-12-01 02:35:05,137:INFO:Uploading results into container
2022-12-01 02:35:05,138:INFO:Uploading model into container now
2022-12-01 02:35:05,139:INFO:master_model_container: 5
2022-12-01 02:35:05,139:INFO:display_container: 2
2022-12-01 02:35:05,140:INFO:Lars(random_state=123)
2022-12-01 02:35:05,140:INFO:create_model() successfully completed......................................
2022-12-01 02:35:05,269:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:05,270:INFO:Creating metrics dataframe
2022-12-01 02:35:05,289:INFO:Initializing Lasso Least Angle Regression
2022-12-01 02:35:05,289:INFO:Total runtime is 0.04070629278818766 minutes
2022-12-01 02:35:05,297:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:05,297:INFO:Initializing create_model()
2022-12-01 02:35:05,298:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49618f52e0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e61fd0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:05,298:INFO:Checking exceptions
2022-12-01 02:35:05,300:INFO:Importing libraries
2022-12-01 02:35:05,300:INFO:Copying training dataset
2022-12-01 02:35:05,308:INFO:Defining folds
2022-12-01 02:35:05,308:INFO:Declaring metric variables
2022-12-01 02:35:05,318:INFO:Importing untrained model
2022-12-01 02:35:05,325:INFO:Lasso Least Angle Regression Imported successfully
2022-12-01 02:35:05,340:INFO:Starting cross validation
2022-12-01 02:35:05,342:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:05,384:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:05,404:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:05,434:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:05,458:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:05,487:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:05,526:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:05,527:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:05,566:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:05,566:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:05,597:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:05,609:INFO:Calculating mean and std
2022-12-01 02:35:05,611:INFO:Creating metrics dataframe
2022-12-01 02:35:05,620:INFO:Uploading results into container
2022-12-01 02:35:05,623:INFO:Uploading model into container now
2022-12-01 02:35:05,624:INFO:master_model_container: 6
2022-12-01 02:35:05,624:INFO:display_container: 2
2022-12-01 02:35:05,625:INFO:LassoLars(random_state=123)
2022-12-01 02:35:05,625:INFO:create_model() successfully completed......................................
2022-12-01 02:35:05,753:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:05,753:INFO:Creating metrics dataframe
2022-12-01 02:35:05,772:INFO:Initializing Orthogonal Matching Pursuit
2022-12-01 02:35:05,772:INFO:Total runtime is 0.04875699281692505 minutes
2022-12-01 02:35:05,784:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:05,785:INFO:Initializing create_model()
2022-12-01 02:35:05,785:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49618f52e0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e61fd0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:05,786:INFO:Checking exceptions
2022-12-01 02:35:05,790:INFO:Importing libraries
2022-12-01 02:35:05,790:INFO:Copying training dataset
2022-12-01 02:35:05,795:INFO:Defining folds
2022-12-01 02:35:05,795:INFO:Declaring metric variables
2022-12-01 02:35:05,804:INFO:Importing untrained model
2022-12-01 02:35:05,815:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-01 02:35:05,837:INFO:Starting cross validation
2022-12-01 02:35:05,839:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:05,867:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:05,893:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:05,921:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:05,964:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:05,972:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:05,998:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:06,021:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:06,036:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:06,062:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:06,090:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:06,102:INFO:Calculating mean and std
2022-12-01 02:35:06,104:INFO:Creating metrics dataframe
2022-12-01 02:35:06,110:INFO:Uploading results into container
2022-12-01 02:35:06,111:INFO:Uploading model into container now
2022-12-01 02:35:06,112:INFO:master_model_container: 7
2022-12-01 02:35:06,115:INFO:display_container: 2
2022-12-01 02:35:06,116:INFO:OrthogonalMatchingPursuit()
2022-12-01 02:35:06,116:INFO:create_model() successfully completed......................................
2022-12-01 02:35:06,246:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:06,247:INFO:Creating metrics dataframe
2022-12-01 02:35:06,268:INFO:Initializing Bayesian Ridge
2022-12-01 02:35:06,268:INFO:Total runtime is 0.05702757040659587 minutes
2022-12-01 02:35:06,278:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:06,278:INFO:Initializing create_model()
2022-12-01 02:35:06,279:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49618f52e0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e61fd0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:06,279:INFO:Checking exceptions
2022-12-01 02:35:06,281:INFO:Importing libraries
2022-12-01 02:35:06,282:INFO:Copying training dataset
2022-12-01 02:35:06,287:INFO:Defining folds
2022-12-01 02:35:06,287:INFO:Declaring metric variables
2022-12-01 02:35:06,297:INFO:Importing untrained model
2022-12-01 02:35:06,305:INFO:Bayesian Ridge Imported successfully
2022-12-01 02:35:06,323:INFO:Starting cross validation
2022-12-01 02:35:06,326:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:06,588:INFO:Calculating mean and std
2022-12-01 02:35:06,590:INFO:Creating metrics dataframe
2022-12-01 02:35:06,599:INFO:Uploading results into container
2022-12-01 02:35:06,600:INFO:Uploading model into container now
2022-12-01 02:35:06,600:INFO:master_model_container: 8
2022-12-01 02:35:06,601:INFO:display_container: 2
2022-12-01 02:35:06,602:INFO:BayesianRidge()
2022-12-01 02:35:06,602:INFO:create_model() successfully completed......................................
2022-12-01 02:35:06,731:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:06,731:INFO:Creating metrics dataframe
2022-12-01 02:35:06,750:INFO:Initializing Passive Aggressive Regressor
2022-12-01 02:35:06,750:INFO:Total runtime is 0.06505813995997112 minutes
2022-12-01 02:35:06,759:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:06,759:INFO:Initializing create_model()
2022-12-01 02:35:06,760:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49618f52e0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e61fd0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:06,760:INFO:Checking exceptions
2022-12-01 02:35:06,763:INFO:Importing libraries
2022-12-01 02:35:06,763:INFO:Copying training dataset
2022-12-01 02:35:06,768:INFO:Defining folds
2022-12-01 02:35:06,768:INFO:Declaring metric variables
2022-12-01 02:35:06,778:INFO:Importing untrained model
2022-12-01 02:35:06,790:INFO:Passive Aggressive Regressor Imported successfully
2022-12-01 02:35:06,805:INFO:Starting cross validation
2022-12-01 02:35:06,807:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:07,079:INFO:Calculating mean and std
2022-12-01 02:35:07,090:INFO:Creating metrics dataframe
2022-12-01 02:35:07,097:INFO:Uploading results into container
2022-12-01 02:35:07,100:INFO:Uploading model into container now
2022-12-01 02:35:07,101:INFO:master_model_container: 9
2022-12-01 02:35:07,101:INFO:display_container: 2
2022-12-01 02:35:07,102:INFO:PassiveAggressiveRegressor(random_state=123)
2022-12-01 02:35:07,102:INFO:create_model() successfully completed......................................
2022-12-01 02:35:07,230:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:07,230:INFO:Creating metrics dataframe
2022-12-01 02:35:07,252:INFO:Initializing Huber Regressor
2022-12-01 02:35:07,252:INFO:Total runtime is 0.0734289328257243 minutes
2022-12-01 02:35:07,260:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:07,260:INFO:Initializing create_model()
2022-12-01 02:35:07,261:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49618f52e0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e61fd0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:07,261:INFO:Checking exceptions
2022-12-01 02:35:07,263:INFO:Importing libraries
2022-12-01 02:35:07,263:INFO:Copying training dataset
2022-12-01 02:35:07,270:INFO:Defining folds
2022-12-01 02:35:07,270:INFO:Declaring metric variables
2022-12-01 02:35:07,278:INFO:Importing untrained model
2022-12-01 02:35:07,285:INFO:Huber Regressor Imported successfully
2022-12-01 02:35:07,299:INFO:Starting cross validation
2022-12-01 02:35:07,301:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:07,403:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:35:07,414:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:35:07,516:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:35:07,524:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:35:07,625:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:35:07,631:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:35:07,715:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:35:07,715:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:35:07,800:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:35:07,804:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:35:07,820:INFO:Calculating mean and std
2022-12-01 02:35:07,822:INFO:Creating metrics dataframe
2022-12-01 02:35:07,833:INFO:Uploading results into container
2022-12-01 02:35:07,838:INFO:Uploading model into container now
2022-12-01 02:35:07,844:INFO:master_model_container: 10
2022-12-01 02:35:07,844:INFO:display_container: 2
2022-12-01 02:35:07,845:INFO:HuberRegressor()
2022-12-01 02:35:07,845:INFO:create_model() successfully completed......................................
2022-12-01 02:35:07,972:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:07,973:INFO:Creating metrics dataframe
2022-12-01 02:35:07,996:INFO:Initializing K Neighbors Regressor
2022-12-01 02:35:07,996:INFO:Total runtime is 0.08582934141159058 minutes
2022-12-01 02:35:08,004:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:08,004:INFO:Initializing create_model()
2022-12-01 02:35:08,005:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49618f52e0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e61fd0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:08,005:INFO:Checking exceptions
2022-12-01 02:35:08,007:INFO:Importing libraries
2022-12-01 02:35:08,007:INFO:Copying training dataset
2022-12-01 02:35:08,013:INFO:Defining folds
2022-12-01 02:35:08,015:INFO:Declaring metric variables
2022-12-01 02:35:08,023:INFO:Importing untrained model
2022-12-01 02:35:08,031:INFO:K Neighbors Regressor Imported successfully
2022-12-01 02:35:08,046:INFO:Starting cross validation
2022-12-01 02:35:08,050:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:08,350:INFO:Calculating mean and std
2022-12-01 02:35:08,352:INFO:Creating metrics dataframe
2022-12-01 02:35:08,360:INFO:Uploading results into container
2022-12-01 02:35:08,361:INFO:Uploading model into container now
2022-12-01 02:35:08,362:INFO:master_model_container: 11
2022-12-01 02:35:08,362:INFO:display_container: 2
2022-12-01 02:35:08,363:INFO:KNeighborsRegressor(n_jobs=-1)
2022-12-01 02:35:08,363:INFO:create_model() successfully completed......................................
2022-12-01 02:35:08,496:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:08,496:INFO:Creating metrics dataframe
2022-12-01 02:35:08,516:INFO:Initializing Decision Tree Regressor
2022-12-01 02:35:08,517:INFO:Total runtime is 0.0945019284884135 minutes
2022-12-01 02:35:08,526:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:08,526:INFO:Initializing create_model()
2022-12-01 02:35:08,527:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49618f52e0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e61fd0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:08,528:INFO:Checking exceptions
2022-12-01 02:35:08,531:INFO:Importing libraries
2022-12-01 02:35:08,531:INFO:Copying training dataset
2022-12-01 02:35:08,538:INFO:Defining folds
2022-12-01 02:35:08,539:INFO:Declaring metric variables
2022-12-01 02:35:08,547:INFO:Importing untrained model
2022-12-01 02:35:08,556:INFO:Decision Tree Regressor Imported successfully
2022-12-01 02:35:08,571:INFO:Starting cross validation
2022-12-01 02:35:08,573:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:08,905:INFO:Calculating mean and std
2022-12-01 02:35:08,907:INFO:Creating metrics dataframe
2022-12-01 02:35:08,919:INFO:Uploading results into container
2022-12-01 02:35:08,920:INFO:Uploading model into container now
2022-12-01 02:35:08,921:INFO:master_model_container: 12
2022-12-01 02:35:08,921:INFO:display_container: 2
2022-12-01 02:35:08,922:INFO:DecisionTreeRegressor(random_state=123)
2022-12-01 02:35:08,923:INFO:create_model() successfully completed......................................
2022-12-01 02:35:09,059:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:09,060:INFO:Creating metrics dataframe
2022-12-01 02:35:09,079:INFO:Initializing Random Forest Regressor
2022-12-01 02:35:09,080:INFO:Total runtime is 0.10388847986857097 minutes
2022-12-01 02:35:09,088:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:09,089:INFO:Initializing create_model()
2022-12-01 02:35:09,089:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49618f52e0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e61fd0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:09,089:INFO:Checking exceptions
2022-12-01 02:35:09,091:INFO:Importing libraries
2022-12-01 02:35:09,092:INFO:Copying training dataset
2022-12-01 02:35:09,101:INFO:Defining folds
2022-12-01 02:35:09,102:INFO:Declaring metric variables
2022-12-01 02:35:09,115:INFO:Importing untrained model
2022-12-01 02:35:09,124:INFO:Random Forest Regressor Imported successfully
2022-12-01 02:35:09,145:INFO:Starting cross validation
2022-12-01 02:35:09,147:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:13,059:INFO:Calculating mean and std
2022-12-01 02:35:13,061:INFO:Creating metrics dataframe
2022-12-01 02:35:13,070:INFO:Uploading results into container
2022-12-01 02:35:13,071:INFO:Uploading model into container now
2022-12-01 02:35:13,072:INFO:master_model_container: 13
2022-12-01 02:35:13,072:INFO:display_container: 2
2022-12-01 02:35:13,072:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-12-01 02:35:13,073:INFO:create_model() successfully completed......................................
2022-12-01 02:35:13,206:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:13,206:INFO:Creating metrics dataframe
2022-12-01 02:35:13,226:INFO:Initializing Extra Trees Regressor
2022-12-01 02:35:13,226:INFO:Total runtime is 0.17298718293507895 minutes
2022-12-01 02:35:13,234:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:13,234:INFO:Initializing create_model()
2022-12-01 02:35:13,235:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49618f52e0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e61fd0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:13,235:INFO:Checking exceptions
2022-12-01 02:35:13,239:INFO:Importing libraries
2022-12-01 02:35:13,239:INFO:Copying training dataset
2022-12-01 02:35:13,245:INFO:Defining folds
2022-12-01 02:35:13,247:INFO:Declaring metric variables
2022-12-01 02:35:13,256:INFO:Importing untrained model
2022-12-01 02:35:13,264:INFO:Extra Trees Regressor Imported successfully
2022-12-01 02:35:13,287:INFO:Starting cross validation
2022-12-01 02:35:13,289:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:15,323:INFO:Calculating mean and std
2022-12-01 02:35:15,332:INFO:Creating metrics dataframe
2022-12-01 02:35:15,341:INFO:Uploading results into container
2022-12-01 02:35:15,343:INFO:Uploading model into container now
2022-12-01 02:35:15,344:INFO:master_model_container: 14
2022-12-01 02:35:15,344:INFO:display_container: 2
2022-12-01 02:35:15,345:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-12-01 02:35:15,345:INFO:create_model() successfully completed......................................
2022-12-01 02:35:15,476:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:15,477:INFO:Creating metrics dataframe
2022-12-01 02:35:15,496:INFO:Initializing AdaBoost Regressor
2022-12-01 02:35:15,496:INFO:Total runtime is 0.2108288327852885 minutes
2022-12-01 02:35:15,503:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:15,504:INFO:Initializing create_model()
2022-12-01 02:35:15,505:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49618f52e0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e61fd0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:15,505:INFO:Checking exceptions
2022-12-01 02:35:15,508:INFO:Importing libraries
2022-12-01 02:35:15,508:INFO:Copying training dataset
2022-12-01 02:35:15,513:INFO:Defining folds
2022-12-01 02:35:15,514:INFO:Declaring metric variables
2022-12-01 02:35:15,525:INFO:Importing untrained model
2022-12-01 02:35:15,533:INFO:AdaBoost Regressor Imported successfully
2022-12-01 02:35:15,550:INFO:Starting cross validation
2022-12-01 02:35:15,551:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:16,678:INFO:Calculating mean and std
2022-12-01 02:35:16,682:INFO:Creating metrics dataframe
2022-12-01 02:35:16,690:INFO:Uploading results into container
2022-12-01 02:35:16,691:INFO:Uploading model into container now
2022-12-01 02:35:16,692:INFO:master_model_container: 15
2022-12-01 02:35:16,692:INFO:display_container: 2
2022-12-01 02:35:16,692:INFO:AdaBoostRegressor(random_state=123)
2022-12-01 02:35:16,693:INFO:create_model() successfully completed......................................
2022-12-01 02:35:16,819:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:16,819:INFO:Creating metrics dataframe
2022-12-01 02:35:16,845:INFO:Initializing Gradient Boosting Regressor
2022-12-01 02:35:16,849:INFO:Total runtime is 0.23337634404500326 minutes
2022-12-01 02:35:16,854:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:16,857:INFO:Initializing create_model()
2022-12-01 02:35:16,857:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49618f52e0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e61fd0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:16,857:INFO:Checking exceptions
2022-12-01 02:35:16,860:INFO:Importing libraries
2022-12-01 02:35:16,860:INFO:Copying training dataset
2022-12-01 02:35:16,866:INFO:Defining folds
2022-12-01 02:35:16,866:INFO:Declaring metric variables
2022-12-01 02:35:16,874:INFO:Importing untrained model
2022-12-01 02:35:16,882:INFO:Gradient Boosting Regressor Imported successfully
2022-12-01 02:35:16,897:INFO:Starting cross validation
2022-12-01 02:35:16,900:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:18,592:INFO:Calculating mean and std
2022-12-01 02:35:18,594:INFO:Creating metrics dataframe
2022-12-01 02:35:18,605:INFO:Uploading results into container
2022-12-01 02:35:18,606:INFO:Uploading model into container now
2022-12-01 02:35:18,606:INFO:master_model_container: 16
2022-12-01 02:35:18,607:INFO:display_container: 2
2022-12-01 02:35:18,607:INFO:GradientBoostingRegressor(random_state=123)
2022-12-01 02:35:18,607:INFO:create_model() successfully completed......................................
2022-12-01 02:35:18,738:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:18,739:INFO:Creating metrics dataframe
2022-12-01 02:35:18,758:INFO:Initializing Light Gradient Boosting Machine
2022-12-01 02:35:18,758:INFO:Total runtime is 0.2651901642481486 minutes
2022-12-01 02:35:18,766:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:18,766:INFO:Initializing create_model()
2022-12-01 02:35:18,766:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49618f52e0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e61fd0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:18,767:INFO:Checking exceptions
2022-12-01 02:35:18,769:INFO:Importing libraries
2022-12-01 02:35:18,769:INFO:Copying training dataset
2022-12-01 02:35:18,775:INFO:Defining folds
2022-12-01 02:35:18,776:INFO:Declaring metric variables
2022-12-01 02:35:18,784:INFO:Importing untrained model
2022-12-01 02:35:18,791:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-01 02:35:18,806:INFO:Starting cross validation
2022-12-01 02:35:18,807:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:19,612:INFO:Calculating mean and std
2022-12-01 02:35:19,614:INFO:Creating metrics dataframe
2022-12-01 02:35:19,622:INFO:Uploading results into container
2022-12-01 02:35:19,624:INFO:Uploading model into container now
2022-12-01 02:35:19,624:INFO:master_model_container: 17
2022-12-01 02:35:19,625:INFO:display_container: 2
2022-12-01 02:35:19,625:INFO:LGBMRegressor(random_state=123)
2022-12-01 02:35:19,626:INFO:create_model() successfully completed......................................
2022-12-01 02:35:19,757:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:19,757:INFO:Creating metrics dataframe
2022-12-01 02:35:19,786:INFO:Initializing Dummy Regressor
2022-12-01 02:35:19,789:INFO:Total runtime is 0.28236461877822877 minutes
2022-12-01 02:35:19,794:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:19,796:INFO:Initializing create_model()
2022-12-01 02:35:19,797:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49618f52e0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f4961e61fd0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:19,797:INFO:Checking exceptions
2022-12-01 02:35:19,800:INFO:Importing libraries
2022-12-01 02:35:19,800:INFO:Copying training dataset
2022-12-01 02:35:19,806:INFO:Defining folds
2022-12-01 02:35:19,807:INFO:Declaring metric variables
2022-12-01 02:35:19,815:INFO:Importing untrained model
2022-12-01 02:35:19,823:INFO:Dummy Regressor Imported successfully
2022-12-01 02:35:19,839:INFO:Starting cross validation
2022-12-01 02:35:19,842:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:20,070:INFO:Calculating mean and std
2022-12-01 02:35:20,072:INFO:Creating metrics dataframe
2022-12-01 02:35:20,080:INFO:Uploading results into container
2022-12-01 02:35:20,081:INFO:Uploading model into container now
2022-12-01 02:35:20,082:INFO:master_model_container: 18
2022-12-01 02:35:20,082:INFO:display_container: 2
2022-12-01 02:35:20,083:INFO:DummyRegressor()
2022-12-01 02:35:20,083:INFO:create_model() successfully completed......................................
2022-12-01 02:35:20,212:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:20,213:INFO:Creating metrics dataframe
2022-12-01 02:35:20,263:INFO:Initializing create_model()
2022-12-01 02:35:20,264:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49618f52e0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:20,264:INFO:Checking exceptions
2022-12-01 02:35:20,270:INFO:Importing libraries
2022-12-01 02:35:20,270:INFO:Copying training dataset
2022-12-01 02:35:20,273:INFO:Defining folds
2022-12-01 02:35:20,273:INFO:Declaring metric variables
2022-12-01 02:35:20,274:INFO:Importing untrained model
2022-12-01 02:35:20,274:INFO:Declaring custom model
2022-12-01 02:35:20,275:INFO:Random Forest Regressor Imported successfully
2022-12-01 02:35:20,276:INFO:Cross validation set to False
2022-12-01 02:35:20,276:INFO:Fitting Model
2022-12-01 02:35:20,724:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-12-01 02:35:20,724:INFO:create_model() successfully completed......................................
2022-12-01 02:35:20,929:INFO:master_model_container: 18
2022-12-01 02:35:20,930:INFO:display_container: 2
2022-12-01 02:35:20,930:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-12-01 02:35:20,930:INFO:compare_models() successfully completed......................................
2022-12-01 02:35:24,724:WARNING:<ipython-input-18-387158f279ba>:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q1'] = abs(data['PTS_QTR1_x'] - data['PTS_QTR1_y'])

2022-12-01 02:35:24,725:WARNING:<ipython-input-18-387158f279ba>:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q2'] = abs(data['PTS_QTR2_x'] - data['PTS_QTR2_y'])

2022-12-01 02:35:24,726:WARNING:<ipython-input-18-387158f279ba>:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q3'] = abs(data['PTS_QTR3_x'] - data['PTS_QTR3_y'])

2022-12-01 02:35:24,727:WARNING:<ipython-input-18-387158f279ba>:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q4'] = abs(data['PTS_QTR4_x'] - data['PTS_QTR4_y'])

2022-12-01 02:35:24,727:WARNING:<ipython-input-18-387158f279ba>:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['PTS'] = abs(data['PTS_x'] - data['PTS_y'])

2022-12-01 02:35:24,728:WARNING:<ipython-input-18-387158f279ba>:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FG_PCT'] = abs(data['FG_PCT_x'] - data['FG_PCT_y'])

2022-12-01 02:35:24,729:WARNING:<ipython-input-18-387158f279ba>:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT'] = abs(data['FT_PCT_x'] - data['FT_PCT_y'])

2022-12-01 02:35:24,730:WARNING:<ipython-input-18-387158f279ba>:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT3'] = abs(data['FG3_PCT_x'] - data['FG3_PCT_y'])

2022-12-01 02:35:24,731:WARNING:<ipython-input-18-387158f279ba>:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['AST'] = abs(data['AST_x'] - data['AST_y'])

2022-12-01 02:35:24,732:WARNING:<ipython-input-18-387158f279ba>:26: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['REB'] = abs(data['REB_x'] - data['REB_y'])

2022-12-01 02:35:24,733:WARNING:<ipython-input-18-387158f279ba>:27: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['TO'] = abs(data['TOV_x'] - data['TOV_y'])

2022-12-01 02:35:24,737:INFO:PyCaret RegressionExperiment
2022-12-01 02:35:24,737:INFO:Logging name: FullData
2022-12-01 02:35:24,738:INFO:ML Usecase: MLUsecase.REGRESSION
2022-12-01 02:35:24,738:INFO:version 3.0.0.rc4
2022-12-01 02:35:24,738:INFO:Initializing setup()
2022-12-01 02:35:24,738:INFO:self.USI: d28b
2022-12-01 02:35:24,738:INFO:self.variable_keys: {'fold_shuffle_param', 'y_test', 'pipeline', 'data', 'X', 'exp_id', 'master_model_container', '_available_plots', '_all_metrics', '_ml_usecase', 'log_plots_param', '_all_models', 'logging_param', 'idx', 'html_param', 'display_container', 'USI', 'target_param', 'fold_generator', '_gpu_n_jobs_param', 'n_jobs_param', 'transform_target_method_param', 'exp_name_log', 'X_test', 'variable_keys', 'gpu_param', 'memory', 'y_train', 'transform_target_param', 'y', 'X_train', '_all_models_internal', 'fold_groups_param', 'seed'}
2022-12-01 02:35:24,738:INFO:Checking environment
2022-12-01 02:35:24,738:INFO:python_version: 3.8.15
2022-12-01 02:35:24,739:INFO:python_build: ('default', 'Oct 12 2022 19:14:39')
2022-12-01 02:35:24,739:INFO:machine: x86_64
2022-12-01 02:35:24,739:INFO:platform: Linux-5.10.133+-x86_64-with-glibc2.27
2022-12-01 02:35:24,739:INFO:Memory: svmem(total=13616361472, available=11731042304, percent=13.8, used=1774297088, free=4761079808, active=841175040, inactive=7615778816, buffers=423079936, cached=6657904640, shared=1245184, slab=312156160)
2022-12-01 02:35:24,739:INFO:Physical Core: 1
2022-12-01 02:35:24,740:INFO:Logical Core: 2
2022-12-01 02:35:24,740:INFO:Checking libraries
2022-12-01 02:35:24,740:INFO:System:
2022-12-01 02:35:24,740:INFO:    python: 3.8.15 (default, Oct 12 2022, 19:14:39)  [GCC 7.5.0]
2022-12-01 02:35:24,740:INFO:executable: /usr/bin/python3
2022-12-01 02:35:24,740:INFO:   machine: Linux-5.10.133+-x86_64-with-glibc2.27
2022-12-01 02:35:24,740:INFO:PyCaret required dependencies:
2022-12-01 02:35:24,741:INFO:                 pip: 21.1.3
2022-12-01 02:35:24,741:INFO:          setuptools: 57.4.0
2022-12-01 02:35:24,741:INFO:             pycaret: 3.0.0rc4
2022-12-01 02:35:24,741:INFO:             IPython: 7.9.0
2022-12-01 02:35:24,741:INFO:          ipywidgets: 7.7.1
2022-12-01 02:35:24,741:INFO:                tqdm: 4.64.1
2022-12-01 02:35:24,741:INFO:               numpy: 1.21.6
2022-12-01 02:35:24,741:INFO:              pandas: 1.3.5
2022-12-01 02:35:24,741:INFO:              jinja2: 3.0.0
2022-12-01 02:35:24,741:INFO:               scipy: 1.7.3
2022-12-01 02:35:24,742:INFO:              joblib: 1.2.0
2022-12-01 02:35:24,742:INFO:             sklearn: 1.0.2
2022-12-01 02:35:24,742:INFO:                pyod: 1.0.6
2022-12-01 02:35:24,742:INFO:            imblearn: 0.8.1
2022-12-01 02:35:24,742:INFO:   category_encoders: 2.5.1.post0
2022-12-01 02:35:24,743:INFO:            lightgbm: 3.3.3
2022-12-01 02:35:24,743:INFO:               numba: 0.55.2
2022-12-01 02:35:24,743:INFO:            requests: 2.28.1
2022-12-01 02:35:24,743:INFO:          matplotlib: 3.6.2
2022-12-01 02:35:24,743:INFO:          scikitplot: 0.3.7
2022-12-01 02:35:24,744:INFO:         yellowbrick: 1.5
2022-12-01 02:35:24,744:INFO:              plotly: 5.5.0
2022-12-01 02:35:24,744:INFO:             kaleido: 0.2.1
2022-12-01 02:35:24,744:INFO:         statsmodels: 0.12.2
2022-12-01 02:35:24,744:INFO:              sktime: 0.13.4
2022-12-01 02:35:24,744:INFO:               tbats: 1.1.1
2022-12-01 02:35:24,744:INFO:            pmdarima: 1.8.5
2022-12-01 02:35:24,744:INFO:              psutil: 5.9.4
2022-12-01 02:35:24,745:INFO:PyCaret optional dependencies:
2022-12-01 02:35:24,745:INFO:                shap: Not installed
2022-12-01 02:35:24,745:INFO:           interpret: Not installed
2022-12-01 02:35:24,745:INFO:                umap: Not installed
2022-12-01 02:35:24,745:INFO:    pandas_profiling: 1.4.1
2022-12-01 02:35:24,746:INFO:  explainerdashboard: Not installed
2022-12-01 02:35:24,746:INFO:             autoviz: Not installed
2022-12-01 02:35:24,746:INFO:           fairlearn: Not installed
2022-12-01 02:35:24,746:INFO:             xgboost: 0.90
2022-12-01 02:35:24,746:INFO:            catboost: Not installed
2022-12-01 02:35:24,747:INFO:              kmodes: Not installed
2022-12-01 02:35:24,747:INFO:             mlxtend: 0.14.0
2022-12-01 02:35:24,747:INFO:       statsforecast: Not installed
2022-12-01 02:35:24,747:INFO:        tune_sklearn: Not installed
2022-12-01 02:35:24,748:INFO:                 ray: Not installed
2022-12-01 02:35:24,748:INFO:            hyperopt: 0.1.2
2022-12-01 02:35:24,748:INFO:              optuna: Not installed
2022-12-01 02:35:24,748:INFO:               skopt: Not installed
2022-12-01 02:35:24,748:INFO:              mlflow: Not installed
2022-12-01 02:35:24,748:INFO:              gradio: Not installed
2022-12-01 02:35:24,748:INFO:             fastapi: Not installed
2022-12-01 02:35:24,749:INFO:             uvicorn: Not installed
2022-12-01 02:35:24,749:INFO:              m2cgen: Not installed
2022-12-01 02:35:24,749:INFO:           evidently: Not installed
2022-12-01 02:35:24,749:INFO:                nltk: 3.7
2022-12-01 02:35:24,750:INFO:            pyLDAvis: Not installed
2022-12-01 02:35:24,750:INFO:              gensim: 3.6.0
2022-12-01 02:35:24,750:INFO:               spacy: 3.4.3
2022-12-01 02:35:24,750:INFO:           wordcloud: 1.8.2.2
2022-12-01 02:35:24,750:INFO:            textblob: 0.15.3
2022-12-01 02:35:24,750:INFO:               fugue: Not installed
2022-12-01 02:35:24,750:INFO:           streamlit: Not installed
2022-12-01 02:35:24,750:INFO:             prophet: 1.1.1
2022-12-01 02:35:24,751:INFO:None
2022-12-01 02:35:24,751:INFO:Set up data.
2022-12-01 02:35:24,758:INFO:Set up train/test split.
2022-12-01 02:35:24,761:INFO:Set up index.
2022-12-01 02:35:24,761:INFO:Set up folding strategy.
2022-12-01 02:35:24,762:INFO:Assigning column types.
2022-12-01 02:35:24,768:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-12-01 02:35:24,768:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-01 02:35:24,774:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:35:24,779:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:35:24,843:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:24,892:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:35:24,894:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:24,894:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:24,895:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:24,895:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-01 02:35:24,901:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:35:24,906:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:35:24,968:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:25,019:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:35:25,020:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:25,022:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:25,022:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:25,023:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-12-01 02:35:25,031:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:35:25,036:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:35:25,099:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:25,151:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:35:25,152:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:25,152:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:25,152:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:25,158:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:35:25,163:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:35:25,225:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:25,276:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:35:25,277:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:25,277:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:25,277:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:25,278:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-12-01 02:35:25,288:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:35:25,351:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:25,401:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:35:25,402:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:25,402:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:25,402:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:25,412:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:35:25,475:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:25,525:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:35:25,525:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:25,526:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:25,526:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:25,526:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-12-01 02:35:25,603:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:25,662:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:35:25,663:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:25,663:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:25,664:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:25,737:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:25,786:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:35:25,788:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:25,788:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:25,789:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:25,789:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-12-01 02:35:25,866:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:25,916:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:25,917:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:25,918:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:25,997:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:26,046:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:26,047:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:26,047:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:26,048:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-12-01 02:35:26,170:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:26,170:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:26,170:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:26,294:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:26,295:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:26,295:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:26,296:INFO:Preparing preprocessing pipeline...
2022-12-01 02:35:26,297:INFO:Set up simple imputation.
2022-12-01 02:35:26,298:INFO:Set up variance threshold.
2022-12-01 02:35:26,343:INFO:Finished creating preprocessing pipeline.
2022-12-01 02:35:26,349:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO',
                                             'Open_Line_ML_x'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-12-01 02:35:26,349:INFO:Creating final display dataframe.
2022-12-01 02:35:26,508:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 13)
4         Train data shape    (607, 13)
5          Test data shape    (261, 13)
6         Numeric features           12
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         d28b
2022-12-01 02:35:26,665:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:26,665:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:26,666:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:26,789:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:26,790:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:26,790:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:26,798:INFO:setup() successfully completed in 2.06s...............
2022-12-01 02:35:26,798:INFO:Initializing compare_models()
2022-12-01 02:35:26,798:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f496177bcd0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f496177bcd0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-12-01 02:35:26,799:INFO:Checking exceptions
2022-12-01 02:35:26,801:INFO:Preparing display monitor
2022-12-01 02:35:26,874:INFO:Initializing Linear Regression
2022-12-01 02:35:26,878:INFO:Total runtime is 8.24729601542155e-05 minutes
2022-12-01 02:35:26,890:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:26,891:INFO:Initializing create_model()
2022-12-01 02:35:26,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f496177bcd0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f49619cc1f0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:26,891:INFO:Checking exceptions
2022-12-01 02:35:26,894:INFO:Importing libraries
2022-12-01 02:35:26,894:INFO:Copying training dataset
2022-12-01 02:35:26,898:INFO:Defining folds
2022-12-01 02:35:26,899:INFO:Declaring metric variables
2022-12-01 02:35:26,912:INFO:Importing untrained model
2022-12-01 02:35:26,921:INFO:Linear Regression Imported successfully
2022-12-01 02:35:26,938:INFO:Starting cross validation
2022-12-01 02:35:26,943:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:28,430:INFO:Calculating mean and std
2022-12-01 02:35:28,432:INFO:Creating metrics dataframe
2022-12-01 02:35:28,439:INFO:Uploading results into container
2022-12-01 02:35:28,440:INFO:Uploading model into container now
2022-12-01 02:35:28,441:INFO:master_model_container: 1
2022-12-01 02:35:28,441:INFO:display_container: 2
2022-12-01 02:35:28,441:INFO:LinearRegression(n_jobs=-1)
2022-12-01 02:35:28,442:INFO:create_model() successfully completed......................................
2022-12-01 02:35:28,579:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:28,580:INFO:Creating metrics dataframe
2022-12-01 02:35:28,596:INFO:Initializing Lasso Regression
2022-12-01 02:35:28,596:INFO:Total runtime is 0.028710687160491945 minutes
2022-12-01 02:35:28,603:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:28,604:INFO:Initializing create_model()
2022-12-01 02:35:28,608:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f496177bcd0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f49619cc1f0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:28,609:INFO:Checking exceptions
2022-12-01 02:35:28,611:INFO:Importing libraries
2022-12-01 02:35:28,611:INFO:Copying training dataset
2022-12-01 02:35:28,615:INFO:Defining folds
2022-12-01 02:35:28,616:INFO:Declaring metric variables
2022-12-01 02:35:28,627:INFO:Importing untrained model
2022-12-01 02:35:28,638:INFO:Lasso Regression Imported successfully
2022-12-01 02:35:28,654:INFO:Starting cross validation
2022-12-01 02:35:28,655:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:28,923:INFO:Calculating mean and std
2022-12-01 02:35:28,925:INFO:Creating metrics dataframe
2022-12-01 02:35:28,932:INFO:Uploading results into container
2022-12-01 02:35:28,934:INFO:Uploading model into container now
2022-12-01 02:35:28,935:INFO:master_model_container: 2
2022-12-01 02:35:28,935:INFO:display_container: 2
2022-12-01 02:35:28,936:INFO:Lasso(random_state=123)
2022-12-01 02:35:28,936:INFO:create_model() successfully completed......................................
2022-12-01 02:35:29,069:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:29,069:INFO:Creating metrics dataframe
2022-12-01 02:35:29,091:INFO:Initializing Ridge Regression
2022-12-01 02:35:29,092:INFO:Total runtime is 0.036970802148183185 minutes
2022-12-01 02:35:29,099:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:29,105:INFO:Initializing create_model()
2022-12-01 02:35:29,106:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f496177bcd0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f49619cc1f0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:29,106:INFO:Checking exceptions
2022-12-01 02:35:29,109:INFO:Importing libraries
2022-12-01 02:35:29,109:INFO:Copying training dataset
2022-12-01 02:35:29,116:INFO:Defining folds
2022-12-01 02:35:29,116:INFO:Declaring metric variables
2022-12-01 02:35:29,124:INFO:Importing untrained model
2022-12-01 02:35:29,131:INFO:Ridge Regression Imported successfully
2022-12-01 02:35:29,146:INFO:Starting cross validation
2022-12-01 02:35:29,147:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:29,200:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.03719e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:35:29,205:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.05541e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:35:29,256:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.0964e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:35:29,258:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.04032e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:35:29,302:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.07071e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:35:29,325:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.08942e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:35:29,340:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.02164e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:35:29,364:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.05338e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:35:29,377:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.05414e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:35:29,400:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.04893e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:35:29,411:INFO:Calculating mean and std
2022-12-01 02:35:29,413:INFO:Creating metrics dataframe
2022-12-01 02:35:29,426:INFO:Uploading results into container
2022-12-01 02:35:29,428:INFO:Uploading model into container now
2022-12-01 02:35:29,429:INFO:master_model_container: 3
2022-12-01 02:35:29,429:INFO:display_container: 2
2022-12-01 02:35:29,429:INFO:Ridge(random_state=123)
2022-12-01 02:35:29,429:INFO:create_model() successfully completed......................................
2022-12-01 02:35:29,560:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:29,560:INFO:Creating metrics dataframe
2022-12-01 02:35:29,585:INFO:Initializing Elastic Net
2022-12-01 02:35:29,585:INFO:Total runtime is 0.0451970895131429 minutes
2022-12-01 02:35:29,593:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:29,594:INFO:Initializing create_model()
2022-12-01 02:35:29,595:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f496177bcd0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f49619cc1f0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:29,595:INFO:Checking exceptions
2022-12-01 02:35:29,598:INFO:Importing libraries
2022-12-01 02:35:29,598:INFO:Copying training dataset
2022-12-01 02:35:29,603:INFO:Defining folds
2022-12-01 02:35:29,606:INFO:Declaring metric variables
2022-12-01 02:35:29,619:INFO:Importing untrained model
2022-12-01 02:35:29,627:INFO:Elastic Net Imported successfully
2022-12-01 02:35:29,643:INFO:Starting cross validation
2022-12-01 02:35:29,644:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:29,907:INFO:Calculating mean and std
2022-12-01 02:35:29,909:INFO:Creating metrics dataframe
2022-12-01 02:35:29,919:INFO:Uploading results into container
2022-12-01 02:35:29,920:INFO:Uploading model into container now
2022-12-01 02:35:29,921:INFO:master_model_container: 4
2022-12-01 02:35:29,921:INFO:display_container: 2
2022-12-01 02:35:29,922:INFO:ElasticNet(random_state=123)
2022-12-01 02:35:29,922:INFO:create_model() successfully completed......................................
2022-12-01 02:35:30,053:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:30,054:INFO:Creating metrics dataframe
2022-12-01 02:35:30,074:INFO:Initializing Least Angle Regression
2022-12-01 02:35:30,074:INFO:Total runtime is 0.05334965387980143 minutes
2022-12-01 02:35:30,082:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:30,082:INFO:Initializing create_model()
2022-12-01 02:35:30,087:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f496177bcd0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f49619cc1f0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:30,087:INFO:Checking exceptions
2022-12-01 02:35:30,089:INFO:Importing libraries
2022-12-01 02:35:30,089:INFO:Copying training dataset
2022-12-01 02:35:30,093:INFO:Defining folds
2022-12-01 02:35:30,094:INFO:Declaring metric variables
2022-12-01 02:35:30,104:INFO:Importing untrained model
2022-12-01 02:35:30,117:INFO:Least Angle Regression Imported successfully
2022-12-01 02:35:30,138:INFO:Starting cross validation
2022-12-01 02:35:30,140:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:30,179:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:30,204:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:30,226:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:30,270:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:30,294:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:30,312:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:30,347:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:30,349:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:30,389:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:30,391:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:30,412:INFO:Calculating mean and std
2022-12-01 02:35:30,414:INFO:Creating metrics dataframe
2022-12-01 02:35:30,428:INFO:Uploading results into container
2022-12-01 02:35:30,428:INFO:Uploading model into container now
2022-12-01 02:35:30,429:INFO:master_model_container: 5
2022-12-01 02:35:30,429:INFO:display_container: 2
2022-12-01 02:35:30,430:INFO:Lars(random_state=123)
2022-12-01 02:35:30,430:INFO:create_model() successfully completed......................................
2022-12-01 02:35:30,557:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:30,557:INFO:Creating metrics dataframe
2022-12-01 02:35:30,576:INFO:Initializing Lasso Least Angle Regression
2022-12-01 02:35:30,579:INFO:Total runtime is 0.06176628669102986 minutes
2022-12-01 02:35:30,586:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:30,588:INFO:Initializing create_model()
2022-12-01 02:35:30,588:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f496177bcd0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f49619cc1f0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:30,588:INFO:Checking exceptions
2022-12-01 02:35:30,590:INFO:Importing libraries
2022-12-01 02:35:30,590:INFO:Copying training dataset
2022-12-01 02:35:30,595:INFO:Defining folds
2022-12-01 02:35:30,597:INFO:Declaring metric variables
2022-12-01 02:35:30,606:INFO:Importing untrained model
2022-12-01 02:35:30,616:INFO:Lasso Least Angle Regression Imported successfully
2022-12-01 02:35:30,632:INFO:Starting cross validation
2022-12-01 02:35:30,634:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:30,671:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:30,705:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:30,709:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:30,775:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:30,794:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:30,824:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:30,842:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:30,862:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:30,881:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:30,900:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:30,912:INFO:Calculating mean and std
2022-12-01 02:35:30,915:INFO:Creating metrics dataframe
2022-12-01 02:35:30,923:INFO:Uploading results into container
2022-12-01 02:35:30,928:INFO:Uploading model into container now
2022-12-01 02:35:30,929:INFO:master_model_container: 6
2022-12-01 02:35:30,929:INFO:display_container: 2
2022-12-01 02:35:30,930:INFO:LassoLars(random_state=123)
2022-12-01 02:35:30,930:INFO:create_model() successfully completed......................................
2022-12-01 02:35:31,061:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:31,062:INFO:Creating metrics dataframe
2022-12-01 02:35:31,085:INFO:Initializing Orthogonal Matching Pursuit
2022-12-01 02:35:31,085:INFO:Total runtime is 0.07019714514414468 minutes
2022-12-01 02:35:31,097:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:31,098:INFO:Initializing create_model()
2022-12-01 02:35:31,098:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f496177bcd0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f49619cc1f0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:31,098:INFO:Checking exceptions
2022-12-01 02:35:31,101:INFO:Importing libraries
2022-12-01 02:35:31,101:INFO:Copying training dataset
2022-12-01 02:35:31,106:INFO:Defining folds
2022-12-01 02:35:31,107:INFO:Declaring metric variables
2022-12-01 02:35:31,118:INFO:Importing untrained model
2022-12-01 02:35:31,131:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-01 02:35:31,146:INFO:Starting cross validation
2022-12-01 02:35:31,148:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:31,182:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:31,204:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:31,243:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:31,272:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:31,284:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:31,318:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:31,338:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:31,355:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:31,376:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:31,393:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:31,410:INFO:Calculating mean and std
2022-12-01 02:35:31,412:INFO:Creating metrics dataframe
2022-12-01 02:35:31,422:INFO:Uploading results into container
2022-12-01 02:35:31,428:INFO:Uploading model into container now
2022-12-01 02:35:31,428:INFO:master_model_container: 7
2022-12-01 02:35:31,428:INFO:display_container: 2
2022-12-01 02:35:31,429:INFO:OrthogonalMatchingPursuit()
2022-12-01 02:35:31,429:INFO:create_model() successfully completed......................................
2022-12-01 02:35:31,563:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:31,563:INFO:Creating metrics dataframe
2022-12-01 02:35:31,582:INFO:Initializing Bayesian Ridge
2022-12-01 02:35:31,583:INFO:Total runtime is 0.07848418951034544 minutes
2022-12-01 02:35:31,592:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:31,593:INFO:Initializing create_model()
2022-12-01 02:35:31,593:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f496177bcd0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f49619cc1f0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:31,593:INFO:Checking exceptions
2022-12-01 02:35:31,596:INFO:Importing libraries
2022-12-01 02:35:31,596:INFO:Copying training dataset
2022-12-01 02:35:31,602:INFO:Defining folds
2022-12-01 02:35:31,602:INFO:Declaring metric variables
2022-12-01 02:35:31,612:INFO:Importing untrained model
2022-12-01 02:35:31,622:INFO:Bayesian Ridge Imported successfully
2022-12-01 02:35:31,642:INFO:Starting cross validation
2022-12-01 02:35:31,644:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:31,955:INFO:Calculating mean and std
2022-12-01 02:35:31,957:INFO:Creating metrics dataframe
2022-12-01 02:35:31,965:INFO:Uploading results into container
2022-12-01 02:35:31,966:INFO:Uploading model into container now
2022-12-01 02:35:31,966:INFO:master_model_container: 8
2022-12-01 02:35:31,967:INFO:display_container: 2
2022-12-01 02:35:31,967:INFO:BayesianRidge()
2022-12-01 02:35:31,968:INFO:create_model() successfully completed......................................
2022-12-01 02:35:32,099:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:32,100:INFO:Creating metrics dataframe
2022-12-01 02:35:32,120:INFO:Initializing Passive Aggressive Regressor
2022-12-01 02:35:32,121:INFO:Total runtime is 0.08745950857798257 minutes
2022-12-01 02:35:32,131:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:32,132:INFO:Initializing create_model()
2022-12-01 02:35:32,132:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f496177bcd0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f49619cc1f0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:32,132:INFO:Checking exceptions
2022-12-01 02:35:32,134:INFO:Importing libraries
2022-12-01 02:35:32,135:INFO:Copying training dataset
2022-12-01 02:35:32,142:INFO:Defining folds
2022-12-01 02:35:32,142:INFO:Declaring metric variables
2022-12-01 02:35:32,150:INFO:Importing untrained model
2022-12-01 02:35:32,158:INFO:Passive Aggressive Regressor Imported successfully
2022-12-01 02:35:32,174:INFO:Starting cross validation
2022-12-01 02:35:32,176:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:32,427:INFO:Calculating mean and std
2022-12-01 02:35:32,431:INFO:Creating metrics dataframe
2022-12-01 02:35:32,436:INFO:Uploading results into container
2022-12-01 02:35:32,442:INFO:Uploading model into container now
2022-12-01 02:35:32,443:INFO:master_model_container: 9
2022-12-01 02:35:32,443:INFO:display_container: 2
2022-12-01 02:35:32,444:INFO:PassiveAggressiveRegressor(random_state=123)
2022-12-01 02:35:32,444:INFO:create_model() successfully completed......................................
2022-12-01 02:35:32,578:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:32,578:INFO:Creating metrics dataframe
2022-12-01 02:35:32,602:INFO:Initializing Huber Regressor
2022-12-01 02:35:32,603:INFO:Total runtime is 0.09548370838165282 minutes
2022-12-01 02:35:32,611:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:32,612:INFO:Initializing create_model()
2022-12-01 02:35:32,612:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f496177bcd0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f49619cc1f0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:32,615:INFO:Checking exceptions
2022-12-01 02:35:32,618:INFO:Importing libraries
2022-12-01 02:35:32,618:INFO:Copying training dataset
2022-12-01 02:35:32,622:INFO:Defining folds
2022-12-01 02:35:32,622:INFO:Declaring metric variables
2022-12-01 02:35:32,631:INFO:Importing untrained model
2022-12-01 02:35:32,644:INFO:Huber Regressor Imported successfully
2022-12-01 02:35:32,659:INFO:Starting cross validation
2022-12-01 02:35:32,662:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:32,750:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:35:32,788:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:35:32,883:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:35:32,898:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:35:32,989:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:35:33,000:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:35:33,083:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:35:33,088:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:35:33,175:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:35:33,179:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:35:33,195:INFO:Calculating mean and std
2022-12-01 02:35:33,197:INFO:Creating metrics dataframe
2022-12-01 02:35:33,213:INFO:Uploading results into container
2022-12-01 02:35:33,213:INFO:Uploading model into container now
2022-12-01 02:35:33,214:INFO:master_model_container: 10
2022-12-01 02:35:33,214:INFO:display_container: 2
2022-12-01 02:35:33,215:INFO:HuberRegressor()
2022-12-01 02:35:33,215:INFO:create_model() successfully completed......................................
2022-12-01 02:35:33,346:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:33,348:INFO:Creating metrics dataframe
2022-12-01 02:35:33,367:INFO:Initializing K Neighbors Regressor
2022-12-01 02:35:33,367:INFO:Total runtime is 0.10823268890380858 minutes
2022-12-01 02:35:33,376:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:33,377:INFO:Initializing create_model()
2022-12-01 02:35:33,377:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f496177bcd0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f49619cc1f0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:33,377:INFO:Checking exceptions
2022-12-01 02:35:33,380:INFO:Importing libraries
2022-12-01 02:35:33,380:INFO:Copying training dataset
2022-12-01 02:35:33,385:INFO:Defining folds
2022-12-01 02:35:33,386:INFO:Declaring metric variables
2022-12-01 02:35:33,396:INFO:Importing untrained model
2022-12-01 02:35:33,407:INFO:K Neighbors Regressor Imported successfully
2022-12-01 02:35:33,427:INFO:Starting cross validation
2022-12-01 02:35:33,428:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:33,737:INFO:Calculating mean and std
2022-12-01 02:35:33,739:INFO:Creating metrics dataframe
2022-12-01 02:35:33,747:INFO:Uploading results into container
2022-12-01 02:35:33,748:INFO:Uploading model into container now
2022-12-01 02:35:33,748:INFO:master_model_container: 11
2022-12-01 02:35:33,749:INFO:display_container: 2
2022-12-01 02:35:33,749:INFO:KNeighborsRegressor(n_jobs=-1)
2022-12-01 02:35:33,749:INFO:create_model() successfully completed......................................
2022-12-01 02:35:33,881:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:33,881:INFO:Creating metrics dataframe
2022-12-01 02:35:33,900:INFO:Initializing Decision Tree Regressor
2022-12-01 02:35:33,900:INFO:Total runtime is 0.11711577177047727 minutes
2022-12-01 02:35:33,908:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:33,910:INFO:Initializing create_model()
2022-12-01 02:35:33,911:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f496177bcd0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f49619cc1f0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:33,913:INFO:Checking exceptions
2022-12-01 02:35:33,916:INFO:Importing libraries
2022-12-01 02:35:33,916:INFO:Copying training dataset
2022-12-01 02:35:33,920:INFO:Defining folds
2022-12-01 02:35:33,921:INFO:Declaring metric variables
2022-12-01 02:35:33,930:INFO:Importing untrained model
2022-12-01 02:35:33,941:INFO:Decision Tree Regressor Imported successfully
2022-12-01 02:35:33,959:INFO:Starting cross validation
2022-12-01 02:35:33,962:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:34,255:INFO:Calculating mean and std
2022-12-01 02:35:34,257:INFO:Creating metrics dataframe
2022-12-01 02:35:34,269:INFO:Uploading results into container
2022-12-01 02:35:34,270:INFO:Uploading model into container now
2022-12-01 02:35:34,271:INFO:master_model_container: 12
2022-12-01 02:35:34,271:INFO:display_container: 2
2022-12-01 02:35:34,271:INFO:DecisionTreeRegressor(random_state=123)
2022-12-01 02:35:34,272:INFO:create_model() successfully completed......................................
2022-12-01 02:35:34,400:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:34,400:INFO:Creating metrics dataframe
2022-12-01 02:35:34,421:INFO:Initializing Random Forest Regressor
2022-12-01 02:35:34,421:INFO:Total runtime is 0.12579745451609292 minutes
2022-12-01 02:35:34,430:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:34,433:INFO:Initializing create_model()
2022-12-01 02:35:34,434:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f496177bcd0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f49619cc1f0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:34,434:INFO:Checking exceptions
2022-12-01 02:35:34,436:INFO:Importing libraries
2022-12-01 02:35:34,436:INFO:Copying training dataset
2022-12-01 02:35:34,442:INFO:Defining folds
2022-12-01 02:35:34,442:INFO:Declaring metric variables
2022-12-01 02:35:34,451:INFO:Importing untrained model
2022-12-01 02:35:34,461:INFO:Random Forest Regressor Imported successfully
2022-12-01 02:35:34,475:INFO:Starting cross validation
2022-12-01 02:35:34,477:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:38,915:INFO:Calculating mean and std
2022-12-01 02:35:38,919:INFO:Creating metrics dataframe
2022-12-01 02:35:38,932:INFO:Uploading results into container
2022-12-01 02:35:38,932:INFO:Uploading model into container now
2022-12-01 02:35:38,933:INFO:master_model_container: 13
2022-12-01 02:35:38,933:INFO:display_container: 2
2022-12-01 02:35:38,934:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-12-01 02:35:38,934:INFO:create_model() successfully completed......................................
2022-12-01 02:35:39,071:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:39,071:INFO:Creating metrics dataframe
2022-12-01 02:35:39,090:INFO:Initializing Extra Trees Regressor
2022-12-01 02:35:39,090:INFO:Total runtime is 0.20360837380091348 minutes
2022-12-01 02:35:39,097:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:39,099:INFO:Initializing create_model()
2022-12-01 02:35:39,099:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f496177bcd0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f49619cc1f0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:39,099:INFO:Checking exceptions
2022-12-01 02:35:39,102:INFO:Importing libraries
2022-12-01 02:35:39,102:INFO:Copying training dataset
2022-12-01 02:35:39,107:INFO:Defining folds
2022-12-01 02:35:39,111:INFO:Declaring metric variables
2022-12-01 02:35:39,123:INFO:Importing untrained model
2022-12-01 02:35:39,129:INFO:Extra Trees Regressor Imported successfully
2022-12-01 02:35:39,143:INFO:Starting cross validation
2022-12-01 02:35:39,145:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:41,362:INFO:Calculating mean and std
2022-12-01 02:35:41,368:INFO:Creating metrics dataframe
2022-12-01 02:35:41,380:INFO:Uploading results into container
2022-12-01 02:35:41,381:INFO:Uploading model into container now
2022-12-01 02:35:41,381:INFO:master_model_container: 14
2022-12-01 02:35:41,381:INFO:display_container: 2
2022-12-01 02:35:41,382:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-12-01 02:35:41,382:INFO:create_model() successfully completed......................................
2022-12-01 02:35:41,516:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:41,517:INFO:Creating metrics dataframe
2022-12-01 02:35:41,537:INFO:Initializing AdaBoost Regressor
2022-12-01 02:35:41,539:INFO:Total runtime is 0.24443206389745076 minutes
2022-12-01 02:35:41,548:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:41,548:INFO:Initializing create_model()
2022-12-01 02:35:41,548:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f496177bcd0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f49619cc1f0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:41,549:INFO:Checking exceptions
2022-12-01 02:35:41,551:INFO:Importing libraries
2022-12-01 02:35:41,551:INFO:Copying training dataset
2022-12-01 02:35:41,558:INFO:Defining folds
2022-12-01 02:35:41,559:INFO:Declaring metric variables
2022-12-01 02:35:41,567:INFO:Importing untrained model
2022-12-01 02:35:41,576:INFO:AdaBoost Regressor Imported successfully
2022-12-01 02:35:41,593:INFO:Starting cross validation
2022-12-01 02:35:41,595:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:42,691:INFO:Calculating mean and std
2022-12-01 02:35:42,694:INFO:Creating metrics dataframe
2022-12-01 02:35:42,706:INFO:Uploading results into container
2022-12-01 02:35:42,707:INFO:Uploading model into container now
2022-12-01 02:35:42,708:INFO:master_model_container: 15
2022-12-01 02:35:42,708:INFO:display_container: 2
2022-12-01 02:35:42,708:INFO:AdaBoostRegressor(random_state=123)
2022-12-01 02:35:42,708:INFO:create_model() successfully completed......................................
2022-12-01 02:35:42,838:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:42,838:INFO:Creating metrics dataframe
2022-12-01 02:35:42,862:INFO:Initializing Gradient Boosting Regressor
2022-12-01 02:35:42,862:INFO:Total runtime is 0.26648308833440143 minutes
2022-12-01 02:35:42,872:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:42,873:INFO:Initializing create_model()
2022-12-01 02:35:42,873:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f496177bcd0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f49619cc1f0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:42,874:INFO:Checking exceptions
2022-12-01 02:35:42,878:INFO:Importing libraries
2022-12-01 02:35:42,879:INFO:Copying training dataset
2022-12-01 02:35:42,883:INFO:Defining folds
2022-12-01 02:35:42,884:INFO:Declaring metric variables
2022-12-01 02:35:42,897:INFO:Importing untrained model
2022-12-01 02:35:42,906:INFO:Gradient Boosting Regressor Imported successfully
2022-12-01 02:35:42,923:INFO:Starting cross validation
2022-12-01 02:35:42,926:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:44,680:INFO:Calculating mean and std
2022-12-01 02:35:44,683:INFO:Creating metrics dataframe
2022-12-01 02:35:44,691:INFO:Uploading results into container
2022-12-01 02:35:44,692:INFO:Uploading model into container now
2022-12-01 02:35:44,692:INFO:master_model_container: 16
2022-12-01 02:35:44,693:INFO:display_container: 2
2022-12-01 02:35:44,693:INFO:GradientBoostingRegressor(random_state=123)
2022-12-01 02:35:44,694:INFO:create_model() successfully completed......................................
2022-12-01 02:35:44,823:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:44,824:INFO:Creating metrics dataframe
2022-12-01 02:35:44,848:INFO:Initializing Light Gradient Boosting Machine
2022-12-01 02:35:44,849:INFO:Total runtime is 0.29959151744842527 minutes
2022-12-01 02:35:44,857:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:44,858:INFO:Initializing create_model()
2022-12-01 02:35:44,858:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f496177bcd0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f49619cc1f0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:44,859:INFO:Checking exceptions
2022-12-01 02:35:44,862:INFO:Importing libraries
2022-12-01 02:35:44,862:INFO:Copying training dataset
2022-12-01 02:35:44,868:INFO:Defining folds
2022-12-01 02:35:44,868:INFO:Declaring metric variables
2022-12-01 02:35:44,880:INFO:Importing untrained model
2022-12-01 02:35:44,888:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-01 02:35:44,907:INFO:Starting cross validation
2022-12-01 02:35:44,909:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:45,725:INFO:Calculating mean and std
2022-12-01 02:35:45,728:INFO:Creating metrics dataframe
2022-12-01 02:35:45,736:INFO:Uploading results into container
2022-12-01 02:35:45,736:INFO:Uploading model into container now
2022-12-01 02:35:45,737:INFO:master_model_container: 17
2022-12-01 02:35:45,737:INFO:display_container: 2
2022-12-01 02:35:45,738:INFO:LGBMRegressor(random_state=123)
2022-12-01 02:35:45,739:INFO:create_model() successfully completed......................................
2022-12-01 02:35:45,871:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:45,874:INFO:Creating metrics dataframe
2022-12-01 02:35:45,894:INFO:Initializing Dummy Regressor
2022-12-01 02:35:45,895:INFO:Total runtime is 0.31703247626622516 minutes
2022-12-01 02:35:45,905:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:45,906:INFO:Initializing create_model()
2022-12-01 02:35:45,906:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f496177bcd0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f49619cc1f0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:45,907:INFO:Checking exceptions
2022-12-01 02:35:45,909:INFO:Importing libraries
2022-12-01 02:35:45,909:INFO:Copying training dataset
2022-12-01 02:35:45,915:INFO:Defining folds
2022-12-01 02:35:45,915:INFO:Declaring metric variables
2022-12-01 02:35:45,924:INFO:Importing untrained model
2022-12-01 02:35:45,938:INFO:Dummy Regressor Imported successfully
2022-12-01 02:35:45,955:INFO:Starting cross validation
2022-12-01 02:35:45,958:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:46,185:INFO:Calculating mean and std
2022-12-01 02:35:46,191:INFO:Creating metrics dataframe
2022-12-01 02:35:46,199:INFO:Uploading results into container
2022-12-01 02:35:46,203:INFO:Uploading model into container now
2022-12-01 02:35:46,205:INFO:master_model_container: 18
2022-12-01 02:35:46,205:INFO:display_container: 2
2022-12-01 02:35:46,205:INFO:DummyRegressor()
2022-12-01 02:35:46,205:INFO:create_model() successfully completed......................................
2022-12-01 02:35:46,334:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:46,334:INFO:Creating metrics dataframe
2022-12-01 02:35:46,380:INFO:Initializing create_model()
2022-12-01 02:35:46,380:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f496177bcd0>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:46,381:INFO:Checking exceptions
2022-12-01 02:35:46,386:INFO:Importing libraries
2022-12-01 02:35:46,386:INFO:Copying training dataset
2022-12-01 02:35:46,389:INFO:Defining folds
2022-12-01 02:35:46,390:INFO:Declaring metric variables
2022-12-01 02:35:46,390:INFO:Importing untrained model
2022-12-01 02:35:46,390:INFO:Declaring custom model
2022-12-01 02:35:46,391:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-01 02:35:46,393:INFO:Cross validation set to False
2022-12-01 02:35:46,393:INFO:Fitting Model
2022-12-01 02:35:46,424:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:46,427:INFO:OrthogonalMatchingPursuit()
2022-12-01 02:35:46,427:INFO:create_model() successfully completed......................................
2022-12-01 02:35:46,638:INFO:master_model_container: 18
2022-12-01 02:35:46,639:INFO:display_container: 2
2022-12-01 02:35:46,639:INFO:OrthogonalMatchingPursuit()
2022-12-01 02:35:46,640:INFO:compare_models() successfully completed......................................
2022-12-01 02:35:51,843:WARNING:<ipython-input-18-387158f279ba>:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q1'] = abs(data['PTS_QTR1_x'] - data['PTS_QTR1_y'])

2022-12-01 02:35:51,844:WARNING:<ipython-input-18-387158f279ba>:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q2'] = abs(data['PTS_QTR2_x'] - data['PTS_QTR2_y'])

2022-12-01 02:35:51,845:WARNING:<ipython-input-18-387158f279ba>:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q3'] = abs(data['PTS_QTR3_x'] - data['PTS_QTR3_y'])

2022-12-01 02:35:51,846:WARNING:<ipython-input-18-387158f279ba>:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q4'] = abs(data['PTS_QTR4_x'] - data['PTS_QTR4_y'])

2022-12-01 02:35:51,847:WARNING:<ipython-input-18-387158f279ba>:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['PTS'] = abs(data['PTS_x'] - data['PTS_y'])

2022-12-01 02:35:51,848:WARNING:<ipython-input-18-387158f279ba>:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FG_PCT'] = abs(data['FG_PCT_x'] - data['FG_PCT_y'])

2022-12-01 02:35:51,849:WARNING:<ipython-input-18-387158f279ba>:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT'] = abs(data['FT_PCT_x'] - data['FT_PCT_y'])

2022-12-01 02:35:51,850:WARNING:<ipython-input-18-387158f279ba>:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT3'] = abs(data['FG3_PCT_x'] - data['FG3_PCT_y'])

2022-12-01 02:35:51,851:WARNING:<ipython-input-18-387158f279ba>:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['AST'] = abs(data['AST_x'] - data['AST_y'])

2022-12-01 02:35:51,852:WARNING:<ipython-input-18-387158f279ba>:26: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['REB'] = abs(data['REB_x'] - data['REB_y'])

2022-12-01 02:35:51,853:WARNING:<ipython-input-18-387158f279ba>:27: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['TO'] = abs(data['TOV_x'] - data['TOV_y'])

2022-12-01 02:35:51,858:INFO:PyCaret RegressionExperiment
2022-12-01 02:35:51,858:INFO:Logging name: FullData
2022-12-01 02:35:51,858:INFO:ML Usecase: MLUsecase.REGRESSION
2022-12-01 02:35:51,858:INFO:version 3.0.0.rc4
2022-12-01 02:35:51,858:INFO:Initializing setup()
2022-12-01 02:35:51,858:INFO:self.USI: bef7
2022-12-01 02:35:51,859:INFO:self.variable_keys: {'fold_shuffle_param', 'y_test', 'pipeline', 'data', 'X', 'exp_id', 'master_model_container', '_available_plots', '_all_metrics', '_ml_usecase', 'log_plots_param', '_all_models', 'logging_param', 'idx', 'html_param', 'display_container', 'USI', 'target_param', 'fold_generator', '_gpu_n_jobs_param', 'n_jobs_param', 'transform_target_method_param', 'exp_name_log', 'X_test', 'variable_keys', 'gpu_param', 'memory', 'y_train', 'transform_target_param', 'y', 'X_train', '_all_models_internal', 'fold_groups_param', 'seed'}
2022-12-01 02:35:51,859:INFO:Checking environment
2022-12-01 02:35:51,859:INFO:python_version: 3.8.15
2022-12-01 02:35:51,859:INFO:python_build: ('default', 'Oct 12 2022 19:14:39')
2022-12-01 02:35:51,859:INFO:machine: x86_64
2022-12-01 02:35:51,859:INFO:platform: Linux-5.10.133+-x86_64-with-glibc2.27
2022-12-01 02:35:51,860:INFO:Memory: svmem(total=13616361472, available=11729842176, percent=13.9, used=1782550528, free=4744085504, active=843067392, inactive=7629426688, buffers=423260160, cached=6666465280, shared=1245184, slab=313106432)
2022-12-01 02:35:51,860:INFO:Physical Core: 1
2022-12-01 02:35:51,860:INFO:Logical Core: 2
2022-12-01 02:35:51,860:INFO:Checking libraries
2022-12-01 02:35:51,861:INFO:System:
2022-12-01 02:35:51,861:INFO:    python: 3.8.15 (default, Oct 12 2022, 19:14:39)  [GCC 7.5.0]
2022-12-01 02:35:51,861:INFO:executable: /usr/bin/python3
2022-12-01 02:35:51,861:INFO:   machine: Linux-5.10.133+-x86_64-with-glibc2.27
2022-12-01 02:35:51,861:INFO:PyCaret required dependencies:
2022-12-01 02:35:51,861:INFO:                 pip: 21.1.3
2022-12-01 02:35:51,862:INFO:          setuptools: 57.4.0
2022-12-01 02:35:51,862:INFO:             pycaret: 3.0.0rc4
2022-12-01 02:35:51,862:INFO:             IPython: 7.9.0
2022-12-01 02:35:51,862:INFO:          ipywidgets: 7.7.1
2022-12-01 02:35:51,862:INFO:                tqdm: 4.64.1
2022-12-01 02:35:51,862:INFO:               numpy: 1.21.6
2022-12-01 02:35:51,862:INFO:              pandas: 1.3.5
2022-12-01 02:35:51,862:INFO:              jinja2: 3.0.0
2022-12-01 02:35:51,863:INFO:               scipy: 1.7.3
2022-12-01 02:35:51,863:INFO:              joblib: 1.2.0
2022-12-01 02:35:51,863:INFO:             sklearn: 1.0.2
2022-12-01 02:35:51,863:INFO:                pyod: 1.0.6
2022-12-01 02:35:51,863:INFO:            imblearn: 0.8.1
2022-12-01 02:35:51,863:INFO:   category_encoders: 2.5.1.post0
2022-12-01 02:35:51,863:INFO:            lightgbm: 3.3.3
2022-12-01 02:35:51,863:INFO:               numba: 0.55.2
2022-12-01 02:35:51,864:INFO:            requests: 2.28.1
2022-12-01 02:35:51,864:INFO:          matplotlib: 3.6.2
2022-12-01 02:35:51,864:INFO:          scikitplot: 0.3.7
2022-12-01 02:35:51,864:INFO:         yellowbrick: 1.5
2022-12-01 02:35:51,864:INFO:              plotly: 5.5.0
2022-12-01 02:35:51,864:INFO:             kaleido: 0.2.1
2022-12-01 02:35:51,864:INFO:         statsmodels: 0.12.2
2022-12-01 02:35:51,864:INFO:              sktime: 0.13.4
2022-12-01 02:35:51,865:INFO:               tbats: 1.1.1
2022-12-01 02:35:51,865:INFO:            pmdarima: 1.8.5
2022-12-01 02:35:51,865:INFO:              psutil: 5.9.4
2022-12-01 02:35:51,865:INFO:PyCaret optional dependencies:
2022-12-01 02:35:51,865:INFO:                shap: Not installed
2022-12-01 02:35:51,865:INFO:           interpret: Not installed
2022-12-01 02:35:51,865:INFO:                umap: Not installed
2022-12-01 02:35:51,866:INFO:    pandas_profiling: 1.4.1
2022-12-01 02:35:51,866:INFO:  explainerdashboard: Not installed
2022-12-01 02:35:51,866:INFO:             autoviz: Not installed
2022-12-01 02:35:51,866:INFO:           fairlearn: Not installed
2022-12-01 02:35:51,866:INFO:             xgboost: 0.90
2022-12-01 02:35:51,867:INFO:            catboost: Not installed
2022-12-01 02:35:51,867:INFO:              kmodes: Not installed
2022-12-01 02:35:51,867:INFO:             mlxtend: 0.14.0
2022-12-01 02:35:51,867:INFO:       statsforecast: Not installed
2022-12-01 02:35:51,867:INFO:        tune_sklearn: Not installed
2022-12-01 02:35:51,867:INFO:                 ray: Not installed
2022-12-01 02:35:51,868:INFO:            hyperopt: 0.1.2
2022-12-01 02:35:51,868:INFO:              optuna: Not installed
2022-12-01 02:35:51,868:INFO:               skopt: Not installed
2022-12-01 02:35:51,868:INFO:              mlflow: Not installed
2022-12-01 02:35:51,868:INFO:              gradio: Not installed
2022-12-01 02:35:51,868:INFO:             fastapi: Not installed
2022-12-01 02:35:51,868:INFO:             uvicorn: Not installed
2022-12-01 02:35:51,868:INFO:              m2cgen: Not installed
2022-12-01 02:35:51,869:INFO:           evidently: Not installed
2022-12-01 02:35:51,869:INFO:                nltk: 3.7
2022-12-01 02:35:51,869:INFO:            pyLDAvis: Not installed
2022-12-01 02:35:51,869:INFO:              gensim: 3.6.0
2022-12-01 02:35:51,869:INFO:               spacy: 3.4.3
2022-12-01 02:35:51,869:INFO:           wordcloud: 1.8.2.2
2022-12-01 02:35:51,869:INFO:            textblob: 0.15.3
2022-12-01 02:35:51,869:INFO:               fugue: Not installed
2022-12-01 02:35:51,869:INFO:           streamlit: Not installed
2022-12-01 02:35:51,869:INFO:             prophet: 1.1.1
2022-12-01 02:35:51,870:INFO:None
2022-12-01 02:35:51,870:INFO:Set up data.
2022-12-01 02:35:51,876:INFO:Set up train/test split.
2022-12-01 02:35:51,879:INFO:Set up index.
2022-12-01 02:35:51,880:INFO:Set up folding strategy.
2022-12-01 02:35:51,880:INFO:Assigning column types.
2022-12-01 02:35:51,885:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-12-01 02:35:51,886:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-01 02:35:51,891:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:35:51,895:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:35:51,954:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,001:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,001:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:52,002:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:52,002:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:52,002:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,007:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,012:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,072:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,122:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,123:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:52,123:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:52,124:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:52,124:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-12-01 02:35:52,129:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,134:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,198:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,250:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,251:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:52,252:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:52,252:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:52,257:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,262:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,325:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,385:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,385:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:52,386:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:52,386:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:52,386:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-12-01 02:35:52,397:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,461:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,542:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,543:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:52,543:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:52,544:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:52,554:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,618:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,667:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,671:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:52,671:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:52,671:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:52,672:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-12-01 02:35:52,745:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,807:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,808:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:52,808:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:52,808:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:52,882:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,932:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:35:52,932:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:52,933:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:52,933:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:52,933:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-12-01 02:35:53,008:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:53,059:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:53,059:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:53,060:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:53,137:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:35:53,188:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:53,188:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:53,189:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:53,189:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-12-01 02:35:53,315:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:53,315:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:53,316:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:53,450:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:53,450:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:53,450:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:53,451:INFO:Preparing preprocessing pipeline...
2022-12-01 02:35:53,453:INFO:Set up simple imputation.
2022-12-01 02:35:53,453:INFO:Set up variance threshold.
2022-12-01 02:35:53,491:INFO:Finished creating preprocessing pipeline.
2022-12-01 02:35:53,497:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO',
                                             'Open_Line_ML_x'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-12-01 02:35:53,498:INFO:Creating final display dataframe.
2022-12-01 02:35:53,657:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape   (1229, 13)
4         Train data shape    (860, 13)
5          Test data shape    (369, 13)
6         Numeric features           12
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         bef7
2022-12-01 02:35:53,800:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:53,801:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:53,801:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:53,928:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:35:53,929:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:35:53,929:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:35:53,936:INFO:setup() successfully completed in 2.08s...............
2022-12-01 02:35:53,936:INFO:Initializing compare_models()
2022-12-01 02:35:53,936:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961c9f340>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f4961c9f340>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-12-01 02:35:53,936:INFO:Checking exceptions
2022-12-01 02:35:53,937:INFO:Preparing display monitor
2022-12-01 02:35:54,026:INFO:Initializing Linear Regression
2022-12-01 02:35:54,026:INFO:Total runtime is 6.389617919921875e-06 minutes
2022-12-01 02:35:54,035:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:54,035:INFO:Initializing create_model()
2022-12-01 02:35:54,036:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961c9f340>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc53ee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:54,036:INFO:Checking exceptions
2022-12-01 02:35:54,039:INFO:Importing libraries
2022-12-01 02:35:54,039:INFO:Copying training dataset
2022-12-01 02:35:54,044:INFO:Defining folds
2022-12-01 02:35:54,044:INFO:Declaring metric variables
2022-12-01 02:35:54,053:INFO:Importing untrained model
2022-12-01 02:35:54,061:INFO:Linear Regression Imported successfully
2022-12-01 02:35:54,078:INFO:Starting cross validation
2022-12-01 02:35:54,083:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:55,535:INFO:Calculating mean and std
2022-12-01 02:35:55,538:INFO:Creating metrics dataframe
2022-12-01 02:35:55,549:INFO:Uploading results into container
2022-12-01 02:35:55,553:INFO:Uploading model into container now
2022-12-01 02:35:55,553:INFO:master_model_container: 1
2022-12-01 02:35:55,554:INFO:display_container: 2
2022-12-01 02:35:55,554:INFO:LinearRegression(n_jobs=-1)
2022-12-01 02:35:55,554:INFO:create_model() successfully completed......................................
2022-12-01 02:35:55,697:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:55,698:INFO:Creating metrics dataframe
2022-12-01 02:35:55,714:INFO:Initializing Lasso Regression
2022-12-01 02:35:55,714:INFO:Total runtime is 0.028143107891082764 minutes
2022-12-01 02:35:55,723:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:55,724:INFO:Initializing create_model()
2022-12-01 02:35:55,724:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961c9f340>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc53ee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:55,724:INFO:Checking exceptions
2022-12-01 02:35:55,727:INFO:Importing libraries
2022-12-01 02:35:55,728:INFO:Copying training dataset
2022-12-01 02:35:55,736:INFO:Defining folds
2022-12-01 02:35:55,737:INFO:Declaring metric variables
2022-12-01 02:35:55,749:INFO:Importing untrained model
2022-12-01 02:35:55,757:INFO:Lasso Regression Imported successfully
2022-12-01 02:35:55,773:INFO:Starting cross validation
2022-12-01 02:35:55,775:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:56,051:INFO:Calculating mean and std
2022-12-01 02:35:56,053:INFO:Creating metrics dataframe
2022-12-01 02:35:56,061:INFO:Uploading results into container
2022-12-01 02:35:56,062:INFO:Uploading model into container now
2022-12-01 02:35:56,062:INFO:master_model_container: 2
2022-12-01 02:35:56,063:INFO:display_container: 2
2022-12-01 02:35:56,063:INFO:Lasso(random_state=123)
2022-12-01 02:35:56,063:INFO:create_model() successfully completed......................................
2022-12-01 02:35:56,197:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:56,197:INFO:Creating metrics dataframe
2022-12-01 02:35:56,216:INFO:Initializing Ridge Regression
2022-12-01 02:35:56,216:INFO:Total runtime is 0.03650797605514526 minutes
2022-12-01 02:35:56,224:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:56,225:INFO:Initializing create_model()
2022-12-01 02:35:56,225:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961c9f340>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc53ee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:56,225:INFO:Checking exceptions
2022-12-01 02:35:56,228:INFO:Importing libraries
2022-12-01 02:35:56,228:INFO:Copying training dataset
2022-12-01 02:35:56,234:INFO:Defining folds
2022-12-01 02:35:56,234:INFO:Declaring metric variables
2022-12-01 02:35:56,247:INFO:Importing untrained model
2022-12-01 02:35:56,256:INFO:Ridge Regression Imported successfully
2022-12-01 02:35:56,270:INFO:Starting cross validation
2022-12-01 02:35:56,272:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:56,541:INFO:Calculating mean and std
2022-12-01 02:35:56,543:INFO:Creating metrics dataframe
2022-12-01 02:35:56,553:INFO:Uploading results into container
2022-12-01 02:35:56,554:INFO:Uploading model into container now
2022-12-01 02:35:56,555:INFO:master_model_container: 3
2022-12-01 02:35:56,555:INFO:display_container: 2
2022-12-01 02:35:56,555:INFO:Ridge(random_state=123)
2022-12-01 02:35:56,556:INFO:create_model() successfully completed......................................
2022-12-01 02:35:56,688:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:56,688:INFO:Creating metrics dataframe
2022-12-01 02:35:56,706:INFO:Initializing Elastic Net
2022-12-01 02:35:56,707:INFO:Total runtime is 0.04467753966649373 minutes
2022-12-01 02:35:56,714:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:56,715:INFO:Initializing create_model()
2022-12-01 02:35:56,715:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961c9f340>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc53ee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:56,716:INFO:Checking exceptions
2022-12-01 02:35:56,719:INFO:Importing libraries
2022-12-01 02:35:56,719:INFO:Copying training dataset
2022-12-01 02:35:56,724:INFO:Defining folds
2022-12-01 02:35:56,725:INFO:Declaring metric variables
2022-12-01 02:35:56,739:INFO:Importing untrained model
2022-12-01 02:35:56,746:INFO:Elastic Net Imported successfully
2022-12-01 02:35:56,762:INFO:Starting cross validation
2022-12-01 02:35:56,764:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:57,032:INFO:Calculating mean and std
2022-12-01 02:35:57,034:INFO:Creating metrics dataframe
2022-12-01 02:35:57,043:INFO:Uploading results into container
2022-12-01 02:35:57,044:INFO:Uploading model into container now
2022-12-01 02:35:57,050:INFO:master_model_container: 4
2022-12-01 02:35:57,050:INFO:display_container: 2
2022-12-01 02:35:57,051:INFO:ElasticNet(random_state=123)
2022-12-01 02:35:57,051:INFO:create_model() successfully completed......................................
2022-12-01 02:35:57,177:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:57,178:INFO:Creating metrics dataframe
2022-12-01 02:35:57,194:INFO:Initializing Least Angle Regression
2022-12-01 02:35:57,195:INFO:Total runtime is 0.05281298160552978 minutes
2022-12-01 02:35:57,203:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:57,203:INFO:Initializing create_model()
2022-12-01 02:35:57,204:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961c9f340>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc53ee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:57,204:INFO:Checking exceptions
2022-12-01 02:35:57,205:INFO:Importing libraries
2022-12-01 02:35:57,205:INFO:Copying training dataset
2022-12-01 02:35:57,209:INFO:Defining folds
2022-12-01 02:35:57,211:INFO:Declaring metric variables
2022-12-01 02:35:57,222:INFO:Importing untrained model
2022-12-01 02:35:57,231:INFO:Least Angle Regression Imported successfully
2022-12-01 02:35:57,248:INFO:Starting cross validation
2022-12-01 02:35:57,250:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:57,282:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:57,304:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:57,328:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:57,365:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:57,385:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:57,420:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:57,425:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:57,459:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:57,465:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:57,502:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:57,516:INFO:Calculating mean and std
2022-12-01 02:35:57,520:INFO:Creating metrics dataframe
2022-12-01 02:35:57,529:INFO:Uploading results into container
2022-12-01 02:35:57,530:INFO:Uploading model into container now
2022-12-01 02:35:57,531:INFO:master_model_container: 5
2022-12-01 02:35:57,531:INFO:display_container: 2
2022-12-01 02:35:57,531:INFO:Lars(random_state=123)
2022-12-01 02:35:57,531:INFO:create_model() successfully completed......................................
2022-12-01 02:35:57,672:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:57,672:INFO:Creating metrics dataframe
2022-12-01 02:35:57,690:INFO:Initializing Lasso Least Angle Regression
2022-12-01 02:35:57,690:INFO:Total runtime is 0.0610714594523112 minutes
2022-12-01 02:35:57,698:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:57,698:INFO:Initializing create_model()
2022-12-01 02:35:57,699:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961c9f340>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc53ee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:57,699:INFO:Checking exceptions
2022-12-01 02:35:57,701:INFO:Importing libraries
2022-12-01 02:35:57,701:INFO:Copying training dataset
2022-12-01 02:35:57,708:INFO:Defining folds
2022-12-01 02:35:57,708:INFO:Declaring metric variables
2022-12-01 02:35:57,715:INFO:Importing untrained model
2022-12-01 02:35:57,723:INFO:Lasso Least Angle Regression Imported successfully
2022-12-01 02:35:57,737:INFO:Starting cross validation
2022-12-01 02:35:57,738:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:57,774:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:57,800:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:57,842:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:57,847:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:57,886:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:57,924:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:57,924:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:57,963:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:57,966:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:57,994:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:35:58,005:INFO:Calculating mean and std
2022-12-01 02:35:58,007:INFO:Creating metrics dataframe
2022-12-01 02:35:58,022:INFO:Uploading results into container
2022-12-01 02:35:58,023:INFO:Uploading model into container now
2022-12-01 02:35:58,024:INFO:master_model_container: 6
2022-12-01 02:35:58,024:INFO:display_container: 2
2022-12-01 02:35:58,026:INFO:LassoLars(random_state=123)
2022-12-01 02:35:58,027:INFO:create_model() successfully completed......................................
2022-12-01 02:35:58,157:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:58,157:INFO:Creating metrics dataframe
2022-12-01 02:35:58,175:INFO:Initializing Orthogonal Matching Pursuit
2022-12-01 02:35:58,175:INFO:Total runtime is 0.06915889978408814 minutes
2022-12-01 02:35:58,184:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:58,185:INFO:Initializing create_model()
2022-12-01 02:35:58,185:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961c9f340>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc53ee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:58,185:INFO:Checking exceptions
2022-12-01 02:35:58,188:INFO:Importing libraries
2022-12-01 02:35:58,188:INFO:Copying training dataset
2022-12-01 02:35:58,194:INFO:Defining folds
2022-12-01 02:35:58,194:INFO:Declaring metric variables
2022-12-01 02:35:58,204:INFO:Importing untrained model
2022-12-01 02:35:58,215:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-01 02:35:58,231:INFO:Starting cross validation
2022-12-01 02:35:58,233:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:58,278:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:58,298:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:58,328:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:58,354:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:58,383:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:58,416:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:58,426:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:58,460:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:58,465:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:58,492:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:35:58,508:INFO:Calculating mean and std
2022-12-01 02:35:58,511:INFO:Creating metrics dataframe
2022-12-01 02:35:58,522:INFO:Uploading results into container
2022-12-01 02:35:58,523:INFO:Uploading model into container now
2022-12-01 02:35:58,523:INFO:master_model_container: 7
2022-12-01 02:35:58,524:INFO:display_container: 2
2022-12-01 02:35:58,524:INFO:OrthogonalMatchingPursuit()
2022-12-01 02:35:58,525:INFO:create_model() successfully completed......................................
2022-12-01 02:35:58,660:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:58,660:INFO:Creating metrics dataframe
2022-12-01 02:35:58,678:INFO:Initializing Bayesian Ridge
2022-12-01 02:35:58,679:INFO:Total runtime is 0.07754484017690023 minutes
2022-12-01 02:35:58,687:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:58,688:INFO:Initializing create_model()
2022-12-01 02:35:58,688:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961c9f340>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc53ee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:58,688:INFO:Checking exceptions
2022-12-01 02:35:58,691:INFO:Importing libraries
2022-12-01 02:35:58,691:INFO:Copying training dataset
2022-12-01 02:35:58,698:INFO:Defining folds
2022-12-01 02:35:58,698:INFO:Declaring metric variables
2022-12-01 02:35:58,711:INFO:Importing untrained model
2022-12-01 02:35:58,720:INFO:Bayesian Ridge Imported successfully
2022-12-01 02:35:58,738:INFO:Starting cross validation
2022-12-01 02:35:58,744:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:59,010:INFO:Calculating mean and std
2022-12-01 02:35:59,013:INFO:Creating metrics dataframe
2022-12-01 02:35:59,020:INFO:Uploading results into container
2022-12-01 02:35:59,020:INFO:Uploading model into container now
2022-12-01 02:35:59,021:INFO:master_model_container: 8
2022-12-01 02:35:59,021:INFO:display_container: 2
2022-12-01 02:35:59,022:INFO:BayesianRidge()
2022-12-01 02:35:59,022:INFO:create_model() successfully completed......................................
2022-12-01 02:35:59,156:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:59,156:INFO:Creating metrics dataframe
2022-12-01 02:35:59,176:INFO:Initializing Passive Aggressive Regressor
2022-12-01 02:35:59,177:INFO:Total runtime is 0.08585120836893718 minutes
2022-12-01 02:35:59,184:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:59,185:INFO:Initializing create_model()
2022-12-01 02:35:59,185:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961c9f340>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc53ee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:59,186:INFO:Checking exceptions
2022-12-01 02:35:59,189:INFO:Importing libraries
2022-12-01 02:35:59,189:INFO:Copying training dataset
2022-12-01 02:35:59,197:INFO:Defining folds
2022-12-01 02:35:59,197:INFO:Declaring metric variables
2022-12-01 02:35:59,206:INFO:Importing untrained model
2022-12-01 02:35:59,214:INFO:Passive Aggressive Regressor Imported successfully
2022-12-01 02:35:59,229:INFO:Starting cross validation
2022-12-01 02:35:59,231:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:59,494:INFO:Calculating mean and std
2022-12-01 02:35:59,496:INFO:Creating metrics dataframe
2022-12-01 02:35:59,508:INFO:Uploading results into container
2022-12-01 02:35:59,511:INFO:Uploading model into container now
2022-12-01 02:35:59,512:INFO:master_model_container: 9
2022-12-01 02:35:59,512:INFO:display_container: 2
2022-12-01 02:35:59,513:INFO:PassiveAggressiveRegressor(random_state=123)
2022-12-01 02:35:59,513:INFO:create_model() successfully completed......................................
2022-12-01 02:35:59,655:INFO:SubProcess create_model() end ==================================
2022-12-01 02:35:59,656:INFO:Creating metrics dataframe
2022-12-01 02:35:59,674:INFO:Initializing Huber Regressor
2022-12-01 02:35:59,675:INFO:Total runtime is 0.09414546887079876 minutes
2022-12-01 02:35:59,683:INFO:SubProcess create_model() called ==================================
2022-12-01 02:35:59,684:INFO:Initializing create_model()
2022-12-01 02:35:59,684:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961c9f340>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc53ee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:35:59,684:INFO:Checking exceptions
2022-12-01 02:35:59,686:INFO:Importing libraries
2022-12-01 02:35:59,686:INFO:Copying training dataset
2022-12-01 02:35:59,693:INFO:Defining folds
2022-12-01 02:35:59,693:INFO:Declaring metric variables
2022-12-01 02:35:59,704:INFO:Importing untrained model
2022-12-01 02:35:59,714:INFO:Huber Regressor Imported successfully
2022-12-01 02:35:59,732:INFO:Starting cross validation
2022-12-01 02:35:59,734:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:35:59,844:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:35:59,873:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:35:59,958:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:35:59,981:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:36:00,063:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:36:00,105:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:36:00,165:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:36:00,197:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:36:00,264:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:36:00,287:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:36:00,299:INFO:Calculating mean and std
2022-12-01 02:36:00,301:INFO:Creating metrics dataframe
2022-12-01 02:36:00,309:INFO:Uploading results into container
2022-12-01 02:36:00,315:INFO:Uploading model into container now
2022-12-01 02:36:00,316:INFO:master_model_container: 10
2022-12-01 02:36:00,316:INFO:display_container: 2
2022-12-01 02:36:00,316:INFO:HuberRegressor()
2022-12-01 02:36:00,316:INFO:create_model() successfully completed......................................
2022-12-01 02:36:00,442:INFO:SubProcess create_model() end ==================================
2022-12-01 02:36:00,442:INFO:Creating metrics dataframe
2022-12-01 02:36:00,462:INFO:Initializing K Neighbors Regressor
2022-12-01 02:36:00,463:INFO:Total runtime is 0.10728052059809369 minutes
2022-12-01 02:36:00,470:INFO:SubProcess create_model() called ==================================
2022-12-01 02:36:00,470:INFO:Initializing create_model()
2022-12-01 02:36:00,470:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961c9f340>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc53ee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:36:00,471:INFO:Checking exceptions
2022-12-01 02:36:00,473:INFO:Importing libraries
2022-12-01 02:36:00,473:INFO:Copying training dataset
2022-12-01 02:36:00,480:INFO:Defining folds
2022-12-01 02:36:00,480:INFO:Declaring metric variables
2022-12-01 02:36:00,487:INFO:Importing untrained model
2022-12-01 02:36:00,494:INFO:K Neighbors Regressor Imported successfully
2022-12-01 02:36:00,507:INFO:Starting cross validation
2022-12-01 02:36:00,509:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:36:00,802:INFO:Calculating mean and std
2022-12-01 02:36:00,804:INFO:Creating metrics dataframe
2022-12-01 02:36:00,811:INFO:Uploading results into container
2022-12-01 02:36:00,812:INFO:Uploading model into container now
2022-12-01 02:36:00,813:INFO:master_model_container: 11
2022-12-01 02:36:00,814:INFO:display_container: 2
2022-12-01 02:36:00,814:INFO:KNeighborsRegressor(n_jobs=-1)
2022-12-01 02:36:00,814:INFO:create_model() successfully completed......................................
2022-12-01 02:36:00,944:INFO:SubProcess create_model() end ==================================
2022-12-01 02:36:00,945:INFO:Creating metrics dataframe
2022-12-01 02:36:00,969:INFO:Initializing Decision Tree Regressor
2022-12-01 02:36:00,969:INFO:Total runtime is 0.11572602192560834 minutes
2022-12-01 02:36:00,978:INFO:SubProcess create_model() called ==================================
2022-12-01 02:36:00,979:INFO:Initializing create_model()
2022-12-01 02:36:00,979:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961c9f340>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc53ee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:36:00,979:INFO:Checking exceptions
2022-12-01 02:36:00,982:INFO:Importing libraries
2022-12-01 02:36:00,982:INFO:Copying training dataset
2022-12-01 02:36:00,988:INFO:Defining folds
2022-12-01 02:36:00,989:INFO:Declaring metric variables
2022-12-01 02:36:01,001:INFO:Importing untrained model
2022-12-01 02:36:01,010:INFO:Decision Tree Regressor Imported successfully
2022-12-01 02:36:01,026:INFO:Starting cross validation
2022-12-01 02:36:01,028:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:36:01,340:INFO:Calculating mean and std
2022-12-01 02:36:01,342:INFO:Creating metrics dataframe
2022-12-01 02:36:01,359:INFO:Uploading results into container
2022-12-01 02:36:01,360:INFO:Uploading model into container now
2022-12-01 02:36:01,360:INFO:master_model_container: 12
2022-12-01 02:36:01,361:INFO:display_container: 2
2022-12-01 02:36:01,361:INFO:DecisionTreeRegressor(random_state=123)
2022-12-01 02:36:01,361:INFO:create_model() successfully completed......................................
2022-12-01 02:36:01,489:INFO:SubProcess create_model() end ==================================
2022-12-01 02:36:01,490:INFO:Creating metrics dataframe
2022-12-01 02:36:01,508:INFO:Initializing Random Forest Regressor
2022-12-01 02:36:01,509:INFO:Total runtime is 0.12471836407979331 minutes
2022-12-01 02:36:01,519:INFO:SubProcess create_model() called ==================================
2022-12-01 02:36:01,519:INFO:Initializing create_model()
2022-12-01 02:36:01,520:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961c9f340>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc53ee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:36:01,520:INFO:Checking exceptions
2022-12-01 02:36:01,522:INFO:Importing libraries
2022-12-01 02:36:01,522:INFO:Copying training dataset
2022-12-01 02:36:01,530:INFO:Defining folds
2022-12-01 02:36:01,535:INFO:Declaring metric variables
2022-12-01 02:36:01,542:INFO:Importing untrained model
2022-12-01 02:36:01,550:INFO:Random Forest Regressor Imported successfully
2022-12-01 02:36:01,568:INFO:Starting cross validation
2022-12-01 02:36:01,573:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:36:07,389:INFO:Calculating mean and std
2022-12-01 02:36:07,392:INFO:Creating metrics dataframe
2022-12-01 02:36:07,407:INFO:Uploading results into container
2022-12-01 02:36:07,408:INFO:Uploading model into container now
2022-12-01 02:36:07,408:INFO:master_model_container: 13
2022-12-01 02:36:07,409:INFO:display_container: 2
2022-12-01 02:36:07,409:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-12-01 02:36:07,409:INFO:create_model() successfully completed......................................
2022-12-01 02:36:07,539:INFO:SubProcess create_model() end ==================================
2022-12-01 02:36:07,539:INFO:Creating metrics dataframe
2022-12-01 02:36:07,560:INFO:Initializing Extra Trees Regressor
2022-12-01 02:36:07,563:INFO:Total runtime is 0.22561044295628868 minutes
2022-12-01 02:36:07,570:INFO:SubProcess create_model() called ==================================
2022-12-01 02:36:07,571:INFO:Initializing create_model()
2022-12-01 02:36:07,571:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961c9f340>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc53ee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:36:07,571:INFO:Checking exceptions
2022-12-01 02:36:07,574:INFO:Importing libraries
2022-12-01 02:36:07,574:INFO:Copying training dataset
2022-12-01 02:36:07,583:INFO:Defining folds
2022-12-01 02:36:07,584:INFO:Declaring metric variables
2022-12-01 02:36:07,591:INFO:Importing untrained model
2022-12-01 02:36:07,601:INFO:Extra Trees Regressor Imported successfully
2022-12-01 02:36:07,617:INFO:Starting cross validation
2022-12-01 02:36:07,619:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:36:10,362:INFO:Calculating mean and std
2022-12-01 02:36:10,367:INFO:Creating metrics dataframe
2022-12-01 02:36:10,382:INFO:Uploading results into container
2022-12-01 02:36:10,382:INFO:Uploading model into container now
2022-12-01 02:36:10,383:INFO:master_model_container: 14
2022-12-01 02:36:10,383:INFO:display_container: 2
2022-12-01 02:36:10,384:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-12-01 02:36:10,384:INFO:create_model() successfully completed......................................
2022-12-01 02:36:10,516:INFO:SubProcess create_model() end ==================================
2022-12-01 02:36:10,516:INFO:Creating metrics dataframe
2022-12-01 02:36:10,537:INFO:Initializing AdaBoost Regressor
2022-12-01 02:36:10,537:INFO:Total runtime is 0.27518984079360964 minutes
2022-12-01 02:36:10,549:INFO:SubProcess create_model() called ==================================
2022-12-01 02:36:10,550:INFO:Initializing create_model()
2022-12-01 02:36:10,550:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961c9f340>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc53ee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:36:10,550:INFO:Checking exceptions
2022-12-01 02:36:10,553:INFO:Importing libraries
2022-12-01 02:36:10,553:INFO:Copying training dataset
2022-12-01 02:36:10,561:INFO:Defining folds
2022-12-01 02:36:10,561:INFO:Declaring metric variables
2022-12-01 02:36:10,572:INFO:Importing untrained model
2022-12-01 02:36:10,582:INFO:AdaBoost Regressor Imported successfully
2022-12-01 02:36:10,598:INFO:Starting cross validation
2022-12-01 02:36:10,600:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:36:12,038:INFO:Calculating mean and std
2022-12-01 02:36:12,041:INFO:Creating metrics dataframe
2022-12-01 02:36:12,051:INFO:Uploading results into container
2022-12-01 02:36:12,053:INFO:Uploading model into container now
2022-12-01 02:36:12,053:INFO:master_model_container: 15
2022-12-01 02:36:12,054:INFO:display_container: 2
2022-12-01 02:36:12,054:INFO:AdaBoostRegressor(random_state=123)
2022-12-01 02:36:12,054:INFO:create_model() successfully completed......................................
2022-12-01 02:36:12,188:INFO:SubProcess create_model() end ==================================
2022-12-01 02:36:12,188:INFO:Creating metrics dataframe
2022-12-01 02:36:12,209:INFO:Initializing Gradient Boosting Regressor
2022-12-01 02:36:12,213:INFO:Total runtime is 0.3031146764755249 minutes
2022-12-01 02:36:12,220:INFO:SubProcess create_model() called ==================================
2022-12-01 02:36:12,221:INFO:Initializing create_model()
2022-12-01 02:36:12,221:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961c9f340>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc53ee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:36:12,221:INFO:Checking exceptions
2022-12-01 02:36:12,226:INFO:Importing libraries
2022-12-01 02:36:12,226:INFO:Copying training dataset
2022-12-01 02:36:12,231:INFO:Defining folds
2022-12-01 02:36:12,232:INFO:Declaring metric variables
2022-12-01 02:36:12,248:INFO:Importing untrained model
2022-12-01 02:36:12,258:INFO:Gradient Boosting Regressor Imported successfully
2022-12-01 02:36:12,276:INFO:Starting cross validation
2022-12-01 02:36:12,278:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:36:14,663:INFO:Calculating mean and std
2022-12-01 02:36:14,665:INFO:Creating metrics dataframe
2022-12-01 02:36:14,674:INFO:Uploading results into container
2022-12-01 02:36:14,675:INFO:Uploading model into container now
2022-12-01 02:36:14,675:INFO:master_model_container: 16
2022-12-01 02:36:14,676:INFO:display_container: 2
2022-12-01 02:36:14,676:INFO:GradientBoostingRegressor(random_state=123)
2022-12-01 02:36:14,677:INFO:create_model() successfully completed......................................
2022-12-01 02:36:14,803:INFO:SubProcess create_model() end ==================================
2022-12-01 02:36:14,804:INFO:Creating metrics dataframe
2022-12-01 02:36:14,828:INFO:Initializing Light Gradient Boosting Machine
2022-12-01 02:36:14,830:INFO:Total runtime is 0.34672779242197677 minutes
2022-12-01 02:36:14,838:INFO:SubProcess create_model() called ==================================
2022-12-01 02:36:14,839:INFO:Initializing create_model()
2022-12-01 02:36:14,839:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961c9f340>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc53ee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:36:14,839:INFO:Checking exceptions
2022-12-01 02:36:14,841:INFO:Importing libraries
2022-12-01 02:36:14,842:INFO:Copying training dataset
2022-12-01 02:36:14,849:INFO:Defining folds
2022-12-01 02:36:14,849:INFO:Declaring metric variables
2022-12-01 02:36:14,857:INFO:Importing untrained model
2022-12-01 02:36:14,865:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-01 02:36:14,879:INFO:Starting cross validation
2022-12-01 02:36:14,880:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:36:16,108:INFO:Calculating mean and std
2022-12-01 02:36:16,110:INFO:Creating metrics dataframe
2022-12-01 02:36:16,121:INFO:Uploading results into container
2022-12-01 02:36:16,122:INFO:Uploading model into container now
2022-12-01 02:36:16,123:INFO:master_model_container: 17
2022-12-01 02:36:16,123:INFO:display_container: 2
2022-12-01 02:36:16,124:INFO:LGBMRegressor(random_state=123)
2022-12-01 02:36:16,124:INFO:create_model() successfully completed......................................
2022-12-01 02:36:16,258:INFO:SubProcess create_model() end ==================================
2022-12-01 02:36:16,258:INFO:Creating metrics dataframe
2022-12-01 02:36:16,279:INFO:Initializing Dummy Regressor
2022-12-01 02:36:16,279:INFO:Total runtime is 0.3708873391151429 minutes
2022-12-01 02:36:16,290:INFO:SubProcess create_model() called ==================================
2022-12-01 02:36:16,291:INFO:Initializing create_model()
2022-12-01 02:36:16,291:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961c9f340>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc53ee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:36:16,291:INFO:Checking exceptions
2022-12-01 02:36:16,294:INFO:Importing libraries
2022-12-01 02:36:16,294:INFO:Copying training dataset
2022-12-01 02:36:16,304:INFO:Defining folds
2022-12-01 02:36:16,306:INFO:Declaring metric variables
2022-12-01 02:36:16,316:INFO:Importing untrained model
2022-12-01 02:36:16,323:INFO:Dummy Regressor Imported successfully
2022-12-01 02:36:16,338:INFO:Starting cross validation
2022-12-01 02:36:16,340:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:36:16,579:INFO:Calculating mean and std
2022-12-01 02:36:16,581:INFO:Creating metrics dataframe
2022-12-01 02:36:16,589:INFO:Uploading results into container
2022-12-01 02:36:16,591:INFO:Uploading model into container now
2022-12-01 02:36:16,592:INFO:master_model_container: 18
2022-12-01 02:36:16,592:INFO:display_container: 2
2022-12-01 02:36:16,592:INFO:DummyRegressor()
2022-12-01 02:36:16,592:INFO:create_model() successfully completed......................................
2022-12-01 02:36:16,722:INFO:SubProcess create_model() end ==================================
2022-12-01 02:36:16,722:INFO:Creating metrics dataframe
2022-12-01 02:36:16,767:INFO:Initializing create_model()
2022-12-01 02:36:16,767:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961c9f340>, estimator=LassoLars(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:36:16,767:INFO:Checking exceptions
2022-12-01 02:36:16,773:INFO:Importing libraries
2022-12-01 02:36:16,773:INFO:Copying training dataset
2022-12-01 02:36:16,776:INFO:Defining folds
2022-12-01 02:36:16,777:INFO:Declaring metric variables
2022-12-01 02:36:16,777:INFO:Importing untrained model
2022-12-01 02:36:16,778:INFO:Declaring custom model
2022-12-01 02:36:16,779:INFO:Least Angle Regression Imported successfully
2022-12-01 02:36:16,781:INFO:Cross validation set to False
2022-12-01 02:36:16,781:INFO:Fitting Model
2022-12-01 02:36:16,814:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:36:16,816:INFO:LassoLars(random_state=123)
2022-12-01 02:36:16,816:INFO:create_model() successfully completed......................................
2022-12-01 02:36:17,065:INFO:master_model_container: 18
2022-12-01 02:36:17,065:INFO:display_container: 2
2022-12-01 02:36:17,066:INFO:LassoLars(random_state=123)
2022-12-01 02:36:17,066:INFO:compare_models() successfully completed......................................
2022-12-01 02:44:52,238:WARNING:<ipython-input-27-4717cbf528c9>:14: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q1'] = abs(data['PTS_QTR1_x'] - data['PTS_QTR1_y'])

2022-12-01 02:44:52,240:WARNING:<ipython-input-27-4717cbf528c9>:15: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q2'] = abs(data['PTS_QTR2_x'] - data['PTS_QTR2_y'])

2022-12-01 02:44:52,241:WARNING:<ipython-input-27-4717cbf528c9>:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q3'] = abs(data['PTS_QTR3_x'] - data['PTS_QTR3_y'])

2022-12-01 02:44:52,242:WARNING:<ipython-input-27-4717cbf528c9>:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['PTS'] = abs(data['PTS_x'] - data['PTS_y'])

2022-12-01 02:44:52,243:WARNING:<ipython-input-27-4717cbf528c9>:20: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FG_PCT'] = abs(data['FG_PCT_x'] - data['FG_PCT_y'])

2022-12-01 02:44:52,244:WARNING:<ipython-input-27-4717cbf528c9>:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT'] = abs(data['FT_PCT_x'] - data['FT_PCT_y'])

2022-12-01 02:44:52,245:WARNING:<ipython-input-27-4717cbf528c9>:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT3'] = abs(data['FG3_PCT_x'] - data['FG3_PCT_y'])

2022-12-01 02:44:52,246:WARNING:<ipython-input-27-4717cbf528c9>:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['AST'] = abs(data['AST_x'] - data['AST_y'])

2022-12-01 02:44:52,247:WARNING:<ipython-input-27-4717cbf528c9>:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['REB'] = abs(data['REB_x'] - data['REB_y'])

2022-12-01 02:44:52,248:WARNING:<ipython-input-27-4717cbf528c9>:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['TO'] = abs(data['TOV_x'] - data['TOV_y'])

2022-12-01 02:45:08,276:WARNING:<ipython-input-28-8e883510bedb>:14: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q1'] = abs(data['PTS_QTR1_x'] - data['PTS_QTR1_y'])

2022-12-01 02:45:08,278:WARNING:<ipython-input-28-8e883510bedb>:15: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q2'] = abs(data['PTS_QTR2_x'] - data['PTS_QTR2_y'])

2022-12-01 02:45:08,279:WARNING:<ipython-input-28-8e883510bedb>:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q3'] = abs(data['PTS_QTR3_x'] - data['PTS_QTR3_y'])

2022-12-01 02:45:08,280:WARNING:<ipython-input-28-8e883510bedb>:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['PTS'] = abs(data['PTS_x'] - data['PTS_y'])

2022-12-01 02:45:08,281:WARNING:<ipython-input-28-8e883510bedb>:20: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FG_PCT'] = abs(data['FG_PCT_x'] - data['FG_PCT_y'])

2022-12-01 02:45:08,282:WARNING:<ipython-input-28-8e883510bedb>:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT'] = abs(data['FT_PCT_x'] - data['FT_PCT_y'])

2022-12-01 02:45:08,283:WARNING:<ipython-input-28-8e883510bedb>:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT3'] = abs(data['FG3_PCT_x'] - data['FG3_PCT_y'])

2022-12-01 02:45:08,284:WARNING:<ipython-input-28-8e883510bedb>:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['AST'] = abs(data['AST_x'] - data['AST_y'])

2022-12-01 02:45:08,285:WARNING:<ipython-input-28-8e883510bedb>:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['REB'] = abs(data['REB_x'] - data['REB_y'])

2022-12-01 02:45:08,286:WARNING:<ipython-input-28-8e883510bedb>:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['TO'] = abs(data['TOV_x'] - data['TOV_y'])

2022-12-01 02:45:08,291:INFO:PyCaret RegressionExperiment
2022-12-01 02:45:08,292:INFO:Logging name: FullData
2022-12-01 02:45:08,292:INFO:ML Usecase: MLUsecase.REGRESSION
2022-12-01 02:45:08,292:INFO:version 3.0.0.rc4
2022-12-01 02:45:08,292:INFO:Initializing setup()
2022-12-01 02:45:08,292:INFO:self.USI: ab65
2022-12-01 02:45:08,292:INFO:self.variable_keys: {'fold_shuffle_param', 'y_test', 'pipeline', 'data', 'X', 'exp_id', 'master_model_container', '_available_plots', '_all_metrics', '_ml_usecase', 'log_plots_param', '_all_models', 'logging_param', 'idx', 'html_param', 'display_container', 'USI', 'target_param', 'fold_generator', '_gpu_n_jobs_param', 'n_jobs_param', 'transform_target_method_param', 'exp_name_log', 'X_test', 'variable_keys', 'gpu_param', 'memory', 'y_train', 'transform_target_param', 'y', 'X_train', '_all_models_internal', 'fold_groups_param', 'seed'}
2022-12-01 02:45:08,293:INFO:Checking environment
2022-12-01 02:45:08,293:INFO:python_version: 3.8.15
2022-12-01 02:45:08,293:INFO:python_build: ('default', 'Oct 12 2022 19:14:39')
2022-12-01 02:45:08,293:INFO:machine: x86_64
2022-12-01 02:45:08,293:INFO:platform: Linux-5.10.133+-x86_64-with-glibc2.27
2022-12-01 02:45:08,294:INFO:Memory: svmem(total=13616361472, available=11749658624, percent=13.7, used=1709047808, free=6674669568, active=929050624, inactive=5631541248, buffers=423518208, cached=4809125888, shared=1236992, slab=288911360)
2022-12-01 02:45:08,294:INFO:Physical Core: 1
2022-12-01 02:45:08,294:INFO:Logical Core: 2
2022-12-01 02:45:08,295:INFO:Checking libraries
2022-12-01 02:45:08,295:INFO:System:
2022-12-01 02:45:08,295:INFO:    python: 3.8.15 (default, Oct 12 2022, 19:14:39)  [GCC 7.5.0]
2022-12-01 02:45:08,295:INFO:executable: /usr/bin/python3
2022-12-01 02:45:08,295:INFO:   machine: Linux-5.10.133+-x86_64-with-glibc2.27
2022-12-01 02:45:08,295:INFO:PyCaret required dependencies:
2022-12-01 02:45:08,296:INFO:                 pip: 21.1.3
2022-12-01 02:45:08,296:INFO:          setuptools: 57.4.0
2022-12-01 02:45:08,296:INFO:             pycaret: 3.0.0rc4
2022-12-01 02:45:08,296:INFO:             IPython: 7.9.0
2022-12-01 02:45:08,296:INFO:          ipywidgets: 7.7.1
2022-12-01 02:45:08,296:INFO:                tqdm: 4.64.1
2022-12-01 02:45:08,296:INFO:               numpy: 1.21.6
2022-12-01 02:45:08,297:INFO:              pandas: 1.3.5
2022-12-01 02:45:08,297:INFO:              jinja2: 3.0.0
2022-12-01 02:45:08,297:INFO:               scipy: 1.7.3
2022-12-01 02:45:08,297:INFO:              joblib: 1.2.0
2022-12-01 02:45:08,297:INFO:             sklearn: 1.0.2
2022-12-01 02:45:08,297:INFO:                pyod: 1.0.6
2022-12-01 02:45:08,297:INFO:            imblearn: 0.8.1
2022-12-01 02:45:08,297:INFO:   category_encoders: 2.5.1.post0
2022-12-01 02:45:08,298:INFO:            lightgbm: 3.3.3
2022-12-01 02:45:08,298:INFO:               numba: 0.55.2
2022-12-01 02:45:08,298:INFO:            requests: 2.28.1
2022-12-01 02:45:08,298:INFO:          matplotlib: 3.6.2
2022-12-01 02:45:08,298:INFO:          scikitplot: 0.3.7
2022-12-01 02:45:08,298:INFO:         yellowbrick: 1.5
2022-12-01 02:45:08,298:INFO:              plotly: 5.5.0
2022-12-01 02:45:08,299:INFO:             kaleido: 0.2.1
2022-12-01 02:45:08,299:INFO:         statsmodels: 0.12.2
2022-12-01 02:45:08,299:INFO:              sktime: 0.13.4
2022-12-01 02:45:08,299:INFO:               tbats: 1.1.1
2022-12-01 02:45:08,299:INFO:            pmdarima: 1.8.5
2022-12-01 02:45:08,299:INFO:              psutil: 5.9.4
2022-12-01 02:45:08,299:INFO:PyCaret optional dependencies:
2022-12-01 02:45:08,300:INFO:                shap: Not installed
2022-12-01 02:45:08,300:INFO:           interpret: Not installed
2022-12-01 02:45:08,300:INFO:                umap: Not installed
2022-12-01 02:45:08,300:INFO:    pandas_profiling: 1.4.1
2022-12-01 02:45:08,300:INFO:  explainerdashboard: Not installed
2022-12-01 02:45:08,301:INFO:             autoviz: Not installed
2022-12-01 02:45:08,301:INFO:           fairlearn: Not installed
2022-12-01 02:45:08,301:INFO:             xgboost: 0.90
2022-12-01 02:45:08,301:INFO:            catboost: Not installed
2022-12-01 02:45:08,301:INFO:              kmodes: Not installed
2022-12-01 02:45:08,301:INFO:             mlxtend: 0.14.0
2022-12-01 02:45:08,301:INFO:       statsforecast: Not installed
2022-12-01 02:45:08,302:INFO:        tune_sklearn: Not installed
2022-12-01 02:45:08,302:INFO:                 ray: Not installed
2022-12-01 02:45:08,302:INFO:            hyperopt: 0.1.2
2022-12-01 02:45:08,302:INFO:              optuna: Not installed
2022-12-01 02:45:08,303:INFO:               skopt: Not installed
2022-12-01 02:45:08,303:INFO:              mlflow: Not installed
2022-12-01 02:45:08,303:INFO:              gradio: Not installed
2022-12-01 02:45:08,303:INFO:             fastapi: Not installed
2022-12-01 02:45:08,303:INFO:             uvicorn: Not installed
2022-12-01 02:45:08,303:INFO:              m2cgen: Not installed
2022-12-01 02:45:08,303:INFO:           evidently: Not installed
2022-12-01 02:45:08,304:INFO:                nltk: 3.7
2022-12-01 02:45:08,304:INFO:            pyLDAvis: Not installed
2022-12-01 02:45:08,304:INFO:              gensim: 3.6.0
2022-12-01 02:45:08,304:INFO:               spacy: 3.4.3
2022-12-01 02:45:08,305:INFO:           wordcloud: 1.8.2.2
2022-12-01 02:45:08,305:INFO:            textblob: 0.15.3
2022-12-01 02:45:08,305:INFO:               fugue: Not installed
2022-12-01 02:45:08,305:INFO:           streamlit: Not installed
2022-12-01 02:45:08,305:INFO:             prophet: 1.1.1
2022-12-01 02:45:08,305:INFO:None
2022-12-01 02:45:08,305:INFO:Set up data.
2022-12-01 02:45:08,312:INFO:Set up train/test split.
2022-12-01 02:45:08,316:INFO:Set up index.
2022-12-01 02:45:08,316:INFO:Set up folding strategy.
2022-12-01 02:45:08,316:INFO:Assigning column types.
2022-12-01 02:45:08,322:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-12-01 02:45:08,323:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-01 02:45:08,328:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:45:08,333:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:45:08,401:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:45:08,450:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:45:08,451:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:45:08,452:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:45:08,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:45:08,453:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-01 02:45:08,459:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:45:08,464:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:45:08,528:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:45:08,578:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:45:08,579:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:45:08,580:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:45:08,580:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:45:08,581:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-12-01 02:45:08,586:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:45:08,591:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:45:08,654:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:45:08,704:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:45:08,705:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:45:08,706:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:45:08,706:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:45:08,711:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:45:08,717:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:45:08,780:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:45:08,829:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:45:08,830:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:45:08,831:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:45:08,831:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:45:08,831:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-12-01 02:45:08,841:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:45:08,906:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:45:08,958:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:45:08,959:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:45:08,960:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:45:08,960:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:45:08,971:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:45:09,047:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:45:09,098:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:45:09,099:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:45:09,099:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:45:09,099:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:45:09,100:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-12-01 02:45:09,177:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:45:09,227:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:45:09,228:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:45:09,229:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:45:09,229:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:45:09,305:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:45:09,354:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:45:09,355:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:45:09,355:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:45:09,356:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:45:09,357:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-12-01 02:45:09,430:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:45:09,480:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:45:09,480:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:45:09,480:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:45:09,554:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:45:09,605:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:45:09,605:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:45:09,605:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:45:09,606:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-12-01 02:45:09,728:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:45:09,728:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:45:09,729:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:45:09,853:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:45:09,853:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:45:09,854:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:45:09,855:INFO:Preparing preprocessing pipeline...
2022-12-01 02:45:09,856:INFO:Set up simple imputation.
2022-12-01 02:45:09,856:INFO:Set up variance threshold.
2022-12-01 02:45:09,902:INFO:Finished creating preprocessing pipeline.
2022-12-01 02:45:09,909:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'PTS', 'FG_PCT',
                                             'FT_PCT', 'FT_PCT3', 'AST', 'REB',
                                             'TO', 'Open_Line_ML_x'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-12-01 02:45:09,909:INFO:Creating final display dataframe.
2022-12-01 02:45:10,089:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 12)
4         Train data shape    (607, 12)
5          Test data shape    (261, 12)
6         Numeric features           11
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         ab65
2022-12-01 02:45:10,233:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:45:10,234:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:45:10,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:45:10,363:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:45:10,363:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:45:10,364:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:45:10,370:INFO:setup() successfully completed in 2.08s...............
2022-12-01 02:45:10,371:INFO:Initializing compare_models()
2022-12-01 02:45:10,371:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e36df10>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f495e36df10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-12-01 02:45:10,371:INFO:Checking exceptions
2022-12-01 02:45:10,372:INFO:Preparing display monitor
2022-12-01 02:45:10,452:INFO:Initializing Linear Regression
2022-12-01 02:45:10,454:INFO:Total runtime is 3.92913818359375e-05 minutes
2022-12-01 02:45:10,460:INFO:SubProcess create_model() called ==================================
2022-12-01 02:45:10,461:INFO:Initializing create_model()
2022-12-01 02:45:10,461:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e36df10>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495abecc10>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:45:10,461:INFO:Checking exceptions
2022-12-01 02:45:10,464:INFO:Importing libraries
2022-12-01 02:45:10,464:INFO:Copying training dataset
2022-12-01 02:45:10,467:INFO:Defining folds
2022-12-01 02:45:10,468:INFO:Declaring metric variables
2022-12-01 02:45:10,473:INFO:Importing untrained model
2022-12-01 02:45:10,479:INFO:Linear Regression Imported successfully
2022-12-01 02:45:10,491:INFO:Starting cross validation
2022-12-01 02:45:10,495:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:45:14,620:INFO:Calculating mean and std
2022-12-01 02:45:14,628:INFO:Creating metrics dataframe
2022-12-01 02:45:14,635:INFO:Uploading results into container
2022-12-01 02:45:14,636:INFO:Uploading model into container now
2022-12-01 02:45:14,636:INFO:master_model_container: 1
2022-12-01 02:45:14,636:INFO:display_container: 2
2022-12-01 02:45:14,637:INFO:LinearRegression(n_jobs=-1)
2022-12-01 02:45:14,637:INFO:create_model() successfully completed......................................
2022-12-01 02:45:14,835:INFO:SubProcess create_model() end ==================================
2022-12-01 02:45:14,836:INFO:Creating metrics dataframe
2022-12-01 02:45:14,861:INFO:Initializing Lasso Regression
2022-12-01 02:45:14,861:INFO:Total runtime is 0.07348976532618204 minutes
2022-12-01 02:45:14,867:INFO:SubProcess create_model() called ==================================
2022-12-01 02:45:14,868:INFO:Initializing create_model()
2022-12-01 02:45:14,869:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e36df10>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495abecc10>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:45:14,869:INFO:Checking exceptions
2022-12-01 02:45:14,872:INFO:Importing libraries
2022-12-01 02:45:14,872:INFO:Copying training dataset
2022-12-01 02:45:14,876:INFO:Defining folds
2022-12-01 02:45:14,877:INFO:Declaring metric variables
2022-12-01 02:45:14,889:INFO:Importing untrained model
2022-12-01 02:45:14,897:INFO:Lasso Regression Imported successfully
2022-12-01 02:45:14,916:INFO:Starting cross validation
2022-12-01 02:45:14,918:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:45:15,218:INFO:Calculating mean and std
2022-12-01 02:45:15,220:INFO:Creating metrics dataframe
2022-12-01 02:45:15,226:INFO:Uploading results into container
2022-12-01 02:45:15,228:INFO:Uploading model into container now
2022-12-01 02:45:15,229:INFO:master_model_container: 2
2022-12-01 02:45:15,229:INFO:display_container: 2
2022-12-01 02:45:15,230:INFO:Lasso(random_state=123)
2022-12-01 02:45:15,230:INFO:create_model() successfully completed......................................
2022-12-01 02:45:15,370:INFO:SubProcess create_model() end ==================================
2022-12-01 02:45:15,371:INFO:Creating metrics dataframe
2022-12-01 02:45:15,388:INFO:Initializing Ridge Regression
2022-12-01 02:45:15,389:INFO:Total runtime is 0.08228128353754678 minutes
2022-12-01 02:45:15,397:INFO:SubProcess create_model() called ==================================
2022-12-01 02:45:15,399:INFO:Initializing create_model()
2022-12-01 02:45:15,400:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e36df10>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495abecc10>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:45:15,401:INFO:Checking exceptions
2022-12-01 02:45:15,403:INFO:Importing libraries
2022-12-01 02:45:15,403:INFO:Copying training dataset
2022-12-01 02:45:15,407:INFO:Defining folds
2022-12-01 02:45:15,407:INFO:Declaring metric variables
2022-12-01 02:45:15,419:INFO:Importing untrained model
2022-12-01 02:45:15,430:INFO:Ridge Regression Imported successfully
2022-12-01 02:45:15,446:INFO:Starting cross validation
2022-12-01 02:45:15,451:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:45:15,487:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.04384e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:45:15,518:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.06087e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:45:15,553:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.05291e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:45:15,558:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.10221e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:45:15,612:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.09426e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:45:15,619:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.07314e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:45:15,648:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.06298e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:45:15,656:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.02953e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:45:15,685:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.05986e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:45:15,694:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.05663e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:45:15,708:INFO:Calculating mean and std
2022-12-01 02:45:15,710:INFO:Creating metrics dataframe
2022-12-01 02:45:15,727:INFO:Uploading results into container
2022-12-01 02:45:15,729:INFO:Uploading model into container now
2022-12-01 02:45:15,730:INFO:master_model_container: 3
2022-12-01 02:45:15,730:INFO:display_container: 2
2022-12-01 02:45:15,730:INFO:Ridge(random_state=123)
2022-12-01 02:45:15,731:INFO:create_model() successfully completed......................................
2022-12-01 02:45:15,864:INFO:SubProcess create_model() end ==================================
2022-12-01 02:45:15,864:INFO:Creating metrics dataframe
2022-12-01 02:45:15,882:INFO:Initializing Elastic Net
2022-12-01 02:45:15,883:INFO:Total runtime is 0.09050809144973754 minutes
2022-12-01 02:45:15,890:INFO:SubProcess create_model() called ==================================
2022-12-01 02:45:15,891:INFO:Initializing create_model()
2022-12-01 02:45:15,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e36df10>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495abecc10>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:45:15,891:INFO:Checking exceptions
2022-12-01 02:45:15,894:INFO:Importing libraries
2022-12-01 02:45:15,894:INFO:Copying training dataset
2022-12-01 02:45:15,898:INFO:Defining folds
2022-12-01 02:45:15,899:INFO:Declaring metric variables
2022-12-01 02:45:15,911:INFO:Importing untrained model
2022-12-01 02:45:15,924:INFO:Elastic Net Imported successfully
2022-12-01 02:45:15,940:INFO:Starting cross validation
2022-12-01 02:45:15,941:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:45:16,196:INFO:Calculating mean and std
2022-12-01 02:45:16,198:INFO:Creating metrics dataframe
2022-12-01 02:45:16,205:INFO:Uploading results into container
2022-12-01 02:45:16,206:INFO:Uploading model into container now
2022-12-01 02:45:16,206:INFO:master_model_container: 4
2022-12-01 02:45:16,207:INFO:display_container: 2
2022-12-01 02:45:16,207:INFO:ElasticNet(random_state=123)
2022-12-01 02:45:16,207:INFO:create_model() successfully completed......................................
2022-12-01 02:45:16,350:INFO:SubProcess create_model() end ==================================
2022-12-01 02:45:16,350:INFO:Creating metrics dataframe
2022-12-01 02:45:16,368:INFO:Initializing Least Angle Regression
2022-12-01 02:45:16,368:INFO:Total runtime is 0.09860455592473347 minutes
2022-12-01 02:45:16,378:INFO:SubProcess create_model() called ==================================
2022-12-01 02:45:16,379:INFO:Initializing create_model()
2022-12-01 02:45:16,379:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e36df10>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495abecc10>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:45:16,379:INFO:Checking exceptions
2022-12-01 02:45:16,382:INFO:Importing libraries
2022-12-01 02:45:16,382:INFO:Copying training dataset
2022-12-01 02:45:16,386:INFO:Defining folds
2022-12-01 02:45:16,387:INFO:Declaring metric variables
2022-12-01 02:45:16,395:INFO:Importing untrained model
2022-12-01 02:45:16,403:INFO:Least Angle Regression Imported successfully
2022-12-01 02:45:16,420:INFO:Starting cross validation
2022-12-01 02:45:16,422:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:45:16,459:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:45:16,486:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:45:16,502:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:45:16,541:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:45:16,586:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:45:16,598:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:45:16,625:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:45:16,637:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:45:16,665:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:45:16,677:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:45:16,693:INFO:Calculating mean and std
2022-12-01 02:45:16,695:INFO:Creating metrics dataframe
2022-12-01 02:45:16,707:INFO:Uploading results into container
2022-12-01 02:45:16,708:INFO:Uploading model into container now
2022-12-01 02:45:16,708:INFO:master_model_container: 5
2022-12-01 02:45:16,709:INFO:display_container: 2
2022-12-01 02:45:16,709:INFO:Lars(random_state=123)
2022-12-01 02:45:16,709:INFO:create_model() successfully completed......................................
2022-12-01 02:45:16,843:INFO:SubProcess create_model() end ==================================
2022-12-01 02:45:16,843:INFO:Creating metrics dataframe
2022-12-01 02:45:16,861:INFO:Initializing Lasso Least Angle Regression
2022-12-01 02:45:16,861:INFO:Total runtime is 0.1068151315053304 minutes
2022-12-01 02:45:16,867:INFO:SubProcess create_model() called ==================================
2022-12-01 02:45:16,873:INFO:Initializing create_model()
2022-12-01 02:45:16,875:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e36df10>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495abecc10>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:45:16,875:INFO:Checking exceptions
2022-12-01 02:45:16,877:INFO:Importing libraries
2022-12-01 02:45:16,877:INFO:Copying training dataset
2022-12-01 02:45:16,883:INFO:Defining folds
2022-12-01 02:45:16,884:INFO:Declaring metric variables
2022-12-01 02:45:16,892:INFO:Importing untrained model
2022-12-01 02:45:16,899:INFO:Lasso Least Angle Regression Imported successfully
2022-12-01 02:45:16,912:INFO:Starting cross validation
2022-12-01 02:45:16,914:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:45:16,953:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:45:16,975:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:45:17,006:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:45:17,028:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:45:17,061:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:45:17,088:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:45:17,099:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:45:17,128:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:45:17,135:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:45:17,162:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:45:17,173:INFO:Calculating mean and std
2022-12-01 02:45:17,175:INFO:Creating metrics dataframe
2022-12-01 02:45:17,186:INFO:Uploading results into container
2022-12-01 02:45:17,187:INFO:Uploading model into container now
2022-12-01 02:45:17,187:INFO:master_model_container: 6
2022-12-01 02:45:17,188:INFO:display_container: 2
2022-12-01 02:45:17,188:INFO:LassoLars(random_state=123)
2022-12-01 02:45:17,188:INFO:create_model() successfully completed......................................
2022-12-01 02:45:17,324:INFO:SubProcess create_model() end ==================================
2022-12-01 02:45:17,325:INFO:Creating metrics dataframe
2022-12-01 02:45:17,343:INFO:Initializing Orthogonal Matching Pursuit
2022-12-01 02:45:17,343:INFO:Total runtime is 0.11485567490259806 minutes
2022-12-01 02:45:17,355:INFO:SubProcess create_model() called ==================================
2022-12-01 02:45:17,356:INFO:Initializing create_model()
2022-12-01 02:45:17,356:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e36df10>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495abecc10>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:45:17,356:INFO:Checking exceptions
2022-12-01 02:45:17,358:INFO:Importing libraries
2022-12-01 02:45:17,358:INFO:Copying training dataset
2022-12-01 02:45:17,363:INFO:Defining folds
2022-12-01 02:45:17,363:INFO:Declaring metric variables
2022-12-01 02:45:17,370:INFO:Importing untrained model
2022-12-01 02:45:17,377:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-01 02:45:17,391:INFO:Starting cross validation
2022-12-01 02:45:17,394:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:45:17,423:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:45:17,450:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:45:17,487:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:45:17,493:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:45:17,527:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:45:17,562:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:45:17,565:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:45:17,599:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:45:17,603:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:45:17,631:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:45:17,642:INFO:Calculating mean and std
2022-12-01 02:45:17,644:INFO:Creating metrics dataframe
2022-12-01 02:45:17,656:INFO:Uploading results into container
2022-12-01 02:45:17,657:INFO:Uploading model into container now
2022-12-01 02:45:17,657:INFO:master_model_container: 7
2022-12-01 02:45:17,657:INFO:display_container: 2
2022-12-01 02:45:17,657:INFO:OrthogonalMatchingPursuit()
2022-12-01 02:45:17,658:INFO:create_model() successfully completed......................................
2022-12-01 02:45:17,785:INFO:SubProcess create_model() end ==================================
2022-12-01 02:45:17,785:INFO:Creating metrics dataframe
2022-12-01 02:45:17,802:INFO:Initializing Bayesian Ridge
2022-12-01 02:45:17,802:INFO:Total runtime is 0.12250255346298217 minutes
2022-12-01 02:45:17,809:INFO:SubProcess create_model() called ==================================
2022-12-01 02:45:17,810:INFO:Initializing create_model()
2022-12-01 02:45:17,810:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e36df10>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495abecc10>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:45:17,811:INFO:Checking exceptions
2022-12-01 02:45:17,812:INFO:Importing libraries
2022-12-01 02:45:17,812:INFO:Copying training dataset
2022-12-01 02:45:17,817:INFO:Defining folds
2022-12-01 02:45:17,821:INFO:Declaring metric variables
2022-12-01 02:45:17,830:INFO:Importing untrained model
2022-12-01 02:45:17,836:INFO:Bayesian Ridge Imported successfully
2022-12-01 02:45:17,849:INFO:Starting cross validation
2022-12-01 02:45:17,851:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:45:18,112:INFO:Calculating mean and std
2022-12-01 02:45:18,115:INFO:Creating metrics dataframe
2022-12-01 02:45:18,122:INFO:Uploading results into container
2022-12-01 02:45:18,123:INFO:Uploading model into container now
2022-12-01 02:45:18,123:INFO:master_model_container: 8
2022-12-01 02:45:18,124:INFO:display_container: 2
2022-12-01 02:45:18,124:INFO:BayesianRidge()
2022-12-01 02:45:18,124:INFO:create_model() successfully completed......................................
2022-12-01 02:45:18,272:INFO:SubProcess create_model() end ==================================
2022-12-01 02:45:18,272:INFO:Creating metrics dataframe
2022-12-01 02:45:18,291:INFO:Initializing Passive Aggressive Regressor
2022-12-01 02:45:18,291:INFO:Total runtime is 0.13065566619237262 minutes
2022-12-01 02:45:18,302:INFO:SubProcess create_model() called ==================================
2022-12-01 02:45:18,304:INFO:Initializing create_model()
2022-12-01 02:45:18,304:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e36df10>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495abecc10>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:45:18,304:INFO:Checking exceptions
2022-12-01 02:45:18,307:INFO:Importing libraries
2022-12-01 02:45:18,307:INFO:Copying training dataset
2022-12-01 02:45:18,311:INFO:Defining folds
2022-12-01 02:45:18,312:INFO:Declaring metric variables
2022-12-01 02:45:18,320:INFO:Importing untrained model
2022-12-01 02:45:18,331:INFO:Passive Aggressive Regressor Imported successfully
2022-12-01 02:45:18,347:INFO:Starting cross validation
2022-12-01 02:45:18,349:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:45:18,601:INFO:Calculating mean and std
2022-12-01 02:45:18,603:INFO:Creating metrics dataframe
2022-12-01 02:45:18,613:INFO:Uploading results into container
2022-12-01 02:45:18,615:INFO:Uploading model into container now
2022-12-01 02:45:18,615:INFO:master_model_container: 9
2022-12-01 02:45:18,615:INFO:display_container: 2
2022-12-01 02:45:18,616:INFO:PassiveAggressiveRegressor(random_state=123)
2022-12-01 02:45:18,616:INFO:create_model() successfully completed......................................
2022-12-01 02:45:18,751:INFO:SubProcess create_model() end ==================================
2022-12-01 02:45:18,751:INFO:Creating metrics dataframe
2022-12-01 02:45:18,770:INFO:Initializing Huber Regressor
2022-12-01 02:45:18,770:INFO:Total runtime is 0.13863893349965412 minutes
2022-12-01 02:45:18,779:INFO:SubProcess create_model() called ==================================
2022-12-01 02:45:18,780:INFO:Initializing create_model()
2022-12-01 02:45:18,780:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e36df10>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495abecc10>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:45:18,780:INFO:Checking exceptions
2022-12-01 02:45:18,783:INFO:Importing libraries
2022-12-01 02:45:18,783:INFO:Copying training dataset
2022-12-01 02:45:18,789:INFO:Defining folds
2022-12-01 02:45:18,790:INFO:Declaring metric variables
2022-12-01 02:45:18,798:INFO:Importing untrained model
2022-12-01 02:45:18,805:INFO:Huber Regressor Imported successfully
2022-12-01 02:45:18,825:INFO:Starting cross validation
2022-12-01 02:45:18,827:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:45:18,915:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:45:18,964:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:45:19,034:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:45:19,065:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:45:19,149:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:45:19,175:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:45:19,242:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:45:19,264:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:45:19,345:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:45:19,363:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:45:19,374:INFO:Calculating mean and std
2022-12-01 02:45:19,376:INFO:Creating metrics dataframe
2022-12-01 02:45:19,384:INFO:Uploading results into container
2022-12-01 02:45:19,385:INFO:Uploading model into container now
2022-12-01 02:45:19,386:INFO:master_model_container: 10
2022-12-01 02:45:19,386:INFO:display_container: 2
2022-12-01 02:45:19,387:INFO:HuberRegressor()
2022-12-01 02:45:19,387:INFO:create_model() successfully completed......................................
2022-12-01 02:45:19,523:INFO:SubProcess create_model() end ==================================
2022-12-01 02:45:19,523:INFO:Creating metrics dataframe
2022-12-01 02:45:19,545:INFO:Initializing K Neighbors Regressor
2022-12-01 02:45:19,546:INFO:Total runtime is 0.15156125624974567 minutes
2022-12-01 02:45:19,554:INFO:SubProcess create_model() called ==================================
2022-12-01 02:45:19,554:INFO:Initializing create_model()
2022-12-01 02:45:19,555:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e36df10>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495abecc10>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:45:19,555:INFO:Checking exceptions
2022-12-01 02:45:19,557:INFO:Importing libraries
2022-12-01 02:45:19,557:INFO:Copying training dataset
2022-12-01 02:45:19,564:INFO:Defining folds
2022-12-01 02:45:19,565:INFO:Declaring metric variables
2022-12-01 02:45:19,573:INFO:Importing untrained model
2022-12-01 02:45:19,580:INFO:K Neighbors Regressor Imported successfully
2022-12-01 02:45:19,593:INFO:Starting cross validation
2022-12-01 02:45:19,596:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:45:19,878:INFO:Calculating mean and std
2022-12-01 02:45:19,880:INFO:Creating metrics dataframe
2022-12-01 02:45:19,894:INFO:Uploading results into container
2022-12-01 02:45:19,895:INFO:Uploading model into container now
2022-12-01 02:45:19,896:INFO:master_model_container: 11
2022-12-01 02:45:19,896:INFO:display_container: 2
2022-12-01 02:45:19,896:INFO:KNeighborsRegressor(n_jobs=-1)
2022-12-01 02:45:19,896:INFO:create_model() successfully completed......................................
2022-12-01 02:45:20,033:INFO:SubProcess create_model() end ==================================
2022-12-01 02:45:20,034:INFO:Creating metrics dataframe
2022-12-01 02:45:20,057:INFO:Initializing Decision Tree Regressor
2022-12-01 02:45:20,061:INFO:Total runtime is 0.1601459741592407 minutes
2022-12-01 02:45:20,067:INFO:SubProcess create_model() called ==================================
2022-12-01 02:45:20,068:INFO:Initializing create_model()
2022-12-01 02:45:20,068:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e36df10>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495abecc10>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:45:20,068:INFO:Checking exceptions
2022-12-01 02:45:20,072:INFO:Importing libraries
2022-12-01 02:45:20,072:INFO:Copying training dataset
2022-12-01 02:45:20,079:INFO:Defining folds
2022-12-01 02:45:20,079:INFO:Declaring metric variables
2022-12-01 02:45:20,088:INFO:Importing untrained model
2022-12-01 02:45:20,095:INFO:Decision Tree Regressor Imported successfully
2022-12-01 02:45:20,109:INFO:Starting cross validation
2022-12-01 02:45:20,110:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:45:20,427:INFO:Calculating mean and std
2022-12-01 02:45:20,429:INFO:Creating metrics dataframe
2022-12-01 02:45:20,442:INFO:Uploading results into container
2022-12-01 02:45:20,443:INFO:Uploading model into container now
2022-12-01 02:45:20,443:INFO:master_model_container: 12
2022-12-01 02:45:20,444:INFO:display_container: 2
2022-12-01 02:45:20,444:INFO:DecisionTreeRegressor(random_state=123)
2022-12-01 02:45:20,444:INFO:create_model() successfully completed......................................
2022-12-01 02:45:20,577:INFO:SubProcess create_model() end ==================================
2022-12-01 02:45:20,578:INFO:Creating metrics dataframe
2022-12-01 02:45:20,597:INFO:Initializing Random Forest Regressor
2022-12-01 02:45:20,598:INFO:Total runtime is 0.16910143295923866 minutes
2022-12-01 02:45:20,607:INFO:SubProcess create_model() called ==================================
2022-12-01 02:45:20,608:INFO:Initializing create_model()
2022-12-01 02:45:20,608:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e36df10>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495abecc10>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:45:20,608:INFO:Checking exceptions
2022-12-01 02:45:20,611:INFO:Importing libraries
2022-12-01 02:45:20,611:INFO:Copying training dataset
2022-12-01 02:45:20,616:INFO:Defining folds
2022-12-01 02:45:20,617:INFO:Declaring metric variables
2022-12-01 02:45:20,625:INFO:Importing untrained model
2022-12-01 02:45:20,636:INFO:Random Forest Regressor Imported successfully
2022-12-01 02:45:20,651:INFO:Starting cross validation
2022-12-01 02:45:20,655:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:45:24,847:INFO:Calculating mean and std
2022-12-01 02:45:24,850:INFO:Creating metrics dataframe
2022-12-01 02:45:24,862:INFO:Uploading results into container
2022-12-01 02:45:24,863:INFO:Uploading model into container now
2022-12-01 02:45:24,864:INFO:master_model_container: 13
2022-12-01 02:45:24,864:INFO:display_container: 2
2022-12-01 02:45:24,864:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-12-01 02:45:24,864:INFO:create_model() successfully completed......................................
2022-12-01 02:45:25,002:INFO:SubProcess create_model() end ==================================
2022-12-01 02:45:25,003:INFO:Creating metrics dataframe
2022-12-01 02:45:25,023:INFO:Initializing Extra Trees Regressor
2022-12-01 02:45:25,023:INFO:Total runtime is 0.2428569992383321 minutes
2022-12-01 02:45:25,033:INFO:SubProcess create_model() called ==================================
2022-12-01 02:45:25,035:INFO:Initializing create_model()
2022-12-01 02:45:25,035:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e36df10>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495abecc10>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:45:25,035:INFO:Checking exceptions
2022-12-01 02:45:25,038:INFO:Importing libraries
2022-12-01 02:45:25,038:INFO:Copying training dataset
2022-12-01 02:45:25,042:INFO:Defining folds
2022-12-01 02:45:25,043:INFO:Declaring metric variables
2022-12-01 02:45:25,054:INFO:Importing untrained model
2022-12-01 02:45:25,063:INFO:Extra Trees Regressor Imported successfully
2022-12-01 02:45:25,078:INFO:Starting cross validation
2022-12-01 02:45:25,079:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:45:27,264:INFO:Calculating mean and std
2022-12-01 02:45:27,266:INFO:Creating metrics dataframe
2022-12-01 02:45:27,275:INFO:Uploading results into container
2022-12-01 02:45:27,275:INFO:Uploading model into container now
2022-12-01 02:45:27,276:INFO:master_model_container: 14
2022-12-01 02:45:27,276:INFO:display_container: 2
2022-12-01 02:45:27,277:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-12-01 02:45:27,277:INFO:create_model() successfully completed......................................
2022-12-01 02:45:27,407:INFO:SubProcess create_model() end ==================================
2022-12-01 02:45:27,408:INFO:Creating metrics dataframe
2022-12-01 02:45:27,427:INFO:Initializing AdaBoost Regressor
2022-12-01 02:45:27,428:INFO:Total runtime is 0.2829336047172546 minutes
2022-12-01 02:45:27,435:INFO:SubProcess create_model() called ==================================
2022-12-01 02:45:27,436:INFO:Initializing create_model()
2022-12-01 02:45:27,436:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e36df10>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495abecc10>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:45:27,436:INFO:Checking exceptions
2022-12-01 02:45:27,439:INFO:Importing libraries
2022-12-01 02:45:27,439:INFO:Copying training dataset
2022-12-01 02:45:27,443:INFO:Defining folds
2022-12-01 02:45:27,444:INFO:Declaring metric variables
2022-12-01 02:45:27,452:INFO:Importing untrained model
2022-12-01 02:45:27,460:INFO:AdaBoost Regressor Imported successfully
2022-12-01 02:45:27,475:INFO:Starting cross validation
2022-12-01 02:45:27,477:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:45:28,475:INFO:Calculating mean and std
2022-12-01 02:45:28,478:INFO:Creating metrics dataframe
2022-12-01 02:45:28,485:INFO:Uploading results into container
2022-12-01 02:45:28,486:INFO:Uploading model into container now
2022-12-01 02:45:28,487:INFO:master_model_container: 15
2022-12-01 02:45:28,487:INFO:display_container: 2
2022-12-01 02:45:28,488:INFO:AdaBoostRegressor(random_state=123)
2022-12-01 02:45:28,488:INFO:create_model() successfully completed......................................
2022-12-01 02:45:28,622:INFO:SubProcess create_model() end ==================================
2022-12-01 02:45:28,624:INFO:Creating metrics dataframe
2022-12-01 02:45:28,646:INFO:Initializing Gradient Boosting Regressor
2022-12-01 02:45:28,646:INFO:Total runtime is 0.3032365520795186 minutes
2022-12-01 02:45:28,654:INFO:SubProcess create_model() called ==================================
2022-12-01 02:45:28,655:INFO:Initializing create_model()
2022-12-01 02:45:28,655:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e36df10>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495abecc10>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:45:28,655:INFO:Checking exceptions
2022-12-01 02:45:28,658:INFO:Importing libraries
2022-12-01 02:45:28,658:INFO:Copying training dataset
2022-12-01 02:45:28,665:INFO:Defining folds
2022-12-01 02:45:28,665:INFO:Declaring metric variables
2022-12-01 02:45:28,672:INFO:Importing untrained model
2022-12-01 02:45:28,680:INFO:Gradient Boosting Regressor Imported successfully
2022-12-01 02:45:28,692:INFO:Starting cross validation
2022-12-01 02:45:28,695:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:45:30,348:INFO:Calculating mean and std
2022-12-01 02:45:30,350:INFO:Creating metrics dataframe
2022-12-01 02:45:30,361:INFO:Uploading results into container
2022-12-01 02:45:30,362:INFO:Uploading model into container now
2022-12-01 02:45:30,363:INFO:master_model_container: 16
2022-12-01 02:45:30,363:INFO:display_container: 2
2022-12-01 02:45:30,363:INFO:GradientBoostingRegressor(random_state=123)
2022-12-01 02:45:30,363:INFO:create_model() successfully completed......................................
2022-12-01 02:45:30,496:INFO:SubProcess create_model() end ==================================
2022-12-01 02:45:30,496:INFO:Creating metrics dataframe
2022-12-01 02:45:30,517:INFO:Initializing Light Gradient Boosting Machine
2022-12-01 02:45:30,518:INFO:Total runtime is 0.33442632754643753 minutes
2022-12-01 02:45:30,527:INFO:SubProcess create_model() called ==================================
2022-12-01 02:45:30,531:INFO:Initializing create_model()
2022-12-01 02:45:30,531:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e36df10>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495abecc10>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:45:30,532:INFO:Checking exceptions
2022-12-01 02:45:30,534:INFO:Importing libraries
2022-12-01 02:45:30,534:INFO:Copying training dataset
2022-12-01 02:45:30,539:INFO:Defining folds
2022-12-01 02:45:30,539:INFO:Declaring metric variables
2022-12-01 02:45:30,552:INFO:Importing untrained model
2022-12-01 02:45:30,560:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-01 02:45:30,575:INFO:Starting cross validation
2022-12-01 02:45:30,577:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:45:31,994:INFO:Calculating mean and std
2022-12-01 02:45:31,997:INFO:Creating metrics dataframe
2022-12-01 02:45:32,008:INFO:Uploading results into container
2022-12-01 02:45:32,009:INFO:Uploading model into container now
2022-12-01 02:45:32,010:INFO:master_model_container: 17
2022-12-01 02:45:32,010:INFO:display_container: 2
2022-12-01 02:45:32,011:INFO:LGBMRegressor(random_state=123)
2022-12-01 02:45:32,011:INFO:create_model() successfully completed......................................
2022-12-01 02:45:32,149:INFO:SubProcess create_model() end ==================================
2022-12-01 02:45:32,149:INFO:Creating metrics dataframe
2022-12-01 02:45:32,170:INFO:Initializing Dummy Regressor
2022-12-01 02:45:32,171:INFO:Total runtime is 0.3619794845581054 minutes
2022-12-01 02:45:32,182:INFO:SubProcess create_model() called ==================================
2022-12-01 02:45:32,183:INFO:Initializing create_model()
2022-12-01 02:45:32,183:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e36df10>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495abecc10>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:45:32,183:INFO:Checking exceptions
2022-12-01 02:45:32,186:INFO:Importing libraries
2022-12-01 02:45:32,186:INFO:Copying training dataset
2022-12-01 02:45:32,191:INFO:Defining folds
2022-12-01 02:45:32,191:INFO:Declaring metric variables
2022-12-01 02:45:32,200:INFO:Importing untrained model
2022-12-01 02:45:32,209:INFO:Dummy Regressor Imported successfully
2022-12-01 02:45:32,223:INFO:Starting cross validation
2022-12-01 02:45:32,229:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:45:32,461:INFO:Calculating mean and std
2022-12-01 02:45:32,463:INFO:Creating metrics dataframe
2022-12-01 02:45:32,471:INFO:Uploading results into container
2022-12-01 02:45:32,475:INFO:Uploading model into container now
2022-12-01 02:45:32,476:INFO:master_model_container: 18
2022-12-01 02:45:32,476:INFO:display_container: 2
2022-12-01 02:45:32,476:INFO:DummyRegressor()
2022-12-01 02:45:32,477:INFO:create_model() successfully completed......................................
2022-12-01 02:45:32,610:INFO:SubProcess create_model() end ==================================
2022-12-01 02:45:32,611:INFO:Creating metrics dataframe
2022-12-01 02:45:32,659:INFO:Initializing create_model()
2022-12-01 02:45:32,659:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e36df10>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:45:32,660:INFO:Checking exceptions
2022-12-01 02:45:32,666:INFO:Importing libraries
2022-12-01 02:45:32,666:INFO:Copying training dataset
2022-12-01 02:45:32,668:INFO:Defining folds
2022-12-01 02:45:32,668:INFO:Declaring metric variables
2022-12-01 02:45:32,669:INFO:Importing untrained model
2022-12-01 02:45:32,669:INFO:Declaring custom model
2022-12-01 02:45:32,670:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-01 02:45:32,671:INFO:Cross validation set to False
2022-12-01 02:45:32,671:INFO:Fitting Model
2022-12-01 02:45:32,697:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:45:32,700:INFO:OrthogonalMatchingPursuit()
2022-12-01 02:45:32,700:INFO:create_model() successfully completed......................................
2022-12-01 02:45:32,915:INFO:master_model_container: 18
2022-12-01 02:45:32,915:INFO:display_container: 2
2022-12-01 02:45:32,916:INFO:OrthogonalMatchingPursuit()
2022-12-01 02:45:32,916:INFO:compare_models() successfully completed......................................
2022-12-01 02:49:35,222:WARNING:<ipython-input-29-9f6f7b67bc90>:10: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q1'] = abs(data['PTS_QTR1_x'] - data['PTS_QTR1_y'])

2022-12-01 02:49:35,224:WARNING:<ipython-input-29-9f6f7b67bc90>:11: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q2'] = abs(data['PTS_QTR2_x'] - data['PTS_QTR2_y'])

2022-12-01 02:49:35,226:WARNING:<ipython-input-29-9f6f7b67bc90>:12: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q3'] = abs(data['PTS_QTR3_x'] - data['PTS_QTR3_y'])

2022-12-01 02:49:35,227:WARNING:<ipython-input-29-9f6f7b67bc90>:13: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q4'] = abs(data['PTS_QTR4_x'] - data['PTS_QTR4_y'])

2022-12-01 02:49:35,229:WARNING:<ipython-input-29-9f6f7b67bc90>:15: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['PTS'] = abs(data['PTS_x'] - data['PTS_y'])

2022-12-01 02:49:35,230:WARNING:<ipython-input-29-9f6f7b67bc90>:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FG_PCT'] = abs(data['FG_PCT_x'] - data['FG_PCT_y'])

2022-12-01 02:49:35,231:WARNING:<ipython-input-29-9f6f7b67bc90>:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT'] = abs(data['FT_PCT_x'] - data['FT_PCT_y'])

2022-12-01 02:49:35,233:WARNING:<ipython-input-29-9f6f7b67bc90>:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT3'] = abs(data['FG3_PCT_x'] - data['FG3_PCT_y'])

2022-12-01 02:49:35,234:WARNING:<ipython-input-29-9f6f7b67bc90>:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['AST'] = abs(data['AST_x'] - data['AST_y'])

2022-12-01 02:49:35,235:WARNING:<ipython-input-29-9f6f7b67bc90>:20: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['REB'] = abs(data['REB_x'] - data['REB_y'])

2022-12-01 02:49:35,240:WARNING:<ipython-input-29-9f6f7b67bc90>:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['TO'] = abs(data['TOV_x'] - data['TOV_y'])

2022-12-01 02:49:35,246:INFO:PyCaret RegressionExperiment
2022-12-01 02:49:35,247:INFO:Logging name: FullData
2022-12-01 02:49:35,247:INFO:ML Usecase: MLUsecase.REGRESSION
2022-12-01 02:49:35,247:INFO:version 3.0.0.rc4
2022-12-01 02:49:35,247:INFO:Initializing setup()
2022-12-01 02:49:35,247:INFO:self.USI: b5fa
2022-12-01 02:49:35,248:INFO:self.variable_keys: {'fold_shuffle_param', 'y_test', 'pipeline', 'data', 'X', 'exp_id', 'master_model_container', '_available_plots', '_all_metrics', '_ml_usecase', 'log_plots_param', '_all_models', 'logging_param', 'idx', 'html_param', 'display_container', 'USI', 'target_param', 'fold_generator', '_gpu_n_jobs_param', 'n_jobs_param', 'transform_target_method_param', 'exp_name_log', 'X_test', 'variable_keys', 'gpu_param', 'memory', 'y_train', 'transform_target_param', 'y', 'X_train', '_all_models_internal', 'fold_groups_param', 'seed'}
2022-12-01 02:49:35,248:INFO:Checking environment
2022-12-01 02:49:35,249:INFO:python_version: 3.8.15
2022-12-01 02:49:35,249:INFO:python_build: ('default', 'Oct 12 2022 19:14:39')
2022-12-01 02:49:35,249:INFO:machine: x86_64
2022-12-01 02:49:35,249:INFO:platform: Linux-5.10.133+-x86_64-with-glibc2.27
2022-12-01 02:49:35,250:INFO:Memory: svmem(total=13616361472, available=11558113280, percent=15.1, used=1947799552, free=7853191168, active=1000161280, inactive=4389281792, buffers=424275968, cached=3391094784, shared=1245184, slab=279973888)
2022-12-01 02:49:35,250:INFO:Physical Core: 1
2022-12-01 02:49:35,250:INFO:Logical Core: 2
2022-12-01 02:49:35,250:INFO:Checking libraries
2022-12-01 02:49:35,250:INFO:System:
2022-12-01 02:49:35,251:INFO:    python: 3.8.15 (default, Oct 12 2022, 19:14:39)  [GCC 7.5.0]
2022-12-01 02:49:35,251:INFO:executable: /usr/bin/python3
2022-12-01 02:49:35,251:INFO:   machine: Linux-5.10.133+-x86_64-with-glibc2.27
2022-12-01 02:49:35,251:INFO:PyCaret required dependencies:
2022-12-01 02:49:35,251:INFO:                 pip: 21.1.3
2022-12-01 02:49:35,252:INFO:          setuptools: 57.4.0
2022-12-01 02:49:35,252:INFO:             pycaret: 3.0.0rc4
2022-12-01 02:49:35,252:INFO:             IPython: 7.9.0
2022-12-01 02:49:35,252:INFO:          ipywidgets: 7.7.1
2022-12-01 02:49:35,252:INFO:                tqdm: 4.64.1
2022-12-01 02:49:35,252:INFO:               numpy: 1.21.6
2022-12-01 02:49:35,252:INFO:              pandas: 1.3.5
2022-12-01 02:49:35,253:INFO:              jinja2: 3.0.0
2022-12-01 02:49:35,253:INFO:               scipy: 1.7.3
2022-12-01 02:49:35,253:INFO:              joblib: 1.2.0
2022-12-01 02:49:35,253:INFO:             sklearn: 1.0.2
2022-12-01 02:49:35,253:INFO:                pyod: 1.0.6
2022-12-01 02:49:35,253:INFO:            imblearn: 0.8.1
2022-12-01 02:49:35,253:INFO:   category_encoders: 2.5.1.post0
2022-12-01 02:49:35,253:INFO:            lightgbm: 3.3.3
2022-12-01 02:49:35,254:INFO:               numba: 0.55.2
2022-12-01 02:49:35,254:INFO:            requests: 2.28.1
2022-12-01 02:49:35,254:INFO:          matplotlib: 3.6.2
2022-12-01 02:49:35,254:INFO:          scikitplot: 0.3.7
2022-12-01 02:49:35,254:INFO:         yellowbrick: 1.5
2022-12-01 02:49:35,254:INFO:              plotly: 5.5.0
2022-12-01 02:49:35,254:INFO:             kaleido: 0.2.1
2022-12-01 02:49:35,254:INFO:         statsmodels: 0.12.2
2022-12-01 02:49:35,254:INFO:              sktime: 0.13.4
2022-12-01 02:49:35,255:INFO:               tbats: 1.1.1
2022-12-01 02:49:35,255:INFO:            pmdarima: 1.8.5
2022-12-01 02:49:35,255:INFO:              psutil: 5.9.4
2022-12-01 02:49:35,255:INFO:PyCaret optional dependencies:
2022-12-01 02:49:35,255:INFO:                shap: Not installed
2022-12-01 02:49:35,255:INFO:           interpret: Not installed
2022-12-01 02:49:35,255:INFO:                umap: Not installed
2022-12-01 02:49:35,255:INFO:    pandas_profiling: 1.4.1
2022-12-01 02:49:35,256:INFO:  explainerdashboard: Not installed
2022-12-01 02:49:35,256:INFO:             autoviz: Not installed
2022-12-01 02:49:35,256:INFO:           fairlearn: Not installed
2022-12-01 02:49:35,256:INFO:             xgboost: 0.90
2022-12-01 02:49:35,256:INFO:            catboost: Not installed
2022-12-01 02:49:35,256:INFO:              kmodes: Not installed
2022-12-01 02:49:35,256:INFO:             mlxtend: 0.14.0
2022-12-01 02:49:35,256:INFO:       statsforecast: Not installed
2022-12-01 02:49:35,257:INFO:        tune_sklearn: Not installed
2022-12-01 02:49:35,257:INFO:                 ray: Not installed
2022-12-01 02:49:35,257:INFO:            hyperopt: 0.1.2
2022-12-01 02:49:35,257:INFO:              optuna: Not installed
2022-12-01 02:49:35,257:INFO:               skopt: Not installed
2022-12-01 02:49:35,257:INFO:              mlflow: Not installed
2022-12-01 02:49:35,257:INFO:              gradio: Not installed
2022-12-01 02:49:35,257:INFO:             fastapi: Not installed
2022-12-01 02:49:35,258:INFO:             uvicorn: Not installed
2022-12-01 02:49:35,258:INFO:              m2cgen: Not installed
2022-12-01 02:49:35,258:INFO:           evidently: Not installed
2022-12-01 02:49:35,258:INFO:                nltk: 3.7
2022-12-01 02:49:35,258:INFO:            pyLDAvis: Not installed
2022-12-01 02:49:35,258:INFO:              gensim: 3.6.0
2022-12-01 02:49:35,258:INFO:               spacy: 3.4.3
2022-12-01 02:49:35,258:INFO:           wordcloud: 1.8.2.2
2022-12-01 02:49:35,258:INFO:            textblob: 0.15.3
2022-12-01 02:49:35,259:INFO:               fugue: Not installed
2022-12-01 02:49:35,259:INFO:           streamlit: Not installed
2022-12-01 02:49:35,259:INFO:             prophet: 1.1.1
2022-12-01 02:49:35,259:INFO:None
2022-12-01 02:49:35,259:INFO:Set up data.
2022-12-01 02:49:35,266:INFO:Set up train/test split.
2022-12-01 02:49:35,270:INFO:Set up index.
2022-12-01 02:49:35,270:INFO:Set up folding strategy.
2022-12-01 02:49:35,270:INFO:Assigning column types.
2022-12-01 02:49:35,276:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-12-01 02:49:35,276:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-01 02:49:35,281:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:49:35,286:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:49:35,347:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:49:35,402:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:49:35,403:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:49:35,404:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:49:35,404:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:49:35,405:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-01 02:49:35,409:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:49:35,415:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:49:35,473:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:49:35,519:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:49:35,520:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:49:35,521:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:49:35,521:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:49:35,521:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-12-01 02:49:35,528:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:49:35,542:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:49:35,649:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:49:35,806:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:49:35,817:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:49:35,817:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:49:35,820:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:49:35,845:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 02:49:35,868:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:49:36,013:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:49:36,129:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:49:36,130:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:49:36,131:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:49:36,131:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:49:36,132:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-12-01 02:49:36,151:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:49:36,293:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:49:36,440:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:49:36,441:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:49:36,442:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:49:36,442:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:49:36,462:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 02:49:36,604:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:49:36,729:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:49:36,735:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:49:36,742:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:49:36,742:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:49:36,743:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-12-01 02:49:36,973:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:49:37,087:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:49:37,089:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:49:37,090:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:49:37,090:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:49:37,226:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:49:37,277:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 02:49:37,278:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:49:37,278:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:49:37,278:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:49:37,279:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-12-01 02:49:37,353:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:49:37,403:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:49:37,404:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:49:37,404:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:49:37,490:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 02:49:37,540:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:49:37,540:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:49:37,541:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:49:37,541:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-12-01 02:49:37,665:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:49:37,665:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:49:37,666:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:49:37,789:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:49:37,790:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:49:37,790:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:49:37,792:INFO:Preparing preprocessing pipeline...
2022-12-01 02:49:37,793:INFO:Set up simple imputation.
2022-12-01 02:49:37,793:INFO:Set up variance threshold.
2022-12-01 02:49:37,807:INFO:Finished creating preprocessing pipeline.
2022-12-01 02:49:37,813:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO',
                                             'Open_Line_ML_x'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-12-01 02:49:37,813:INFO:Creating final display dataframe.
2022-12-01 02:49:37,889:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 13)
4         Train data shape    (607, 13)
5          Test data shape    (261, 13)
6         Numeric features           12
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         b5fa
2022-12-01 02:49:38,037:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:49:38,038:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:49:38,039:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:49:38,166:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 02:49:38,166:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 02:49:38,167:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 02:49:38,174:INFO:setup() successfully completed in 2.93s...............
2022-12-01 02:49:38,175:INFO:Initializing compare_models()
2022-12-01 02:49:38,175:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4967d6e070>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f4967d6e070>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-12-01 02:49:38,175:INFO:Checking exceptions
2022-12-01 02:49:38,176:INFO:Preparing display monitor
2022-12-01 02:49:38,262:INFO:Initializing Linear Regression
2022-12-01 02:49:38,266:INFO:Total runtime is 5.852381388346354e-05 minutes
2022-12-01 02:49:38,272:INFO:SubProcess create_model() called ==================================
2022-12-01 02:49:38,275:INFO:Initializing create_model()
2022-12-01 02:49:38,276:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4967d6e070>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fd6de80>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:49:38,276:INFO:Checking exceptions
2022-12-01 02:49:38,278:INFO:Importing libraries
2022-12-01 02:49:38,278:INFO:Copying training dataset
2022-12-01 02:49:38,281:INFO:Defining folds
2022-12-01 02:49:38,281:INFO:Declaring metric variables
2022-12-01 02:49:38,286:INFO:Importing untrained model
2022-12-01 02:49:38,294:INFO:Linear Regression Imported successfully
2022-12-01 02:49:38,307:INFO:Starting cross validation
2022-12-01 02:49:38,311:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:49:38,604:INFO:Calculating mean and std
2022-12-01 02:49:38,605:INFO:Creating metrics dataframe
2022-12-01 02:49:38,610:INFO:Uploading results into container
2022-12-01 02:49:38,611:INFO:Uploading model into container now
2022-12-01 02:49:38,611:INFO:master_model_container: 1
2022-12-01 02:49:38,611:INFO:display_container: 2
2022-12-01 02:49:38,612:INFO:LinearRegression(n_jobs=-1)
2022-12-01 02:49:38,612:INFO:create_model() successfully completed......................................
2022-12-01 02:49:38,787:INFO:SubProcess create_model() end ==================================
2022-12-01 02:49:38,788:INFO:Creating metrics dataframe
2022-12-01 02:49:38,807:INFO:Initializing Lasso Regression
2022-12-01 02:49:38,808:INFO:Total runtime is 0.009091262022654216 minutes
2022-12-01 02:49:38,816:INFO:SubProcess create_model() called ==================================
2022-12-01 02:49:38,817:INFO:Initializing create_model()
2022-12-01 02:49:38,817:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4967d6e070>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fd6de80>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:49:38,817:INFO:Checking exceptions
2022-12-01 02:49:38,821:INFO:Importing libraries
2022-12-01 02:49:38,822:INFO:Copying training dataset
2022-12-01 02:49:38,825:INFO:Defining folds
2022-12-01 02:49:38,825:INFO:Declaring metric variables
2022-12-01 02:49:38,830:INFO:Importing untrained model
2022-12-01 02:49:38,840:INFO:Lasso Regression Imported successfully
2022-12-01 02:49:38,855:INFO:Starting cross validation
2022-12-01 02:49:38,858:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:49:39,124:INFO:Calculating mean and std
2022-12-01 02:49:39,125:INFO:Creating metrics dataframe
2022-12-01 02:49:39,130:INFO:Uploading results into container
2022-12-01 02:49:39,130:INFO:Uploading model into container now
2022-12-01 02:49:39,131:INFO:master_model_container: 2
2022-12-01 02:49:39,131:INFO:display_container: 2
2022-12-01 02:49:39,131:INFO:Lasso(random_state=123)
2022-12-01 02:49:39,131:INFO:create_model() successfully completed......................................
2022-12-01 02:49:39,275:INFO:SubProcess create_model() end ==================================
2022-12-01 02:49:39,275:INFO:Creating metrics dataframe
2022-12-01 02:49:39,294:INFO:Initializing Ridge Regression
2022-12-01 02:49:39,294:INFO:Total runtime is 0.017200295130411783 minutes
2022-12-01 02:49:39,302:INFO:SubProcess create_model() called ==================================
2022-12-01 02:49:39,304:INFO:Initializing create_model()
2022-12-01 02:49:39,304:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4967d6e070>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fd6de80>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:49:39,304:INFO:Checking exceptions
2022-12-01 02:49:39,307:INFO:Importing libraries
2022-12-01 02:49:39,307:INFO:Copying training dataset
2022-12-01 02:49:39,314:INFO:Defining folds
2022-12-01 02:49:39,314:INFO:Declaring metric variables
2022-12-01 02:49:39,323:INFO:Importing untrained model
2022-12-01 02:49:39,331:INFO:Ridge Regression Imported successfully
2022-12-01 02:49:39,345:INFO:Starting cross validation
2022-12-01 02:49:39,346:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:49:39,383:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.03719e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:49:39,409:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.05541e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:49:39,446:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.04032e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:49:39,470:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.0964e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:49:39,523:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.08942e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:49:39,531:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.07071e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:49:39,564:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.05338e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:49:39,567:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.02164e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:49:39,606:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.05414e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:49:39,609:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.04893e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 02:49:39,626:INFO:Calculating mean and std
2022-12-01 02:49:39,628:INFO:Creating metrics dataframe
2022-12-01 02:49:39,640:INFO:Uploading results into container
2022-12-01 02:49:39,641:INFO:Uploading model into container now
2022-12-01 02:49:39,642:INFO:master_model_container: 3
2022-12-01 02:49:39,642:INFO:display_container: 2
2022-12-01 02:49:39,643:INFO:Ridge(random_state=123)
2022-12-01 02:49:39,643:INFO:create_model() successfully completed......................................
2022-12-01 02:49:39,778:INFO:SubProcess create_model() end ==================================
2022-12-01 02:49:39,778:INFO:Creating metrics dataframe
2022-12-01 02:49:39,797:INFO:Initializing Elastic Net
2022-12-01 02:49:39,797:INFO:Total runtime is 0.02558933893839518 minutes
2022-12-01 02:49:39,806:INFO:SubProcess create_model() called ==================================
2022-12-01 02:49:39,808:INFO:Initializing create_model()
2022-12-01 02:49:39,810:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4967d6e070>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fd6de80>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:49:39,810:INFO:Checking exceptions
2022-12-01 02:49:39,812:INFO:Importing libraries
2022-12-01 02:49:39,813:INFO:Copying training dataset
2022-12-01 02:49:39,818:INFO:Defining folds
2022-12-01 02:49:39,819:INFO:Declaring metric variables
2022-12-01 02:49:39,828:INFO:Importing untrained model
2022-12-01 02:49:39,836:INFO:Elastic Net Imported successfully
2022-12-01 02:49:39,850:INFO:Starting cross validation
2022-12-01 02:49:39,852:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:49:40,112:INFO:Calculating mean and std
2022-12-01 02:49:40,119:INFO:Creating metrics dataframe
2022-12-01 02:49:40,127:INFO:Uploading results into container
2022-12-01 02:49:40,128:INFO:Uploading model into container now
2022-12-01 02:49:40,128:INFO:master_model_container: 4
2022-12-01 02:49:40,128:INFO:display_container: 2
2022-12-01 02:49:40,129:INFO:ElasticNet(random_state=123)
2022-12-01 02:49:40,129:INFO:create_model() successfully completed......................................
2022-12-01 02:49:40,268:INFO:SubProcess create_model() end ==================================
2022-12-01 02:49:40,268:INFO:Creating metrics dataframe
2022-12-01 02:49:40,288:INFO:Initializing Least Angle Regression
2022-12-01 02:49:40,288:INFO:Total runtime is 0.033768379688262934 minutes
2022-12-01 02:49:40,296:INFO:SubProcess create_model() called ==================================
2022-12-01 02:49:40,297:INFO:Initializing create_model()
2022-12-01 02:49:40,297:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4967d6e070>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fd6de80>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:49:40,297:INFO:Checking exceptions
2022-12-01 02:49:40,301:INFO:Importing libraries
2022-12-01 02:49:40,302:INFO:Copying training dataset
2022-12-01 02:49:40,306:INFO:Defining folds
2022-12-01 02:49:40,306:INFO:Declaring metric variables
2022-12-01 02:49:40,319:INFO:Importing untrained model
2022-12-01 02:49:40,328:INFO:Least Angle Regression Imported successfully
2022-12-01 02:49:40,344:INFO:Starting cross validation
2022-12-01 02:49:40,347:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:49:40,385:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:49:40,413:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:49:40,436:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:49:40,488:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:49:40,495:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:49:40,551:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:49:40,553:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:49:40,592:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:49:40,595:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:49:40,628:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:49:40,641:INFO:Calculating mean and std
2022-12-01 02:49:40,643:INFO:Creating metrics dataframe
2022-12-01 02:49:40,651:INFO:Uploading results into container
2022-12-01 02:49:40,651:INFO:Uploading model into container now
2022-12-01 02:49:40,652:INFO:master_model_container: 5
2022-12-01 02:49:40,652:INFO:display_container: 2
2022-12-01 02:49:40,653:INFO:Lars(random_state=123)
2022-12-01 02:49:40,653:INFO:create_model() successfully completed......................................
2022-12-01 02:49:40,797:INFO:SubProcess create_model() end ==================================
2022-12-01 02:49:40,798:INFO:Creating metrics dataframe
2022-12-01 02:49:40,827:INFO:Initializing Lasso Least Angle Regression
2022-12-01 02:49:40,828:INFO:Total runtime is 0.042759561538696284 minutes
2022-12-01 02:49:40,834:INFO:SubProcess create_model() called ==================================
2022-12-01 02:49:40,836:INFO:Initializing create_model()
2022-12-01 02:49:40,836:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4967d6e070>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fd6de80>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:49:40,836:INFO:Checking exceptions
2022-12-01 02:49:40,840:INFO:Importing libraries
2022-12-01 02:49:40,840:INFO:Copying training dataset
2022-12-01 02:49:40,845:INFO:Defining folds
2022-12-01 02:49:40,846:INFO:Declaring metric variables
2022-12-01 02:49:40,855:INFO:Importing untrained model
2022-12-01 02:49:40,867:INFO:Lasso Least Angle Regression Imported successfully
2022-12-01 02:49:40,885:INFO:Starting cross validation
2022-12-01 02:49:40,886:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:49:40,922:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:49:40,948:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:49:40,975:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:49:41,007:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:49:41,032:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:49:41,050:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:49:41,087:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:49:41,092:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:49:41,128:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:49:41,134:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 02:49:41,160:INFO:Calculating mean and std
2022-12-01 02:49:41,163:INFO:Creating metrics dataframe
2022-12-01 02:49:41,174:INFO:Uploading results into container
2022-12-01 02:49:41,175:INFO:Uploading model into container now
2022-12-01 02:49:41,175:INFO:master_model_container: 6
2022-12-01 02:49:41,176:INFO:display_container: 2
2022-12-01 02:49:41,176:INFO:LassoLars(random_state=123)
2022-12-01 02:49:41,176:INFO:create_model() successfully completed......................................
2022-12-01 02:49:41,318:INFO:SubProcess create_model() end ==================================
2022-12-01 02:49:41,319:INFO:Creating metrics dataframe
2022-12-01 02:49:41,338:INFO:Initializing Orthogonal Matching Pursuit
2022-12-01 02:49:41,339:INFO:Total runtime is 0.05128015279769897 minutes
2022-12-01 02:49:41,348:INFO:SubProcess create_model() called ==================================
2022-12-01 02:49:41,349:INFO:Initializing create_model()
2022-12-01 02:49:41,349:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4967d6e070>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fd6de80>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:49:41,349:INFO:Checking exceptions
2022-12-01 02:49:41,352:INFO:Importing libraries
2022-12-01 02:49:41,352:INFO:Copying training dataset
2022-12-01 02:49:41,358:INFO:Defining folds
2022-12-01 02:49:41,358:INFO:Declaring metric variables
2022-12-01 02:49:41,368:INFO:Importing untrained model
2022-12-01 02:49:41,378:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-01 02:49:41,395:INFO:Starting cross validation
2022-12-01 02:49:41,398:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:49:41,433:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:49:41,456:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:49:41,488:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:49:41,540:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:49:41,537:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:49:41,586:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:49:41,601:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:49:41,625:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:49:41,637:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:49:41,662:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:49:41,676:INFO:Calculating mean and std
2022-12-01 02:49:41,678:INFO:Creating metrics dataframe
2022-12-01 02:49:41,685:INFO:Uploading results into container
2022-12-01 02:49:41,687:INFO:Uploading model into container now
2022-12-01 02:49:41,687:INFO:master_model_container: 7
2022-12-01 02:49:41,687:INFO:display_container: 2
2022-12-01 02:49:41,688:INFO:OrthogonalMatchingPursuit()
2022-12-01 02:49:41,688:INFO:create_model() successfully completed......................................
2022-12-01 02:49:41,829:INFO:SubProcess create_model() end ==================================
2022-12-01 02:49:41,829:INFO:Creating metrics dataframe
2022-12-01 02:49:41,855:INFO:Initializing Bayesian Ridge
2022-12-01 02:49:41,858:INFO:Total runtime is 0.05993746916453043 minutes
2022-12-01 02:49:41,866:INFO:SubProcess create_model() called ==================================
2022-12-01 02:49:41,868:INFO:Initializing create_model()
2022-12-01 02:49:41,868:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4967d6e070>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fd6de80>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:49:41,868:INFO:Checking exceptions
2022-12-01 02:49:41,871:INFO:Importing libraries
2022-12-01 02:49:41,871:INFO:Copying training dataset
2022-12-01 02:49:41,878:INFO:Defining folds
2022-12-01 02:49:41,878:INFO:Declaring metric variables
2022-12-01 02:49:41,886:INFO:Importing untrained model
2022-12-01 02:49:41,895:INFO:Bayesian Ridge Imported successfully
2022-12-01 02:49:41,910:INFO:Starting cross validation
2022-12-01 02:49:41,912:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:49:42,179:INFO:Calculating mean and std
2022-12-01 02:49:42,182:INFO:Creating metrics dataframe
2022-12-01 02:49:42,188:INFO:Uploading results into container
2022-12-01 02:49:42,189:INFO:Uploading model into container now
2022-12-01 02:49:42,190:INFO:master_model_container: 8
2022-12-01 02:49:42,190:INFO:display_container: 2
2022-12-01 02:49:42,191:INFO:BayesianRidge()
2022-12-01 02:49:42,191:INFO:create_model() successfully completed......................................
2022-12-01 02:49:42,333:INFO:SubProcess create_model() end ==================================
2022-12-01 02:49:42,333:INFO:Creating metrics dataframe
2022-12-01 02:49:42,360:INFO:Initializing Passive Aggressive Regressor
2022-12-01 02:49:42,361:INFO:Total runtime is 0.06830897331237792 minutes
2022-12-01 02:49:42,368:INFO:SubProcess create_model() called ==================================
2022-12-01 02:49:42,369:INFO:Initializing create_model()
2022-12-01 02:49:42,369:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4967d6e070>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fd6de80>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:49:42,370:INFO:Checking exceptions
2022-12-01 02:49:42,373:INFO:Importing libraries
2022-12-01 02:49:42,373:INFO:Copying training dataset
2022-12-01 02:49:42,378:INFO:Defining folds
2022-12-01 02:49:42,378:INFO:Declaring metric variables
2022-12-01 02:49:42,387:INFO:Importing untrained model
2022-12-01 02:49:42,397:INFO:Passive Aggressive Regressor Imported successfully
2022-12-01 02:49:42,414:INFO:Starting cross validation
2022-12-01 02:49:42,416:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:49:42,696:INFO:Calculating mean and std
2022-12-01 02:49:42,699:INFO:Creating metrics dataframe
2022-12-01 02:49:42,706:INFO:Uploading results into container
2022-12-01 02:49:42,707:INFO:Uploading model into container now
2022-12-01 02:49:42,708:INFO:master_model_container: 9
2022-12-01 02:49:42,708:INFO:display_container: 2
2022-12-01 02:49:42,708:INFO:PassiveAggressiveRegressor(random_state=123)
2022-12-01 02:49:42,709:INFO:create_model() successfully completed......................................
2022-12-01 02:49:42,850:INFO:SubProcess create_model() end ==================================
2022-12-01 02:49:42,852:INFO:Creating metrics dataframe
2022-12-01 02:49:42,872:INFO:Initializing Huber Regressor
2022-12-01 02:49:42,872:INFO:Total runtime is 0.0768341302871704 minutes
2022-12-01 02:49:42,880:INFO:SubProcess create_model() called ==================================
2022-12-01 02:49:42,882:INFO:Initializing create_model()
2022-12-01 02:49:42,882:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4967d6e070>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fd6de80>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:49:42,882:INFO:Checking exceptions
2022-12-01 02:49:42,885:INFO:Importing libraries
2022-12-01 02:49:42,885:INFO:Copying training dataset
2022-12-01 02:49:42,889:INFO:Defining folds
2022-12-01 02:49:42,890:INFO:Declaring metric variables
2022-12-01 02:49:42,900:INFO:Importing untrained model
2022-12-01 02:49:42,911:INFO:Huber Regressor Imported successfully
2022-12-01 02:49:42,929:INFO:Starting cross validation
2022-12-01 02:49:42,930:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:49:43,021:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:49:43,055:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:49:43,143:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:49:43,166:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:49:43,252:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:49:43,278:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:49:43,343:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:49:43,368:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:49:43,435:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:49:43,457:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 02:49:43,469:INFO:Calculating mean and std
2022-12-01 02:49:43,471:INFO:Creating metrics dataframe
2022-12-01 02:49:43,482:INFO:Uploading results into container
2022-12-01 02:49:43,483:INFO:Uploading model into container now
2022-12-01 02:49:43,484:INFO:master_model_container: 10
2022-12-01 02:49:43,485:INFO:display_container: 2
2022-12-01 02:49:43,486:INFO:HuberRegressor()
2022-12-01 02:49:43,492:INFO:create_model() successfully completed......................................
2022-12-01 02:49:43,635:INFO:SubProcess create_model() end ==================================
2022-12-01 02:49:43,636:INFO:Creating metrics dataframe
2022-12-01 02:49:43,655:INFO:Initializing K Neighbors Regressor
2022-12-01 02:49:43,656:INFO:Total runtime is 0.08989460468292235 minutes
2022-12-01 02:49:43,663:INFO:SubProcess create_model() called ==================================
2022-12-01 02:49:43,664:INFO:Initializing create_model()
2022-12-01 02:49:43,664:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4967d6e070>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fd6de80>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:49:43,667:INFO:Checking exceptions
2022-12-01 02:49:43,670:INFO:Importing libraries
2022-12-01 02:49:43,670:INFO:Copying training dataset
2022-12-01 02:49:43,676:INFO:Defining folds
2022-12-01 02:49:43,677:INFO:Declaring metric variables
2022-12-01 02:49:43,685:INFO:Importing untrained model
2022-12-01 02:49:43,695:INFO:K Neighbors Regressor Imported successfully
2022-12-01 02:49:43,712:INFO:Starting cross validation
2022-12-01 02:49:43,714:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:49:44,010:INFO:Calculating mean and std
2022-12-01 02:49:44,012:INFO:Creating metrics dataframe
2022-12-01 02:49:44,025:INFO:Uploading results into container
2022-12-01 02:49:44,026:INFO:Uploading model into container now
2022-12-01 02:49:44,027:INFO:master_model_container: 11
2022-12-01 02:49:44,027:INFO:display_container: 2
2022-12-01 02:49:44,028:INFO:KNeighborsRegressor(n_jobs=-1)
2022-12-01 02:49:44,028:INFO:create_model() successfully completed......................................
2022-12-01 02:49:44,163:INFO:SubProcess create_model() end ==================================
2022-12-01 02:49:44,163:INFO:Creating metrics dataframe
2022-12-01 02:49:44,182:INFO:Initializing Decision Tree Regressor
2022-12-01 02:49:44,182:INFO:Total runtime is 0.09867017666498819 minutes
2022-12-01 02:49:44,192:INFO:SubProcess create_model() called ==================================
2022-12-01 02:49:44,193:INFO:Initializing create_model()
2022-12-01 02:49:44,194:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4967d6e070>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fd6de80>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:49:44,194:INFO:Checking exceptions
2022-12-01 02:49:44,197:INFO:Importing libraries
2022-12-01 02:49:44,197:INFO:Copying training dataset
2022-12-01 02:49:44,200:INFO:Defining folds
2022-12-01 02:49:44,201:INFO:Declaring metric variables
2022-12-01 02:49:44,211:INFO:Importing untrained model
2022-12-01 02:49:44,221:INFO:Decision Tree Regressor Imported successfully
2022-12-01 02:49:44,239:INFO:Starting cross validation
2022-12-01 02:49:44,240:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:49:44,566:INFO:Calculating mean and std
2022-12-01 02:49:44,569:INFO:Creating metrics dataframe
2022-12-01 02:49:44,579:INFO:Uploading results into container
2022-12-01 02:49:44,580:INFO:Uploading model into container now
2022-12-01 02:49:44,580:INFO:master_model_container: 12
2022-12-01 02:49:44,581:INFO:display_container: 2
2022-12-01 02:49:44,581:INFO:DecisionTreeRegressor(random_state=123)
2022-12-01 02:49:44,581:INFO:create_model() successfully completed......................................
2022-12-01 02:49:44,720:INFO:SubProcess create_model() end ==================================
2022-12-01 02:49:44,720:INFO:Creating metrics dataframe
2022-12-01 02:49:44,739:INFO:Initializing Random Forest Regressor
2022-12-01 02:49:44,739:INFO:Total runtime is 0.10795597632726033 minutes
2022-12-01 02:49:44,747:INFO:SubProcess create_model() called ==================================
2022-12-01 02:49:44,748:INFO:Initializing create_model()
2022-12-01 02:49:44,748:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4967d6e070>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fd6de80>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:49:44,748:INFO:Checking exceptions
2022-12-01 02:49:44,751:INFO:Importing libraries
2022-12-01 02:49:44,751:INFO:Copying training dataset
2022-12-01 02:49:44,757:INFO:Defining folds
2022-12-01 02:49:44,757:INFO:Declaring metric variables
2022-12-01 02:49:44,769:INFO:Importing untrained model
2022-12-01 02:49:44,775:INFO:Random Forest Regressor Imported successfully
2022-12-01 02:49:44,792:INFO:Starting cross validation
2022-12-01 02:49:44,795:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:49:49,224:INFO:Calculating mean and std
2022-12-01 02:49:49,232:INFO:Creating metrics dataframe
2022-12-01 02:49:49,243:INFO:Uploading results into container
2022-12-01 02:49:49,245:INFO:Uploading model into container now
2022-12-01 02:49:49,247:INFO:master_model_container: 13
2022-12-01 02:49:49,247:INFO:display_container: 2
2022-12-01 02:49:49,248:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-12-01 02:49:49,248:INFO:create_model() successfully completed......................................
2022-12-01 02:49:49,387:INFO:SubProcess create_model() end ==================================
2022-12-01 02:49:49,387:INFO:Creating metrics dataframe
2022-12-01 02:49:49,407:INFO:Initializing Extra Trees Regressor
2022-12-01 02:49:49,407:INFO:Total runtime is 0.1857566237449646 minutes
2022-12-01 02:49:49,416:INFO:SubProcess create_model() called ==================================
2022-12-01 02:49:49,417:INFO:Initializing create_model()
2022-12-01 02:49:49,417:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4967d6e070>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fd6de80>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:49:49,417:INFO:Checking exceptions
2022-12-01 02:49:49,421:INFO:Importing libraries
2022-12-01 02:49:49,421:INFO:Copying training dataset
2022-12-01 02:49:49,428:INFO:Defining folds
2022-12-01 02:49:49,428:INFO:Declaring metric variables
2022-12-01 02:49:49,436:INFO:Importing untrained model
2022-12-01 02:49:49,445:INFO:Extra Trees Regressor Imported successfully
2022-12-01 02:49:49,462:INFO:Starting cross validation
2022-12-01 02:49:49,469:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:49:51,734:INFO:Calculating mean and std
2022-12-01 02:49:51,738:INFO:Creating metrics dataframe
2022-12-01 02:49:51,747:INFO:Uploading results into container
2022-12-01 02:49:51,749:INFO:Uploading model into container now
2022-12-01 02:49:51,749:INFO:master_model_container: 14
2022-12-01 02:49:51,749:INFO:display_container: 2
2022-12-01 02:49:51,750:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-12-01 02:49:51,750:INFO:create_model() successfully completed......................................
2022-12-01 02:49:51,894:INFO:SubProcess create_model() end ==================================
2022-12-01 02:49:51,895:INFO:Creating metrics dataframe
2022-12-01 02:49:51,916:INFO:Initializing AdaBoost Regressor
2022-12-01 02:49:51,917:INFO:Total runtime is 0.2275817314783732 minutes
2022-12-01 02:49:51,925:INFO:SubProcess create_model() called ==================================
2022-12-01 02:49:51,925:INFO:Initializing create_model()
2022-12-01 02:49:51,926:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4967d6e070>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fd6de80>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:49:51,926:INFO:Checking exceptions
2022-12-01 02:49:51,928:INFO:Importing libraries
2022-12-01 02:49:51,928:INFO:Copying training dataset
2022-12-01 02:49:51,936:INFO:Defining folds
2022-12-01 02:49:51,936:INFO:Declaring metric variables
2022-12-01 02:49:51,948:INFO:Importing untrained model
2022-12-01 02:49:51,956:INFO:AdaBoost Regressor Imported successfully
2022-12-01 02:49:51,969:INFO:Starting cross validation
2022-12-01 02:49:51,971:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:49:53,069:INFO:Calculating mean and std
2022-12-01 02:49:53,072:INFO:Creating metrics dataframe
2022-12-01 02:49:53,082:INFO:Uploading results into container
2022-12-01 02:49:53,083:INFO:Uploading model into container now
2022-12-01 02:49:53,084:INFO:master_model_container: 15
2022-12-01 02:49:53,084:INFO:display_container: 2
2022-12-01 02:49:53,084:INFO:AdaBoostRegressor(random_state=123)
2022-12-01 02:49:53,085:INFO:create_model() successfully completed......................................
2022-12-01 02:49:53,222:INFO:SubProcess create_model() end ==================================
2022-12-01 02:49:53,223:INFO:Creating metrics dataframe
2022-12-01 02:49:53,247:INFO:Initializing Gradient Boosting Regressor
2022-12-01 02:49:53,249:INFO:Total runtime is 0.24978129069010416 minutes
2022-12-01 02:49:53,258:INFO:SubProcess create_model() called ==================================
2022-12-01 02:49:53,259:INFO:Initializing create_model()
2022-12-01 02:49:53,259:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4967d6e070>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fd6de80>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:49:53,259:INFO:Checking exceptions
2022-12-01 02:49:53,262:INFO:Importing libraries
2022-12-01 02:49:53,262:INFO:Copying training dataset
2022-12-01 02:49:53,269:INFO:Defining folds
2022-12-01 02:49:53,269:INFO:Declaring metric variables
2022-12-01 02:49:53,278:INFO:Importing untrained model
2022-12-01 02:49:53,285:INFO:Gradient Boosting Regressor Imported successfully
2022-12-01 02:49:53,300:INFO:Starting cross validation
2022-12-01 02:49:53,307:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:49:55,123:INFO:Calculating mean and std
2022-12-01 02:49:55,125:INFO:Creating metrics dataframe
2022-12-01 02:49:55,135:INFO:Uploading results into container
2022-12-01 02:49:55,136:INFO:Uploading model into container now
2022-12-01 02:49:55,137:INFO:master_model_container: 16
2022-12-01 02:49:55,137:INFO:display_container: 2
2022-12-01 02:49:55,138:INFO:GradientBoostingRegressor(random_state=123)
2022-12-01 02:49:55,139:INFO:create_model() successfully completed......................................
2022-12-01 02:49:55,277:INFO:SubProcess create_model() end ==================================
2022-12-01 02:49:55,277:INFO:Creating metrics dataframe
2022-12-01 02:49:55,297:INFO:Initializing Light Gradient Boosting Machine
2022-12-01 02:49:55,298:INFO:Total runtime is 0.28392653465270995 minutes
2022-12-01 02:49:55,306:INFO:SubProcess create_model() called ==================================
2022-12-01 02:49:55,306:INFO:Initializing create_model()
2022-12-01 02:49:55,307:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4967d6e070>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fd6de80>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:49:55,307:INFO:Checking exceptions
2022-12-01 02:49:55,310:INFO:Importing libraries
2022-12-01 02:49:55,310:INFO:Copying training dataset
2022-12-01 02:49:55,315:INFO:Defining folds
2022-12-01 02:49:55,317:INFO:Declaring metric variables
2022-12-01 02:49:55,326:INFO:Importing untrained model
2022-12-01 02:49:55,335:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-01 02:49:55,349:INFO:Starting cross validation
2022-12-01 02:49:55,351:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:49:56,176:INFO:Calculating mean and std
2022-12-01 02:49:56,180:INFO:Creating metrics dataframe
2022-12-01 02:49:56,192:INFO:Uploading results into container
2022-12-01 02:49:56,193:INFO:Uploading model into container now
2022-12-01 02:49:56,193:INFO:master_model_container: 17
2022-12-01 02:49:56,194:INFO:display_container: 2
2022-12-01 02:49:56,194:INFO:LGBMRegressor(random_state=123)
2022-12-01 02:49:56,194:INFO:create_model() successfully completed......................................
2022-12-01 02:49:56,330:INFO:SubProcess create_model() end ==================================
2022-12-01 02:49:56,331:INFO:Creating metrics dataframe
2022-12-01 02:49:56,352:INFO:Initializing Dummy Regressor
2022-12-01 02:49:56,352:INFO:Total runtime is 0.30150636831919353 minutes
2022-12-01 02:49:56,361:INFO:SubProcess create_model() called ==================================
2022-12-01 02:49:56,362:INFO:Initializing create_model()
2022-12-01 02:49:56,362:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4967d6e070>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fd6de80>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:49:56,363:INFO:Checking exceptions
2022-12-01 02:49:56,366:INFO:Importing libraries
2022-12-01 02:49:56,366:INFO:Copying training dataset
2022-12-01 02:49:56,371:INFO:Defining folds
2022-12-01 02:49:56,372:INFO:Declaring metric variables
2022-12-01 02:49:56,381:INFO:Importing untrained model
2022-12-01 02:49:56,391:INFO:Dummy Regressor Imported successfully
2022-12-01 02:49:56,409:INFO:Starting cross validation
2022-12-01 02:49:56,415:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 02:49:56,654:INFO:Calculating mean and std
2022-12-01 02:49:56,656:INFO:Creating metrics dataframe
2022-12-01 02:49:56,668:INFO:Uploading results into container
2022-12-01 02:49:56,673:INFO:Uploading model into container now
2022-12-01 02:49:56,673:INFO:master_model_container: 18
2022-12-01 02:49:56,673:INFO:display_container: 2
2022-12-01 02:49:56,674:INFO:DummyRegressor()
2022-12-01 02:49:56,674:INFO:create_model() successfully completed......................................
2022-12-01 02:49:56,810:INFO:SubProcess create_model() end ==================================
2022-12-01 02:49:56,810:INFO:Creating metrics dataframe
2022-12-01 02:49:56,859:INFO:Initializing create_model()
2022-12-01 02:49:56,859:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4967d6e070>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-01 02:49:56,859:INFO:Checking exceptions
2022-12-01 02:49:56,866:INFO:Importing libraries
2022-12-01 02:49:56,867:INFO:Copying training dataset
2022-12-01 02:49:56,871:INFO:Defining folds
2022-12-01 02:49:56,872:INFO:Declaring metric variables
2022-12-01 02:49:56,872:INFO:Importing untrained model
2022-12-01 02:49:56,872:INFO:Declaring custom model
2022-12-01 02:49:56,873:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-01 02:49:56,875:INFO:Cross validation set to False
2022-12-01 02:49:56,875:INFO:Fitting Model
2022-12-01 02:49:56,893:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 02:49:56,897:INFO:OrthogonalMatchingPursuit()
2022-12-01 02:49:56,897:INFO:create_model() successfully completed......................................
2022-12-01 02:49:57,126:INFO:master_model_container: 18
2022-12-01 02:49:57,128:INFO:display_container: 2
2022-12-01 02:49:57,130:INFO:OrthogonalMatchingPursuit()
2022-12-01 02:49:57,130:INFO:compare_models() successfully completed......................................
2022-12-01 02:50:32,621:WARNING:<ipython-input-30-eecbb6570112>:10: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q1'] = abs(data['PTS_QTR1_x'] - data['PTS_QTR1_y'])

2022-12-01 02:50:32,622:WARNING:<ipython-input-30-eecbb6570112>:11: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q2'] = abs(data['PTS_QTR2_x'] - data['PTS_QTR2_y'])

2022-12-01 02:50:32,623:WARNING:<ipython-input-30-eecbb6570112>:12: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q3'] = abs(data['PTS_QTR3_x'] - data['PTS_QTR3_y'])

2022-12-01 02:50:32,624:WARNING:<ipython-input-30-eecbb6570112>:13: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q4'] = abs(data['PTS_QTR4_x'] - data['PTS_QTR4_y'])

2022-12-01 02:50:32,625:WARNING:<ipython-input-30-eecbb6570112>:15: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['PTS'] = abs(data['PTS_x'] - data['PTS_y'])

2022-12-01 02:50:32,626:WARNING:<ipython-input-30-eecbb6570112>:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FG_PCT'] = abs(data['FG_PCT_x'] - data['FG_PCT_y'])

2022-12-01 02:50:32,627:WARNING:<ipython-input-30-eecbb6570112>:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT'] = abs(data['FT_PCT_x'] - data['FT_PCT_y'])

2022-12-01 02:50:32,628:WARNING:<ipython-input-30-eecbb6570112>:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT3'] = abs(data['FG3_PCT_x'] - data['FG3_PCT_y'])

2022-12-01 02:50:32,629:WARNING:<ipython-input-30-eecbb6570112>:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['AST'] = abs(data['AST_x'] - data['AST_y'])

2022-12-01 02:50:32,630:WARNING:<ipython-input-30-eecbb6570112>:20: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['REB'] = abs(data['REB_x'] - data['REB_y'])

2022-12-01 02:50:32,631:WARNING:<ipython-input-30-eecbb6570112>:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['TO'] = abs(data['TOV_x'] - data['TOV_y'])

2022-12-01 02:52:43,044:WARNING:<ipython-input-31-48bf1f344662>:10: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q1'] = abs(data['PTS_QTR1_x'] - data['PTS_QTR1_y'])

2022-12-01 02:52:43,045:WARNING:<ipython-input-31-48bf1f344662>:11: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q2'] = abs(data['PTS_QTR2_x'] - data['PTS_QTR2_y'])

2022-12-01 02:52:43,046:WARNING:<ipython-input-31-48bf1f344662>:12: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q3'] = abs(data['PTS_QTR3_x'] - data['PTS_QTR3_y'])

2022-12-01 02:52:43,047:WARNING:<ipython-input-31-48bf1f344662>:13: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q4'] = abs(data['PTS_QTR4_x'] - data['PTS_QTR4_y'])

2022-12-01 02:52:43,048:WARNING:<ipython-input-31-48bf1f344662>:15: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['PTS'] = abs(data['PTS_x'] - data['PTS_y'])

2022-12-01 02:52:43,049:WARNING:<ipython-input-31-48bf1f344662>:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FG_PCT'] = abs(data['FG_PCT_x'] - data['FG_PCT_y'])

2022-12-01 02:52:43,050:WARNING:<ipython-input-31-48bf1f344662>:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT'] = abs(data['FT_PCT_x'] - data['FT_PCT_y'])

2022-12-01 02:52:43,051:WARNING:<ipython-input-31-48bf1f344662>:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT3'] = abs(data['FG3_PCT_x'] - data['FG3_PCT_y'])

2022-12-01 02:52:43,052:WARNING:<ipython-input-31-48bf1f344662>:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['AST'] = abs(data['AST_x'] - data['AST_y'])

2022-12-01 02:52:43,053:WARNING:<ipython-input-31-48bf1f344662>:20: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['REB'] = abs(data['REB_x'] - data['REB_y'])

2022-12-01 02:52:43,054:WARNING:<ipython-input-31-48bf1f344662>:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['TO'] = abs(data['TOV_x'] - data['TOV_y'])

2022-12-01 02:56:02,781:WARNING:<ipython-input-33-cfdd7455425e>:13: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q1'] = abs(data['PTS_QTR1_x'] - data['PTS_QTR1_y'])

2022-12-01 02:56:02,782:WARNING:<ipython-input-33-cfdd7455425e>:14: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q2'] = abs(data['PTS_QTR2_x'] - data['PTS_QTR2_y'])

2022-12-01 02:56:02,783:WARNING:<ipython-input-33-cfdd7455425e>:15: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q3'] = abs(data['PTS_QTR3_x'] - data['PTS_QTR3_y'])

2022-12-01 02:56:02,784:WARNING:<ipython-input-33-cfdd7455425e>:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q4'] = abs(data['PTS_QTR4_x'] - data['PTS_QTR4_y'])

2022-12-01 02:56:02,785:WARNING:<ipython-input-33-cfdd7455425e>:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['PTS'] = abs(data['PTS_x'] - data['PTS_y'])

2022-12-01 02:56:02,786:WARNING:<ipython-input-33-cfdd7455425e>:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FG_PCT'] = abs(data['FG_PCT_x'] - data['FG_PCT_y'])

2022-12-01 02:56:02,787:WARNING:<ipython-input-33-cfdd7455425e>:20: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT'] = abs(data['FT_PCT_x'] - data['FT_PCT_y'])

2022-12-01 02:56:02,788:WARNING:<ipython-input-33-cfdd7455425e>:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT3'] = abs(data['FG3_PCT_x'] - data['FG3_PCT_y'])

2022-12-01 02:56:02,789:WARNING:<ipython-input-33-cfdd7455425e>:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['AST'] = abs(data['AST_x'] - data['AST_y'])

2022-12-01 02:56:02,790:WARNING:<ipython-input-33-cfdd7455425e>:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['REB'] = abs(data['REB_x'] - data['REB_y'])

2022-12-01 02:56:02,791:WARNING:<ipython-input-33-cfdd7455425e>:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['TO'] = abs(data['TOV_x'] - data['TOV_y'])

2022-12-01 02:57:02,836:WARNING:<ipython-input-34-dc22e93ab7af>:13: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q1'] = abs(data['PTS_QTR1_x'] - data['PTS_QTR1_y'])

2022-12-01 02:57:02,837:WARNING:<ipython-input-34-dc22e93ab7af>:14: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q2'] = abs(data['PTS_QTR2_x'] - data['PTS_QTR2_y'])

2022-12-01 02:57:02,838:WARNING:<ipython-input-34-dc22e93ab7af>:15: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q3'] = abs(data['PTS_QTR3_x'] - data['PTS_QTR3_y'])

2022-12-01 02:57:02,839:WARNING:<ipython-input-34-dc22e93ab7af>:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q4'] = abs(data['PTS_QTR4_x'] - data['PTS_QTR4_y'])

2022-12-01 02:57:02,841:WARNING:<ipython-input-34-dc22e93ab7af>:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['PTS'] = abs(data['PTS_x'] - data['PTS_y'])

2022-12-01 02:57:02,842:WARNING:<ipython-input-34-dc22e93ab7af>:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FG_PCT'] = abs(data['FG_PCT_x'] - data['FG_PCT_y'])

2022-12-01 02:57:02,843:WARNING:<ipython-input-34-dc22e93ab7af>:20: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT'] = abs(data['FT_PCT_x'] - data['FT_PCT_y'])

2022-12-01 02:57:02,844:WARNING:<ipython-input-34-dc22e93ab7af>:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT3'] = abs(data['FG3_PCT_x'] - data['FG3_PCT_y'])

2022-12-01 02:57:02,845:WARNING:<ipython-input-34-dc22e93ab7af>:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['AST'] = abs(data['AST_x'] - data['AST_y'])

2022-12-01 02:57:02,846:WARNING:<ipython-input-34-dc22e93ab7af>:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['REB'] = abs(data['REB_x'] - data['REB_y'])

2022-12-01 02:57:02,847:WARNING:<ipython-input-34-dc22e93ab7af>:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['TO'] = abs(data['TOV_x'] - data['TOV_y'])

2022-12-01 03:00:25,449:WARNING:<ipython-input-40-1fe3249cd1e0>:13: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q1'] = abs(data['PTS_QTR1_x'] - data['PTS_QTR1_y'])

2022-12-01 03:00:25,450:WARNING:<ipython-input-40-1fe3249cd1e0>:14: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q2'] = abs(data['PTS_QTR2_x'] - data['PTS_QTR2_y'])

2022-12-01 03:00:25,451:WARNING:<ipython-input-40-1fe3249cd1e0>:15: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q3'] = abs(data['PTS_QTR3_x'] - data['PTS_QTR3_y'])

2022-12-01 03:00:25,453:WARNING:<ipython-input-40-1fe3249cd1e0>:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q4'] = abs(data['PTS_QTR4_x'] - data['PTS_QTR4_y'])

2022-12-01 03:00:25,454:WARNING:<ipython-input-40-1fe3249cd1e0>:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['PTS'] = abs(data['PTS_x'] - data['PTS_y'])

2022-12-01 03:00:25,455:WARNING:<ipython-input-40-1fe3249cd1e0>:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FG_PCT'] = abs(data['FG_PCT_x'] - data['FG_PCT_y'])

2022-12-01 03:00:25,456:WARNING:<ipython-input-40-1fe3249cd1e0>:20: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT'] = abs(data['FT_PCT_x'] - data['FT_PCT_y'])

2022-12-01 03:00:25,457:WARNING:<ipython-input-40-1fe3249cd1e0>:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT3'] = abs(data['FG3_PCT_x'] - data['FG3_PCT_y'])

2022-12-01 03:00:25,458:WARNING:<ipython-input-40-1fe3249cd1e0>:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['AST'] = abs(data['AST_x'] - data['AST_y'])

2022-12-01 03:00:25,459:WARNING:<ipython-input-40-1fe3249cd1e0>:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['REB'] = abs(data['REB_x'] - data['REB_y'])

2022-12-01 03:00:25,460:WARNING:<ipython-input-40-1fe3249cd1e0>:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['TO'] = abs(data['TOV_x'] - data['TOV_y'])

2022-12-01 03:00:25,465:INFO:PyCaret RegressionExperiment
2022-12-01 03:00:25,466:INFO:Logging name: FullData
2022-12-01 03:00:25,467:INFO:ML Usecase: MLUsecase.REGRESSION
2022-12-01 03:00:25,467:INFO:version 3.0.0.rc4
2022-12-01 03:00:25,467:INFO:Initializing setup()
2022-12-01 03:00:25,467:INFO:self.USI: 4844
2022-12-01 03:00:25,468:INFO:self.variable_keys: {'fold_shuffle_param', 'y_test', 'pipeline', 'data', 'X', 'exp_id', 'master_model_container', '_available_plots', '_all_metrics', '_ml_usecase', 'log_plots_param', '_all_models', 'logging_param', 'idx', 'html_param', 'display_container', 'USI', 'target_param', 'fold_generator', '_gpu_n_jobs_param', 'n_jobs_param', 'transform_target_method_param', 'exp_name_log', 'X_test', 'variable_keys', 'gpu_param', 'memory', 'y_train', 'transform_target_param', 'y', 'X_train', '_all_models_internal', 'fold_groups_param', 'seed'}
2022-12-01 03:00:25,468:INFO:Checking environment
2022-12-01 03:00:25,468:INFO:python_version: 3.8.15
2022-12-01 03:00:25,468:INFO:python_build: ('default', 'Oct 12 2022 19:14:39')
2022-12-01 03:00:25,468:INFO:machine: x86_64
2022-12-01 03:00:25,468:INFO:platform: Linux-5.10.133+-x86_64-with-glibc2.27
2022-12-01 03:00:25,469:INFO:Memory: svmem(total=13616361472, available=11611574272, percent=14.7, used=1853960192, free=8981278720, active=1025593344, inactive=3274760192, buffers=426639360, cached=2354483200, shared=1236992, slab=238804992)
2022-12-01 03:00:25,469:INFO:Physical Core: 1
2022-12-01 03:00:25,469:INFO:Logical Core: 2
2022-12-01 03:00:25,470:INFO:Checking libraries
2022-12-01 03:00:25,470:INFO:System:
2022-12-01 03:00:25,470:INFO:    python: 3.8.15 (default, Oct 12 2022, 19:14:39)  [GCC 7.5.0]
2022-12-01 03:00:25,470:INFO:executable: /usr/bin/python3
2022-12-01 03:00:25,470:INFO:   machine: Linux-5.10.133+-x86_64-with-glibc2.27
2022-12-01 03:00:25,471:INFO:PyCaret required dependencies:
2022-12-01 03:00:25,471:INFO:                 pip: 21.1.3
2022-12-01 03:00:25,471:INFO:          setuptools: 57.4.0
2022-12-01 03:00:25,471:INFO:             pycaret: 3.0.0rc4
2022-12-01 03:00:25,471:INFO:             IPython: 7.9.0
2022-12-01 03:00:25,472:INFO:          ipywidgets: 7.7.1
2022-12-01 03:00:25,472:INFO:                tqdm: 4.64.1
2022-12-01 03:00:25,472:INFO:               numpy: 1.21.6
2022-12-01 03:00:25,472:INFO:              pandas: 1.3.5
2022-12-01 03:00:25,472:INFO:              jinja2: 3.0.0
2022-12-01 03:00:25,473:INFO:               scipy: 1.7.3
2022-12-01 03:00:25,473:INFO:              joblib: 1.2.0
2022-12-01 03:00:25,473:INFO:             sklearn: 1.0.2
2022-12-01 03:00:25,473:INFO:                pyod: 1.0.6
2022-12-01 03:00:25,473:INFO:            imblearn: 0.8.1
2022-12-01 03:00:25,473:INFO:   category_encoders: 2.5.1.post0
2022-12-01 03:00:25,474:INFO:            lightgbm: 3.3.3
2022-12-01 03:00:25,474:INFO:               numba: 0.55.2
2022-12-01 03:00:25,474:INFO:            requests: 2.28.1
2022-12-01 03:00:25,474:INFO:          matplotlib: 3.6.2
2022-12-01 03:00:25,474:INFO:          scikitplot: 0.3.7
2022-12-01 03:00:25,474:INFO:         yellowbrick: 1.5
2022-12-01 03:00:25,474:INFO:              plotly: 5.5.0
2022-12-01 03:00:25,475:INFO:             kaleido: 0.2.1
2022-12-01 03:00:25,475:INFO:         statsmodels: 0.12.2
2022-12-01 03:00:25,475:INFO:              sktime: 0.13.4
2022-12-01 03:00:25,475:INFO:               tbats: 1.1.1
2022-12-01 03:00:25,475:INFO:            pmdarima: 1.8.5
2022-12-01 03:00:25,476:INFO:              psutil: 5.9.4
2022-12-01 03:00:25,476:INFO:PyCaret optional dependencies:
2022-12-01 03:00:25,476:INFO:                shap: Not installed
2022-12-01 03:00:25,476:INFO:           interpret: Not installed
2022-12-01 03:00:25,476:INFO:                umap: Not installed
2022-12-01 03:00:25,476:INFO:    pandas_profiling: 1.4.1
2022-12-01 03:00:25,477:INFO:  explainerdashboard: Not installed
2022-12-01 03:00:25,477:INFO:             autoviz: Not installed
2022-12-01 03:00:25,477:INFO:           fairlearn: Not installed
2022-12-01 03:00:25,477:INFO:             xgboost: 0.90
2022-12-01 03:00:25,477:INFO:            catboost: Not installed
2022-12-01 03:00:25,477:INFO:              kmodes: Not installed
2022-12-01 03:00:25,478:INFO:             mlxtend: 0.14.0
2022-12-01 03:00:25,478:INFO:       statsforecast: Not installed
2022-12-01 03:00:25,478:INFO:        tune_sklearn: Not installed
2022-12-01 03:00:25,478:INFO:                 ray: Not installed
2022-12-01 03:00:25,478:INFO:            hyperopt: 0.1.2
2022-12-01 03:00:25,478:INFO:              optuna: Not installed
2022-12-01 03:00:25,479:INFO:               skopt: Not installed
2022-12-01 03:00:25,479:INFO:              mlflow: Not installed
2022-12-01 03:00:25,479:INFO:              gradio: Not installed
2022-12-01 03:00:25,479:INFO:             fastapi: Not installed
2022-12-01 03:00:25,479:INFO:             uvicorn: Not installed
2022-12-01 03:00:25,479:INFO:              m2cgen: Not installed
2022-12-01 03:00:25,480:INFO:           evidently: Not installed
2022-12-01 03:00:25,480:INFO:                nltk: 3.7
2022-12-01 03:00:25,480:INFO:            pyLDAvis: Not installed
2022-12-01 03:00:25,480:INFO:              gensim: 3.6.0
2022-12-01 03:00:25,480:INFO:               spacy: 3.4.3
2022-12-01 03:00:25,481:INFO:           wordcloud: 1.8.2.2
2022-12-01 03:00:25,481:INFO:            textblob: 0.15.3
2022-12-01 03:00:25,481:INFO:               fugue: Not installed
2022-12-01 03:00:25,481:INFO:           streamlit: Not installed
2022-12-01 03:00:25,481:INFO:             prophet: 1.1.1
2022-12-01 03:00:25,481:INFO:None
2022-12-01 03:00:25,482:INFO:Set up data.
2022-12-01 03:00:25,489:INFO:Set up train/test split.
2022-12-01 03:00:25,493:INFO:Set up index.
2022-12-01 03:00:25,494:INFO:Set up folding strategy.
2022-12-01 03:00:25,494:INFO:Assigning column types.
2022-12-01 03:00:25,500:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-12-01 03:00:25,501:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-01 03:00:25,506:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 03:00:25,511:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:00:25,586:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:00:25,636:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:00:25,637:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:00:25,637:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:00:25,638:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:00:25,639:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-01 03:00:25,644:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 03:00:25,650:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:00:25,713:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:00:25,763:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:00:25,764:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:00:25,764:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:00:25,765:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:00:25,765:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-12-01 03:00:25,770:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 03:00:25,776:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:00:25,839:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:00:25,890:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:00:25,891:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:00:25,892:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:00:25,892:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:00:25,898:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 03:00:25,904:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:00:25,971:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:00:26,018:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:00:26,019:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:00:26,020:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:00:26,020:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:00:26,020:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-12-01 03:00:26,030:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:00:26,095:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:00:26,143:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:00:26,144:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:00:26,144:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:00:26,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:00:26,155:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:00:26,217:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:00:26,269:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:00:26,270:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:00:26,271:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:00:26,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:00:26,272:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-12-01 03:00:26,344:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:00:26,394:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:00:26,395:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:00:26,395:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:00:26,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:00:26,469:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:00:26,519:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:00:26,520:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:00:26,520:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:00:26,521:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:00:26,521:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-12-01 03:00:26,604:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:00:26,654:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:00:26,655:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:00:26,655:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:00:26,728:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:00:26,778:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:00:26,778:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:00:26,779:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:00:26,779:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-12-01 03:00:26,913:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:00:26,913:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:00:26,914:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:00:27,048:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:00:27,049:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:00:27,050:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:00:27,051:INFO:Preparing preprocessing pipeline...
2022-12-01 03:00:27,052:INFO:Set up simple imputation.
2022-12-01 03:00:27,052:INFO:Set up variance threshold.
2022-12-01 03:00:27,097:INFO:Finished creating preprocessing pipeline.
2022-12-01 03:00:27,104:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO',
                                             'Open_Line_ML_x', '10000_x',
                                             '10001_x'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-12-01 03:00:27,104:INFO:Creating final display dataframe.
2022-12-01 03:00:27,287:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 15)
4         Train data shape    (607, 15)
5          Test data shape    (261, 15)
6         Numeric features           14
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         4844
2022-12-01 03:00:27,530:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:00:27,530:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:00:27,531:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:00:27,769:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:00:27,769:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:00:27,770:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:00:27,779:INFO:setup() successfully completed in 2.32s...............
2022-12-01 03:00:27,780:INFO:Initializing compare_models()
2022-12-01 03:00:27,780:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e28f370>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f495e28f370>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-12-01 03:00:27,780:INFO:Checking exceptions
2022-12-01 03:00:27,782:INFO:Preparing display monitor
2022-12-01 03:00:27,870:INFO:Initializing Linear Regression
2022-12-01 03:00:27,870:INFO:Total runtime is 6.834665934244792e-06 minutes
2022-12-01 03:00:27,880:INFO:SubProcess create_model() called ==================================
2022-12-01 03:00:27,881:INFO:Initializing create_model()
2022-12-01 03:00:27,881:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e28f370>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e3bd730>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:00:27,881:INFO:Checking exceptions
2022-12-01 03:00:27,884:INFO:Importing libraries
2022-12-01 03:00:27,885:INFO:Copying training dataset
2022-12-01 03:00:27,888:INFO:Defining folds
2022-12-01 03:00:27,890:INFO:Declaring metric variables
2022-12-01 03:00:27,901:INFO:Importing untrained model
2022-12-01 03:00:27,913:INFO:Linear Regression Imported successfully
2022-12-01 03:00:27,933:INFO:Starting cross validation
2022-12-01 03:00:27,938:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:00:35,640:INFO:Calculating mean and std
2022-12-01 03:00:35,645:INFO:Creating metrics dataframe
2022-12-01 03:00:35,655:INFO:Uploading results into container
2022-12-01 03:00:35,656:INFO:Uploading model into container now
2022-12-01 03:00:35,657:INFO:master_model_container: 1
2022-12-01 03:00:35,657:INFO:display_container: 2
2022-12-01 03:00:35,658:INFO:LinearRegression(n_jobs=-1)
2022-12-01 03:00:35,658:INFO:create_model() successfully completed......................................
2022-12-01 03:00:35,851:INFO:SubProcess create_model() end ==================================
2022-12-01 03:00:35,851:INFO:Creating metrics dataframe
2022-12-01 03:00:35,868:INFO:Initializing Lasso Regression
2022-12-01 03:00:35,869:INFO:Total runtime is 0.13332714637120563 minutes
2022-12-01 03:00:35,877:INFO:SubProcess create_model() called ==================================
2022-12-01 03:00:35,877:INFO:Initializing create_model()
2022-12-01 03:00:35,877:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e28f370>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e3bd730>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:00:35,878:INFO:Checking exceptions
2022-12-01 03:00:35,881:INFO:Importing libraries
2022-12-01 03:00:35,881:INFO:Copying training dataset
2022-12-01 03:00:35,887:INFO:Defining folds
2022-12-01 03:00:35,888:INFO:Declaring metric variables
2022-12-01 03:00:35,897:INFO:Importing untrained model
2022-12-01 03:00:35,906:INFO:Lasso Regression Imported successfully
2022-12-01 03:00:35,923:INFO:Starting cross validation
2022-12-01 03:00:35,925:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:00:36,235:INFO:Calculating mean and std
2022-12-01 03:00:36,240:INFO:Creating metrics dataframe
2022-12-01 03:00:36,251:INFO:Uploading results into container
2022-12-01 03:00:36,252:INFO:Uploading model into container now
2022-12-01 03:00:36,253:INFO:master_model_container: 2
2022-12-01 03:00:36,253:INFO:display_container: 2
2022-12-01 03:00:36,253:INFO:Lasso(random_state=123)
2022-12-01 03:00:36,254:INFO:create_model() successfully completed......................................
2022-12-01 03:00:36,395:INFO:SubProcess create_model() end ==================================
2022-12-01 03:00:36,396:INFO:Creating metrics dataframe
2022-12-01 03:00:36,414:INFO:Initializing Ridge Regression
2022-12-01 03:00:36,414:INFO:Total runtime is 0.14241451422373452 minutes
2022-12-01 03:00:36,422:INFO:SubProcess create_model() called ==================================
2022-12-01 03:00:36,423:INFO:Initializing create_model()
2022-12-01 03:00:36,423:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e28f370>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e3bd730>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:00:36,423:INFO:Checking exceptions
2022-12-01 03:00:36,426:INFO:Importing libraries
2022-12-01 03:00:36,426:INFO:Copying training dataset
2022-12-01 03:00:36,431:INFO:Defining folds
2022-12-01 03:00:36,433:INFO:Declaring metric variables
2022-12-01 03:00:36,443:INFO:Importing untrained model
2022-12-01 03:00:36,452:INFO:Ridge Regression Imported successfully
2022-12-01 03:00:36,470:INFO:Starting cross validation
2022-12-01 03:00:36,472:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:00:36,513:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.0339e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:00:36,536:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.05208e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:00:36,567:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.03856e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:00:36,588:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.09176e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:00:36,625:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.06567e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:00:36,660:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.08452e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:00:36,665:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.01841e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:00:36,704:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.05102e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:00:36,705:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.05116e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:00:36,735:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.04631e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:00:36,746:INFO:Calculating mean and std
2022-12-01 03:00:36,748:INFO:Creating metrics dataframe
2022-12-01 03:00:36,763:INFO:Uploading results into container
2022-12-01 03:00:36,764:INFO:Uploading model into container now
2022-12-01 03:00:36,764:INFO:master_model_container: 3
2022-12-01 03:00:36,764:INFO:display_container: 2
2022-12-01 03:00:36,765:INFO:Ridge(random_state=123)
2022-12-01 03:00:36,765:INFO:create_model() successfully completed......................................
2022-12-01 03:00:36,903:INFO:SubProcess create_model() end ==================================
2022-12-01 03:00:36,903:INFO:Creating metrics dataframe
2022-12-01 03:00:36,926:INFO:Initializing Elastic Net
2022-12-01 03:00:36,927:INFO:Total runtime is 0.15095107555389403 minutes
2022-12-01 03:00:36,935:INFO:SubProcess create_model() called ==================================
2022-12-01 03:00:36,936:INFO:Initializing create_model()
2022-12-01 03:00:36,936:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e28f370>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e3bd730>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:00:36,936:INFO:Checking exceptions
2022-12-01 03:00:36,939:INFO:Importing libraries
2022-12-01 03:00:36,939:INFO:Copying training dataset
2022-12-01 03:00:36,946:INFO:Defining folds
2022-12-01 03:00:36,946:INFO:Declaring metric variables
2022-12-01 03:00:36,954:INFO:Importing untrained model
2022-12-01 03:00:36,963:INFO:Elastic Net Imported successfully
2022-12-01 03:00:36,980:INFO:Starting cross validation
2022-12-01 03:00:36,983:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:00:37,254:INFO:Calculating mean and std
2022-12-01 03:00:37,256:INFO:Creating metrics dataframe
2022-12-01 03:00:37,268:INFO:Uploading results into container
2022-12-01 03:00:37,269:INFO:Uploading model into container now
2022-12-01 03:00:37,270:INFO:master_model_container: 4
2022-12-01 03:00:37,270:INFO:display_container: 2
2022-12-01 03:00:37,270:INFO:ElasticNet(random_state=123)
2022-12-01 03:00:37,270:INFO:create_model() successfully completed......................................
2022-12-01 03:00:37,410:INFO:SubProcess create_model() end ==================================
2022-12-01 03:00:37,411:INFO:Creating metrics dataframe
2022-12-01 03:00:37,427:INFO:Initializing Least Angle Regression
2022-12-01 03:00:37,428:INFO:Total runtime is 0.15930489699045816 minutes
2022-12-01 03:00:37,437:INFO:SubProcess create_model() called ==================================
2022-12-01 03:00:37,441:INFO:Initializing create_model()
2022-12-01 03:00:37,442:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e28f370>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e3bd730>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:00:37,442:INFO:Checking exceptions
2022-12-01 03:00:37,444:INFO:Importing libraries
2022-12-01 03:00:37,444:INFO:Copying training dataset
2022-12-01 03:00:37,449:INFO:Defining folds
2022-12-01 03:00:37,449:INFO:Declaring metric variables
2022-12-01 03:00:37,457:INFO:Importing untrained model
2022-12-01 03:00:37,466:INFO:Least Angle Regression Imported successfully
2022-12-01 03:00:37,481:INFO:Starting cross validation
2022-12-01 03:00:37,486:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:00:37,520:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:00:37,543:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:00:37,575:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:00:37,606:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:00:37,639:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:00:37,654:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:00:37,692:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:00:37,698:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:00:37,734:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:00:37,739:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:00:37,758:INFO:Calculating mean and std
2022-12-01 03:00:37,760:INFO:Creating metrics dataframe
2022-12-01 03:00:37,768:INFO:Uploading results into container
2022-12-01 03:00:37,769:INFO:Uploading model into container now
2022-12-01 03:00:37,770:INFO:master_model_container: 5
2022-12-01 03:00:37,770:INFO:display_container: 2
2022-12-01 03:00:37,770:INFO:Lars(random_state=123)
2022-12-01 03:00:37,771:INFO:create_model() successfully completed......................................
2022-12-01 03:00:37,907:INFO:SubProcess create_model() end ==================================
2022-12-01 03:00:37,907:INFO:Creating metrics dataframe
2022-12-01 03:00:37,927:INFO:Initializing Lasso Least Angle Regression
2022-12-01 03:00:37,928:INFO:Total runtime is 0.16763348579406737 minutes
2022-12-01 03:00:37,935:INFO:SubProcess create_model() called ==================================
2022-12-01 03:00:37,936:INFO:Initializing create_model()
2022-12-01 03:00:37,936:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e28f370>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e3bd730>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:00:37,937:INFO:Checking exceptions
2022-12-01 03:00:37,939:INFO:Importing libraries
2022-12-01 03:00:37,939:INFO:Copying training dataset
2022-12-01 03:00:37,947:INFO:Defining folds
2022-12-01 03:00:37,947:INFO:Declaring metric variables
2022-12-01 03:00:37,956:INFO:Importing untrained model
2022-12-01 03:00:37,963:INFO:Lasso Least Angle Regression Imported successfully
2022-12-01 03:00:37,980:INFO:Starting cross validation
2022-12-01 03:00:37,982:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:00:38,022:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:00:38,060:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:00:38,093:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:00:38,145:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:00:38,145:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:00:38,183:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:00:38,197:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:00:38,223:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:00:38,235:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:00:38,261:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:00:38,276:INFO:Calculating mean and std
2022-12-01 03:00:38,278:INFO:Creating metrics dataframe
2022-12-01 03:00:38,292:INFO:Uploading results into container
2022-12-01 03:00:38,293:INFO:Uploading model into container now
2022-12-01 03:00:38,294:INFO:master_model_container: 6
2022-12-01 03:00:38,294:INFO:display_container: 2
2022-12-01 03:00:38,295:INFO:LassoLars(random_state=123)
2022-12-01 03:00:38,295:INFO:create_model() successfully completed......................................
2022-12-01 03:00:38,437:INFO:SubProcess create_model() end ==================================
2022-12-01 03:00:38,437:INFO:Creating metrics dataframe
2022-12-01 03:00:38,456:INFO:Initializing Orthogonal Matching Pursuit
2022-12-01 03:00:38,456:INFO:Total runtime is 0.17644582986831664 minutes
2022-12-01 03:00:38,465:INFO:SubProcess create_model() called ==================================
2022-12-01 03:00:38,466:INFO:Initializing create_model()
2022-12-01 03:00:38,466:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e28f370>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e3bd730>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:00:38,466:INFO:Checking exceptions
2022-12-01 03:00:38,470:INFO:Importing libraries
2022-12-01 03:00:38,470:INFO:Copying training dataset
2022-12-01 03:00:38,474:INFO:Defining folds
2022-12-01 03:00:38,475:INFO:Declaring metric variables
2022-12-01 03:00:38,488:INFO:Importing untrained model
2022-12-01 03:00:38,496:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-01 03:00:38,510:INFO:Starting cross validation
2022-12-01 03:00:38,512:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:00:38,544:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:00:38,574:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:00:38,608:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:00:38,635:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:00:38,659:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:00:38,696:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:00:38,699:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:00:38,736:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:00:38,746:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:00:38,772:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:00:38,785:INFO:Calculating mean and std
2022-12-01 03:00:38,787:INFO:Creating metrics dataframe
2022-12-01 03:00:38,796:INFO:Uploading results into container
2022-12-01 03:00:38,797:INFO:Uploading model into container now
2022-12-01 03:00:38,798:INFO:master_model_container: 7
2022-12-01 03:00:38,799:INFO:display_container: 2
2022-12-01 03:00:38,799:INFO:OrthogonalMatchingPursuit()
2022-12-01 03:00:38,799:INFO:create_model() successfully completed......................................
2022-12-01 03:00:38,941:INFO:SubProcess create_model() end ==================================
2022-12-01 03:00:38,942:INFO:Creating metrics dataframe
2022-12-01 03:00:38,961:INFO:Initializing Bayesian Ridge
2022-12-01 03:00:38,961:INFO:Total runtime is 0.18486261765162149 minutes
2022-12-01 03:00:38,971:INFO:SubProcess create_model() called ==================================
2022-12-01 03:00:38,972:INFO:Initializing create_model()
2022-12-01 03:00:38,973:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e28f370>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e3bd730>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:00:38,973:INFO:Checking exceptions
2022-12-01 03:00:38,977:INFO:Importing libraries
2022-12-01 03:00:38,977:INFO:Copying training dataset
2022-12-01 03:00:38,981:INFO:Defining folds
2022-12-01 03:00:38,982:INFO:Declaring metric variables
2022-12-01 03:00:38,992:INFO:Importing untrained model
2022-12-01 03:00:39,003:INFO:Bayesian Ridge Imported successfully
2022-12-01 03:00:39,017:INFO:Starting cross validation
2022-12-01 03:00:39,019:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:00:39,305:INFO:Calculating mean and std
2022-12-01 03:00:39,307:INFO:Creating metrics dataframe
2022-12-01 03:00:39,320:INFO:Uploading results into container
2022-12-01 03:00:39,321:INFO:Uploading model into container now
2022-12-01 03:00:39,321:INFO:master_model_container: 8
2022-12-01 03:00:39,321:INFO:display_container: 2
2022-12-01 03:00:39,322:INFO:BayesianRidge()
2022-12-01 03:00:39,322:INFO:create_model() successfully completed......................................
2022-12-01 03:00:39,464:INFO:SubProcess create_model() end ==================================
2022-12-01 03:00:39,464:INFO:Creating metrics dataframe
2022-12-01 03:00:39,483:INFO:Initializing Passive Aggressive Regressor
2022-12-01 03:00:39,483:INFO:Total runtime is 0.1935617486635844 minutes
2022-12-01 03:00:39,491:INFO:SubProcess create_model() called ==================================
2022-12-01 03:00:39,492:INFO:Initializing create_model()
2022-12-01 03:00:39,492:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e28f370>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e3bd730>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:00:39,493:INFO:Checking exceptions
2022-12-01 03:00:39,497:INFO:Importing libraries
2022-12-01 03:00:39,497:INFO:Copying training dataset
2022-12-01 03:00:39,506:INFO:Defining folds
2022-12-01 03:00:39,506:INFO:Declaring metric variables
2022-12-01 03:00:39,514:INFO:Importing untrained model
2022-12-01 03:00:39,524:INFO:Passive Aggressive Regressor Imported successfully
2022-12-01 03:00:39,538:INFO:Starting cross validation
2022-12-01 03:00:39,541:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:00:39,808:INFO:Calculating mean and std
2022-12-01 03:00:39,810:INFO:Creating metrics dataframe
2022-12-01 03:00:39,815:INFO:Uploading results into container
2022-12-01 03:00:39,819:INFO:Uploading model into container now
2022-12-01 03:00:39,825:INFO:master_model_container: 9
2022-12-01 03:00:39,825:INFO:display_container: 2
2022-12-01 03:00:39,826:INFO:PassiveAggressiveRegressor(random_state=123)
2022-12-01 03:00:39,826:INFO:create_model() successfully completed......................................
2022-12-01 03:00:39,964:INFO:SubProcess create_model() end ==================================
2022-12-01 03:00:39,965:INFO:Creating metrics dataframe
2022-12-01 03:00:39,984:INFO:Initializing Huber Regressor
2022-12-01 03:00:39,987:INFO:Total runtime is 0.20195557276407877 minutes
2022-12-01 03:00:39,995:INFO:SubProcess create_model() called ==================================
2022-12-01 03:00:39,997:INFO:Initializing create_model()
2022-12-01 03:00:40,001:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e28f370>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e3bd730>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:00:40,001:INFO:Checking exceptions
2022-12-01 03:00:40,003:INFO:Importing libraries
2022-12-01 03:00:40,003:INFO:Copying training dataset
2022-12-01 03:00:40,008:INFO:Defining folds
2022-12-01 03:00:40,009:INFO:Declaring metric variables
2022-12-01 03:00:40,019:INFO:Importing untrained model
2022-12-01 03:00:40,027:INFO:Huber Regressor Imported successfully
2022-12-01 03:00:40,041:INFO:Starting cross validation
2022-12-01 03:00:40,044:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:00:40,159:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:00:40,175:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:00:40,298:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:00:40,334:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:00:40,406:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:00:40,441:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:00:40,504:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:00:40,530:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:00:40,597:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:00:40,623:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:00:40,634:INFO:Calculating mean and std
2022-12-01 03:00:40,636:INFO:Creating metrics dataframe
2022-12-01 03:00:40,646:INFO:Uploading results into container
2022-12-01 03:00:40,649:INFO:Uploading model into container now
2022-12-01 03:00:40,649:INFO:master_model_container: 10
2022-12-01 03:00:40,650:INFO:display_container: 2
2022-12-01 03:00:40,650:INFO:HuberRegressor()
2022-12-01 03:00:40,650:INFO:create_model() successfully completed......................................
2022-12-01 03:00:40,786:INFO:SubProcess create_model() end ==================================
2022-12-01 03:00:40,786:INFO:Creating metrics dataframe
2022-12-01 03:00:40,807:INFO:Initializing K Neighbors Regressor
2022-12-01 03:00:40,807:INFO:Total runtime is 0.2156315485636393 minutes
2022-12-01 03:00:40,816:INFO:SubProcess create_model() called ==================================
2022-12-01 03:00:40,818:INFO:Initializing create_model()
2022-12-01 03:00:40,818:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e28f370>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e3bd730>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:00:40,818:INFO:Checking exceptions
2022-12-01 03:00:40,821:INFO:Importing libraries
2022-12-01 03:00:40,822:INFO:Copying training dataset
2022-12-01 03:00:40,828:INFO:Defining folds
2022-12-01 03:00:40,830:INFO:Declaring metric variables
2022-12-01 03:00:40,840:INFO:Importing untrained model
2022-12-01 03:00:40,848:INFO:K Neighbors Regressor Imported successfully
2022-12-01 03:00:40,864:INFO:Starting cross validation
2022-12-01 03:00:40,866:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:00:41,160:INFO:Calculating mean and std
2022-12-01 03:00:41,162:INFO:Creating metrics dataframe
2022-12-01 03:00:41,173:INFO:Uploading results into container
2022-12-01 03:00:41,174:INFO:Uploading model into container now
2022-12-01 03:00:41,175:INFO:master_model_container: 11
2022-12-01 03:00:41,175:INFO:display_container: 2
2022-12-01 03:00:41,176:INFO:KNeighborsRegressor(n_jobs=-1)
2022-12-01 03:00:41,176:INFO:create_model() successfully completed......................................
2022-12-01 03:00:41,317:INFO:SubProcess create_model() end ==================================
2022-12-01 03:00:41,317:INFO:Creating metrics dataframe
2022-12-01 03:00:41,337:INFO:Initializing Decision Tree Regressor
2022-12-01 03:00:41,338:INFO:Total runtime is 0.22446738481521605 minutes
2022-12-01 03:00:41,346:INFO:SubProcess create_model() called ==================================
2022-12-01 03:00:41,347:INFO:Initializing create_model()
2022-12-01 03:00:41,347:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e28f370>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e3bd730>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:00:41,347:INFO:Checking exceptions
2022-12-01 03:00:41,351:INFO:Importing libraries
2022-12-01 03:00:41,351:INFO:Copying training dataset
2022-12-01 03:00:41,355:INFO:Defining folds
2022-12-01 03:00:41,356:INFO:Declaring metric variables
2022-12-01 03:00:41,366:INFO:Importing untrained model
2022-12-01 03:00:41,375:INFO:Decision Tree Regressor Imported successfully
2022-12-01 03:00:41,389:INFO:Starting cross validation
2022-12-01 03:00:41,391:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:00:41,709:INFO:Calculating mean and std
2022-12-01 03:00:41,711:INFO:Creating metrics dataframe
2022-12-01 03:00:41,719:INFO:Uploading results into container
2022-12-01 03:00:41,720:INFO:Uploading model into container now
2022-12-01 03:00:41,721:INFO:master_model_container: 12
2022-12-01 03:00:41,721:INFO:display_container: 2
2022-12-01 03:00:41,721:INFO:DecisionTreeRegressor(random_state=123)
2022-12-01 03:00:41,722:INFO:create_model() successfully completed......................................
2022-12-01 03:00:41,860:INFO:SubProcess create_model() end ==================================
2022-12-01 03:00:41,861:INFO:Creating metrics dataframe
2022-12-01 03:00:41,881:INFO:Initializing Random Forest Regressor
2022-12-01 03:00:41,882:INFO:Total runtime is 0.23353627125422158 minutes
2022-12-01 03:00:41,890:INFO:SubProcess create_model() called ==================================
2022-12-01 03:00:41,890:INFO:Initializing create_model()
2022-12-01 03:00:41,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e28f370>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e3bd730>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:00:41,891:INFO:Checking exceptions
2022-12-01 03:00:41,893:INFO:Importing libraries
2022-12-01 03:00:41,894:INFO:Copying training dataset
2022-12-01 03:00:41,899:INFO:Defining folds
2022-12-01 03:00:41,902:INFO:Declaring metric variables
2022-12-01 03:00:41,910:INFO:Importing untrained model
2022-12-01 03:00:41,920:INFO:Random Forest Regressor Imported successfully
2022-12-01 03:00:41,934:INFO:Starting cross validation
2022-12-01 03:00:41,938:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:00:46,899:INFO:Calculating mean and std
2022-12-01 03:00:46,906:INFO:Creating metrics dataframe
2022-12-01 03:00:46,914:INFO:Uploading results into container
2022-12-01 03:00:46,915:INFO:Uploading model into container now
2022-12-01 03:00:46,916:INFO:master_model_container: 13
2022-12-01 03:00:46,917:INFO:display_container: 2
2022-12-01 03:00:46,918:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-12-01 03:00:46,918:INFO:create_model() successfully completed......................................
2022-12-01 03:00:47,060:INFO:SubProcess create_model() end ==================================
2022-12-01 03:00:47,060:INFO:Creating metrics dataframe
2022-12-01 03:00:47,081:INFO:Initializing Extra Trees Regressor
2022-12-01 03:00:47,082:INFO:Total runtime is 0.3202040632565816 minutes
2022-12-01 03:00:47,090:INFO:SubProcess create_model() called ==================================
2022-12-01 03:00:47,090:INFO:Initializing create_model()
2022-12-01 03:00:47,090:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e28f370>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e3bd730>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:00:47,091:INFO:Checking exceptions
2022-12-01 03:00:47,093:INFO:Importing libraries
2022-12-01 03:00:47,093:INFO:Copying training dataset
2022-12-01 03:00:47,100:INFO:Defining folds
2022-12-01 03:00:47,102:INFO:Declaring metric variables
2022-12-01 03:00:47,110:INFO:Importing untrained model
2022-12-01 03:00:47,118:INFO:Extra Trees Regressor Imported successfully
2022-12-01 03:00:47,132:INFO:Starting cross validation
2022-12-01 03:00:47,134:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:00:49,540:INFO:Calculating mean and std
2022-12-01 03:00:49,549:INFO:Creating metrics dataframe
2022-12-01 03:00:49,556:INFO:Uploading results into container
2022-12-01 03:00:49,557:INFO:Uploading model into container now
2022-12-01 03:00:49,557:INFO:master_model_container: 14
2022-12-01 03:00:49,558:INFO:display_container: 2
2022-12-01 03:00:49,558:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-12-01 03:00:49,558:INFO:create_model() successfully completed......................................
2022-12-01 03:00:49,698:INFO:SubProcess create_model() end ==================================
2022-12-01 03:00:49,698:INFO:Creating metrics dataframe
2022-12-01 03:00:49,719:INFO:Initializing AdaBoost Regressor
2022-12-01 03:00:49,719:INFO:Total runtime is 0.36416045427322385 minutes
2022-12-01 03:00:49,727:INFO:SubProcess create_model() called ==================================
2022-12-01 03:00:49,728:INFO:Initializing create_model()
2022-12-01 03:00:49,729:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e28f370>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e3bd730>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:00:49,729:INFO:Checking exceptions
2022-12-01 03:00:49,732:INFO:Importing libraries
2022-12-01 03:00:49,732:INFO:Copying training dataset
2022-12-01 03:00:49,737:INFO:Defining folds
2022-12-01 03:00:49,738:INFO:Declaring metric variables
2022-12-01 03:00:49,748:INFO:Importing untrained model
2022-12-01 03:00:49,757:INFO:AdaBoost Regressor Imported successfully
2022-12-01 03:00:49,774:INFO:Starting cross validation
2022-12-01 03:00:49,776:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:00:50,726:INFO:Calculating mean and std
2022-12-01 03:00:50,729:INFO:Creating metrics dataframe
2022-12-01 03:00:50,741:INFO:Uploading results into container
2022-12-01 03:00:50,741:INFO:Uploading model into container now
2022-12-01 03:00:50,742:INFO:master_model_container: 15
2022-12-01 03:00:50,742:INFO:display_container: 2
2022-12-01 03:00:50,743:INFO:AdaBoostRegressor(random_state=123)
2022-12-01 03:00:50,743:INFO:create_model() successfully completed......................................
2022-12-01 03:00:50,881:INFO:SubProcess create_model() end ==================================
2022-12-01 03:00:50,881:INFO:Creating metrics dataframe
2022-12-01 03:00:50,902:INFO:Initializing Gradient Boosting Regressor
2022-12-01 03:00:50,902:INFO:Total runtime is 0.3838809331258138 minutes
2022-12-01 03:00:50,910:INFO:SubProcess create_model() called ==================================
2022-12-01 03:00:50,911:INFO:Initializing create_model()
2022-12-01 03:00:50,911:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e28f370>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e3bd730>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:00:50,911:INFO:Checking exceptions
2022-12-01 03:00:50,914:INFO:Importing libraries
2022-12-01 03:00:50,915:INFO:Copying training dataset
2022-12-01 03:00:50,921:INFO:Defining folds
2022-12-01 03:00:50,922:INFO:Declaring metric variables
2022-12-01 03:00:50,929:INFO:Importing untrained model
2022-12-01 03:00:50,939:INFO:Gradient Boosting Regressor Imported successfully
2022-12-01 03:00:50,953:INFO:Starting cross validation
2022-12-01 03:00:50,955:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:00:52,945:INFO:Calculating mean and std
2022-12-01 03:00:52,947:INFO:Creating metrics dataframe
2022-12-01 03:00:52,956:INFO:Uploading results into container
2022-12-01 03:00:52,961:INFO:Uploading model into container now
2022-12-01 03:00:52,961:INFO:master_model_container: 16
2022-12-01 03:00:52,961:INFO:display_container: 2
2022-12-01 03:00:52,962:INFO:GradientBoostingRegressor(random_state=123)
2022-12-01 03:00:52,962:INFO:create_model() successfully completed......................................
2022-12-01 03:00:53,100:INFO:SubProcess create_model() end ==================================
2022-12-01 03:00:53,100:INFO:Creating metrics dataframe
2022-12-01 03:00:53,122:INFO:Initializing Light Gradient Boosting Machine
2022-12-01 03:00:53,123:INFO:Total runtime is 0.4208985884984334 minutes
2022-12-01 03:00:53,133:INFO:SubProcess create_model() called ==================================
2022-12-01 03:00:53,134:INFO:Initializing create_model()
2022-12-01 03:00:53,134:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e28f370>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e3bd730>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:00:53,134:INFO:Checking exceptions
2022-12-01 03:00:53,137:INFO:Importing libraries
2022-12-01 03:00:53,137:INFO:Copying training dataset
2022-12-01 03:00:53,142:INFO:Defining folds
2022-12-01 03:00:53,143:INFO:Declaring metric variables
2022-12-01 03:00:53,152:INFO:Importing untrained model
2022-12-01 03:00:53,160:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-01 03:00:53,179:INFO:Starting cross validation
2022-12-01 03:00:53,181:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:00:54,738:INFO:Calculating mean and std
2022-12-01 03:00:54,740:INFO:Creating metrics dataframe
2022-12-01 03:00:54,749:INFO:Uploading results into container
2022-12-01 03:00:54,750:INFO:Uploading model into container now
2022-12-01 03:00:54,750:INFO:master_model_container: 17
2022-12-01 03:00:54,751:INFO:display_container: 2
2022-12-01 03:00:54,753:INFO:LGBMRegressor(random_state=123)
2022-12-01 03:00:54,754:INFO:create_model() successfully completed......................................
2022-12-01 03:00:54,890:INFO:SubProcess create_model() end ==================================
2022-12-01 03:00:54,891:INFO:Creating metrics dataframe
2022-12-01 03:00:54,912:INFO:Initializing Dummy Regressor
2022-12-01 03:00:54,912:INFO:Total runtime is 0.4507154067357381 minutes
2022-12-01 03:00:54,921:INFO:SubProcess create_model() called ==================================
2022-12-01 03:00:54,922:INFO:Initializing create_model()
2022-12-01 03:00:54,922:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e28f370>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e3bd730>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:00:54,922:INFO:Checking exceptions
2022-12-01 03:00:54,924:INFO:Importing libraries
2022-12-01 03:00:54,925:INFO:Copying training dataset
2022-12-01 03:00:54,930:INFO:Defining folds
2022-12-01 03:00:54,933:INFO:Declaring metric variables
2022-12-01 03:00:54,942:INFO:Importing untrained model
2022-12-01 03:00:54,950:INFO:Dummy Regressor Imported successfully
2022-12-01 03:00:54,965:INFO:Starting cross validation
2022-12-01 03:00:54,970:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:00:55,206:INFO:Calculating mean and std
2022-12-01 03:00:55,208:INFO:Creating metrics dataframe
2022-12-01 03:00:55,220:INFO:Uploading results into container
2022-12-01 03:00:55,221:INFO:Uploading model into container now
2022-12-01 03:00:55,221:INFO:master_model_container: 18
2022-12-01 03:00:55,221:INFO:display_container: 2
2022-12-01 03:00:55,222:INFO:DummyRegressor()
2022-12-01 03:00:55,222:INFO:create_model() successfully completed......................................
2022-12-01 03:00:55,364:INFO:SubProcess create_model() end ==================================
2022-12-01 03:00:55,365:INFO:Creating metrics dataframe
2022-12-01 03:00:55,415:INFO:Initializing create_model()
2022-12-01 03:00:55,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f495e28f370>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:00:55,416:INFO:Checking exceptions
2022-12-01 03:00:55,422:INFO:Importing libraries
2022-12-01 03:00:55,422:INFO:Copying training dataset
2022-12-01 03:00:55,425:INFO:Defining folds
2022-12-01 03:00:55,426:INFO:Declaring metric variables
2022-12-01 03:00:55,426:INFO:Importing untrained model
2022-12-01 03:00:55,426:INFO:Declaring custom model
2022-12-01 03:00:55,427:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-01 03:00:55,428:INFO:Cross validation set to False
2022-12-01 03:00:55,428:INFO:Fitting Model
2022-12-01 03:00:55,455:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:00:55,458:INFO:OrthogonalMatchingPursuit()
2022-12-01 03:00:55,459:INFO:create_model() successfully completed......................................
2022-12-01 03:00:55,690:INFO:master_model_container: 18
2022-12-01 03:00:55,691:INFO:display_container: 2
2022-12-01 03:00:55,692:INFO:OrthogonalMatchingPursuit()
2022-12-01 03:00:55,692:INFO:compare_models() successfully completed......................................
2022-12-01 03:25:39,694:WARNING:<ipython-input-41-387158f279ba>:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q1'] = abs(data['PTS_QTR1_x'] - data['PTS_QTR1_y'])

2022-12-01 03:25:39,695:WARNING:<ipython-input-41-387158f279ba>:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q2'] = abs(data['PTS_QTR2_x'] - data['PTS_QTR2_y'])

2022-12-01 03:25:39,696:WARNING:<ipython-input-41-387158f279ba>:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q3'] = abs(data['PTS_QTR3_x'] - data['PTS_QTR3_y'])

2022-12-01 03:25:39,697:WARNING:<ipython-input-41-387158f279ba>:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q4'] = abs(data['PTS_QTR4_x'] - data['PTS_QTR4_y'])

2022-12-01 03:25:39,698:WARNING:<ipython-input-41-387158f279ba>:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['PTS'] = abs(data['PTS_x'] - data['PTS_y'])

2022-12-01 03:25:39,698:WARNING:<ipython-input-41-387158f279ba>:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FG_PCT'] = abs(data['FG_PCT_x'] - data['FG_PCT_y'])

2022-12-01 03:25:39,699:WARNING:<ipython-input-41-387158f279ba>:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT'] = abs(data['FT_PCT_x'] - data['FT_PCT_y'])

2022-12-01 03:25:39,700:WARNING:<ipython-input-41-387158f279ba>:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT3'] = abs(data['FG3_PCT_x'] - data['FG3_PCT_y'])

2022-12-01 03:25:39,701:WARNING:<ipython-input-41-387158f279ba>:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['AST'] = abs(data['AST_x'] - data['AST_y'])

2022-12-01 03:25:39,702:WARNING:<ipython-input-41-387158f279ba>:26: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['REB'] = abs(data['REB_x'] - data['REB_y'])

2022-12-01 03:25:39,703:WARNING:<ipython-input-41-387158f279ba>:27: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['TO'] = abs(data['TOV_x'] - data['TOV_y'])

2022-12-01 03:25:39,709:INFO:PyCaret RegressionExperiment
2022-12-01 03:25:39,709:INFO:Logging name: FullData
2022-12-01 03:25:39,710:INFO:ML Usecase: MLUsecase.REGRESSION
2022-12-01 03:25:39,710:INFO:version 3.0.0.rc4
2022-12-01 03:25:39,710:INFO:Initializing setup()
2022-12-01 03:25:39,710:INFO:self.USI: a4ce
2022-12-01 03:25:39,710:INFO:self.variable_keys: {'fold_shuffle_param', 'y_test', 'pipeline', 'data', 'X', 'exp_id', 'master_model_container', '_available_plots', '_all_metrics', '_ml_usecase', 'log_plots_param', '_all_models', 'logging_param', 'idx', 'html_param', 'display_container', 'USI', 'target_param', 'fold_generator', '_gpu_n_jobs_param', 'n_jobs_param', 'transform_target_method_param', 'exp_name_log', 'X_test', 'variable_keys', 'gpu_param', 'memory', 'y_train', 'transform_target_param', 'y', 'X_train', '_all_models_internal', 'fold_groups_param', 'seed'}
2022-12-01 03:25:39,711:INFO:Checking environment
2022-12-01 03:25:39,711:INFO:python_version: 3.8.15
2022-12-01 03:25:39,711:INFO:python_build: ('default', 'Oct 12 2022 19:14:39')
2022-12-01 03:25:39,711:INFO:machine: x86_64
2022-12-01 03:25:39,711:INFO:platform: Linux-5.10.133+-x86_64-with-glibc2.27
2022-12-01 03:25:39,712:INFO:Memory: svmem(total=13616361472, available=11784835072, percent=13.5, used=1680756736, free=9121292288, active=1042972672, inactive=3122311168, buffers=431009792, cached=2383302656, shared=1236992, slab=238886912)
2022-12-01 03:25:39,712:INFO:Physical Core: 1
2022-12-01 03:25:39,712:INFO:Logical Core: 2
2022-12-01 03:25:39,713:INFO:Checking libraries
2022-12-01 03:25:39,713:INFO:System:
2022-12-01 03:25:39,713:INFO:    python: 3.8.15 (default, Oct 12 2022, 19:14:39)  [GCC 7.5.0]
2022-12-01 03:25:39,713:INFO:executable: /usr/bin/python3
2022-12-01 03:25:39,713:INFO:   machine: Linux-5.10.133+-x86_64-with-glibc2.27
2022-12-01 03:25:39,713:INFO:PyCaret required dependencies:
2022-12-01 03:25:39,714:INFO:                 pip: 21.1.3
2022-12-01 03:25:39,714:INFO:          setuptools: 57.4.0
2022-12-01 03:25:39,714:INFO:             pycaret: 3.0.0rc4
2022-12-01 03:25:39,714:INFO:             IPython: 7.9.0
2022-12-01 03:25:39,714:INFO:          ipywidgets: 7.7.1
2022-12-01 03:25:39,714:INFO:                tqdm: 4.64.1
2022-12-01 03:25:39,714:INFO:               numpy: 1.21.6
2022-12-01 03:25:39,715:INFO:              pandas: 1.3.5
2022-12-01 03:25:39,715:INFO:              jinja2: 3.0.0
2022-12-01 03:25:39,715:INFO:               scipy: 1.7.3
2022-12-01 03:25:39,715:INFO:              joblib: 1.2.0
2022-12-01 03:25:39,715:INFO:             sklearn: 1.0.2
2022-12-01 03:25:39,715:INFO:                pyod: 1.0.6
2022-12-01 03:25:39,715:INFO:            imblearn: 0.8.1
2022-12-01 03:25:39,715:INFO:   category_encoders: 2.5.1.post0
2022-12-01 03:25:39,716:INFO:            lightgbm: 3.3.3
2022-12-01 03:25:39,716:INFO:               numba: 0.55.2
2022-12-01 03:25:39,716:INFO:            requests: 2.28.1
2022-12-01 03:25:39,716:INFO:          matplotlib: 3.6.2
2022-12-01 03:25:39,716:INFO:          scikitplot: 0.3.7
2022-12-01 03:25:39,716:INFO:         yellowbrick: 1.5
2022-12-01 03:25:39,716:INFO:              plotly: 5.5.0
2022-12-01 03:25:39,717:INFO:             kaleido: 0.2.1
2022-12-01 03:25:39,717:INFO:         statsmodels: 0.12.2
2022-12-01 03:25:39,717:INFO:              sktime: 0.13.4
2022-12-01 03:25:39,717:INFO:               tbats: 1.1.1
2022-12-01 03:25:39,717:INFO:            pmdarima: 1.8.5
2022-12-01 03:25:39,717:INFO:              psutil: 5.9.4
2022-12-01 03:25:39,717:INFO:PyCaret optional dependencies:
2022-12-01 03:25:39,718:INFO:                shap: Not installed
2022-12-01 03:25:39,718:INFO:           interpret: Not installed
2022-12-01 03:25:39,718:INFO:                umap: Not installed
2022-12-01 03:25:39,718:INFO:    pandas_profiling: 1.4.1
2022-12-01 03:25:39,718:INFO:  explainerdashboard: Not installed
2022-12-01 03:25:39,718:INFO:             autoviz: Not installed
2022-12-01 03:25:39,718:INFO:           fairlearn: Not installed
2022-12-01 03:25:39,719:INFO:             xgboost: 0.90
2022-12-01 03:25:39,719:INFO:            catboost: Not installed
2022-12-01 03:25:39,719:INFO:              kmodes: Not installed
2022-12-01 03:25:39,719:INFO:             mlxtend: 0.14.0
2022-12-01 03:25:39,719:INFO:       statsforecast: Not installed
2022-12-01 03:25:39,719:INFO:        tune_sklearn: Not installed
2022-12-01 03:25:39,719:INFO:                 ray: Not installed
2022-12-01 03:25:39,719:INFO:            hyperopt: 0.1.2
2022-12-01 03:25:39,720:INFO:              optuna: Not installed
2022-12-01 03:25:39,720:INFO:               skopt: Not installed
2022-12-01 03:25:39,720:INFO:              mlflow: Not installed
2022-12-01 03:25:39,720:INFO:              gradio: Not installed
2022-12-01 03:25:39,720:INFO:             fastapi: Not installed
2022-12-01 03:25:39,720:INFO:             uvicorn: Not installed
2022-12-01 03:25:39,720:INFO:              m2cgen: Not installed
2022-12-01 03:25:39,721:INFO:           evidently: Not installed
2022-12-01 03:25:39,721:INFO:                nltk: 3.7
2022-12-01 03:25:39,721:INFO:            pyLDAvis: Not installed
2022-12-01 03:25:39,721:INFO:              gensim: 3.6.0
2022-12-01 03:25:39,721:INFO:               spacy: 3.4.3
2022-12-01 03:25:39,721:INFO:           wordcloud: 1.8.2.2
2022-12-01 03:25:39,721:INFO:            textblob: 0.15.3
2022-12-01 03:25:39,721:INFO:               fugue: Not installed
2022-12-01 03:25:39,722:INFO:           streamlit: Not installed
2022-12-01 03:25:39,722:INFO:             prophet: 1.1.1
2022-12-01 03:25:39,722:INFO:None
2022-12-01 03:25:39,722:INFO:Set up data.
2022-12-01 03:25:39,729:INFO:Set up train/test split.
2022-12-01 03:25:39,733:INFO:Set up index.
2022-12-01 03:25:39,733:INFO:Set up folding strategy.
2022-12-01 03:25:39,734:INFO:Assigning column types.
2022-12-01 03:25:39,739:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-12-01 03:25:39,740:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-01 03:25:39,745:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 03:25:39,751:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:25:39,815:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:25:39,866:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:25:39,868:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:25:39,869:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:25:39,869:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:25:39,870:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-01 03:25:39,875:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 03:25:39,880:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:25:39,944:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:25:39,991:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:25:39,992:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:25:39,992:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:25:39,993:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:25:39,993:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-12-01 03:25:39,998:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 03:25:40,003:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:25:40,064:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:25:40,110:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:25:40,111:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:25:40,112:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:25:40,112:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:25:40,117:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 03:25:40,122:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:25:40,182:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:25:40,228:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:25:40,229:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:25:40,229:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:25:40,229:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:25:40,230:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-12-01 03:25:40,240:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:25:40,300:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:25:40,346:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:25:40,350:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:25:40,350:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:25:40,351:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:25:40,361:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:25:40,420:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:25:40,466:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:25:40,467:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:25:40,467:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:25:40,468:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:25:40,468:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-12-01 03:25:40,536:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:25:40,583:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:25:40,584:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:25:40,584:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:25:40,585:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:25:40,653:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:25:40,709:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:25:40,710:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:25:40,710:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:25:40,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:25:40,711:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-12-01 03:25:40,780:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:25:40,828:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:25:40,829:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:25:40,829:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:25:40,901:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:25:40,947:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:25:40,948:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:25:40,948:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:25:40,949:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-12-01 03:25:41,068:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:25:41,069:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:25:41,070:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:25:41,194:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:25:41,194:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:25:41,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:25:41,196:INFO:Preparing preprocessing pipeline...
2022-12-01 03:25:41,197:INFO:Set up simple imputation.
2022-12-01 03:25:41,198:INFO:Set up variance threshold.
2022-12-01 03:25:41,210:INFO:Finished creating preprocessing pipeline.
2022-12-01 03:25:41,216:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO',
                                             'Open_Line_ML_x'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-12-01 03:25:41,217:INFO:Creating final display dataframe.
2022-12-01 03:25:41,299:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 13)
4         Train data shape    (607, 13)
5          Test data shape    (261, 13)
6         Numeric features           12
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         a4ce
2022-12-01 03:25:41,442:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:25:41,443:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:25:41,443:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:25:41,571:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:25:41,571:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:25:41,572:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:25:41,579:INFO:setup() successfully completed in 1.87s...............
2022-12-01 03:25:41,579:INFO:Initializing compare_models()
2022-12-01 03:25:41,579:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619ceeb0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f49619ceeb0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-12-01 03:25:41,580:INFO:Checking exceptions
2022-12-01 03:25:41,581:INFO:Preparing display monitor
2022-12-01 03:25:41,657:INFO:Initializing Linear Regression
2022-12-01 03:25:41,657:INFO:Total runtime is 6.818771362304688e-06 minutes
2022-12-01 03:25:41,665:INFO:SubProcess create_model() called ==================================
2022-12-01 03:25:41,666:INFO:Initializing create_model()
2022-12-01 03:25:41,666:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619ceeb0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc11100>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:25:41,666:INFO:Checking exceptions
2022-12-01 03:25:41,669:INFO:Importing libraries
2022-12-01 03:25:41,669:INFO:Copying training dataset
2022-12-01 03:25:41,674:INFO:Defining folds
2022-12-01 03:25:41,675:INFO:Declaring metric variables
2022-12-01 03:25:41,681:INFO:Importing untrained model
2022-12-01 03:25:41,687:INFO:Linear Regression Imported successfully
2022-12-01 03:25:41,702:INFO:Starting cross validation
2022-12-01 03:25:41,707:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:25:44,631:INFO:Calculating mean and std
2022-12-01 03:25:44,635:INFO:Creating metrics dataframe
2022-12-01 03:25:44,645:INFO:Uploading results into container
2022-12-01 03:25:44,646:INFO:Uploading model into container now
2022-12-01 03:25:44,647:INFO:master_model_container: 1
2022-12-01 03:25:44,647:INFO:display_container: 2
2022-12-01 03:25:44,647:INFO:LinearRegression(n_jobs=-1)
2022-12-01 03:25:44,647:INFO:create_model() successfully completed......................................
2022-12-01 03:25:44,832:INFO:SubProcess create_model() end ==================================
2022-12-01 03:25:44,833:INFO:Creating metrics dataframe
2022-12-01 03:25:44,853:INFO:Initializing Lasso Regression
2022-12-01 03:25:44,853:INFO:Total runtime is 0.05327787399291992 minutes
2022-12-01 03:25:44,861:INFO:SubProcess create_model() called ==================================
2022-12-01 03:25:44,861:INFO:Initializing create_model()
2022-12-01 03:25:44,861:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619ceeb0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc11100>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:25:44,862:INFO:Checking exceptions
2022-12-01 03:25:44,864:INFO:Importing libraries
2022-12-01 03:25:44,864:INFO:Copying training dataset
2022-12-01 03:25:44,871:INFO:Defining folds
2022-12-01 03:25:44,871:INFO:Declaring metric variables
2022-12-01 03:25:44,879:INFO:Importing untrained model
2022-12-01 03:25:44,886:INFO:Lasso Regression Imported successfully
2022-12-01 03:25:44,903:INFO:Starting cross validation
2022-12-01 03:25:44,907:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:25:45,171:INFO:Calculating mean and std
2022-12-01 03:25:45,174:INFO:Creating metrics dataframe
2022-12-01 03:25:45,182:INFO:Uploading results into container
2022-12-01 03:25:45,183:INFO:Uploading model into container now
2022-12-01 03:25:45,184:INFO:master_model_container: 2
2022-12-01 03:25:45,184:INFO:display_container: 2
2022-12-01 03:25:45,184:INFO:Lasso(random_state=123)
2022-12-01 03:25:45,185:INFO:create_model() successfully completed......................................
2022-12-01 03:25:45,323:INFO:SubProcess create_model() end ==================================
2022-12-01 03:25:45,323:INFO:Creating metrics dataframe
2022-12-01 03:25:45,340:INFO:Initializing Ridge Regression
2022-12-01 03:25:45,342:INFO:Total runtime is 0.06143027146657308 minutes
2022-12-01 03:25:45,348:INFO:SubProcess create_model() called ==================================
2022-12-01 03:25:45,349:INFO:Initializing create_model()
2022-12-01 03:25:45,349:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619ceeb0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc11100>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:25:45,349:INFO:Checking exceptions
2022-12-01 03:25:45,351:INFO:Importing libraries
2022-12-01 03:25:45,352:INFO:Copying training dataset
2022-12-01 03:25:45,356:INFO:Defining folds
2022-12-01 03:25:45,357:INFO:Declaring metric variables
2022-12-01 03:25:45,366:INFO:Importing untrained model
2022-12-01 03:25:45,375:INFO:Ridge Regression Imported successfully
2022-12-01 03:25:45,388:INFO:Starting cross validation
2022-12-01 03:25:45,389:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:25:45,432:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.19612e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:25:45,460:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1832e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:25:45,467:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.25596e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:25:45,501:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.27134e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:25:45,539:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.25177e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:25:45,542:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1563e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:25:45,572:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1922e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:25:45,583:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.30751e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:25:45,607:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.19532e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:25:45,617:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.20778e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:25:45,629:INFO:Calculating mean and std
2022-12-01 03:25:45,631:INFO:Creating metrics dataframe
2022-12-01 03:25:45,639:INFO:Uploading results into container
2022-12-01 03:25:45,640:INFO:Uploading model into container now
2022-12-01 03:25:45,640:INFO:master_model_container: 3
2022-12-01 03:25:45,640:INFO:display_container: 2
2022-12-01 03:25:45,641:INFO:Ridge(random_state=123)
2022-12-01 03:25:45,641:INFO:create_model() successfully completed......................................
2022-12-01 03:25:45,774:INFO:SubProcess create_model() end ==================================
2022-12-01 03:25:45,775:INFO:Creating metrics dataframe
2022-12-01 03:25:45,791:INFO:Initializing Elastic Net
2022-12-01 03:25:45,792:INFO:Total runtime is 0.06891684929529826 minutes
2022-12-01 03:25:45,798:INFO:SubProcess create_model() called ==================================
2022-12-01 03:25:45,799:INFO:Initializing create_model()
2022-12-01 03:25:45,799:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619ceeb0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc11100>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:25:45,799:INFO:Checking exceptions
2022-12-01 03:25:45,802:INFO:Importing libraries
2022-12-01 03:25:45,802:INFO:Copying training dataset
2022-12-01 03:25:45,806:INFO:Defining folds
2022-12-01 03:25:45,807:INFO:Declaring metric variables
2022-12-01 03:25:45,817:INFO:Importing untrained model
2022-12-01 03:25:45,832:INFO:Elastic Net Imported successfully
2022-12-01 03:25:45,847:INFO:Starting cross validation
2022-12-01 03:25:45,849:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:25:46,108:INFO:Calculating mean and std
2022-12-01 03:25:46,110:INFO:Creating metrics dataframe
2022-12-01 03:25:46,123:INFO:Uploading results into container
2022-12-01 03:25:46,124:INFO:Uploading model into container now
2022-12-01 03:25:46,125:INFO:master_model_container: 4
2022-12-01 03:25:46,125:INFO:display_container: 2
2022-12-01 03:25:46,126:INFO:ElasticNet(random_state=123)
2022-12-01 03:25:46,126:INFO:create_model() successfully completed......................................
2022-12-01 03:25:46,267:INFO:SubProcess create_model() end ==================================
2022-12-01 03:25:46,267:INFO:Creating metrics dataframe
2022-12-01 03:25:46,286:INFO:Initializing Least Angle Regression
2022-12-01 03:25:46,287:INFO:Total runtime is 0.0771715760231018 minutes
2022-12-01 03:25:46,295:INFO:SubProcess create_model() called ==================================
2022-12-01 03:25:46,296:INFO:Initializing create_model()
2022-12-01 03:25:46,297:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619ceeb0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc11100>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:25:46,297:INFO:Checking exceptions
2022-12-01 03:25:46,301:INFO:Importing libraries
2022-12-01 03:25:46,301:INFO:Copying training dataset
2022-12-01 03:25:46,306:INFO:Defining folds
2022-12-01 03:25:46,307:INFO:Declaring metric variables
2022-12-01 03:25:46,319:INFO:Importing untrained model
2022-12-01 03:25:46,328:INFO:Least Angle Regression Imported successfully
2022-12-01 03:25:46,347:INFO:Starting cross validation
2022-12-01 03:25:46,349:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:25:46,387:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:25:46,411:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:25:46,450:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:25:46,472:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:25:46,520:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:25:46,528:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:25:46,559:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:25:46,569:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:25:46,604:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:25:46,610:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:25:46,629:INFO:Calculating mean and std
2022-12-01 03:25:46,632:INFO:Creating metrics dataframe
2022-12-01 03:25:46,643:INFO:Uploading results into container
2022-12-01 03:25:46,644:INFO:Uploading model into container now
2022-12-01 03:25:46,645:INFO:master_model_container: 5
2022-12-01 03:25:46,645:INFO:display_container: 2
2022-12-01 03:25:46,646:INFO:Lars(random_state=123)
2022-12-01 03:25:46,646:INFO:create_model() successfully completed......................................
2022-12-01 03:25:46,785:INFO:SubProcess create_model() end ==================================
2022-12-01 03:25:46,786:INFO:Creating metrics dataframe
2022-12-01 03:25:46,809:INFO:Initializing Lasso Least Angle Regression
2022-12-01 03:25:46,809:INFO:Total runtime is 0.08587936957677206 minutes
2022-12-01 03:25:46,816:INFO:SubProcess create_model() called ==================================
2022-12-01 03:25:46,820:INFO:Initializing create_model()
2022-12-01 03:25:46,821:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619ceeb0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc11100>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:25:46,821:INFO:Checking exceptions
2022-12-01 03:25:46,822:INFO:Importing libraries
2022-12-01 03:25:46,822:INFO:Copying training dataset
2022-12-01 03:25:46,826:INFO:Defining folds
2022-12-01 03:25:46,827:INFO:Declaring metric variables
2022-12-01 03:25:46,838:INFO:Importing untrained model
2022-12-01 03:25:46,848:INFO:Lasso Least Angle Regression Imported successfully
2022-12-01 03:25:46,865:INFO:Starting cross validation
2022-12-01 03:25:46,867:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:25:46,906:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:25:46,932:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:25:46,962:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:25:46,999:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:25:47,024:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:25:47,038:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:25:47,077:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:25:47,081:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:25:47,117:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:25:47,122:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:25:47,139:INFO:Calculating mean and std
2022-12-01 03:25:47,141:INFO:Creating metrics dataframe
2022-12-01 03:25:47,150:INFO:Uploading results into container
2022-12-01 03:25:47,151:INFO:Uploading model into container now
2022-12-01 03:25:47,152:INFO:master_model_container: 6
2022-12-01 03:25:47,152:INFO:display_container: 2
2022-12-01 03:25:47,153:INFO:LassoLars(random_state=123)
2022-12-01 03:25:47,153:INFO:create_model() successfully completed......................................
2022-12-01 03:25:47,294:INFO:SubProcess create_model() end ==================================
2022-12-01 03:25:47,295:INFO:Creating metrics dataframe
2022-12-01 03:25:47,319:INFO:Initializing Orthogonal Matching Pursuit
2022-12-01 03:25:47,319:INFO:Total runtime is 0.09437952041625977 minutes
2022-12-01 03:25:47,327:INFO:SubProcess create_model() called ==================================
2022-12-01 03:25:47,327:INFO:Initializing create_model()
2022-12-01 03:25:47,328:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619ceeb0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc11100>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:25:47,328:INFO:Checking exceptions
2022-12-01 03:25:47,330:INFO:Importing libraries
2022-12-01 03:25:47,331:INFO:Copying training dataset
2022-12-01 03:25:47,338:INFO:Defining folds
2022-12-01 03:25:47,338:INFO:Declaring metric variables
2022-12-01 03:25:47,347:INFO:Importing untrained model
2022-12-01 03:25:47,355:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-01 03:25:47,369:INFO:Starting cross validation
2022-12-01 03:25:47,371:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:25:47,404:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:25:47,427:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:25:47,461:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:25:47,473:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:25:47,510:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:25:47,546:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:25:47,552:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:25:47,586:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:25:47,593:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:25:47,620:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:25:47,632:INFO:Calculating mean and std
2022-12-01 03:25:47,635:INFO:Creating metrics dataframe
2022-12-01 03:25:47,645:INFO:Uploading results into container
2022-12-01 03:25:47,647:INFO:Uploading model into container now
2022-12-01 03:25:47,647:INFO:master_model_container: 7
2022-12-01 03:25:47,648:INFO:display_container: 2
2022-12-01 03:25:47,648:INFO:OrthogonalMatchingPursuit()
2022-12-01 03:25:47,648:INFO:create_model() successfully completed......................................
2022-12-01 03:25:47,787:INFO:SubProcess create_model() end ==================================
2022-12-01 03:25:47,787:INFO:Creating metrics dataframe
2022-12-01 03:25:47,810:INFO:Initializing Bayesian Ridge
2022-12-01 03:25:47,810:INFO:Total runtime is 0.10255887508392335 minutes
2022-12-01 03:25:47,818:INFO:SubProcess create_model() called ==================================
2022-12-01 03:25:47,819:INFO:Initializing create_model()
2022-12-01 03:25:47,819:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619ceeb0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc11100>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:25:47,822:INFO:Checking exceptions
2022-12-01 03:25:47,824:INFO:Importing libraries
2022-12-01 03:25:47,824:INFO:Copying training dataset
2022-12-01 03:25:47,830:INFO:Defining folds
2022-12-01 03:25:47,831:INFO:Declaring metric variables
2022-12-01 03:25:47,839:INFO:Importing untrained model
2022-12-01 03:25:47,846:INFO:Bayesian Ridge Imported successfully
2022-12-01 03:25:47,862:INFO:Starting cross validation
2022-12-01 03:25:47,864:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:25:48,152:INFO:Calculating mean and std
2022-12-01 03:25:48,154:INFO:Creating metrics dataframe
2022-12-01 03:25:48,166:INFO:Uploading results into container
2022-12-01 03:25:48,167:INFO:Uploading model into container now
2022-12-01 03:25:48,168:INFO:master_model_container: 8
2022-12-01 03:25:48,168:INFO:display_container: 2
2022-12-01 03:25:48,168:INFO:BayesianRidge()
2022-12-01 03:25:48,168:INFO:create_model() successfully completed......................................
2022-12-01 03:25:48,308:INFO:SubProcess create_model() end ==================================
2022-12-01 03:25:48,309:INFO:Creating metrics dataframe
2022-12-01 03:25:48,328:INFO:Initializing Passive Aggressive Regressor
2022-12-01 03:25:48,329:INFO:Total runtime is 0.11119953393936158 minutes
2022-12-01 03:25:48,337:INFO:SubProcess create_model() called ==================================
2022-12-01 03:25:48,338:INFO:Initializing create_model()
2022-12-01 03:25:48,338:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619ceeb0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc11100>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:25:48,338:INFO:Checking exceptions
2022-12-01 03:25:48,341:INFO:Importing libraries
2022-12-01 03:25:48,341:INFO:Copying training dataset
2022-12-01 03:25:48,347:INFO:Defining folds
2022-12-01 03:25:48,348:INFO:Declaring metric variables
2022-12-01 03:25:48,358:INFO:Importing untrained model
2022-12-01 03:25:48,365:INFO:Passive Aggressive Regressor Imported successfully
2022-12-01 03:25:48,378:INFO:Starting cross validation
2022-12-01 03:25:48,379:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:25:48,645:INFO:Calculating mean and std
2022-12-01 03:25:48,647:INFO:Creating metrics dataframe
2022-12-01 03:25:48,657:INFO:Uploading results into container
2022-12-01 03:25:48,658:INFO:Uploading model into container now
2022-12-01 03:25:48,658:INFO:master_model_container: 9
2022-12-01 03:25:48,658:INFO:display_container: 2
2022-12-01 03:25:48,659:INFO:PassiveAggressiveRegressor(random_state=123)
2022-12-01 03:25:48,659:INFO:create_model() successfully completed......................................
2022-12-01 03:25:48,800:INFO:SubProcess create_model() end ==================================
2022-12-01 03:25:48,800:INFO:Creating metrics dataframe
2022-12-01 03:25:48,819:INFO:Initializing Huber Regressor
2022-12-01 03:25:48,820:INFO:Total runtime is 0.1193893074989319 minutes
2022-12-01 03:25:48,829:INFO:SubProcess create_model() called ==================================
2022-12-01 03:25:48,830:INFO:Initializing create_model()
2022-12-01 03:25:48,830:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619ceeb0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc11100>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:25:48,830:INFO:Checking exceptions
2022-12-01 03:25:48,833:INFO:Importing libraries
2022-12-01 03:25:48,833:INFO:Copying training dataset
2022-12-01 03:25:48,838:INFO:Defining folds
2022-12-01 03:25:48,838:INFO:Declaring metric variables
2022-12-01 03:25:48,850:INFO:Importing untrained model
2022-12-01 03:25:48,859:INFO:Huber Regressor Imported successfully
2022-12-01 03:25:48,876:INFO:Starting cross validation
2022-12-01 03:25:48,879:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:25:48,997:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:25:49,006:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:25:49,116:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:25:49,119:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:25:49,224:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:25:49,228:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:25:49,320:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:25:49,325:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:25:49,413:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:25:49,420:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:25:49,435:INFO:Calculating mean and std
2022-12-01 03:25:49,437:INFO:Creating metrics dataframe
2022-12-01 03:25:49,447:INFO:Uploading results into container
2022-12-01 03:25:49,448:INFO:Uploading model into container now
2022-12-01 03:25:49,449:INFO:master_model_container: 10
2022-12-01 03:25:49,449:INFO:display_container: 2
2022-12-01 03:25:49,450:INFO:HuberRegressor()
2022-12-01 03:25:49,450:INFO:create_model() successfully completed......................................
2022-12-01 03:25:49,589:INFO:SubProcess create_model() end ==================================
2022-12-01 03:25:49,589:INFO:Creating metrics dataframe
2022-12-01 03:25:49,609:INFO:Initializing K Neighbors Regressor
2022-12-01 03:25:49,610:INFO:Total runtime is 0.13255604108174643 minutes
2022-12-01 03:25:49,618:INFO:SubProcess create_model() called ==================================
2022-12-01 03:25:49,619:INFO:Initializing create_model()
2022-12-01 03:25:49,619:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619ceeb0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc11100>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:25:49,620:INFO:Checking exceptions
2022-12-01 03:25:49,623:INFO:Importing libraries
2022-12-01 03:25:49,623:INFO:Copying training dataset
2022-12-01 03:25:49,628:INFO:Defining folds
2022-12-01 03:25:49,629:INFO:Declaring metric variables
2022-12-01 03:25:49,640:INFO:Importing untrained model
2022-12-01 03:25:49,650:INFO:K Neighbors Regressor Imported successfully
2022-12-01 03:25:49,668:INFO:Starting cross validation
2022-12-01 03:25:49,670:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:25:49,964:INFO:Calculating mean and std
2022-12-01 03:25:49,967:INFO:Creating metrics dataframe
2022-12-01 03:25:49,979:INFO:Uploading results into container
2022-12-01 03:25:49,981:INFO:Uploading model into container now
2022-12-01 03:25:49,982:INFO:master_model_container: 11
2022-12-01 03:25:49,982:INFO:display_container: 2
2022-12-01 03:25:49,982:INFO:KNeighborsRegressor(n_jobs=-1)
2022-12-01 03:25:49,983:INFO:create_model() successfully completed......................................
2022-12-01 03:25:50,126:INFO:SubProcess create_model() end ==================================
2022-12-01 03:25:50,127:INFO:Creating metrics dataframe
2022-12-01 03:25:50,149:INFO:Initializing Decision Tree Regressor
2022-12-01 03:25:50,149:INFO:Total runtime is 0.14154313802719118 minutes
2022-12-01 03:25:50,158:INFO:SubProcess create_model() called ==================================
2022-12-01 03:25:50,159:INFO:Initializing create_model()
2022-12-01 03:25:50,159:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619ceeb0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc11100>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:25:50,159:INFO:Checking exceptions
2022-12-01 03:25:50,162:INFO:Importing libraries
2022-12-01 03:25:50,162:INFO:Copying training dataset
2022-12-01 03:25:50,167:INFO:Defining folds
2022-12-01 03:25:50,168:INFO:Declaring metric variables
2022-12-01 03:25:50,177:INFO:Importing untrained model
2022-12-01 03:25:50,187:INFO:Decision Tree Regressor Imported successfully
2022-12-01 03:25:50,202:INFO:Starting cross validation
2022-12-01 03:25:50,204:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:25:50,492:INFO:Calculating mean and std
2022-12-01 03:25:50,494:INFO:Creating metrics dataframe
2022-12-01 03:25:50,499:INFO:Uploading results into container
2022-12-01 03:25:50,501:INFO:Uploading model into container now
2022-12-01 03:25:50,505:INFO:master_model_container: 12
2022-12-01 03:25:50,505:INFO:display_container: 2
2022-12-01 03:25:50,506:INFO:DecisionTreeRegressor(random_state=123)
2022-12-01 03:25:50,506:INFO:create_model() successfully completed......................................
2022-12-01 03:25:50,640:INFO:SubProcess create_model() end ==================================
2022-12-01 03:25:50,641:INFO:Creating metrics dataframe
2022-12-01 03:25:50,659:INFO:Initializing Random Forest Regressor
2022-12-01 03:25:50,660:INFO:Total runtime is 0.15006310542424522 minutes
2022-12-01 03:25:50,668:INFO:SubProcess create_model() called ==================================
2022-12-01 03:25:50,669:INFO:Initializing create_model()
2022-12-01 03:25:50,669:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619ceeb0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc11100>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:25:50,669:INFO:Checking exceptions
2022-12-01 03:25:50,671:INFO:Importing libraries
2022-12-01 03:25:50,672:INFO:Copying training dataset
2022-12-01 03:25:50,676:INFO:Defining folds
2022-12-01 03:25:50,676:INFO:Declaring metric variables
2022-12-01 03:25:50,684:INFO:Importing untrained model
2022-12-01 03:25:50,692:INFO:Random Forest Regressor Imported successfully
2022-12-01 03:25:50,705:INFO:Starting cross validation
2022-12-01 03:25:50,707:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:25:54,605:INFO:Calculating mean and std
2022-12-01 03:25:54,608:INFO:Creating metrics dataframe
2022-12-01 03:25:54,620:INFO:Uploading results into container
2022-12-01 03:25:54,621:INFO:Uploading model into container now
2022-12-01 03:25:54,621:INFO:master_model_container: 13
2022-12-01 03:25:54,621:INFO:display_container: 2
2022-12-01 03:25:54,622:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-12-01 03:25:54,622:INFO:create_model() successfully completed......................................
2022-12-01 03:25:54,762:INFO:SubProcess create_model() end ==================================
2022-12-01 03:25:54,765:INFO:Creating metrics dataframe
2022-12-01 03:25:54,785:INFO:Initializing Extra Trees Regressor
2022-12-01 03:25:54,786:INFO:Total runtime is 0.21882211367289228 minutes
2022-12-01 03:25:54,796:INFO:SubProcess create_model() called ==================================
2022-12-01 03:25:54,797:INFO:Initializing create_model()
2022-12-01 03:25:54,797:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619ceeb0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc11100>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:25:54,797:INFO:Checking exceptions
2022-12-01 03:25:54,801:INFO:Importing libraries
2022-12-01 03:25:54,801:INFO:Copying training dataset
2022-12-01 03:25:54,809:INFO:Defining folds
2022-12-01 03:25:54,809:INFO:Declaring metric variables
2022-12-01 03:25:54,820:INFO:Importing untrained model
2022-12-01 03:25:54,829:INFO:Extra Trees Regressor Imported successfully
2022-12-01 03:25:54,842:INFO:Starting cross validation
2022-12-01 03:25:54,845:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:25:56,978:INFO:Calculating mean and std
2022-12-01 03:25:56,985:INFO:Creating metrics dataframe
2022-12-01 03:25:56,993:INFO:Uploading results into container
2022-12-01 03:25:56,994:INFO:Uploading model into container now
2022-12-01 03:25:56,994:INFO:master_model_container: 14
2022-12-01 03:25:56,994:INFO:display_container: 2
2022-12-01 03:25:56,995:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-12-01 03:25:56,995:INFO:create_model() successfully completed......................................
2022-12-01 03:25:57,136:INFO:SubProcess create_model() end ==================================
2022-12-01 03:25:57,137:INFO:Creating metrics dataframe
2022-12-01 03:25:57,165:INFO:Initializing AdaBoost Regressor
2022-12-01 03:25:57,168:INFO:Total runtime is 0.25852355559666956 minutes
2022-12-01 03:25:57,175:INFO:SubProcess create_model() called ==================================
2022-12-01 03:25:57,176:INFO:Initializing create_model()
2022-12-01 03:25:57,176:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619ceeb0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc11100>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:25:57,176:INFO:Checking exceptions
2022-12-01 03:25:57,179:INFO:Importing libraries
2022-12-01 03:25:57,179:INFO:Copying training dataset
2022-12-01 03:25:57,184:INFO:Defining folds
2022-12-01 03:25:57,185:INFO:Declaring metric variables
2022-12-01 03:25:57,197:INFO:Importing untrained model
2022-12-01 03:25:57,206:INFO:AdaBoost Regressor Imported successfully
2022-12-01 03:25:57,224:INFO:Starting cross validation
2022-12-01 03:25:57,227:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:25:58,396:INFO:Calculating mean and std
2022-12-01 03:25:58,399:INFO:Creating metrics dataframe
2022-12-01 03:25:58,407:INFO:Uploading results into container
2022-12-01 03:25:58,408:INFO:Uploading model into container now
2022-12-01 03:25:58,409:INFO:master_model_container: 15
2022-12-01 03:25:58,409:INFO:display_container: 2
2022-12-01 03:25:58,410:INFO:AdaBoostRegressor(random_state=123)
2022-12-01 03:25:58,410:INFO:create_model() successfully completed......................................
2022-12-01 03:25:58,550:INFO:SubProcess create_model() end ==================================
2022-12-01 03:25:58,551:INFO:Creating metrics dataframe
2022-12-01 03:25:58,573:INFO:Initializing Gradient Boosting Regressor
2022-12-01 03:25:58,573:INFO:Total runtime is 0.2819467862447103 minutes
2022-12-01 03:25:58,583:INFO:SubProcess create_model() called ==================================
2022-12-01 03:25:58,584:INFO:Initializing create_model()
2022-12-01 03:25:58,585:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619ceeb0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc11100>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:25:58,585:INFO:Checking exceptions
2022-12-01 03:25:58,588:INFO:Importing libraries
2022-12-01 03:25:58,588:INFO:Copying training dataset
2022-12-01 03:25:58,593:INFO:Defining folds
2022-12-01 03:25:58,594:INFO:Declaring metric variables
2022-12-01 03:25:58,606:INFO:Importing untrained model
2022-12-01 03:25:58,614:INFO:Gradient Boosting Regressor Imported successfully
2022-12-01 03:25:58,629:INFO:Starting cross validation
2022-12-01 03:25:58,631:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:00,340:INFO:Calculating mean and std
2022-12-01 03:26:00,342:INFO:Creating metrics dataframe
2022-12-01 03:26:00,357:INFO:Uploading results into container
2022-12-01 03:26:00,357:INFO:Uploading model into container now
2022-12-01 03:26:00,358:INFO:master_model_container: 16
2022-12-01 03:26:00,358:INFO:display_container: 2
2022-12-01 03:26:00,359:INFO:GradientBoostingRegressor(random_state=123)
2022-12-01 03:26:00,359:INFO:create_model() successfully completed......................................
2022-12-01 03:26:00,494:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:00,494:INFO:Creating metrics dataframe
2022-12-01 03:26:00,514:INFO:Initializing Light Gradient Boosting Machine
2022-12-01 03:26:00,514:INFO:Total runtime is 0.3142922441164653 minutes
2022-12-01 03:26:00,522:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:00,522:INFO:Initializing create_model()
2022-12-01 03:26:00,522:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619ceeb0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc11100>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:00,523:INFO:Checking exceptions
2022-12-01 03:26:00,525:INFO:Importing libraries
2022-12-01 03:26:00,525:INFO:Copying training dataset
2022-12-01 03:26:00,530:INFO:Defining folds
2022-12-01 03:26:00,530:INFO:Declaring metric variables
2022-12-01 03:26:00,538:INFO:Importing untrained model
2022-12-01 03:26:00,548:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-01 03:26:00,564:INFO:Starting cross validation
2022-12-01 03:26:00,568:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:01,979:INFO:Calculating mean and std
2022-12-01 03:26:01,981:INFO:Creating metrics dataframe
2022-12-01 03:26:01,995:INFO:Uploading results into container
2022-12-01 03:26:01,995:INFO:Uploading model into container now
2022-12-01 03:26:01,996:INFO:master_model_container: 17
2022-12-01 03:26:01,996:INFO:display_container: 2
2022-12-01 03:26:01,997:INFO:LGBMRegressor(random_state=123)
2022-12-01 03:26:01,997:INFO:create_model() successfully completed......................................
2022-12-01 03:26:02,136:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:02,136:INFO:Creating metrics dataframe
2022-12-01 03:26:02,161:INFO:Initializing Dummy Regressor
2022-12-01 03:26:02,170:INFO:Total runtime is 0.3418851455052694 minutes
2022-12-01 03:26:02,176:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:02,176:INFO:Initializing create_model()
2022-12-01 03:26:02,176:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619ceeb0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495fc11100>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:02,177:INFO:Checking exceptions
2022-12-01 03:26:02,180:INFO:Importing libraries
2022-12-01 03:26:02,181:INFO:Copying training dataset
2022-12-01 03:26:02,185:INFO:Defining folds
2022-12-01 03:26:02,185:INFO:Declaring metric variables
2022-12-01 03:26:02,193:INFO:Importing untrained model
2022-12-01 03:26:02,203:INFO:Dummy Regressor Imported successfully
2022-12-01 03:26:02,218:INFO:Starting cross validation
2022-12-01 03:26:02,220:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:02,472:INFO:Calculating mean and std
2022-12-01 03:26:02,474:INFO:Creating metrics dataframe
2022-12-01 03:26:02,481:INFO:Uploading results into container
2022-12-01 03:26:02,482:INFO:Uploading model into container now
2022-12-01 03:26:02,483:INFO:master_model_container: 18
2022-12-01 03:26:02,483:INFO:display_container: 2
2022-12-01 03:26:02,484:INFO:DummyRegressor()
2022-12-01 03:26:02,484:INFO:create_model() successfully completed......................................
2022-12-01 03:26:02,620:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:02,620:INFO:Creating metrics dataframe
2022-12-01 03:26:02,664:INFO:Initializing create_model()
2022-12-01 03:26:02,664:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619ceeb0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:02,664:INFO:Checking exceptions
2022-12-01 03:26:02,670:INFO:Importing libraries
2022-12-01 03:26:02,670:INFO:Copying training dataset
2022-12-01 03:26:02,674:INFO:Defining folds
2022-12-01 03:26:02,674:INFO:Declaring metric variables
2022-12-01 03:26:02,674:INFO:Importing untrained model
2022-12-01 03:26:02,675:INFO:Declaring custom model
2022-12-01 03:26:02,676:INFO:Random Forest Regressor Imported successfully
2022-12-01 03:26:02,677:INFO:Cross validation set to False
2022-12-01 03:26:02,677:INFO:Fitting Model
2022-12-01 03:26:03,120:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-12-01 03:26:03,120:INFO:create_model() successfully completed......................................
2022-12-01 03:26:03,349:INFO:master_model_container: 18
2022-12-01 03:26:03,349:INFO:display_container: 2
2022-12-01 03:26:03,350:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-12-01 03:26:03,350:INFO:compare_models() successfully completed......................................
2022-12-01 03:26:07,316:WARNING:<ipython-input-41-387158f279ba>:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q1'] = abs(data['PTS_QTR1_x'] - data['PTS_QTR1_y'])

2022-12-01 03:26:07,318:WARNING:<ipython-input-41-387158f279ba>:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q2'] = abs(data['PTS_QTR2_x'] - data['PTS_QTR2_y'])

2022-12-01 03:26:07,319:WARNING:<ipython-input-41-387158f279ba>:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q3'] = abs(data['PTS_QTR3_x'] - data['PTS_QTR3_y'])

2022-12-01 03:26:07,320:WARNING:<ipython-input-41-387158f279ba>:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q4'] = abs(data['PTS_QTR4_x'] - data['PTS_QTR4_y'])

2022-12-01 03:26:07,321:WARNING:<ipython-input-41-387158f279ba>:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['PTS'] = abs(data['PTS_x'] - data['PTS_y'])

2022-12-01 03:26:07,321:WARNING:<ipython-input-41-387158f279ba>:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FG_PCT'] = abs(data['FG_PCT_x'] - data['FG_PCT_y'])

2022-12-01 03:26:07,322:WARNING:<ipython-input-41-387158f279ba>:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT'] = abs(data['FT_PCT_x'] - data['FT_PCT_y'])

2022-12-01 03:26:07,323:WARNING:<ipython-input-41-387158f279ba>:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT3'] = abs(data['FG3_PCT_x'] - data['FG3_PCT_y'])

2022-12-01 03:26:07,324:WARNING:<ipython-input-41-387158f279ba>:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['AST'] = abs(data['AST_x'] - data['AST_y'])

2022-12-01 03:26:07,325:WARNING:<ipython-input-41-387158f279ba>:26: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['REB'] = abs(data['REB_x'] - data['REB_y'])

2022-12-01 03:26:07,326:WARNING:<ipython-input-41-387158f279ba>:27: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['TO'] = abs(data['TOV_x'] - data['TOV_y'])

2022-12-01 03:26:07,330:INFO:PyCaret RegressionExperiment
2022-12-01 03:26:07,331:INFO:Logging name: FullData
2022-12-01 03:26:07,331:INFO:ML Usecase: MLUsecase.REGRESSION
2022-12-01 03:26:07,331:INFO:version 3.0.0.rc4
2022-12-01 03:26:07,331:INFO:Initializing setup()
2022-12-01 03:26:07,331:INFO:self.USI: 883b
2022-12-01 03:26:07,331:INFO:self.variable_keys: {'fold_shuffle_param', 'y_test', 'pipeline', 'data', 'X', 'exp_id', 'master_model_container', '_available_plots', '_all_metrics', '_ml_usecase', 'log_plots_param', '_all_models', 'logging_param', 'idx', 'html_param', 'display_container', 'USI', 'target_param', 'fold_generator', '_gpu_n_jobs_param', 'n_jobs_param', 'transform_target_method_param', 'exp_name_log', 'X_test', 'variable_keys', 'gpu_param', 'memory', 'y_train', 'transform_target_param', 'y', 'X_train', '_all_models_internal', 'fold_groups_param', 'seed'}
2022-12-01 03:26:07,331:INFO:Checking environment
2022-12-01 03:26:07,332:INFO:python_version: 3.8.15
2022-12-01 03:26:07,332:INFO:python_build: ('default', 'Oct 12 2022 19:14:39')
2022-12-01 03:26:07,332:INFO:machine: x86_64
2022-12-01 03:26:07,332:INFO:platform: Linux-5.10.133+-x86_64-with-glibc2.27
2022-12-01 03:26:07,332:INFO:Memory: svmem(total=13616361472, available=11560456192, percent=15.1, used=1954054144, free=8845938688, active=1043132416, inactive=3393949696, buffers=431149056, cached=2385219584, shared=1245184, slab=239796224)
2022-12-01 03:26:07,333:INFO:Physical Core: 1
2022-12-01 03:26:07,333:INFO:Logical Core: 2
2022-12-01 03:26:07,333:INFO:Checking libraries
2022-12-01 03:26:07,333:INFO:System:
2022-12-01 03:26:07,333:INFO:    python: 3.8.15 (default, Oct 12 2022, 19:14:39)  [GCC 7.5.0]
2022-12-01 03:26:07,333:INFO:executable: /usr/bin/python3
2022-12-01 03:26:07,334:INFO:   machine: Linux-5.10.133+-x86_64-with-glibc2.27
2022-12-01 03:26:07,334:INFO:PyCaret required dependencies:
2022-12-01 03:26:07,334:INFO:                 pip: 21.1.3
2022-12-01 03:26:07,334:INFO:          setuptools: 57.4.0
2022-12-01 03:26:07,334:INFO:             pycaret: 3.0.0rc4
2022-12-01 03:26:07,334:INFO:             IPython: 7.9.0
2022-12-01 03:26:07,334:INFO:          ipywidgets: 7.7.1
2022-12-01 03:26:07,335:INFO:                tqdm: 4.64.1
2022-12-01 03:26:07,335:INFO:               numpy: 1.21.6
2022-12-01 03:26:07,335:INFO:              pandas: 1.3.5
2022-12-01 03:26:07,335:INFO:              jinja2: 3.0.0
2022-12-01 03:26:07,335:INFO:               scipy: 1.7.3
2022-12-01 03:26:07,335:INFO:              joblib: 1.2.0
2022-12-01 03:26:07,335:INFO:             sklearn: 1.0.2
2022-12-01 03:26:07,335:INFO:                pyod: 1.0.6
2022-12-01 03:26:07,335:INFO:            imblearn: 0.8.1
2022-12-01 03:26:07,336:INFO:   category_encoders: 2.5.1.post0
2022-12-01 03:26:07,336:INFO:            lightgbm: 3.3.3
2022-12-01 03:26:07,336:INFO:               numba: 0.55.2
2022-12-01 03:26:07,336:INFO:            requests: 2.28.1
2022-12-01 03:26:07,336:INFO:          matplotlib: 3.6.2
2022-12-01 03:26:07,336:INFO:          scikitplot: 0.3.7
2022-12-01 03:26:07,336:INFO:         yellowbrick: 1.5
2022-12-01 03:26:07,336:INFO:              plotly: 5.5.0
2022-12-01 03:26:07,336:INFO:             kaleido: 0.2.1
2022-12-01 03:26:07,337:INFO:         statsmodels: 0.12.2
2022-12-01 03:26:07,337:INFO:              sktime: 0.13.4
2022-12-01 03:26:07,337:INFO:               tbats: 1.1.1
2022-12-01 03:26:07,337:INFO:            pmdarima: 1.8.5
2022-12-01 03:26:07,337:INFO:              psutil: 5.9.4
2022-12-01 03:26:07,337:INFO:PyCaret optional dependencies:
2022-12-01 03:26:07,337:INFO:                shap: Not installed
2022-12-01 03:26:07,337:INFO:           interpret: Not installed
2022-12-01 03:26:07,338:INFO:                umap: Not installed
2022-12-01 03:26:07,338:INFO:    pandas_profiling: 1.4.1
2022-12-01 03:26:07,338:INFO:  explainerdashboard: Not installed
2022-12-01 03:26:07,338:INFO:             autoviz: Not installed
2022-12-01 03:26:07,339:INFO:           fairlearn: Not installed
2022-12-01 03:26:07,339:INFO:             xgboost: 0.90
2022-12-01 03:26:07,339:INFO:            catboost: Not installed
2022-12-01 03:26:07,339:INFO:              kmodes: Not installed
2022-12-01 03:26:07,339:INFO:             mlxtend: 0.14.0
2022-12-01 03:26:07,339:INFO:       statsforecast: Not installed
2022-12-01 03:26:07,339:INFO:        tune_sklearn: Not installed
2022-12-01 03:26:07,339:INFO:                 ray: Not installed
2022-12-01 03:26:07,339:INFO:            hyperopt: 0.1.2
2022-12-01 03:26:07,339:INFO:              optuna: Not installed
2022-12-01 03:26:07,340:INFO:               skopt: Not installed
2022-12-01 03:26:07,340:INFO:              mlflow: Not installed
2022-12-01 03:26:07,340:INFO:              gradio: Not installed
2022-12-01 03:26:07,340:INFO:             fastapi: Not installed
2022-12-01 03:26:07,340:INFO:             uvicorn: Not installed
2022-12-01 03:26:07,340:INFO:              m2cgen: Not installed
2022-12-01 03:26:07,340:INFO:           evidently: Not installed
2022-12-01 03:26:07,340:INFO:                nltk: 3.7
2022-12-01 03:26:07,341:INFO:            pyLDAvis: Not installed
2022-12-01 03:26:07,341:INFO:              gensim: 3.6.0
2022-12-01 03:26:07,341:INFO:               spacy: 3.4.3
2022-12-01 03:26:07,341:INFO:           wordcloud: 1.8.2.2
2022-12-01 03:26:07,341:INFO:            textblob: 0.15.3
2022-12-01 03:26:07,341:INFO:               fugue: Not installed
2022-12-01 03:26:07,341:INFO:           streamlit: Not installed
2022-12-01 03:26:07,341:INFO:             prophet: 1.1.1
2022-12-01 03:26:07,341:INFO:None
2022-12-01 03:26:07,342:INFO:Set up data.
2022-12-01 03:26:07,349:INFO:Set up train/test split.
2022-12-01 03:26:07,352:INFO:Set up index.
2022-12-01 03:26:07,352:INFO:Set up folding strategy.
2022-12-01 03:26:07,352:INFO:Assigning column types.
2022-12-01 03:26:07,357:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-12-01 03:26:07,358:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-01 03:26:07,363:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 03:26:07,367:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:26:07,435:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:26:07,481:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:26:07,482:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:07,483:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:07,483:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:07,484:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-01 03:26:07,489:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 03:26:07,494:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:26:07,552:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:26:07,599:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:26:07,600:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:07,600:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:07,600:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:07,601:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-12-01 03:26:07,606:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 03:26:07,611:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:26:07,670:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:26:07,715:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:26:07,716:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:07,717:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:07,717:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:07,722:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 03:26:07,727:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:26:07,786:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:26:07,832:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:26:07,833:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:07,833:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:07,834:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:07,834:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-12-01 03:26:07,844:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:26:07,903:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:26:07,953:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:26:07,954:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:07,954:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:07,954:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:07,965:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:26:08,036:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:26:08,089:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:26:08,090:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:08,090:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:08,091:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:08,091:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-12-01 03:26:08,167:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:26:08,216:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:26:08,218:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:08,218:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:08,219:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:08,295:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:26:08,347:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:26:08,348:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:08,348:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:08,349:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:08,349:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-12-01 03:26:08,423:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:26:08,482:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:08,483:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:08,483:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:08,557:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:26:08,608:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:08,608:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:08,609:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:08,609:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-12-01 03:26:08,733:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:08,734:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:08,734:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:08,857:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:08,857:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:08,857:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:08,858:INFO:Preparing preprocessing pipeline...
2022-12-01 03:26:08,859:INFO:Set up simple imputation.
2022-12-01 03:26:08,859:INFO:Set up variance threshold.
2022-12-01 03:26:08,871:INFO:Finished creating preprocessing pipeline.
2022-12-01 03:26:08,877:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO',
                                             'Open_Line_ML_x'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-12-01 03:26:08,877:INFO:Creating final display dataframe.
2022-12-01 03:26:08,953:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 13)
4         Train data shape    (607, 13)
5          Test data shape    (261, 13)
6         Numeric features           12
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         883b
2022-12-01 03:26:09,102:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:09,102:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:09,103:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:09,225:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:09,225:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:09,226:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:09,233:INFO:setup() successfully completed in 1.91s...............
2022-12-01 03:26:09,233:INFO:Initializing compare_models()
2022-12-01 03:26:09,233:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619cba00>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f49619cba00>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-12-01 03:26:09,233:INFO:Checking exceptions
2022-12-01 03:26:09,235:INFO:Preparing display monitor
2022-12-01 03:26:09,317:INFO:Initializing Linear Regression
2022-12-01 03:26:09,317:INFO:Total runtime is 1.0466575622558593e-05 minutes
2022-12-01 03:26:09,330:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:09,334:INFO:Initializing create_model()
2022-12-01 03:26:09,334:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619cba00>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495ab469a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:09,334:INFO:Checking exceptions
2022-12-01 03:26:09,337:INFO:Importing libraries
2022-12-01 03:26:09,337:INFO:Copying training dataset
2022-12-01 03:26:09,341:INFO:Defining folds
2022-12-01 03:26:09,341:INFO:Declaring metric variables
2022-12-01 03:26:09,347:INFO:Importing untrained model
2022-12-01 03:26:09,354:INFO:Linear Regression Imported successfully
2022-12-01 03:26:09,367:INFO:Starting cross validation
2022-12-01 03:26:09,372:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:09,644:INFO:Calculating mean and std
2022-12-01 03:26:09,644:INFO:Creating metrics dataframe
2022-12-01 03:26:09,649:INFO:Uploading results into container
2022-12-01 03:26:09,649:INFO:Uploading model into container now
2022-12-01 03:26:09,650:INFO:master_model_container: 1
2022-12-01 03:26:09,650:INFO:display_container: 2
2022-12-01 03:26:09,650:INFO:LinearRegression(n_jobs=-1)
2022-12-01 03:26:09,650:INFO:create_model() successfully completed......................................
2022-12-01 03:26:09,791:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:09,792:INFO:Creating metrics dataframe
2022-12-01 03:26:09,807:INFO:Initializing Lasso Regression
2022-12-01 03:26:09,807:INFO:Total runtime is 0.008185231685638427 minutes
2022-12-01 03:26:09,815:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:09,816:INFO:Initializing create_model()
2022-12-01 03:26:09,816:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619cba00>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495ab469a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:09,816:INFO:Checking exceptions
2022-12-01 03:26:09,819:INFO:Importing libraries
2022-12-01 03:26:09,819:INFO:Copying training dataset
2022-12-01 03:26:09,822:INFO:Defining folds
2022-12-01 03:26:09,823:INFO:Declaring metric variables
2022-12-01 03:26:09,827:INFO:Importing untrained model
2022-12-01 03:26:09,833:INFO:Lasso Regression Imported successfully
2022-12-01 03:26:09,848:INFO:Starting cross validation
2022-12-01 03:26:09,850:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:10,126:INFO:Calculating mean and std
2022-12-01 03:26:10,127:INFO:Creating metrics dataframe
2022-12-01 03:26:10,131:INFO:Uploading results into container
2022-12-01 03:26:10,132:INFO:Uploading model into container now
2022-12-01 03:26:10,133:INFO:master_model_container: 2
2022-12-01 03:26:10,133:INFO:display_container: 2
2022-12-01 03:26:10,133:INFO:Lasso(random_state=123)
2022-12-01 03:26:10,133:INFO:create_model() successfully completed......................................
2022-12-01 03:26:10,269:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:10,270:INFO:Creating metrics dataframe
2022-12-01 03:26:10,288:INFO:Initializing Ridge Regression
2022-12-01 03:26:10,289:INFO:Total runtime is 0.016205390294392902 minutes
2022-12-01 03:26:10,297:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:10,298:INFO:Initializing create_model()
2022-12-01 03:26:10,298:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619cba00>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495ab469a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:10,298:INFO:Checking exceptions
2022-12-01 03:26:10,301:INFO:Importing libraries
2022-12-01 03:26:10,301:INFO:Copying training dataset
2022-12-01 03:26:10,306:INFO:Defining folds
2022-12-01 03:26:10,307:INFO:Declaring metric variables
2022-12-01 03:26:10,316:INFO:Importing untrained model
2022-12-01 03:26:10,324:INFO:Ridge Regression Imported successfully
2022-12-01 03:26:10,340:INFO:Starting cross validation
2022-12-01 03:26:10,342:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:10,381:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.19612e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:26:10,405:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1832e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:26:10,439:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.25596e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:26:10,473:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.27134e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:26:10,485:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1563e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:26:10,538:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.30751e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:26:10,550:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.25177e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:26:10,585:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.19532e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:26:10,588:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1922e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:26:10,617:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.20778e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:26:10,628:INFO:Calculating mean and std
2022-12-01 03:26:10,630:INFO:Creating metrics dataframe
2022-12-01 03:26:10,641:INFO:Uploading results into container
2022-12-01 03:26:10,642:INFO:Uploading model into container now
2022-12-01 03:26:10,643:INFO:master_model_container: 3
2022-12-01 03:26:10,643:INFO:display_container: 2
2022-12-01 03:26:10,644:INFO:Ridge(random_state=123)
2022-12-01 03:26:10,644:INFO:create_model() successfully completed......................................
2022-12-01 03:26:10,782:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:10,782:INFO:Creating metrics dataframe
2022-12-01 03:26:10,799:INFO:Initializing Elastic Net
2022-12-01 03:26:10,800:INFO:Total runtime is 0.024728775024414062 minutes
2022-12-01 03:26:10,807:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:10,808:INFO:Initializing create_model()
2022-12-01 03:26:10,809:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619cba00>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495ab469a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:10,809:INFO:Checking exceptions
2022-12-01 03:26:10,811:INFO:Importing libraries
2022-12-01 03:26:10,811:INFO:Copying training dataset
2022-12-01 03:26:10,817:INFO:Defining folds
2022-12-01 03:26:10,817:INFO:Declaring metric variables
2022-12-01 03:26:10,829:INFO:Importing untrained model
2022-12-01 03:26:10,838:INFO:Elastic Net Imported successfully
2022-12-01 03:26:10,856:INFO:Starting cross validation
2022-12-01 03:26:10,858:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:11,127:INFO:Calculating mean and std
2022-12-01 03:26:11,130:INFO:Creating metrics dataframe
2022-12-01 03:26:11,142:INFO:Uploading results into container
2022-12-01 03:26:11,143:INFO:Uploading model into container now
2022-12-01 03:26:11,144:INFO:master_model_container: 4
2022-12-01 03:26:11,144:INFO:display_container: 2
2022-12-01 03:26:11,145:INFO:ElasticNet(random_state=123)
2022-12-01 03:26:11,145:INFO:create_model() successfully completed......................................
2022-12-01 03:26:11,284:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:11,286:INFO:Creating metrics dataframe
2022-12-01 03:26:11,303:INFO:Initializing Least Angle Regression
2022-12-01 03:26:11,307:INFO:Total runtime is 0.033172571659088136 minutes
2022-12-01 03:26:11,312:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:11,313:INFO:Initializing create_model()
2022-12-01 03:26:11,314:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619cba00>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495ab469a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:11,314:INFO:Checking exceptions
2022-12-01 03:26:11,316:INFO:Importing libraries
2022-12-01 03:26:11,317:INFO:Copying training dataset
2022-12-01 03:26:11,323:INFO:Defining folds
2022-12-01 03:26:11,324:INFO:Declaring metric variables
2022-12-01 03:26:11,333:INFO:Importing untrained model
2022-12-01 03:26:11,341:INFO:Least Angle Regression Imported successfully
2022-12-01 03:26:11,357:INFO:Starting cross validation
2022-12-01 03:26:11,361:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:11,396:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:11,424:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:11,443:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:11,495:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:11,543:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:11,551:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:11,584:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:11,592:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:11,632:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:11,640:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:11,659:INFO:Calculating mean and std
2022-12-01 03:26:11,662:INFO:Creating metrics dataframe
2022-12-01 03:26:11,669:INFO:Uploading results into container
2022-12-01 03:26:11,670:INFO:Uploading model into container now
2022-12-01 03:26:11,671:INFO:master_model_container: 5
2022-12-01 03:26:11,671:INFO:display_container: 2
2022-12-01 03:26:11,672:INFO:Lars(random_state=123)
2022-12-01 03:26:11,672:INFO:create_model() successfully completed......................................
2022-12-01 03:26:11,813:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:11,814:INFO:Creating metrics dataframe
2022-12-01 03:26:11,834:INFO:Initializing Lasso Least Angle Regression
2022-12-01 03:26:11,834:INFO:Total runtime is 0.04196838935216268 minutes
2022-12-01 03:26:11,843:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:11,844:INFO:Initializing create_model()
2022-12-01 03:26:11,844:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619cba00>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495ab469a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:11,844:INFO:Checking exceptions
2022-12-01 03:26:11,848:INFO:Importing libraries
2022-12-01 03:26:11,849:INFO:Copying training dataset
2022-12-01 03:26:11,853:INFO:Defining folds
2022-12-01 03:26:11,854:INFO:Declaring metric variables
2022-12-01 03:26:11,864:INFO:Importing untrained model
2022-12-01 03:26:11,876:INFO:Lasso Least Angle Regression Imported successfully
2022-12-01 03:26:11,893:INFO:Starting cross validation
2022-12-01 03:26:11,895:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:11,934:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:26:11,962:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:26:11,995:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:26:12,021:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:26:12,054:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:26:12,079:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:26:12,090:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:26:12,130:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:26:12,132:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:26:12,163:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:26:12,175:INFO:Calculating mean and std
2022-12-01 03:26:12,177:INFO:Creating metrics dataframe
2022-12-01 03:26:12,188:INFO:Uploading results into container
2022-12-01 03:26:12,189:INFO:Uploading model into container now
2022-12-01 03:26:12,190:INFO:master_model_container: 6
2022-12-01 03:26:12,191:INFO:display_container: 2
2022-12-01 03:26:12,191:INFO:LassoLars(random_state=123)
2022-12-01 03:26:12,192:INFO:create_model() successfully completed......................................
2022-12-01 03:26:12,338:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:12,338:INFO:Creating metrics dataframe
2022-12-01 03:26:12,358:INFO:Initializing Orthogonal Matching Pursuit
2022-12-01 03:26:12,359:INFO:Total runtime is 0.05070395867029826 minutes
2022-12-01 03:26:12,370:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:12,370:INFO:Initializing create_model()
2022-12-01 03:26:12,371:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619cba00>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495ab469a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:12,371:INFO:Checking exceptions
2022-12-01 03:26:12,373:INFO:Importing libraries
2022-12-01 03:26:12,374:INFO:Copying training dataset
2022-12-01 03:26:12,379:INFO:Defining folds
2022-12-01 03:26:12,380:INFO:Declaring metric variables
2022-12-01 03:26:12,390:INFO:Importing untrained model
2022-12-01 03:26:12,399:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-01 03:26:12,415:INFO:Starting cross validation
2022-12-01 03:26:12,417:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:12,450:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:12,480:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:12,508:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:12,533:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:12,573:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:12,600:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:12,614:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:12,648:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:12,658:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:12,685:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:12,698:INFO:Calculating mean and std
2022-12-01 03:26:12,700:INFO:Creating metrics dataframe
2022-12-01 03:26:12,707:INFO:Uploading results into container
2022-12-01 03:26:12,708:INFO:Uploading model into container now
2022-12-01 03:26:12,709:INFO:master_model_container: 7
2022-12-01 03:26:12,709:INFO:display_container: 2
2022-12-01 03:26:12,710:INFO:OrthogonalMatchingPursuit()
2022-12-01 03:26:12,710:INFO:create_model() successfully completed......................................
2022-12-01 03:26:12,847:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:12,847:INFO:Creating metrics dataframe
2022-12-01 03:26:12,873:INFO:Initializing Bayesian Ridge
2022-12-01 03:26:12,873:INFO:Total runtime is 0.05928351879119873 minutes
2022-12-01 03:26:12,885:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:12,886:INFO:Initializing create_model()
2022-12-01 03:26:12,887:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619cba00>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495ab469a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:12,887:INFO:Checking exceptions
2022-12-01 03:26:12,889:INFO:Importing libraries
2022-12-01 03:26:12,889:INFO:Copying training dataset
2022-12-01 03:26:12,893:INFO:Defining folds
2022-12-01 03:26:12,894:INFO:Declaring metric variables
2022-12-01 03:26:12,907:INFO:Importing untrained model
2022-12-01 03:26:12,915:INFO:Bayesian Ridge Imported successfully
2022-12-01 03:26:12,931:INFO:Starting cross validation
2022-12-01 03:26:12,933:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:13,204:INFO:Calculating mean and std
2022-12-01 03:26:13,206:INFO:Creating metrics dataframe
2022-12-01 03:26:13,220:INFO:Uploading results into container
2022-12-01 03:26:13,221:INFO:Uploading model into container now
2022-12-01 03:26:13,228:INFO:master_model_container: 8
2022-12-01 03:26:13,229:INFO:display_container: 2
2022-12-01 03:26:13,229:INFO:BayesianRidge()
2022-12-01 03:26:13,230:INFO:create_model() successfully completed......................................
2022-12-01 03:26:13,379:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:13,379:INFO:Creating metrics dataframe
2022-12-01 03:26:13,399:INFO:Initializing Passive Aggressive Regressor
2022-12-01 03:26:13,400:INFO:Total runtime is 0.06805438200632731 minutes
2022-12-01 03:26:13,409:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:13,410:INFO:Initializing create_model()
2022-12-01 03:26:13,410:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619cba00>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495ab469a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:13,410:INFO:Checking exceptions
2022-12-01 03:26:13,413:INFO:Importing libraries
2022-12-01 03:26:13,413:INFO:Copying training dataset
2022-12-01 03:26:13,419:INFO:Defining folds
2022-12-01 03:26:13,419:INFO:Declaring metric variables
2022-12-01 03:26:13,433:INFO:Importing untrained model
2022-12-01 03:26:13,441:INFO:Passive Aggressive Regressor Imported successfully
2022-12-01 03:26:13,463:INFO:Starting cross validation
2022-12-01 03:26:13,464:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:13,759:INFO:Calculating mean and std
2022-12-01 03:26:13,761:INFO:Creating metrics dataframe
2022-12-01 03:26:13,766:INFO:Uploading results into container
2022-12-01 03:26:13,769:INFO:Uploading model into container now
2022-12-01 03:26:13,772:INFO:master_model_container: 9
2022-12-01 03:26:13,772:INFO:display_container: 2
2022-12-01 03:26:13,774:INFO:PassiveAggressiveRegressor(random_state=123)
2022-12-01 03:26:13,774:INFO:create_model() successfully completed......................................
2022-12-01 03:26:13,914:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:13,914:INFO:Creating metrics dataframe
2022-12-01 03:26:13,933:INFO:Initializing Huber Regressor
2022-12-01 03:26:13,934:INFO:Total runtime is 0.07695645888646443 minutes
2022-12-01 03:26:13,944:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:13,946:INFO:Initializing create_model()
2022-12-01 03:26:13,946:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619cba00>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495ab469a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:13,946:INFO:Checking exceptions
2022-12-01 03:26:13,949:INFO:Importing libraries
2022-12-01 03:26:13,949:INFO:Copying training dataset
2022-12-01 03:26:13,953:INFO:Defining folds
2022-12-01 03:26:13,953:INFO:Declaring metric variables
2022-12-01 03:26:13,964:INFO:Importing untrained model
2022-12-01 03:26:13,973:INFO:Huber Regressor Imported successfully
2022-12-01 03:26:13,994:INFO:Starting cross validation
2022-12-01 03:26:13,996:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:14,089:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:26:14,146:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:26:14,196:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:26:14,258:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:26:14,307:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:26:14,363:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:26:14,401:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:26:14,452:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:26:14,492:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:26:14,529:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:26:14,540:INFO:Calculating mean and std
2022-12-01 03:26:14,542:INFO:Creating metrics dataframe
2022-12-01 03:26:14,550:INFO:Uploading results into container
2022-12-01 03:26:14,550:INFO:Uploading model into container now
2022-12-01 03:26:14,551:INFO:master_model_container: 10
2022-12-01 03:26:14,551:INFO:display_container: 2
2022-12-01 03:26:14,552:INFO:HuberRegressor()
2022-12-01 03:26:14,552:INFO:create_model() successfully completed......................................
2022-12-01 03:26:14,703:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:14,707:INFO:Creating metrics dataframe
2022-12-01 03:26:14,730:INFO:Initializing K Neighbors Regressor
2022-12-01 03:26:14,730:INFO:Total runtime is 0.090234903494517 minutes
2022-12-01 03:26:14,739:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:14,740:INFO:Initializing create_model()
2022-12-01 03:26:14,740:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619cba00>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495ab469a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:14,740:INFO:Checking exceptions
2022-12-01 03:26:14,743:INFO:Importing libraries
2022-12-01 03:26:14,743:INFO:Copying training dataset
2022-12-01 03:26:14,750:INFO:Defining folds
2022-12-01 03:26:14,750:INFO:Declaring metric variables
2022-12-01 03:26:14,760:INFO:Importing untrained model
2022-12-01 03:26:14,766:INFO:K Neighbors Regressor Imported successfully
2022-12-01 03:26:14,779:INFO:Starting cross validation
2022-12-01 03:26:14,781:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:15,076:INFO:Calculating mean and std
2022-12-01 03:26:15,078:INFO:Creating metrics dataframe
2022-12-01 03:26:15,086:INFO:Uploading results into container
2022-12-01 03:26:15,086:INFO:Uploading model into container now
2022-12-01 03:26:15,087:INFO:master_model_container: 11
2022-12-01 03:26:15,087:INFO:display_container: 2
2022-12-01 03:26:15,088:INFO:KNeighborsRegressor(n_jobs=-1)
2022-12-01 03:26:15,088:INFO:create_model() successfully completed......................................
2022-12-01 03:26:15,225:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:15,225:INFO:Creating metrics dataframe
2022-12-01 03:26:15,250:INFO:Initializing Decision Tree Regressor
2022-12-01 03:26:15,250:INFO:Total runtime is 0.09890062014261881 minutes
2022-12-01 03:26:15,259:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:15,262:INFO:Initializing create_model()
2022-12-01 03:26:15,264:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619cba00>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495ab469a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:15,264:INFO:Checking exceptions
2022-12-01 03:26:15,266:INFO:Importing libraries
2022-12-01 03:26:15,266:INFO:Copying training dataset
2022-12-01 03:26:15,270:INFO:Defining folds
2022-12-01 03:26:15,273:INFO:Declaring metric variables
2022-12-01 03:26:15,283:INFO:Importing untrained model
2022-12-01 03:26:15,291:INFO:Decision Tree Regressor Imported successfully
2022-12-01 03:26:15,308:INFO:Starting cross validation
2022-12-01 03:26:15,310:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:15,611:INFO:Calculating mean and std
2022-12-01 03:26:15,613:INFO:Creating metrics dataframe
2022-12-01 03:26:15,625:INFO:Uploading results into container
2022-12-01 03:26:15,627:INFO:Uploading model into container now
2022-12-01 03:26:15,627:INFO:master_model_container: 12
2022-12-01 03:26:15,627:INFO:display_container: 2
2022-12-01 03:26:15,628:INFO:DecisionTreeRegressor(random_state=123)
2022-12-01 03:26:15,628:INFO:create_model() successfully completed......................................
2022-12-01 03:26:15,771:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:15,772:INFO:Creating metrics dataframe
2022-12-01 03:26:15,792:INFO:Initializing Random Forest Regressor
2022-12-01 03:26:15,792:INFO:Total runtime is 0.10793397029240925 minutes
2022-12-01 03:26:15,800:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:15,802:INFO:Initializing create_model()
2022-12-01 03:26:15,803:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619cba00>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495ab469a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:15,803:INFO:Checking exceptions
2022-12-01 03:26:15,805:INFO:Importing libraries
2022-12-01 03:26:15,806:INFO:Copying training dataset
2022-12-01 03:26:15,812:INFO:Defining folds
2022-12-01 03:26:15,812:INFO:Declaring metric variables
2022-12-01 03:26:15,820:INFO:Importing untrained model
2022-12-01 03:26:15,828:INFO:Random Forest Regressor Imported successfully
2022-12-01 03:26:15,842:INFO:Starting cross validation
2022-12-01 03:26:15,844:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:19,693:INFO:Calculating mean and std
2022-12-01 03:26:19,695:INFO:Creating metrics dataframe
2022-12-01 03:26:19,707:INFO:Uploading results into container
2022-12-01 03:26:19,708:INFO:Uploading model into container now
2022-12-01 03:26:19,708:INFO:master_model_container: 13
2022-12-01 03:26:19,709:INFO:display_container: 2
2022-12-01 03:26:19,709:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-12-01 03:26:19,709:INFO:create_model() successfully completed......................................
2022-12-01 03:26:19,852:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:19,852:INFO:Creating metrics dataframe
2022-12-01 03:26:19,876:INFO:Initializing Extra Trees Regressor
2022-12-01 03:26:19,880:INFO:Total runtime is 0.17605270942052204 minutes
2022-12-01 03:26:19,887:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:19,888:INFO:Initializing create_model()
2022-12-01 03:26:19,888:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619cba00>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495ab469a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:19,888:INFO:Checking exceptions
2022-12-01 03:26:19,891:INFO:Importing libraries
2022-12-01 03:26:19,892:INFO:Copying training dataset
2022-12-01 03:26:19,897:INFO:Defining folds
2022-12-01 03:26:19,897:INFO:Declaring metric variables
2022-12-01 03:26:19,908:INFO:Importing untrained model
2022-12-01 03:26:19,920:INFO:Extra Trees Regressor Imported successfully
2022-12-01 03:26:19,938:INFO:Starting cross validation
2022-12-01 03:26:19,940:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:22,049:INFO:Calculating mean and std
2022-12-01 03:26:22,055:INFO:Creating metrics dataframe
2022-12-01 03:26:22,065:INFO:Uploading results into container
2022-12-01 03:26:22,066:INFO:Uploading model into container now
2022-12-01 03:26:22,067:INFO:master_model_container: 14
2022-12-01 03:26:22,067:INFO:display_container: 2
2022-12-01 03:26:22,067:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-12-01 03:26:22,068:INFO:create_model() successfully completed......................................
2022-12-01 03:26:22,207:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:22,207:INFO:Creating metrics dataframe
2022-12-01 03:26:22,230:INFO:Initializing AdaBoost Regressor
2022-12-01 03:26:22,230:INFO:Total runtime is 0.21523127555847166 minutes
2022-12-01 03:26:22,239:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:22,240:INFO:Initializing create_model()
2022-12-01 03:26:22,244:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619cba00>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495ab469a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:22,244:INFO:Checking exceptions
2022-12-01 03:26:22,246:INFO:Importing libraries
2022-12-01 03:26:22,246:INFO:Copying training dataset
2022-12-01 03:26:22,252:INFO:Defining folds
2022-12-01 03:26:22,252:INFO:Declaring metric variables
2022-12-01 03:26:22,261:INFO:Importing untrained model
2022-12-01 03:26:22,269:INFO:AdaBoost Regressor Imported successfully
2022-12-01 03:26:22,284:INFO:Starting cross validation
2022-12-01 03:26:22,286:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:23,472:INFO:Calculating mean and std
2022-12-01 03:26:23,474:INFO:Creating metrics dataframe
2022-12-01 03:26:23,491:INFO:Uploading results into container
2022-12-01 03:26:23,491:INFO:Uploading model into container now
2022-12-01 03:26:23,492:INFO:master_model_container: 15
2022-12-01 03:26:23,492:INFO:display_container: 2
2022-12-01 03:26:23,492:INFO:AdaBoostRegressor(random_state=123)
2022-12-01 03:26:23,493:INFO:create_model() successfully completed......................................
2022-12-01 03:26:23,633:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:23,633:INFO:Creating metrics dataframe
2022-12-01 03:26:23,654:INFO:Initializing Gradient Boosting Regressor
2022-12-01 03:26:23,654:INFO:Total runtime is 0.23896540006001787 minutes
2022-12-01 03:26:23,663:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:23,664:INFO:Initializing create_model()
2022-12-01 03:26:23,664:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619cba00>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495ab469a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:23,664:INFO:Checking exceptions
2022-12-01 03:26:23,666:INFO:Importing libraries
2022-12-01 03:26:23,667:INFO:Copying training dataset
2022-12-01 03:26:23,674:INFO:Defining folds
2022-12-01 03:26:23,674:INFO:Declaring metric variables
2022-12-01 03:26:23,683:INFO:Importing untrained model
2022-12-01 03:26:23,690:INFO:Gradient Boosting Regressor Imported successfully
2022-12-01 03:26:23,708:INFO:Starting cross validation
2022-12-01 03:26:23,712:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:25,463:INFO:Calculating mean and std
2022-12-01 03:26:25,466:INFO:Creating metrics dataframe
2022-12-01 03:26:25,478:INFO:Uploading results into container
2022-12-01 03:26:25,479:INFO:Uploading model into container now
2022-12-01 03:26:25,480:INFO:master_model_container: 16
2022-12-01 03:26:25,480:INFO:display_container: 2
2022-12-01 03:26:25,480:INFO:GradientBoostingRegressor(random_state=123)
2022-12-01 03:26:25,480:INFO:create_model() successfully completed......................................
2022-12-01 03:26:25,620:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:25,621:INFO:Creating metrics dataframe
2022-12-01 03:26:25,643:INFO:Initializing Light Gradient Boosting Machine
2022-12-01 03:26:25,644:INFO:Total runtime is 0.27212549050649004 minutes
2022-12-01 03:26:25,655:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:25,658:INFO:Initializing create_model()
2022-12-01 03:26:25,660:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619cba00>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495ab469a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:25,661:INFO:Checking exceptions
2022-12-01 03:26:25,663:INFO:Importing libraries
2022-12-01 03:26:25,663:INFO:Copying training dataset
2022-12-01 03:26:25,667:INFO:Defining folds
2022-12-01 03:26:25,668:INFO:Declaring metric variables
2022-12-01 03:26:25,681:INFO:Importing untrained model
2022-12-01 03:26:25,690:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-01 03:26:25,704:INFO:Starting cross validation
2022-12-01 03:26:25,706:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:26,531:INFO:Calculating mean and std
2022-12-01 03:26:26,534:INFO:Creating metrics dataframe
2022-12-01 03:26:26,545:INFO:Uploading results into container
2022-12-01 03:26:26,548:INFO:Uploading model into container now
2022-12-01 03:26:26,549:INFO:master_model_container: 17
2022-12-01 03:26:26,549:INFO:display_container: 2
2022-12-01 03:26:26,550:INFO:LGBMRegressor(random_state=123)
2022-12-01 03:26:26,550:INFO:create_model() successfully completed......................................
2022-12-01 03:26:26,692:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:26,692:INFO:Creating metrics dataframe
2022-12-01 03:26:26,713:INFO:Initializing Dummy Regressor
2022-12-01 03:26:26,714:INFO:Total runtime is 0.289959983030955 minutes
2022-12-01 03:26:26,725:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:26,725:INFO:Initializing create_model()
2022-12-01 03:26:26,726:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619cba00>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495ab469a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:26,726:INFO:Checking exceptions
2022-12-01 03:26:26,729:INFO:Importing libraries
2022-12-01 03:26:26,730:INFO:Copying training dataset
2022-12-01 03:26:26,737:INFO:Defining folds
2022-12-01 03:26:26,737:INFO:Declaring metric variables
2022-12-01 03:26:26,746:INFO:Importing untrained model
2022-12-01 03:26:26,757:INFO:Dummy Regressor Imported successfully
2022-12-01 03:26:26,773:INFO:Starting cross validation
2022-12-01 03:26:26,775:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:27,042:INFO:Calculating mean and std
2022-12-01 03:26:27,044:INFO:Creating metrics dataframe
2022-12-01 03:26:27,054:INFO:Uploading results into container
2022-12-01 03:26:27,056:INFO:Uploading model into container now
2022-12-01 03:26:27,057:INFO:master_model_container: 18
2022-12-01 03:26:27,057:INFO:display_container: 2
2022-12-01 03:26:27,057:INFO:DummyRegressor()
2022-12-01 03:26:27,058:INFO:create_model() successfully completed......................................
2022-12-01 03:26:27,201:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:27,202:INFO:Creating metrics dataframe
2022-12-01 03:26:27,256:INFO:Initializing create_model()
2022-12-01 03:26:27,257:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619cba00>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:27,257:INFO:Checking exceptions
2022-12-01 03:26:27,263:INFO:Importing libraries
2022-12-01 03:26:27,266:INFO:Copying training dataset
2022-12-01 03:26:27,269:INFO:Defining folds
2022-12-01 03:26:27,269:INFO:Declaring metric variables
2022-12-01 03:26:27,270:INFO:Importing untrained model
2022-12-01 03:26:27,270:INFO:Declaring custom model
2022-12-01 03:26:27,271:INFO:Random Forest Regressor Imported successfully
2022-12-01 03:26:27,272:INFO:Cross validation set to False
2022-12-01 03:26:27,273:INFO:Fitting Model
2022-12-01 03:26:27,718:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-12-01 03:26:27,718:INFO:create_model() successfully completed......................................
2022-12-01 03:26:27,949:INFO:master_model_container: 18
2022-12-01 03:26:27,950:INFO:display_container: 2
2022-12-01 03:26:27,951:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-12-01 03:26:27,952:INFO:compare_models() successfully completed......................................
2022-12-01 03:26:35,395:WARNING:<ipython-input-41-387158f279ba>:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q1'] = abs(data['PTS_QTR1_x'] - data['PTS_QTR1_y'])

2022-12-01 03:26:35,397:WARNING:<ipython-input-41-387158f279ba>:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q2'] = abs(data['PTS_QTR2_x'] - data['PTS_QTR2_y'])

2022-12-01 03:26:35,398:WARNING:<ipython-input-41-387158f279ba>:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q3'] = abs(data['PTS_QTR3_x'] - data['PTS_QTR3_y'])

2022-12-01 03:26:35,400:WARNING:<ipython-input-41-387158f279ba>:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q4'] = abs(data['PTS_QTR4_x'] - data['PTS_QTR4_y'])

2022-12-01 03:26:35,401:WARNING:<ipython-input-41-387158f279ba>:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['PTS'] = abs(data['PTS_x'] - data['PTS_y'])

2022-12-01 03:26:35,403:WARNING:<ipython-input-41-387158f279ba>:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FG_PCT'] = abs(data['FG_PCT_x'] - data['FG_PCT_y'])

2022-12-01 03:26:35,404:WARNING:<ipython-input-41-387158f279ba>:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT'] = abs(data['FT_PCT_x'] - data['FT_PCT_y'])

2022-12-01 03:26:35,405:WARNING:<ipython-input-41-387158f279ba>:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT3'] = abs(data['FG3_PCT_x'] - data['FG3_PCT_y'])

2022-12-01 03:26:35,407:WARNING:<ipython-input-41-387158f279ba>:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['AST'] = abs(data['AST_x'] - data['AST_y'])

2022-12-01 03:26:35,408:WARNING:<ipython-input-41-387158f279ba>:26: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['REB'] = abs(data['REB_x'] - data['REB_y'])

2022-12-01 03:26:35,410:WARNING:<ipython-input-41-387158f279ba>:27: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['TO'] = abs(data['TOV_x'] - data['TOV_y'])

2022-12-01 03:26:35,417:INFO:PyCaret RegressionExperiment
2022-12-01 03:26:35,417:INFO:Logging name: FullData
2022-12-01 03:26:35,417:INFO:ML Usecase: MLUsecase.REGRESSION
2022-12-01 03:26:35,417:INFO:version 3.0.0.rc4
2022-12-01 03:26:35,418:INFO:Initializing setup()
2022-12-01 03:26:35,418:INFO:self.USI: 0b68
2022-12-01 03:26:35,418:INFO:self.variable_keys: {'fold_shuffle_param', 'y_test', 'pipeline', 'data', 'X', 'exp_id', 'master_model_container', '_available_plots', '_all_metrics', '_ml_usecase', 'log_plots_param', '_all_models', 'logging_param', 'idx', 'html_param', 'display_container', 'USI', 'target_param', 'fold_generator', '_gpu_n_jobs_param', 'n_jobs_param', 'transform_target_method_param', 'exp_name_log', 'X_test', 'variable_keys', 'gpu_param', 'memory', 'y_train', 'transform_target_param', 'y', 'X_train', '_all_models_internal', 'fold_groups_param', 'seed'}
2022-12-01 03:26:35,418:INFO:Checking environment
2022-12-01 03:26:35,418:INFO:python_version: 3.8.15
2022-12-01 03:26:35,418:INFO:python_build: ('default', 'Oct 12 2022 19:14:39')
2022-12-01 03:26:35,418:INFO:machine: x86_64
2022-12-01 03:26:35,418:INFO:platform: Linux-5.10.133+-x86_64-with-glibc2.27
2022-12-01 03:26:35,419:INFO:Memory: svmem(total=13616361472, available=11509624832, percent=15.5, used=2023698432, free=8773443584, active=1043271680, inactive=3466055680, buffers=431312896, cached=2387906560, shared=1245184, slab=239685632)
2022-12-01 03:26:35,419:INFO:Physical Core: 1
2022-12-01 03:26:35,419:INFO:Logical Core: 2
2022-12-01 03:26:35,419:INFO:Checking libraries
2022-12-01 03:26:35,420:INFO:System:
2022-12-01 03:26:35,420:INFO:    python: 3.8.15 (default, Oct 12 2022, 19:14:39)  [GCC 7.5.0]
2022-12-01 03:26:35,420:INFO:executable: /usr/bin/python3
2022-12-01 03:26:35,420:INFO:   machine: Linux-5.10.133+-x86_64-with-glibc2.27
2022-12-01 03:26:35,420:INFO:PyCaret required dependencies:
2022-12-01 03:26:35,420:INFO:                 pip: 21.1.3
2022-12-01 03:26:35,420:INFO:          setuptools: 57.4.0
2022-12-01 03:26:35,420:INFO:             pycaret: 3.0.0rc4
2022-12-01 03:26:35,420:INFO:             IPython: 7.9.0
2022-12-01 03:26:35,421:INFO:          ipywidgets: 7.7.1
2022-12-01 03:26:35,421:INFO:                tqdm: 4.64.1
2022-12-01 03:26:35,421:INFO:               numpy: 1.21.6
2022-12-01 03:26:35,421:INFO:              pandas: 1.3.5
2022-12-01 03:26:35,421:INFO:              jinja2: 3.0.0
2022-12-01 03:26:35,421:INFO:               scipy: 1.7.3
2022-12-01 03:26:35,421:INFO:              joblib: 1.2.0
2022-12-01 03:26:35,421:INFO:             sklearn: 1.0.2
2022-12-01 03:26:35,421:INFO:                pyod: 1.0.6
2022-12-01 03:26:35,422:INFO:            imblearn: 0.8.1
2022-12-01 03:26:35,422:INFO:   category_encoders: 2.5.1.post0
2022-12-01 03:26:35,422:INFO:            lightgbm: 3.3.3
2022-12-01 03:26:35,422:INFO:               numba: 0.55.2
2022-12-01 03:26:35,422:INFO:            requests: 2.28.1
2022-12-01 03:26:35,422:INFO:          matplotlib: 3.6.2
2022-12-01 03:26:35,422:INFO:          scikitplot: 0.3.7
2022-12-01 03:26:35,422:INFO:         yellowbrick: 1.5
2022-12-01 03:26:35,422:INFO:              plotly: 5.5.0
2022-12-01 03:26:35,423:INFO:             kaleido: 0.2.1
2022-12-01 03:26:35,423:INFO:         statsmodels: 0.12.2
2022-12-01 03:26:35,423:INFO:              sktime: 0.13.4
2022-12-01 03:26:35,423:INFO:               tbats: 1.1.1
2022-12-01 03:26:35,423:INFO:            pmdarima: 1.8.5
2022-12-01 03:26:35,423:INFO:              psutil: 5.9.4
2022-12-01 03:26:35,423:INFO:PyCaret optional dependencies:
2022-12-01 03:26:35,424:INFO:                shap: Not installed
2022-12-01 03:26:35,424:INFO:           interpret: Not installed
2022-12-01 03:26:35,424:INFO:                umap: Not installed
2022-12-01 03:26:35,424:INFO:    pandas_profiling: 1.4.1
2022-12-01 03:26:35,424:INFO:  explainerdashboard: Not installed
2022-12-01 03:26:35,424:INFO:             autoviz: Not installed
2022-12-01 03:26:35,424:INFO:           fairlearn: Not installed
2022-12-01 03:26:35,425:INFO:             xgboost: 0.90
2022-12-01 03:26:35,425:INFO:            catboost: Not installed
2022-12-01 03:26:35,425:INFO:              kmodes: Not installed
2022-12-01 03:26:35,425:INFO:             mlxtend: 0.14.0
2022-12-01 03:26:35,425:INFO:       statsforecast: Not installed
2022-12-01 03:26:35,425:INFO:        tune_sklearn: Not installed
2022-12-01 03:26:35,426:INFO:                 ray: Not installed
2022-12-01 03:26:35,426:INFO:            hyperopt: 0.1.2
2022-12-01 03:26:35,426:INFO:              optuna: Not installed
2022-12-01 03:26:35,426:INFO:               skopt: Not installed
2022-12-01 03:26:35,426:INFO:              mlflow: Not installed
2022-12-01 03:26:35,426:INFO:              gradio: Not installed
2022-12-01 03:26:35,426:INFO:             fastapi: Not installed
2022-12-01 03:26:35,427:INFO:             uvicorn: Not installed
2022-12-01 03:26:35,427:INFO:              m2cgen: Not installed
2022-12-01 03:26:35,427:INFO:           evidently: Not installed
2022-12-01 03:26:35,427:INFO:                nltk: 3.7
2022-12-01 03:26:35,427:INFO:            pyLDAvis: Not installed
2022-12-01 03:26:35,427:INFO:              gensim: 3.6.0
2022-12-01 03:26:35,427:INFO:               spacy: 3.4.3
2022-12-01 03:26:35,428:INFO:           wordcloud: 1.8.2.2
2022-12-01 03:26:35,428:INFO:            textblob: 0.15.3
2022-12-01 03:26:35,428:INFO:               fugue: Not installed
2022-12-01 03:26:35,428:INFO:           streamlit: Not installed
2022-12-01 03:26:35,428:INFO:             prophet: 1.1.1
2022-12-01 03:26:35,428:INFO:None
2022-12-01 03:26:35,428:INFO:Set up data.
2022-12-01 03:26:35,441:INFO:Set up train/test split.
2022-12-01 03:26:35,447:INFO:Set up index.
2022-12-01 03:26:35,447:INFO:Set up folding strategy.
2022-12-01 03:26:35,448:INFO:Assigning column types.
2022-12-01 03:26:35,456:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-12-01 03:26:35,457:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-01 03:26:35,466:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 03:26:35,475:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:26:35,596:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:26:35,721:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:26:35,723:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:35,723:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:35,724:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:35,725:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-01 03:26:35,734:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 03:26:35,743:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:26:35,984:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:26:36,080:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:26:36,082:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:36,082:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:36,083:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:36,083:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-12-01 03:26:36,093:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 03:26:36,117:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:26:36,272:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:26:36,321:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:26:36,322:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:36,323:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:36,323:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:36,328:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 03:26:36,333:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:26:36,399:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:26:36,449:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:26:36,450:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:36,450:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:36,450:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:36,451:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-12-01 03:26:36,461:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:26:36,527:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:26:36,577:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:26:36,578:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:36,579:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:36,579:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:36,590:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:26:36,653:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:26:36,702:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:26:36,707:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:36,707:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:36,708:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:36,708:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-12-01 03:26:36,781:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:26:36,831:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:26:36,832:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:36,833:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:36,833:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:36,907:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:26:36,957:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:26:36,958:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:36,958:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:36,959:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:36,959:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-12-01 03:26:37,034:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:26:37,087:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:37,088:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:37,088:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:37,167:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:26:37,217:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:37,217:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:37,218:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:37,218:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-12-01 03:26:37,355:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:37,355:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:37,356:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:37,480:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:37,481:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:37,481:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:37,482:INFO:Preparing preprocessing pipeline...
2022-12-01 03:26:37,483:INFO:Set up simple imputation.
2022-12-01 03:26:37,483:INFO:Set up variance threshold.
2022-12-01 03:26:37,500:INFO:Finished creating preprocessing pipeline.
2022-12-01 03:26:37,509:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO',
                                             'Open_Line_ML_x'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-12-01 03:26:37,509:INFO:Creating final display dataframe.
2022-12-01 03:26:37,588:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape    (868, 13)
4         Train data shape    (607, 13)
5          Test data shape    (261, 13)
6         Numeric features           12
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         0b68
2022-12-01 03:26:37,732:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:37,733:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:37,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:37,860:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:26:37,860:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:26:37,861:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:26:37,868:INFO:setup() successfully completed in 2.46s...............
2022-12-01 03:26:37,869:INFO:Initializing compare_models()
2022-12-01 03:26:37,869:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b9880>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f49619b9880>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-12-01 03:26:37,869:INFO:Checking exceptions
2022-12-01 03:26:37,871:INFO:Preparing display monitor
2022-12-01 03:26:37,954:INFO:Initializing Linear Regression
2022-12-01 03:26:37,955:INFO:Total runtime is 6.29425048828125e-06 minutes
2022-12-01 03:26:37,963:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:37,963:INFO:Initializing create_model()
2022-12-01 03:26:37,964:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b9880>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e09e6a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:37,964:INFO:Checking exceptions
2022-12-01 03:26:37,967:INFO:Importing libraries
2022-12-01 03:26:37,967:INFO:Copying training dataset
2022-12-01 03:26:37,971:INFO:Defining folds
2022-12-01 03:26:37,971:INFO:Declaring metric variables
2022-12-01 03:26:37,979:INFO:Importing untrained model
2022-12-01 03:26:37,987:INFO:Linear Regression Imported successfully
2022-12-01 03:26:38,001:INFO:Starting cross validation
2022-12-01 03:26:38,005:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:38,279:INFO:Calculating mean and std
2022-12-01 03:26:38,280:INFO:Creating metrics dataframe
2022-12-01 03:26:38,289:INFO:Uploading results into container
2022-12-01 03:26:38,290:INFO:Uploading model into container now
2022-12-01 03:26:38,290:INFO:master_model_container: 1
2022-12-01 03:26:38,291:INFO:display_container: 2
2022-12-01 03:26:38,291:INFO:LinearRegression(n_jobs=-1)
2022-12-01 03:26:38,291:INFO:create_model() successfully completed......................................
2022-12-01 03:26:38,440:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:38,441:INFO:Creating metrics dataframe
2022-12-01 03:26:38,457:INFO:Initializing Lasso Regression
2022-12-01 03:26:38,457:INFO:Total runtime is 0.008380746841430664 minutes
2022-12-01 03:26:38,467:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:38,468:INFO:Initializing create_model()
2022-12-01 03:26:38,468:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b9880>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e09e6a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:38,469:INFO:Checking exceptions
2022-12-01 03:26:38,471:INFO:Importing libraries
2022-12-01 03:26:38,472:INFO:Copying training dataset
2022-12-01 03:26:38,475:INFO:Defining folds
2022-12-01 03:26:38,475:INFO:Declaring metric variables
2022-12-01 03:26:38,480:INFO:Importing untrained model
2022-12-01 03:26:38,488:INFO:Lasso Regression Imported successfully
2022-12-01 03:26:38,502:INFO:Starting cross validation
2022-12-01 03:26:38,503:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:38,780:INFO:Calculating mean and std
2022-12-01 03:26:38,781:INFO:Creating metrics dataframe
2022-12-01 03:26:38,785:INFO:Uploading results into container
2022-12-01 03:26:38,786:INFO:Uploading model into container now
2022-12-01 03:26:38,786:INFO:master_model_container: 2
2022-12-01 03:26:38,786:INFO:display_container: 2
2022-12-01 03:26:38,787:INFO:Lasso(random_state=123)
2022-12-01 03:26:38,787:INFO:create_model() successfully completed......................................
2022-12-01 03:26:38,926:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:38,926:INFO:Creating metrics dataframe
2022-12-01 03:26:38,943:INFO:Initializing Ridge Regression
2022-12-01 03:26:38,944:INFO:Total runtime is 0.016487785180409747 minutes
2022-12-01 03:26:38,954:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:38,955:INFO:Initializing create_model()
2022-12-01 03:26:38,955:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b9880>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e09e6a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:38,955:INFO:Checking exceptions
2022-12-01 03:26:38,958:INFO:Importing libraries
2022-12-01 03:26:38,958:INFO:Copying training dataset
2022-12-01 03:26:38,963:INFO:Defining folds
2022-12-01 03:26:38,964:INFO:Declaring metric variables
2022-12-01 03:26:38,974:INFO:Importing untrained model
2022-12-01 03:26:38,982:INFO:Ridge Regression Imported successfully
2022-12-01 03:26:38,998:INFO:Starting cross validation
2022-12-01 03:26:39,000:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:39,058:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.03719e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:26:39,063:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.05541e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:26:39,121:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.0964e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:26:39,123:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.04032e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:26:39,164:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.08942e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:26:39,188:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.07071e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:26:39,199:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.05338e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:26:39,227:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.02164e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:26:39,244:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.05414e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:26:39,268:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.04893e-08): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2022-12-01 03:26:39,279:INFO:Calculating mean and std
2022-12-01 03:26:39,282:INFO:Creating metrics dataframe
2022-12-01 03:26:39,290:INFO:Uploading results into container
2022-12-01 03:26:39,292:INFO:Uploading model into container now
2022-12-01 03:26:39,292:INFO:master_model_container: 3
2022-12-01 03:26:39,293:INFO:display_container: 2
2022-12-01 03:26:39,293:INFO:Ridge(random_state=123)
2022-12-01 03:26:39,293:INFO:create_model() successfully completed......................................
2022-12-01 03:26:39,444:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:39,444:INFO:Creating metrics dataframe
2022-12-01 03:26:39,462:INFO:Initializing Elastic Net
2022-12-01 03:26:39,463:INFO:Total runtime is 0.025137201944986975 minutes
2022-12-01 03:26:39,471:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:39,472:INFO:Initializing create_model()
2022-12-01 03:26:39,472:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b9880>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e09e6a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:39,476:INFO:Checking exceptions
2022-12-01 03:26:39,478:INFO:Importing libraries
2022-12-01 03:26:39,479:INFO:Copying training dataset
2022-12-01 03:26:39,484:INFO:Defining folds
2022-12-01 03:26:39,488:INFO:Declaring metric variables
2022-12-01 03:26:39,497:INFO:Importing untrained model
2022-12-01 03:26:39,506:INFO:Elastic Net Imported successfully
2022-12-01 03:26:39,521:INFO:Starting cross validation
2022-12-01 03:26:39,528:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:39,796:INFO:Calculating mean and std
2022-12-01 03:26:39,798:INFO:Creating metrics dataframe
2022-12-01 03:26:39,807:INFO:Uploading results into container
2022-12-01 03:26:39,808:INFO:Uploading model into container now
2022-12-01 03:26:39,809:INFO:master_model_container: 4
2022-12-01 03:26:39,809:INFO:display_container: 2
2022-12-01 03:26:39,809:INFO:ElasticNet(random_state=123)
2022-12-01 03:26:39,810:INFO:create_model() successfully completed......................................
2022-12-01 03:26:39,947:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:39,948:INFO:Creating metrics dataframe
2022-12-01 03:26:39,966:INFO:Initializing Least Angle Regression
2022-12-01 03:26:39,966:INFO:Total runtime is 0.03353527386983235 minutes
2022-12-01 03:26:39,974:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:39,975:INFO:Initializing create_model()
2022-12-01 03:26:39,976:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b9880>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e09e6a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:39,976:INFO:Checking exceptions
2022-12-01 03:26:39,979:INFO:Importing libraries
2022-12-01 03:26:39,979:INFO:Copying training dataset
2022-12-01 03:26:39,988:INFO:Defining folds
2022-12-01 03:26:39,988:INFO:Declaring metric variables
2022-12-01 03:26:39,999:INFO:Importing untrained model
2022-12-01 03:26:40,009:INFO:Least Angle Regression Imported successfully
2022-12-01 03:26:40,025:INFO:Starting cross validation
2022-12-01 03:26:40,027:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:40,065:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:40,094:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:40,137:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:40,138:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:40,190:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:40,205:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:40,236:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:40,248:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:40,279:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:40,296:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:40,311:INFO:Calculating mean and std
2022-12-01 03:26:40,316:INFO:Creating metrics dataframe
2022-12-01 03:26:40,332:INFO:Uploading results into container
2022-12-01 03:26:40,333:INFO:Uploading model into container now
2022-12-01 03:26:40,333:INFO:master_model_container: 5
2022-12-01 03:26:40,334:INFO:display_container: 2
2022-12-01 03:26:40,334:INFO:Lars(random_state=123)
2022-12-01 03:26:40,334:INFO:create_model() successfully completed......................................
2022-12-01 03:26:40,480:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:40,480:INFO:Creating metrics dataframe
2022-12-01 03:26:40,500:INFO:Initializing Lasso Least Angle Regression
2022-12-01 03:26:40,500:INFO:Total runtime is 0.04243435462315877 minutes
2022-12-01 03:26:40,509:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:40,510:INFO:Initializing create_model()
2022-12-01 03:26:40,510:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b9880>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e09e6a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:40,510:INFO:Checking exceptions
2022-12-01 03:26:40,513:INFO:Importing libraries
2022-12-01 03:26:40,514:INFO:Copying training dataset
2022-12-01 03:26:40,521:INFO:Defining folds
2022-12-01 03:26:40,521:INFO:Declaring metric variables
2022-12-01 03:26:40,530:INFO:Importing untrained model
2022-12-01 03:26:40,540:INFO:Lasso Least Angle Regression Imported successfully
2022-12-01 03:26:40,558:INFO:Starting cross validation
2022-12-01 03:26:40,560:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:40,597:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:26:40,631:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:26:40,658:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:26:40,704:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:26:40,718:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:26:40,764:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:26:40,770:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:26:40,803:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:26:40,813:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:26:40,846:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:26:40,859:INFO:Calculating mean and std
2022-12-01 03:26:40,862:INFO:Creating metrics dataframe
2022-12-01 03:26:40,876:INFO:Uploading results into container
2022-12-01 03:26:40,877:INFO:Uploading model into container now
2022-12-01 03:26:40,878:INFO:master_model_container: 6
2022-12-01 03:26:40,878:INFO:display_container: 2
2022-12-01 03:26:40,878:INFO:LassoLars(random_state=123)
2022-12-01 03:26:40,878:INFO:create_model() successfully completed......................................
2022-12-01 03:26:41,029:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:41,029:INFO:Creating metrics dataframe
2022-12-01 03:26:41,049:INFO:Initializing Orthogonal Matching Pursuit
2022-12-01 03:26:41,050:INFO:Total runtime is 0.051590677102406814 minutes
2022-12-01 03:26:41,061:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:41,062:INFO:Initializing create_model()
2022-12-01 03:26:41,063:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b9880>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e09e6a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:41,064:INFO:Checking exceptions
2022-12-01 03:26:41,068:INFO:Importing libraries
2022-12-01 03:26:41,069:INFO:Copying training dataset
2022-12-01 03:26:41,073:INFO:Defining folds
2022-12-01 03:26:41,074:INFO:Declaring metric variables
2022-12-01 03:26:41,085:INFO:Importing untrained model
2022-12-01 03:26:41,097:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-01 03:26:41,119:INFO:Starting cross validation
2022-12-01 03:26:41,121:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:41,186:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:41,218:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:41,287:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:41,312:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:41,401:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:41,402:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:41,439:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:41,535:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:41,584:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:41,634:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:41,657:INFO:Calculating mean and std
2022-12-01 03:26:41,662:INFO:Creating metrics dataframe
2022-12-01 03:26:41,670:INFO:Uploading results into container
2022-12-01 03:26:41,671:INFO:Uploading model into container now
2022-12-01 03:26:41,672:INFO:master_model_container: 7
2022-12-01 03:26:41,672:INFO:display_container: 2
2022-12-01 03:26:41,673:INFO:OrthogonalMatchingPursuit()
2022-12-01 03:26:41,673:INFO:create_model() successfully completed......................................
2022-12-01 03:26:41,905:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:41,905:INFO:Creating metrics dataframe
2022-12-01 03:26:41,938:INFO:Initializing Bayesian Ridge
2022-12-01 03:26:41,938:INFO:Total runtime is 0.0663976510365804 minutes
2022-12-01 03:26:41,951:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:41,952:INFO:Initializing create_model()
2022-12-01 03:26:41,952:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b9880>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e09e6a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:41,952:INFO:Checking exceptions
2022-12-01 03:26:41,955:INFO:Importing libraries
2022-12-01 03:26:41,955:INFO:Copying training dataset
2022-12-01 03:26:41,973:INFO:Defining folds
2022-12-01 03:26:41,973:INFO:Declaring metric variables
2022-12-01 03:26:41,987:INFO:Importing untrained model
2022-12-01 03:26:41,999:INFO:Bayesian Ridge Imported successfully
2022-12-01 03:26:42,062:INFO:Starting cross validation
2022-12-01 03:26:42,069:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:42,500:INFO:Calculating mean and std
2022-12-01 03:26:42,509:INFO:Creating metrics dataframe
2022-12-01 03:26:42,522:INFO:Uploading results into container
2022-12-01 03:26:42,526:INFO:Uploading model into container now
2022-12-01 03:26:42,527:INFO:master_model_container: 8
2022-12-01 03:26:42,528:INFO:display_container: 2
2022-12-01 03:26:42,530:INFO:BayesianRidge()
2022-12-01 03:26:42,530:INFO:create_model() successfully completed......................................
2022-12-01 03:26:42,671:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:42,671:INFO:Creating metrics dataframe
2022-12-01 03:26:42,690:INFO:Initializing Passive Aggressive Regressor
2022-12-01 03:26:42,691:INFO:Total runtime is 0.07894542614618937 minutes
2022-12-01 03:26:42,700:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:42,701:INFO:Initializing create_model()
2022-12-01 03:26:42,701:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b9880>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e09e6a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:42,702:INFO:Checking exceptions
2022-12-01 03:26:42,704:INFO:Importing libraries
2022-12-01 03:26:42,704:INFO:Copying training dataset
2022-12-01 03:26:42,710:INFO:Defining folds
2022-12-01 03:26:42,711:INFO:Declaring metric variables
2022-12-01 03:26:42,722:INFO:Importing untrained model
2022-12-01 03:26:42,732:INFO:Passive Aggressive Regressor Imported successfully
2022-12-01 03:26:42,748:INFO:Starting cross validation
2022-12-01 03:26:42,749:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:43,023:INFO:Calculating mean and std
2022-12-01 03:26:43,027:INFO:Creating metrics dataframe
2022-12-01 03:26:43,038:INFO:Uploading results into container
2022-12-01 03:26:43,039:INFO:Uploading model into container now
2022-12-01 03:26:43,040:INFO:master_model_container: 9
2022-12-01 03:26:43,040:INFO:display_container: 2
2022-12-01 03:26:43,041:INFO:PassiveAggressiveRegressor(random_state=123)
2022-12-01 03:26:43,041:INFO:create_model() successfully completed......................................
2022-12-01 03:26:43,183:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:43,183:INFO:Creating metrics dataframe
2022-12-01 03:26:43,203:INFO:Initializing Huber Regressor
2022-12-01 03:26:43,204:INFO:Total runtime is 0.08750243186950683 minutes
2022-12-01 03:26:43,213:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:43,214:INFO:Initializing create_model()
2022-12-01 03:26:43,214:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b9880>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e09e6a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:43,214:INFO:Checking exceptions
2022-12-01 03:26:43,217:INFO:Importing libraries
2022-12-01 03:26:43,218:INFO:Copying training dataset
2022-12-01 03:26:43,223:INFO:Defining folds
2022-12-01 03:26:43,224:INFO:Declaring metric variables
2022-12-01 03:26:43,237:INFO:Importing untrained model
2022-12-01 03:26:43,246:INFO:Huber Regressor Imported successfully
2022-12-01 03:26:43,265:INFO:Starting cross validation
2022-12-01 03:26:43,267:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:43,365:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:26:43,396:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:26:43,504:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:26:43,513:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:26:43,615:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:26:43,618:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:26:43,704:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:26:43,710:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:26:43,798:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:26:43,800:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:26:43,819:INFO:Calculating mean and std
2022-12-01 03:26:43,821:INFO:Creating metrics dataframe
2022-12-01 03:26:43,831:INFO:Uploading results into container
2022-12-01 03:26:43,832:INFO:Uploading model into container now
2022-12-01 03:26:43,833:INFO:master_model_container: 10
2022-12-01 03:26:43,833:INFO:display_container: 2
2022-12-01 03:26:43,833:INFO:HuberRegressor()
2022-12-01 03:26:43,834:INFO:create_model() successfully completed......................................
2022-12-01 03:26:43,975:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:43,976:INFO:Creating metrics dataframe
2022-12-01 03:26:43,997:INFO:Initializing K Neighbors Regressor
2022-12-01 03:26:43,998:INFO:Total runtime is 0.10072861115137735 minutes
2022-12-01 03:26:44,007:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:44,008:INFO:Initializing create_model()
2022-12-01 03:26:44,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b9880>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e09e6a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:44,009:INFO:Checking exceptions
2022-12-01 03:26:44,012:INFO:Importing libraries
2022-12-01 03:26:44,012:INFO:Copying training dataset
2022-12-01 03:26:44,017:INFO:Defining folds
2022-12-01 03:26:44,018:INFO:Declaring metric variables
2022-12-01 03:26:44,030:INFO:Importing untrained model
2022-12-01 03:26:44,040:INFO:K Neighbors Regressor Imported successfully
2022-12-01 03:26:44,057:INFO:Starting cross validation
2022-12-01 03:26:44,062:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:44,364:INFO:Calculating mean and std
2022-12-01 03:26:44,367:INFO:Creating metrics dataframe
2022-12-01 03:26:44,374:INFO:Uploading results into container
2022-12-01 03:26:44,375:INFO:Uploading model into container now
2022-12-01 03:26:44,376:INFO:master_model_container: 11
2022-12-01 03:26:44,376:INFO:display_container: 2
2022-12-01 03:26:44,377:INFO:KNeighborsRegressor(n_jobs=-1)
2022-12-01 03:26:44,377:INFO:create_model() successfully completed......................................
2022-12-01 03:26:44,524:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:44,525:INFO:Creating metrics dataframe
2022-12-01 03:26:44,550:INFO:Initializing Decision Tree Regressor
2022-12-01 03:26:44,550:INFO:Total runtime is 0.10993125438690185 minutes
2022-12-01 03:26:44,558:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:44,558:INFO:Initializing create_model()
2022-12-01 03:26:44,559:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b9880>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e09e6a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:44,559:INFO:Checking exceptions
2022-12-01 03:26:44,561:INFO:Importing libraries
2022-12-01 03:26:44,562:INFO:Copying training dataset
2022-12-01 03:26:44,569:INFO:Defining folds
2022-12-01 03:26:44,569:INFO:Declaring metric variables
2022-12-01 03:26:44,577:INFO:Importing untrained model
2022-12-01 03:26:44,585:INFO:Decision Tree Regressor Imported successfully
2022-12-01 03:26:44,600:INFO:Starting cross validation
2022-12-01 03:26:44,602:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:44,930:INFO:Calculating mean and std
2022-12-01 03:26:44,932:INFO:Creating metrics dataframe
2022-12-01 03:26:44,940:INFO:Uploading results into container
2022-12-01 03:26:44,945:INFO:Uploading model into container now
2022-12-01 03:26:44,949:INFO:master_model_container: 12
2022-12-01 03:26:44,949:INFO:display_container: 2
2022-12-01 03:26:44,950:INFO:DecisionTreeRegressor(random_state=123)
2022-12-01 03:26:44,950:INFO:create_model() successfully completed......................................
2022-12-01 03:26:45,090:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:45,090:INFO:Creating metrics dataframe
2022-12-01 03:26:45,110:INFO:Initializing Random Forest Regressor
2022-12-01 03:26:45,110:INFO:Total runtime is 0.11926753520965576 minutes
2022-12-01 03:26:45,118:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:45,119:INFO:Initializing create_model()
2022-12-01 03:26:45,121:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b9880>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e09e6a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:45,121:INFO:Checking exceptions
2022-12-01 03:26:45,124:INFO:Importing libraries
2022-12-01 03:26:45,124:INFO:Copying training dataset
2022-12-01 03:26:45,132:INFO:Defining folds
2022-12-01 03:26:45,133:INFO:Declaring metric variables
2022-12-01 03:26:45,143:INFO:Importing untrained model
2022-12-01 03:26:45,150:INFO:Random Forest Regressor Imported successfully
2022-12-01 03:26:45,168:INFO:Starting cross validation
2022-12-01 03:26:45,170:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:49,566:INFO:Calculating mean and std
2022-12-01 03:26:49,569:INFO:Creating metrics dataframe
2022-12-01 03:26:49,584:INFO:Uploading results into container
2022-12-01 03:26:49,584:INFO:Uploading model into container now
2022-12-01 03:26:49,585:INFO:master_model_container: 13
2022-12-01 03:26:49,585:INFO:display_container: 2
2022-12-01 03:26:49,586:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-12-01 03:26:49,586:INFO:create_model() successfully completed......................................
2022-12-01 03:26:49,724:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:49,724:INFO:Creating metrics dataframe
2022-12-01 03:26:49,749:INFO:Initializing Extra Trees Regressor
2022-12-01 03:26:49,749:INFO:Total runtime is 0.19658084313074747 minutes
2022-12-01 03:26:49,757:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:49,758:INFO:Initializing create_model()
2022-12-01 03:26:49,758:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b9880>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e09e6a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:49,758:INFO:Checking exceptions
2022-12-01 03:26:49,763:INFO:Importing libraries
2022-12-01 03:26:49,763:INFO:Copying training dataset
2022-12-01 03:26:49,769:INFO:Defining folds
2022-12-01 03:26:49,769:INFO:Declaring metric variables
2022-12-01 03:26:49,779:INFO:Importing untrained model
2022-12-01 03:26:49,787:INFO:Extra Trees Regressor Imported successfully
2022-12-01 03:26:49,800:INFO:Starting cross validation
2022-12-01 03:26:49,801:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:52,035:INFO:Calculating mean and std
2022-12-01 03:26:52,039:INFO:Creating metrics dataframe
2022-12-01 03:26:52,047:INFO:Uploading results into container
2022-12-01 03:26:52,047:INFO:Uploading model into container now
2022-12-01 03:26:52,048:INFO:master_model_container: 14
2022-12-01 03:26:52,048:INFO:display_container: 2
2022-12-01 03:26:52,049:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-12-01 03:26:52,049:INFO:create_model() successfully completed......................................
2022-12-01 03:26:52,187:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:52,187:INFO:Creating metrics dataframe
2022-12-01 03:26:52,208:INFO:Initializing AdaBoost Regressor
2022-12-01 03:26:52,209:INFO:Total runtime is 0.2375722567240397 minutes
2022-12-01 03:26:52,216:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:52,217:INFO:Initializing create_model()
2022-12-01 03:26:52,217:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b9880>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e09e6a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:52,217:INFO:Checking exceptions
2022-12-01 03:26:52,219:INFO:Importing libraries
2022-12-01 03:26:52,220:INFO:Copying training dataset
2022-12-01 03:26:52,227:INFO:Defining folds
2022-12-01 03:26:52,228:INFO:Declaring metric variables
2022-12-01 03:26:52,235:INFO:Importing untrained model
2022-12-01 03:26:52,244:INFO:AdaBoost Regressor Imported successfully
2022-12-01 03:26:52,261:INFO:Starting cross validation
2022-12-01 03:26:52,263:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:53,313:INFO:Calculating mean and std
2022-12-01 03:26:53,316:INFO:Creating metrics dataframe
2022-12-01 03:26:53,332:INFO:Uploading results into container
2022-12-01 03:26:53,332:INFO:Uploading model into container now
2022-12-01 03:26:53,333:INFO:master_model_container: 15
2022-12-01 03:26:53,333:INFO:display_container: 2
2022-12-01 03:26:53,334:INFO:AdaBoostRegressor(random_state=123)
2022-12-01 03:26:53,334:INFO:create_model() successfully completed......................................
2022-12-01 03:26:53,469:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:53,469:INFO:Creating metrics dataframe
2022-12-01 03:26:53,488:INFO:Initializing Gradient Boosting Regressor
2022-12-01 03:26:53,489:INFO:Total runtime is 0.25890755256017045 minutes
2022-12-01 03:26:53,498:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:53,498:INFO:Initializing create_model()
2022-12-01 03:26:53,499:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b9880>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e09e6a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:53,499:INFO:Checking exceptions
2022-12-01 03:26:53,502:INFO:Importing libraries
2022-12-01 03:26:53,502:INFO:Copying training dataset
2022-12-01 03:26:53,507:INFO:Defining folds
2022-12-01 03:26:53,507:INFO:Declaring metric variables
2022-12-01 03:26:53,518:INFO:Importing untrained model
2022-12-01 03:26:53,530:INFO:Gradient Boosting Regressor Imported successfully
2022-12-01 03:26:53,545:INFO:Starting cross validation
2022-12-01 03:26:53,551:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:55,352:INFO:Calculating mean and std
2022-12-01 03:26:55,357:INFO:Creating metrics dataframe
2022-12-01 03:26:55,364:INFO:Uploading results into container
2022-12-01 03:26:55,365:INFO:Uploading model into container now
2022-12-01 03:26:55,366:INFO:master_model_container: 16
2022-12-01 03:26:55,366:INFO:display_container: 2
2022-12-01 03:26:55,367:INFO:GradientBoostingRegressor(random_state=123)
2022-12-01 03:26:55,367:INFO:create_model() successfully completed......................................
2022-12-01 03:26:55,512:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:55,512:INFO:Creating metrics dataframe
2022-12-01 03:26:55,533:INFO:Initializing Light Gradient Boosting Machine
2022-12-01 03:26:55,534:INFO:Total runtime is 0.2929915428161621 minutes
2022-12-01 03:26:55,544:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:55,544:INFO:Initializing create_model()
2022-12-01 03:26:55,544:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b9880>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e09e6a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:55,545:INFO:Checking exceptions
2022-12-01 03:26:55,547:INFO:Importing libraries
2022-12-01 03:26:55,548:INFO:Copying training dataset
2022-12-01 03:26:55,554:INFO:Defining folds
2022-12-01 03:26:55,559:INFO:Declaring metric variables
2022-12-01 03:26:55,567:INFO:Importing untrained model
2022-12-01 03:26:55,580:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-01 03:26:55,594:INFO:Starting cross validation
2022-12-01 03:26:55,595:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:56,429:INFO:Calculating mean and std
2022-12-01 03:26:56,437:INFO:Creating metrics dataframe
2022-12-01 03:26:56,443:INFO:Uploading results into container
2022-12-01 03:26:56,447:INFO:Uploading model into container now
2022-12-01 03:26:56,448:INFO:master_model_container: 17
2022-12-01 03:26:56,448:INFO:display_container: 2
2022-12-01 03:26:56,449:INFO:LGBMRegressor(random_state=123)
2022-12-01 03:26:56,449:INFO:create_model() successfully completed......................................
2022-12-01 03:26:56,592:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:56,593:INFO:Creating metrics dataframe
2022-12-01 03:26:56,616:INFO:Initializing Dummy Regressor
2022-12-01 03:26:56,616:INFO:Total runtime is 0.3110343178113301 minutes
2022-12-01 03:26:56,625:INFO:SubProcess create_model() called ==================================
2022-12-01 03:26:56,625:INFO:Initializing create_model()
2022-12-01 03:26:56,625:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b9880>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495e09e6a0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:56,626:INFO:Checking exceptions
2022-12-01 03:26:56,629:INFO:Importing libraries
2022-12-01 03:26:56,629:INFO:Copying training dataset
2022-12-01 03:26:56,640:INFO:Defining folds
2022-12-01 03:26:56,641:INFO:Declaring metric variables
2022-12-01 03:26:56,650:INFO:Importing untrained model
2022-12-01 03:26:56,659:INFO:Dummy Regressor Imported successfully
2022-12-01 03:26:56,674:INFO:Starting cross validation
2022-12-01 03:26:56,677:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:26:56,937:INFO:Calculating mean and std
2022-12-01 03:26:56,940:INFO:Creating metrics dataframe
2022-12-01 03:26:56,951:INFO:Uploading results into container
2022-12-01 03:26:56,956:INFO:Uploading model into container now
2022-12-01 03:26:56,957:INFO:master_model_container: 18
2022-12-01 03:26:56,957:INFO:display_container: 2
2022-12-01 03:26:56,958:INFO:DummyRegressor()
2022-12-01 03:26:56,958:INFO:create_model() successfully completed......................................
2022-12-01 03:26:57,101:INFO:SubProcess create_model() end ==================================
2022-12-01 03:26:57,102:INFO:Creating metrics dataframe
2022-12-01 03:26:57,154:INFO:Initializing create_model()
2022-12-01 03:26:57,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f49619b9880>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:26:57,154:INFO:Checking exceptions
2022-12-01 03:26:57,161:INFO:Importing libraries
2022-12-01 03:26:57,161:INFO:Copying training dataset
2022-12-01 03:26:57,163:INFO:Defining folds
2022-12-01 03:26:57,164:INFO:Declaring metric variables
2022-12-01 03:26:57,164:INFO:Importing untrained model
2022-12-01 03:26:57,164:INFO:Declaring custom model
2022-12-01 03:26:57,165:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-01 03:26:57,166:INFO:Cross validation set to False
2022-12-01 03:26:57,167:INFO:Fitting Model
2022-12-01 03:26:57,177:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:26:57,180:INFO:OrthogonalMatchingPursuit()
2022-12-01 03:26:57,180:INFO:create_model() successfully completed......................................
2022-12-01 03:26:57,410:INFO:master_model_container: 18
2022-12-01 03:26:57,410:INFO:display_container: 2
2022-12-01 03:26:57,411:INFO:OrthogonalMatchingPursuit()
2022-12-01 03:26:57,411:INFO:compare_models() successfully completed......................................
2022-12-01 03:27:02,621:WARNING:<ipython-input-41-387158f279ba>:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q1'] = abs(data['PTS_QTR1_x'] - data['PTS_QTR1_y'])

2022-12-01 03:27:02,622:WARNING:<ipython-input-41-387158f279ba>:17: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q2'] = abs(data['PTS_QTR2_x'] - data['PTS_QTR2_y'])

2022-12-01 03:27:02,623:WARNING:<ipython-input-41-387158f279ba>:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q3'] = abs(data['PTS_QTR3_x'] - data['PTS_QTR3_y'])

2022-12-01 03:27:02,624:WARNING:<ipython-input-41-387158f279ba>:19: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['Points_Q4'] = abs(data['PTS_QTR4_x'] - data['PTS_QTR4_y'])

2022-12-01 03:27:02,625:WARNING:<ipython-input-41-387158f279ba>:21: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['PTS'] = abs(data['PTS_x'] - data['PTS_y'])

2022-12-01 03:27:02,626:WARNING:<ipython-input-41-387158f279ba>:22: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FG_PCT'] = abs(data['FG_PCT_x'] - data['FG_PCT_y'])

2022-12-01 03:27:02,626:WARNING:<ipython-input-41-387158f279ba>:23: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT'] = abs(data['FT_PCT_x'] - data['FT_PCT_y'])

2022-12-01 03:27:02,627:WARNING:<ipython-input-41-387158f279ba>:24: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['FT_PCT3'] = abs(data['FG3_PCT_x'] - data['FG3_PCT_y'])

2022-12-01 03:27:02,628:WARNING:<ipython-input-41-387158f279ba>:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['AST'] = abs(data['AST_x'] - data['AST_y'])

2022-12-01 03:27:02,629:WARNING:<ipython-input-41-387158f279ba>:26: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['REB'] = abs(data['REB_x'] - data['REB_y'])

2022-12-01 03:27:02,630:WARNING:<ipython-input-41-387158f279ba>:27: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  data['TO'] = abs(data['TOV_x'] - data['TOV_y'])

2022-12-01 03:27:02,635:INFO:PyCaret RegressionExperiment
2022-12-01 03:27:02,635:INFO:Logging name: FullData
2022-12-01 03:27:02,635:INFO:ML Usecase: MLUsecase.REGRESSION
2022-12-01 03:27:02,635:INFO:version 3.0.0.rc4
2022-12-01 03:27:02,635:INFO:Initializing setup()
2022-12-01 03:27:02,635:INFO:self.USI: c3f3
2022-12-01 03:27:02,635:INFO:self.variable_keys: {'fold_shuffle_param', 'y_test', 'pipeline', 'data', 'X', 'exp_id', 'master_model_container', '_available_plots', '_all_metrics', '_ml_usecase', 'log_plots_param', '_all_models', 'logging_param', 'idx', 'html_param', 'display_container', 'USI', 'target_param', 'fold_generator', '_gpu_n_jobs_param', 'n_jobs_param', 'transform_target_method_param', 'exp_name_log', 'X_test', 'variable_keys', 'gpu_param', 'memory', 'y_train', 'transform_target_param', 'y', 'X_train', '_all_models_internal', 'fold_groups_param', 'seed'}
2022-12-01 03:27:02,636:INFO:Checking environment
2022-12-01 03:27:02,636:INFO:python_version: 3.8.15
2022-12-01 03:27:02,636:INFO:python_build: ('default', 'Oct 12 2022 19:14:39')
2022-12-01 03:27:02,636:INFO:machine: x86_64
2022-12-01 03:27:02,636:INFO:platform: Linux-5.10.133+-x86_64-with-glibc2.27
2022-12-01 03:27:02,636:INFO:Memory: svmem(total=13616361472, available=11506393088, percent=15.5, used=2035318784, free=8759234560, active=1043460096, inactive=3480137728, buffers=431435776, cached=2390372352, shared=1245184, slab=239771648)
2022-12-01 03:27:02,637:INFO:Physical Core: 1
2022-12-01 03:27:02,637:INFO:Logical Core: 2
2022-12-01 03:27:02,637:INFO:Checking libraries
2022-12-01 03:27:02,637:INFO:System:
2022-12-01 03:27:02,637:INFO:    python: 3.8.15 (default, Oct 12 2022, 19:14:39)  [GCC 7.5.0]
2022-12-01 03:27:02,638:INFO:executable: /usr/bin/python3
2022-12-01 03:27:02,638:INFO:   machine: Linux-5.10.133+-x86_64-with-glibc2.27
2022-12-01 03:27:02,638:INFO:PyCaret required dependencies:
2022-12-01 03:27:02,638:INFO:                 pip: 21.1.3
2022-12-01 03:27:02,638:INFO:          setuptools: 57.4.0
2022-12-01 03:27:02,638:INFO:             pycaret: 3.0.0rc4
2022-12-01 03:27:02,638:INFO:             IPython: 7.9.0
2022-12-01 03:27:02,639:INFO:          ipywidgets: 7.7.1
2022-12-01 03:27:02,639:INFO:                tqdm: 4.64.1
2022-12-01 03:27:02,639:INFO:               numpy: 1.21.6
2022-12-01 03:27:02,639:INFO:              pandas: 1.3.5
2022-12-01 03:27:02,639:INFO:              jinja2: 3.0.0
2022-12-01 03:27:02,639:INFO:               scipy: 1.7.3
2022-12-01 03:27:02,639:INFO:              joblib: 1.2.0
2022-12-01 03:27:02,640:INFO:             sklearn: 1.0.2
2022-12-01 03:27:02,640:INFO:                pyod: 1.0.6
2022-12-01 03:27:02,640:INFO:            imblearn: 0.8.1
2022-12-01 03:27:02,640:INFO:   category_encoders: 2.5.1.post0
2022-12-01 03:27:02,640:INFO:            lightgbm: 3.3.3
2022-12-01 03:27:02,640:INFO:               numba: 0.55.2
2022-12-01 03:27:02,640:INFO:            requests: 2.28.1
2022-12-01 03:27:02,641:INFO:          matplotlib: 3.6.2
2022-12-01 03:27:02,641:INFO:          scikitplot: 0.3.7
2022-12-01 03:27:02,641:INFO:         yellowbrick: 1.5
2022-12-01 03:27:02,641:INFO:              plotly: 5.5.0
2022-12-01 03:27:02,641:INFO:             kaleido: 0.2.1
2022-12-01 03:27:02,641:INFO:         statsmodels: 0.12.2
2022-12-01 03:27:02,641:INFO:              sktime: 0.13.4
2022-12-01 03:27:02,642:INFO:               tbats: 1.1.1
2022-12-01 03:27:02,642:INFO:            pmdarima: 1.8.5
2022-12-01 03:27:02,642:INFO:              psutil: 5.9.4
2022-12-01 03:27:02,642:INFO:PyCaret optional dependencies:
2022-12-01 03:27:02,642:INFO:                shap: Not installed
2022-12-01 03:27:02,642:INFO:           interpret: Not installed
2022-12-01 03:27:02,642:INFO:                umap: Not installed
2022-12-01 03:27:02,643:INFO:    pandas_profiling: 1.4.1
2022-12-01 03:27:02,643:INFO:  explainerdashboard: Not installed
2022-12-01 03:27:02,643:INFO:             autoviz: Not installed
2022-12-01 03:27:02,643:INFO:           fairlearn: Not installed
2022-12-01 03:27:02,643:INFO:             xgboost: 0.90
2022-12-01 03:27:02,643:INFO:            catboost: Not installed
2022-12-01 03:27:02,643:INFO:              kmodes: Not installed
2022-12-01 03:27:02,644:INFO:             mlxtend: 0.14.0
2022-12-01 03:27:02,644:INFO:       statsforecast: Not installed
2022-12-01 03:27:02,644:INFO:        tune_sklearn: Not installed
2022-12-01 03:27:02,644:INFO:                 ray: Not installed
2022-12-01 03:27:02,644:INFO:            hyperopt: 0.1.2
2022-12-01 03:27:02,644:INFO:              optuna: Not installed
2022-12-01 03:27:02,644:INFO:               skopt: Not installed
2022-12-01 03:27:02,645:INFO:              mlflow: Not installed
2022-12-01 03:27:02,645:INFO:              gradio: Not installed
2022-12-01 03:27:02,645:INFO:             fastapi: Not installed
2022-12-01 03:27:02,645:INFO:             uvicorn: Not installed
2022-12-01 03:27:02,645:INFO:              m2cgen: Not installed
2022-12-01 03:27:02,645:INFO:           evidently: Not installed
2022-12-01 03:27:02,645:INFO:                nltk: 3.7
2022-12-01 03:27:02,645:INFO:            pyLDAvis: Not installed
2022-12-01 03:27:02,646:INFO:              gensim: 3.6.0
2022-12-01 03:27:02,646:INFO:               spacy: 3.4.3
2022-12-01 03:27:02,646:INFO:           wordcloud: 1.8.2.2
2022-12-01 03:27:02,646:INFO:            textblob: 0.15.3
2022-12-01 03:27:02,646:INFO:               fugue: Not installed
2022-12-01 03:27:02,646:INFO:           streamlit: Not installed
2022-12-01 03:27:02,647:INFO:             prophet: 1.1.1
2022-12-01 03:27:02,647:INFO:None
2022-12-01 03:27:02,647:INFO:Set up data.
2022-12-01 03:27:02,653:INFO:Set up train/test split.
2022-12-01 03:27:02,657:INFO:Set up index.
2022-12-01 03:27:02,657:INFO:Set up folding strategy.
2022-12-01 03:27:02,658:INFO:Assigning column types.
2022-12-01 03:27:02,663:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2022-12-01 03:27:02,664:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-01 03:27:02,669:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 03:27:02,674:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:27:02,737:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:27:02,787:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:27:02,788:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:27:02,788:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:27:02,789:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:27:02,789:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2022-12-01 03:27:02,794:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 03:27:02,800:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:27:02,864:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:27:02,917:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:27:02,918:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:27:02,918:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:27:02,919:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:27:02,920:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2022-12-01 03:27:02,926:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 03:27:02,931:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:27:03,005:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:27:03,059:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:27:03,060:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:27:03,060:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:27:03,061:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:27:03,066:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2022-12-01 03:27:03,071:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:27:03,136:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:27:03,185:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:27:03,186:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:27:03,187:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:27:03,188:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:27:03,188:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2022-12-01 03:27:03,198:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:27:03,266:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:27:03,314:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:27:03,315:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:27:03,315:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:27:03,315:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:27:03,326:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2022-12-01 03:27:03,388:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:27:03,438:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:27:03,439:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:27:03,440:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:27:03,440:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:27:03,441:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2022-12-01 03:27:03,515:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:27:03,564:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:27:03,570:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:27:03,570:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:27:03,571:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:27:03,643:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:27:03,694:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2022-12-01 03:27:03,695:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:27:03,695:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:27:03,696:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:27:03,696:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2022-12-01 03:27:03,770:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:27:03,823:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:27:03,824:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:27:03,824:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:27:03,903:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2022-12-01 03:27:03,957:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:27:03,957:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:27:03,958:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:27:03,958:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2022-12-01 03:27:04,091:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:27:04,091:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:27:04,091:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:27:04,214:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:27:04,214:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:27:04,215:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:27:04,216:INFO:Preparing preprocessing pipeline...
2022-12-01 03:27:04,217:INFO:Set up simple imputation.
2022-12-01 03:27:04,217:INFO:Set up variance threshold.
2022-12-01 03:27:04,229:INFO:Finished creating preprocessing pipeline.
2022-12-01 03:27:04,235:INFO:Pipeline: Pipeline(memory=Memory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Points_Q1', 'Points_Q2',
                                             'Points_Q3', 'Points_Q4', 'PTS',
                                             'FG_PCT', 'FT_PCT', 'FT_PCT3',
                                             'AST', 'REB', 'TO',
                                             'Open_Line_ML_x'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(fill_value='constant',
                                                              strategy='constant'))),
                ('low_variance',
                 TransformerWrapper(exclude=[],
                                    transformer=VarianceThreshold(threshold=0)))])
2022-12-01 03:27:04,235:INFO:Creating final display dataframe.
2022-12-01 03:27:04,318:INFO:Setup display_container:                Description        Value
0               Session id          123
1                   Target  ABS_Line_ML
2              Target type   Regression
3               Data shape   (1229, 13)
4         Train data shape    (860, 13)
5          Test data shape    (369, 13)
6         Numeric features           12
7               Preprocess         True
8          Imputation type       simple
9       Numeric imputation         mean
10  Categorical imputation     constant
11  Low variance threshold            0
12          Fold Generator        KFold
13             Fold Number           10
14                CPU Jobs           -1
15                 Use GPU        False
16          Log Experiment        False
17         Experiment Name     FullData
18                     USI         c3f3
2022-12-01 03:27:04,462:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:27:04,462:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:27:04,463:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:27:04,588:INFO:Soft dependency imported: xgboost: 0.90
2022-12-01 03:27:04,588:WARNING:Wrong xgboost version. Expected xgboost>=1.1.0, got xgboost==0.90
2022-12-01 03:27:04,589:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2022-12-01 03:27:04,595:INFO:setup() successfully completed in 1.96s...............
2022-12-01 03:27:04,596:INFO:Initializing compare_models()
2022-12-01 03:27:04,596:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961f5fe80>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f4961f5fe80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2022-12-01 03:27:04,596:INFO:Checking exceptions
2022-12-01 03:27:04,598:INFO:Preparing display monitor
2022-12-01 03:27:04,684:INFO:Initializing Linear Regression
2022-12-01 03:27:04,684:INFO:Total runtime is 6.850560506184896e-06 minutes
2022-12-01 03:27:04,694:INFO:SubProcess create_model() called ==================================
2022-12-01 03:27:04,695:INFO:Initializing create_model()
2022-12-01 03:27:04,696:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961f5fe80>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495dfddee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:27:04,696:INFO:Checking exceptions
2022-12-01 03:27:04,699:INFO:Importing libraries
2022-12-01 03:27:04,699:INFO:Copying training dataset
2022-12-01 03:27:04,703:INFO:Defining folds
2022-12-01 03:27:04,703:INFO:Declaring metric variables
2022-12-01 03:27:04,711:INFO:Importing untrained model
2022-12-01 03:27:04,726:INFO:Linear Regression Imported successfully
2022-12-01 03:27:04,742:INFO:Starting cross validation
2022-12-01 03:27:04,749:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:27:05,026:INFO:Calculating mean and std
2022-12-01 03:27:05,027:INFO:Creating metrics dataframe
2022-12-01 03:27:05,031:INFO:Uploading results into container
2022-12-01 03:27:05,032:INFO:Uploading model into container now
2022-12-01 03:27:05,032:INFO:master_model_container: 1
2022-12-01 03:27:05,033:INFO:display_container: 2
2022-12-01 03:27:05,033:INFO:LinearRegression(n_jobs=-1)
2022-12-01 03:27:05,033:INFO:create_model() successfully completed......................................
2022-12-01 03:27:05,181:INFO:SubProcess create_model() end ==================================
2022-12-01 03:27:05,182:INFO:Creating metrics dataframe
2022-12-01 03:27:05,203:INFO:Initializing Lasso Regression
2022-12-01 03:27:05,203:INFO:Total runtime is 0.008650080362955729 minutes
2022-12-01 03:27:05,213:INFO:SubProcess create_model() called ==================================
2022-12-01 03:27:05,215:INFO:Initializing create_model()
2022-12-01 03:27:05,215:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961f5fe80>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495dfddee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:27:05,215:INFO:Checking exceptions
2022-12-01 03:27:05,218:INFO:Importing libraries
2022-12-01 03:27:05,218:INFO:Copying training dataset
2022-12-01 03:27:05,222:INFO:Defining folds
2022-12-01 03:27:05,222:INFO:Declaring metric variables
2022-12-01 03:27:05,227:INFO:Importing untrained model
2022-12-01 03:27:05,242:INFO:Lasso Regression Imported successfully
2022-12-01 03:27:05,258:INFO:Starting cross validation
2022-12-01 03:27:05,262:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:27:05,565:INFO:Calculating mean and std
2022-12-01 03:27:05,565:INFO:Creating metrics dataframe
2022-12-01 03:27:05,570:INFO:Uploading results into container
2022-12-01 03:27:05,570:INFO:Uploading model into container now
2022-12-01 03:27:05,571:INFO:master_model_container: 2
2022-12-01 03:27:05,571:INFO:display_container: 2
2022-12-01 03:27:05,571:INFO:Lasso(random_state=123)
2022-12-01 03:27:05,572:INFO:create_model() successfully completed......................................
2022-12-01 03:27:05,718:INFO:SubProcess create_model() end ==================================
2022-12-01 03:27:05,718:INFO:Creating metrics dataframe
2022-12-01 03:27:05,735:INFO:Initializing Ridge Regression
2022-12-01 03:27:05,736:INFO:Total runtime is 0.017536457379659018 minutes
2022-12-01 03:27:05,747:INFO:SubProcess create_model() called ==================================
2022-12-01 03:27:05,748:INFO:Initializing create_model()
2022-12-01 03:27:05,748:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961f5fe80>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495dfddee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:27:05,748:INFO:Checking exceptions
2022-12-01 03:27:05,751:INFO:Importing libraries
2022-12-01 03:27:05,751:INFO:Copying training dataset
2022-12-01 03:27:05,758:INFO:Defining folds
2022-12-01 03:27:05,762:INFO:Declaring metric variables
2022-12-01 03:27:05,771:INFO:Importing untrained model
2022-12-01 03:27:05,779:INFO:Ridge Regression Imported successfully
2022-12-01 03:27:05,794:INFO:Starting cross validation
2022-12-01 03:27:05,796:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:27:06,077:INFO:Calculating mean and std
2022-12-01 03:27:06,080:INFO:Creating metrics dataframe
2022-12-01 03:27:06,095:INFO:Uploading results into container
2022-12-01 03:27:06,096:INFO:Uploading model into container now
2022-12-01 03:27:06,097:INFO:master_model_container: 3
2022-12-01 03:27:06,097:INFO:display_container: 2
2022-12-01 03:27:06,097:INFO:Ridge(random_state=123)
2022-12-01 03:27:06,098:INFO:create_model() successfully completed......................................
2022-12-01 03:27:06,240:INFO:SubProcess create_model() end ==================================
2022-12-01 03:27:06,240:INFO:Creating metrics dataframe
2022-12-01 03:27:06,258:INFO:Initializing Elastic Net
2022-12-01 03:27:06,258:INFO:Total runtime is 0.02624088923136393 minutes
2022-12-01 03:27:06,266:INFO:SubProcess create_model() called ==================================
2022-12-01 03:27:06,267:INFO:Initializing create_model()
2022-12-01 03:27:06,267:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961f5fe80>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495dfddee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:27:06,268:INFO:Checking exceptions
2022-12-01 03:27:06,270:INFO:Importing libraries
2022-12-01 03:27:06,271:INFO:Copying training dataset
2022-12-01 03:27:06,276:INFO:Defining folds
2022-12-01 03:27:06,277:INFO:Declaring metric variables
2022-12-01 03:27:06,287:INFO:Importing untrained model
2022-12-01 03:27:06,297:INFO:Elastic Net Imported successfully
2022-12-01 03:27:06,316:INFO:Starting cross validation
2022-12-01 03:27:06,319:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:27:06,586:INFO:Calculating mean and std
2022-12-01 03:27:06,588:INFO:Creating metrics dataframe
2022-12-01 03:27:06,595:INFO:Uploading results into container
2022-12-01 03:27:06,596:INFO:Uploading model into container now
2022-12-01 03:27:06,597:INFO:master_model_container: 4
2022-12-01 03:27:06,598:INFO:display_container: 2
2022-12-01 03:27:06,599:INFO:ElasticNet(random_state=123)
2022-12-01 03:27:06,599:INFO:create_model() successfully completed......................................
2022-12-01 03:27:06,736:INFO:SubProcess create_model() end ==================================
2022-12-01 03:27:06,736:INFO:Creating metrics dataframe
2022-12-01 03:27:06,754:INFO:Initializing Least Angle Regression
2022-12-01 03:27:06,755:INFO:Total runtime is 0.03450928131739298 minutes
2022-12-01 03:27:06,763:INFO:SubProcess create_model() called ==================================
2022-12-01 03:27:06,763:INFO:Initializing create_model()
2022-12-01 03:27:06,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961f5fe80>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495dfddee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:27:06,764:INFO:Checking exceptions
2022-12-01 03:27:06,767:INFO:Importing libraries
2022-12-01 03:27:06,767:INFO:Copying training dataset
2022-12-01 03:27:06,773:INFO:Defining folds
2022-12-01 03:27:06,774:INFO:Declaring metric variables
2022-12-01 03:27:06,786:INFO:Importing untrained model
2022-12-01 03:27:06,794:INFO:Least Angle Regression Imported successfully
2022-12-01 03:27:06,811:INFO:Starting cross validation
2022-12-01 03:27:06,814:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:27:06,852:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:27:06,874:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:27:06,917:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:27:06,929:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:27:06,970:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:27:06,997:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:27:07,007:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:27:07,046:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:27:07,054:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:27:07,090:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:27:07,103:INFO:Calculating mean and std
2022-12-01 03:27:07,106:INFO:Creating metrics dataframe
2022-12-01 03:27:07,114:INFO:Uploading results into container
2022-12-01 03:27:07,115:INFO:Uploading model into container now
2022-12-01 03:27:07,116:INFO:master_model_container: 5
2022-12-01 03:27:07,117:INFO:display_container: 2
2022-12-01 03:27:07,118:INFO:Lars(random_state=123)
2022-12-01 03:27:07,118:INFO:create_model() successfully completed......................................
2022-12-01 03:27:07,261:INFO:SubProcess create_model() end ==================================
2022-12-01 03:27:07,261:INFO:Creating metrics dataframe
2022-12-01 03:27:07,279:INFO:Initializing Lasso Least Angle Regression
2022-12-01 03:27:07,280:INFO:Total runtime is 0.043261297543843585 minutes
2022-12-01 03:27:07,291:INFO:SubProcess create_model() called ==================================
2022-12-01 03:27:07,292:INFO:Initializing create_model()
2022-12-01 03:27:07,292:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961f5fe80>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495dfddee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:27:07,293:INFO:Checking exceptions
2022-12-01 03:27:07,296:INFO:Importing libraries
2022-12-01 03:27:07,296:INFO:Copying training dataset
2022-12-01 03:27:07,303:INFO:Defining folds
2022-12-01 03:27:07,304:INFO:Declaring metric variables
2022-12-01 03:27:07,315:INFO:Importing untrained model
2022-12-01 03:27:07,325:INFO:Lasso Least Angle Regression Imported successfully
2022-12-01 03:27:07,340:INFO:Starting cross validation
2022-12-01 03:27:07,345:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:27:07,380:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:27:07,404:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:27:07,433:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:27:07,456:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:27:07,477:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:27:07,512:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:27:07,537:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:27:07,548:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:27:07,574:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:27:07,586:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:27:07,599:INFO:Calculating mean and std
2022-12-01 03:27:07,601:INFO:Creating metrics dataframe
2022-12-01 03:27:07,615:INFO:Uploading results into container
2022-12-01 03:27:07,615:INFO:Uploading model into container now
2022-12-01 03:27:07,616:INFO:master_model_container: 6
2022-12-01 03:27:07,616:INFO:display_container: 2
2022-12-01 03:27:07,617:INFO:LassoLars(random_state=123)
2022-12-01 03:27:07,617:INFO:create_model() successfully completed......................................
2022-12-01 03:27:07,752:INFO:SubProcess create_model() end ==================================
2022-12-01 03:27:07,752:INFO:Creating metrics dataframe
2022-12-01 03:27:07,772:INFO:Initializing Orthogonal Matching Pursuit
2022-12-01 03:27:07,773:INFO:Total runtime is 0.05148998498916626 minutes
2022-12-01 03:27:07,781:INFO:SubProcess create_model() called ==================================
2022-12-01 03:27:07,782:INFO:Initializing create_model()
2022-12-01 03:27:07,782:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961f5fe80>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495dfddee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:27:07,782:INFO:Checking exceptions
2022-12-01 03:27:07,785:INFO:Importing libraries
2022-12-01 03:27:07,785:INFO:Copying training dataset
2022-12-01 03:27:07,791:INFO:Defining folds
2022-12-01 03:27:07,797:INFO:Declaring metric variables
2022-12-01 03:27:07,805:INFO:Importing untrained model
2022-12-01 03:27:07,813:INFO:Orthogonal Matching Pursuit Imported successfully
2022-12-01 03:27:07,830:INFO:Starting cross validation
2022-12-01 03:27:07,833:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:27:07,868:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:27:07,901:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:27:07,926:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:27:07,950:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:27:07,980:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:27:08,005:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:27:08,013:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:27:08,051:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:27:08,057:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:27:08,089:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2022-12-01 03:27:08,108:INFO:Calculating mean and std
2022-12-01 03:27:08,110:INFO:Creating metrics dataframe
2022-12-01 03:27:08,121:INFO:Uploading results into container
2022-12-01 03:27:08,124:INFO:Uploading model into container now
2022-12-01 03:27:08,125:INFO:master_model_container: 7
2022-12-01 03:27:08,125:INFO:display_container: 2
2022-12-01 03:27:08,125:INFO:OrthogonalMatchingPursuit()
2022-12-01 03:27:08,126:INFO:create_model() successfully completed......................................
2022-12-01 03:27:08,269:INFO:SubProcess create_model() end ==================================
2022-12-01 03:27:08,269:INFO:Creating metrics dataframe
2022-12-01 03:27:08,288:INFO:Initializing Bayesian Ridge
2022-12-01 03:27:08,289:INFO:Total runtime is 0.06007736921310425 minutes
2022-12-01 03:27:08,299:INFO:SubProcess create_model() called ==================================
2022-12-01 03:27:08,300:INFO:Initializing create_model()
2022-12-01 03:27:08,301:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961f5fe80>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495dfddee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:27:08,301:INFO:Checking exceptions
2022-12-01 03:27:08,304:INFO:Importing libraries
2022-12-01 03:27:08,304:INFO:Copying training dataset
2022-12-01 03:27:08,310:INFO:Defining folds
2022-12-01 03:27:08,311:INFO:Declaring metric variables
2022-12-01 03:27:08,320:INFO:Importing untrained model
2022-12-01 03:27:08,330:INFO:Bayesian Ridge Imported successfully
2022-12-01 03:27:08,349:INFO:Starting cross validation
2022-12-01 03:27:08,350:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:27:08,631:INFO:Calculating mean and std
2022-12-01 03:27:08,634:INFO:Creating metrics dataframe
2022-12-01 03:27:08,647:INFO:Uploading results into container
2022-12-01 03:27:08,650:INFO:Uploading model into container now
2022-12-01 03:27:08,651:INFO:master_model_container: 8
2022-12-01 03:27:08,651:INFO:display_container: 2
2022-12-01 03:27:08,651:INFO:BayesianRidge()
2022-12-01 03:27:08,651:INFO:create_model() successfully completed......................................
2022-12-01 03:27:08,790:INFO:SubProcess create_model() end ==================================
2022-12-01 03:27:08,790:INFO:Creating metrics dataframe
2022-12-01 03:27:08,809:INFO:Initializing Passive Aggressive Regressor
2022-12-01 03:27:08,810:INFO:Total runtime is 0.06876136461893717 minutes
2022-12-01 03:27:08,818:INFO:SubProcess create_model() called ==================================
2022-12-01 03:27:08,818:INFO:Initializing create_model()
2022-12-01 03:27:08,819:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961f5fe80>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495dfddee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:27:08,819:INFO:Checking exceptions
2022-12-01 03:27:08,822:INFO:Importing libraries
2022-12-01 03:27:08,822:INFO:Copying training dataset
2022-12-01 03:27:08,829:INFO:Defining folds
2022-12-01 03:27:08,830:INFO:Declaring metric variables
2022-12-01 03:27:08,838:INFO:Importing untrained model
2022-12-01 03:27:08,846:INFO:Passive Aggressive Regressor Imported successfully
2022-12-01 03:27:08,861:INFO:Starting cross validation
2022-12-01 03:27:08,862:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:27:09,149:INFO:Calculating mean and std
2022-12-01 03:27:09,152:INFO:Creating metrics dataframe
2022-12-01 03:27:09,164:INFO:Uploading results into container
2022-12-01 03:27:09,165:INFO:Uploading model into container now
2022-12-01 03:27:09,165:INFO:master_model_container: 9
2022-12-01 03:27:09,166:INFO:display_container: 2
2022-12-01 03:27:09,166:INFO:PassiveAggressiveRegressor(random_state=123)
2022-12-01 03:27:09,166:INFO:create_model() successfully completed......................................
2022-12-01 03:27:09,306:INFO:SubProcess create_model() end ==================================
2022-12-01 03:27:09,307:INFO:Creating metrics dataframe
2022-12-01 03:27:09,326:INFO:Initializing Huber Regressor
2022-12-01 03:27:09,327:INFO:Total runtime is 0.0773760437965393 minutes
2022-12-01 03:27:09,335:INFO:SubProcess create_model() called ==================================
2022-12-01 03:27:09,336:INFO:Initializing create_model()
2022-12-01 03:27:09,336:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961f5fe80>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495dfddee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:27:09,336:INFO:Checking exceptions
2022-12-01 03:27:09,338:INFO:Importing libraries
2022-12-01 03:27:09,339:INFO:Copying training dataset
2022-12-01 03:27:09,350:INFO:Defining folds
2022-12-01 03:27:09,350:INFO:Declaring metric variables
2022-12-01 03:27:09,362:INFO:Importing untrained model
2022-12-01 03:27:09,370:INFO:Huber Regressor Imported successfully
2022-12-01 03:27:09,388:INFO:Starting cross validation
2022-12-01 03:27:09,389:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:27:09,486:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:27:09,529:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:27:09,603:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:27:09,636:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:27:09,713:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:27:09,758:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:27:09,819:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:27:09,851:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:27:09,923:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:27:09,948:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2022-12-01 03:27:09,959:INFO:Calculating mean and std
2022-12-01 03:27:09,961:INFO:Creating metrics dataframe
2022-12-01 03:27:09,971:INFO:Uploading results into container
2022-12-01 03:27:09,975:INFO:Uploading model into container now
2022-12-01 03:27:09,976:INFO:master_model_container: 10
2022-12-01 03:27:09,976:INFO:display_container: 2
2022-12-01 03:27:09,977:INFO:HuberRegressor()
2022-12-01 03:27:09,977:INFO:create_model() successfully completed......................................
2022-12-01 03:27:10,118:INFO:SubProcess create_model() end ==================================
2022-12-01 03:27:10,119:INFO:Creating metrics dataframe
2022-12-01 03:27:10,141:INFO:Initializing K Neighbors Regressor
2022-12-01 03:27:10,144:INFO:Total runtime is 0.09100287357966104 minutes
2022-12-01 03:27:10,154:INFO:SubProcess create_model() called ==================================
2022-12-01 03:27:10,155:INFO:Initializing create_model()
2022-12-01 03:27:10,155:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961f5fe80>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495dfddee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:27:10,155:INFO:Checking exceptions
2022-12-01 03:27:10,157:INFO:Importing libraries
2022-12-01 03:27:10,158:INFO:Copying training dataset
2022-12-01 03:27:10,163:INFO:Defining folds
2022-12-01 03:27:10,163:INFO:Declaring metric variables
2022-12-01 03:27:10,172:INFO:Importing untrained model
2022-12-01 03:27:10,182:INFO:K Neighbors Regressor Imported successfully
2022-12-01 03:27:10,197:INFO:Starting cross validation
2022-12-01 03:27:10,202:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:27:10,497:INFO:Calculating mean and std
2022-12-01 03:27:10,499:INFO:Creating metrics dataframe
2022-12-01 03:27:10,514:INFO:Uploading results into container
2022-12-01 03:27:10,515:INFO:Uploading model into container now
2022-12-01 03:27:10,516:INFO:master_model_container: 11
2022-12-01 03:27:10,516:INFO:display_container: 2
2022-12-01 03:27:10,516:INFO:KNeighborsRegressor(n_jobs=-1)
2022-12-01 03:27:10,517:INFO:create_model() successfully completed......................................
2022-12-01 03:27:10,654:INFO:SubProcess create_model() end ==================================
2022-12-01 03:27:10,655:INFO:Creating metrics dataframe
2022-12-01 03:27:10,673:INFO:Initializing Decision Tree Regressor
2022-12-01 03:27:10,674:INFO:Total runtime is 0.09984123309453327 minutes
2022-12-01 03:27:10,685:INFO:SubProcess create_model() called ==================================
2022-12-01 03:27:10,686:INFO:Initializing create_model()
2022-12-01 03:27:10,686:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961f5fe80>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495dfddee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:27:10,687:INFO:Checking exceptions
2022-12-01 03:27:10,689:INFO:Importing libraries
2022-12-01 03:27:10,690:INFO:Copying training dataset
2022-12-01 03:27:10,695:INFO:Defining folds
2022-12-01 03:27:10,696:INFO:Declaring metric variables
2022-12-01 03:27:10,708:INFO:Importing untrained model
2022-12-01 03:27:10,718:INFO:Decision Tree Regressor Imported successfully
2022-12-01 03:27:10,736:INFO:Starting cross validation
2022-12-01 03:27:10,738:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:27:11,061:INFO:Calculating mean and std
2022-12-01 03:27:11,063:INFO:Creating metrics dataframe
2022-12-01 03:27:11,073:INFO:Uploading results into container
2022-12-01 03:27:11,074:INFO:Uploading model into container now
2022-12-01 03:27:11,075:INFO:master_model_container: 12
2022-12-01 03:27:11,075:INFO:display_container: 2
2022-12-01 03:27:11,076:INFO:DecisionTreeRegressor(random_state=123)
2022-12-01 03:27:11,076:INFO:create_model() successfully completed......................................
2022-12-01 03:27:11,221:INFO:SubProcess create_model() end ==================================
2022-12-01 03:27:11,221:INFO:Creating metrics dataframe
2022-12-01 03:27:11,242:INFO:Initializing Random Forest Regressor
2022-12-01 03:27:11,242:INFO:Total runtime is 0.1093001087506612 minutes
2022-12-01 03:27:11,250:INFO:SubProcess create_model() called ==================================
2022-12-01 03:27:11,251:INFO:Initializing create_model()
2022-12-01 03:27:11,251:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961f5fe80>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495dfddee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:27:11,251:INFO:Checking exceptions
2022-12-01 03:27:11,254:INFO:Importing libraries
2022-12-01 03:27:11,254:INFO:Copying training dataset
2022-12-01 03:27:11,261:INFO:Defining folds
2022-12-01 03:27:11,261:INFO:Declaring metric variables
2022-12-01 03:27:11,269:INFO:Importing untrained model
2022-12-01 03:27:11,277:INFO:Random Forest Regressor Imported successfully
2022-12-01 03:27:11,291:INFO:Starting cross validation
2022-12-01 03:27:11,293:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:27:17,125:INFO:Calculating mean and std
2022-12-01 03:27:17,129:INFO:Creating metrics dataframe
2022-12-01 03:27:17,138:INFO:Uploading results into container
2022-12-01 03:27:17,139:INFO:Uploading model into container now
2022-12-01 03:27:17,140:INFO:master_model_container: 13
2022-12-01 03:27:17,140:INFO:display_container: 2
2022-12-01 03:27:17,141:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2022-12-01 03:27:17,141:INFO:create_model() successfully completed......................................
2022-12-01 03:27:17,285:INFO:SubProcess create_model() end ==================================
2022-12-01 03:27:17,286:INFO:Creating metrics dataframe
2022-12-01 03:27:17,305:INFO:Initializing Extra Trees Regressor
2022-12-01 03:27:17,308:INFO:Total runtime is 0.21040045022964476 minutes
2022-12-01 03:27:17,316:INFO:SubProcess create_model() called ==================================
2022-12-01 03:27:17,317:INFO:Initializing create_model()
2022-12-01 03:27:17,318:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961f5fe80>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495dfddee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:27:17,318:INFO:Checking exceptions
2022-12-01 03:27:17,321:INFO:Importing libraries
2022-12-01 03:27:17,322:INFO:Copying training dataset
2022-12-01 03:27:17,332:INFO:Defining folds
2022-12-01 03:27:17,334:INFO:Declaring metric variables
2022-12-01 03:27:17,345:INFO:Importing untrained model
2022-12-01 03:27:17,356:INFO:Extra Trees Regressor Imported successfully
2022-12-01 03:27:17,372:INFO:Starting cross validation
2022-12-01 03:27:17,374:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:27:20,143:INFO:Calculating mean and std
2022-12-01 03:27:20,150:INFO:Creating metrics dataframe
2022-12-01 03:27:20,158:INFO:Uploading results into container
2022-12-01 03:27:20,159:INFO:Uploading model into container now
2022-12-01 03:27:20,160:INFO:master_model_container: 14
2022-12-01 03:27:20,160:INFO:display_container: 2
2022-12-01 03:27:20,160:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2022-12-01 03:27:20,160:INFO:create_model() successfully completed......................................
2022-12-01 03:27:20,302:INFO:SubProcess create_model() end ==================================
2022-12-01 03:27:20,303:INFO:Creating metrics dataframe
2022-12-01 03:27:20,324:INFO:Initializing AdaBoost Regressor
2022-12-01 03:27:20,325:INFO:Total runtime is 0.2606798529624939 minutes
2022-12-01 03:27:20,334:INFO:SubProcess create_model() called ==================================
2022-12-01 03:27:20,335:INFO:Initializing create_model()
2022-12-01 03:27:20,335:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961f5fe80>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495dfddee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:27:20,335:INFO:Checking exceptions
2022-12-01 03:27:20,338:INFO:Importing libraries
2022-12-01 03:27:20,338:INFO:Copying training dataset
2022-12-01 03:27:20,345:INFO:Defining folds
2022-12-01 03:27:20,345:INFO:Declaring metric variables
2022-12-01 03:27:20,352:INFO:Importing untrained model
2022-12-01 03:27:20,359:INFO:AdaBoost Regressor Imported successfully
2022-12-01 03:27:20,373:INFO:Starting cross validation
2022-12-01 03:27:20,375:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:27:21,321:INFO:Calculating mean and std
2022-12-01 03:27:21,323:INFO:Creating metrics dataframe
2022-12-01 03:27:21,334:INFO:Uploading results into container
2022-12-01 03:27:21,336:INFO:Uploading model into container now
2022-12-01 03:27:21,337:INFO:master_model_container: 15
2022-12-01 03:27:21,337:INFO:display_container: 2
2022-12-01 03:27:21,338:INFO:AdaBoostRegressor(random_state=123)
2022-12-01 03:27:21,338:INFO:create_model() successfully completed......................................
2022-12-01 03:27:21,481:INFO:SubProcess create_model() end ==================================
2022-12-01 03:27:21,481:INFO:Creating metrics dataframe
2022-12-01 03:27:21,501:INFO:Initializing Gradient Boosting Regressor
2022-12-01 03:27:21,502:INFO:Total runtime is 0.28029985427856446 minutes
2022-12-01 03:27:21,513:INFO:SubProcess create_model() called ==================================
2022-12-01 03:27:21,514:INFO:Initializing create_model()
2022-12-01 03:27:21,514:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961f5fe80>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495dfddee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:27:21,514:INFO:Checking exceptions
2022-12-01 03:27:21,517:INFO:Importing libraries
2022-12-01 03:27:21,517:INFO:Copying training dataset
2022-12-01 03:27:21,522:INFO:Defining folds
2022-12-01 03:27:21,523:INFO:Declaring metric variables
2022-12-01 03:27:21,532:INFO:Importing untrained model
2022-12-01 03:27:21,541:INFO:Gradient Boosting Regressor Imported successfully
2022-12-01 03:27:21,558:INFO:Starting cross validation
2022-12-01 03:27:21,560:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:27:23,972:INFO:Calculating mean and std
2022-12-01 03:27:23,976:INFO:Creating metrics dataframe
2022-12-01 03:27:23,990:INFO:Uploading results into container
2022-12-01 03:27:23,991:INFO:Uploading model into container now
2022-12-01 03:27:23,991:INFO:master_model_container: 16
2022-12-01 03:27:23,991:INFO:display_container: 2
2022-12-01 03:27:23,992:INFO:GradientBoostingRegressor(random_state=123)
2022-12-01 03:27:23,992:INFO:create_model() successfully completed......................................
2022-12-01 03:27:24,130:INFO:SubProcess create_model() end ==================================
2022-12-01 03:27:24,130:INFO:Creating metrics dataframe
2022-12-01 03:27:24,149:INFO:Initializing Light Gradient Boosting Machine
2022-12-01 03:27:24,152:INFO:Total runtime is 0.3244747837384542 minutes
2022-12-01 03:27:24,162:INFO:SubProcess create_model() called ==================================
2022-12-01 03:27:24,163:INFO:Initializing create_model()
2022-12-01 03:27:24,167:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961f5fe80>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495dfddee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:27:24,168:INFO:Checking exceptions
2022-12-01 03:27:24,170:INFO:Importing libraries
2022-12-01 03:27:24,170:INFO:Copying training dataset
2022-12-01 03:27:24,174:INFO:Defining folds
2022-12-01 03:27:24,174:INFO:Declaring metric variables
2022-12-01 03:27:24,188:INFO:Importing untrained model
2022-12-01 03:27:24,196:INFO:Light Gradient Boosting Machine Imported successfully
2022-12-01 03:27:24,209:INFO:Starting cross validation
2022-12-01 03:27:24,210:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:27:25,435:INFO:Calculating mean and std
2022-12-01 03:27:25,439:INFO:Creating metrics dataframe
2022-12-01 03:27:25,450:INFO:Uploading results into container
2022-12-01 03:27:25,453:INFO:Uploading model into container now
2022-12-01 03:27:25,454:INFO:master_model_container: 17
2022-12-01 03:27:25,454:INFO:display_container: 2
2022-12-01 03:27:25,455:INFO:LGBMRegressor(random_state=123)
2022-12-01 03:27:25,455:INFO:create_model() successfully completed......................................
2022-12-01 03:27:25,595:INFO:SubProcess create_model() end ==================================
2022-12-01 03:27:25,596:INFO:Creating metrics dataframe
2022-12-01 03:27:25,624:INFO:Initializing Dummy Regressor
2022-12-01 03:27:25,625:INFO:Total runtime is 0.34901051918665565 minutes
2022-12-01 03:27:25,633:INFO:SubProcess create_model() called ==================================
2022-12-01 03:27:25,634:INFO:Initializing create_model()
2022-12-01 03:27:25,634:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961f5fe80>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f495dfddee0>, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:27:25,634:INFO:Checking exceptions
2022-12-01 03:27:25,637:INFO:Importing libraries
2022-12-01 03:27:25,637:INFO:Copying training dataset
2022-12-01 03:27:25,645:INFO:Defining folds
2022-12-01 03:27:25,646:INFO:Declaring metric variables
2022-12-01 03:27:25,653:INFO:Importing untrained model
2022-12-01 03:27:25,662:INFO:Dummy Regressor Imported successfully
2022-12-01 03:27:25,677:INFO:Starting cross validation
2022-12-01 03:27:25,683:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2022-12-01 03:27:25,935:INFO:Calculating mean and std
2022-12-01 03:27:25,939:INFO:Creating metrics dataframe
2022-12-01 03:27:25,947:INFO:Uploading results into container
2022-12-01 03:27:25,948:INFO:Uploading model into container now
2022-12-01 03:27:25,949:INFO:master_model_container: 18
2022-12-01 03:27:25,949:INFO:display_container: 2
2022-12-01 03:27:25,950:INFO:DummyRegressor()
2022-12-01 03:27:25,950:INFO:create_model() successfully completed......................................
2022-12-01 03:27:26,093:INFO:SubProcess create_model() end ==================================
2022-12-01 03:27:26,093:INFO:Creating metrics dataframe
2022-12-01 03:27:26,148:INFO:Initializing create_model()
2022-12-01 03:27:26,150:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f4961f5fe80>, estimator=LassoLars(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2022-12-01 03:27:26,150:INFO:Checking exceptions
2022-12-01 03:27:26,155:INFO:Importing libraries
2022-12-01 03:27:26,155:INFO:Copying training dataset
2022-12-01 03:27:26,157:INFO:Defining folds
2022-12-01 03:27:26,157:INFO:Declaring metric variables
2022-12-01 03:27:26,158:INFO:Importing untrained model
2022-12-01 03:27:26,158:INFO:Declaring custom model
2022-12-01 03:27:26,160:INFO:Least Angle Regression Imported successfully
2022-12-01 03:27:26,161:INFO:Cross validation set to False
2022-12-01 03:27:26,162:INFO:Fitting Model
2022-12-01 03:27:26,174:WARNING:/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2022-12-01 03:27:26,175:INFO:LassoLars(random_state=123)
2022-12-01 03:27:26,176:INFO:create_model() successfully completed......................................
2022-12-01 03:27:26,420:INFO:master_model_container: 18
2022-12-01 03:27:26,421:INFO:display_container: 2
2022-12-01 03:27:26,421:INFO:LassoLars(random_state=123)
2022-12-01 03:27:26,422:INFO:compare_models() successfully completed......................................
